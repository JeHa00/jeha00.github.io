[{"categories":"Spring","content":"0. Introduction 의존관계를 주입하는 여러 방법들에 대해 알아본다. 의존관계를 주입하는 4가지 방을 다루는 첫 단원은 코드 설계의 관점이라 바로 이해가 되었지만, 나머지들은 도구 사용법이라서 실제 프로젝트를 만들어갈 때 참고하려고 정리해준다.\n1. 의존관계를 주입하는 방법 4가지 의존관계를 주입하는 방법은 크게 4가지 방법이 있다.\n생성자를 통한 주입 방법 수정자 주입(setter 주입) 필드 주입 일반 메서드 주입 1.1 생성자를 통한 주입 방법 생성자를 통해서 의존관계를 주입받기 때문에, 호출 시점 단 한번만 호출되는 것이 보장된다. 그래서 불변, 필수 의존관계 에 사용된다. 이전 Spring 학습 글에서 예시로 보여준 것이 이 주입 방법이다.\n스프링 빈은 생성 단계와 의존관계를 주입하는 두 단계로 나눌 수 있는데, 생성자 주입은 bean 등록을 위해 생성자를 호출하므로 생성 단계와 주입 단계를 같이 한다.\n1 2 3 4 5 6 7 8 9 10 @Component public class OrderServiceImpl implements OrderService { private final MemberRepository memberRepository; private final DiscountPolicy discountPolicy; public OrderServiceImpl(MemberRepository memberRepository, DiscountPolicy discountPolicy) { this.memberRepository = memberRepository; this.discountPolicy = discountPolicy; } } 1.2 수정자 주입(setter 주입) 필드의 값을 변경하는 수정자 메서드인 setter를 통해 의존관계를 주입하는 방법이다. 단 한 번만 사용할 수 있는 생성자와 달리 계속 사용할 수 있기 때문에 선택, 변경 가능성이 있는 의존관계에 사용된다. 변경 가능하기 때문에 필드를 final로 선언하면 안된다.\n1 2 3 4 5 6 7 8 9 10 11 @Component public class OrderServiceImpl implements OrderService { private MemberRepository memberRepository; private DiscountPolicy discountPolicy; @Autowired public void setMemberRepository(MemberRepository memberRepository) { this.memberRepository = memberRepository; } } 자바빈 프로퍼티에서는 필드값을 조회하고 수정하는 메서드의 명칭을 getXxx, setXxx 라는 형식으로 작명해서 사용하기로 정했는데 이를 \u0026lsquo;자바빈 프로퍼티 규약\u0026rsquo; 이라 한다.\n1.3 필드 주입 필드에 바로 주입하는 방법이다. 코드가 간결하지만 외부에서 변경이 불가능하기 때문에 테스트하기 힘들다는 큰 단점이 있다. 그래서 DI 프레임워크가 없으면 아무것도 할 수 없다. 차라리 생성자 주입을 사용하도록 하자.\n1 2 3 4 5 6 7 @Component public class OrderServiceImpl implements OrderService { @Autowired private MemberRepository memberRepository; @Autowired private DiscountPolicy discountPolicy; } 1.4 일반 메서드를 통한 주입 일반 메서드를 통해서도 주입받을 수 있으나, 일반적으로 잘 사용하지 않는다고 한다. 생성자 주입과 수정자 주입을 통해 주로 다 하므로 이 방식은 사용하지 않는다.\n스프링 컨테이너가 관리하는 스프링 빈이어야 동작한다. 스프링 빈이 아닌 일반 자바 클래스에 @Autowired를 적용하면 동작하지 않는다.\n1.5 결론 과거에는 수정자 주입과 필드 주입을 많이 사용했지만, 최근에는 스프링을 포함한 DI 프레임워크 대부분이 생성자 주입을 권장한다. 그 이유는 위에서 언급한 내용을 정리하면 다음과 같다.\n대부분의 의존관계 주입은 한번 일어나면 애플리케이션 종료시점까지 변경하지 않는다. 변경되어서도 안된다. 그런데, 수정자 주입을 사용하면 수정 메서드를 public으로 열어야 한다. 이러면 누군가 실수로 변경할 수 있으므로 좋은 설계 방법이 아니다. 생성자이기 때문에 final 키워드를 사용할 수 있어서 확실하게 불변으로 설계할 수 있다. 생성자 주입은 객체 생성 시 딱 한 번만 호출되므로 불변으로 설계할 수 있다. 생성자 주입은 프레임워크에 의존하지 않고, 순수한 자바 언어의 특징을 잘 살리는 방법이기도 하다. 기본으로 생성자 주입을 사용하고, 필수 값이 아닌 경우에는 옵션이 필요하면 수정자 주입 방식을 사용하면 된다. 필드 주입은 사용하지 말자. 2. 롬복(Lombok)을 사용해 생성자 코드 만들기 스프링에서는 롬복이라는 라이브러리를 사용해 생성자, 조회자, 수정자를 자동으로 생성할 수 있어서 스프링과 자주 사용한다.\n롬복 라이브러리를 사용해 생성자 코드를 자동으로 만드는 것을 알아보자. 롬복 라이브러리는 Dependencies에서 Lombok을 추가하면 된다. build.gradle에는 다음과 같이 추가한다.\nconfigurations { compileOnly { extendsFrom annotationProcessor } } 그후, Preferences -\u0026gt; plugin -\u0026gt; lombok 검색해서 설치를 진행 -\u0026gt; 재시작 순서로 진행한다.\n그러면 롬복이 어떤 역할을 하는지 코드 관점에서 확인해보자. 현재 아래 코드를 가지고 있다고 하자.\n1 2 3 4 5 6 7 8 9 10 11 @Componet public class OrderServiceImpl implements OrderService { private final MemberRepository memberRepository; private final DiscountPolicy discountPolicy; @Autowired public OrderServiceImpl(MemberRepository memberRepository, DiscountPolicy discountPolicy) { this.memberRepository = memberRepository; this.discountPolicy = discountPolicy; } } 생성자가 1개이므로 @Autowired 를 생략할 수 있다. 그리고, 롬복 라이브러리가 제공하는 @RequiredArgsConstructor 를 사용하면 final이 붙은 필드를 모아 생성자를 자동으로 만들어주어 아래와 같이 작성만 하면 된다. 매우 간결해졌다. (import lombok.RequiredArgsConstructor 를 입력해야 한다.)\n1 2 3 4 5 6 @Componet public class OrderServiceImpl implements OrderService { private final MemberRepository memberRepository; private final DiscountPolicy discountPolicy; } 롬복을 스프링에서 사용하려면 다음 단계를 거쳐야 한다.\nPreferences(window는 settings) -\u0026gt; Plugin -\u0026gt; lombok 검색 설치 진행(재시작) Preferences -\u0026gt; Annotation Processors 검색 -\u0026gt; Enable annotation processing 체크(재시작) import lombok.Getter, import lombok.Setter 를 작성하면 getter, setter를 만들지 않아도 자동으로 넣어준다. 3. 조회 빈이 2개 이상인 경우 @Autowired는 기본적으로 타입(Type)으로 조회하므로 ApplicationContext의 getBean 메서드와 동일하다. 예를 들어 코드가 다음과 같다고 하자.\n1 2 @Autowired private DiscountPolicy discountPolicy 이면 ac.getBean(discountPolicy.class) 와 유사하게 동작한다. 빈 조회 시 선택된 빈이 2개 이상이면 문제가 발생한다. 예를 들어 위 타입을 구현한 두 객체가 있을 경우, NoUniqueBeanDefinitionException 가 발생한다. 하위 타입으로 지정하면 DIP를 할 수 없다. 이런 경우 어떻게 해야할까?\n총 3가지 방법이 있다.\n@Autowired 필드명 매칭: 동일한 타입을 가져왔는데 빈이 여러 개라면 필드명이 매칭되는 것 하나를 가져온다.\n첫 번째, 타입을 매칭한다. 두 번째, 타입 매칭 결과가 2개 이상이면 필드명, 파라미터 명으로 빈 이름을 매칭한다. @Qualifier -\u0026gt; @Qualifiter끼리 매칭 -\u0026gt; 빈 이름 매칭\n@Qulifier는 추가 구분자를 붙여주는 방법으로, 빈 이름을 변경하는 것은 아니다. 1 2 3 4 // Case 1 @Component @Qualifier(\u0026#34;mainPolicy\u0026#34;) public class RateDiscountPolicy implements DiscountPolicy {} 1 2 3 4 // Case 2: 매개변수에 사용할 경우 @Autowired public OrderServiceImpl(@Qulifiter(\u0026#34;mainDiscountPolicy\u0026#34;) DiscountPolicy discountPolicy) ... @Qualifier는 @Qualifier를 찾는 용도로만 사용해야 한다. @Primary 사용: 여러 빈이 매칭되면 @Primary를 가지고 있는 빈이 우선권을 가지도록 하는 방법이다.\n1 2 3 4 5 6 @Component @Primary public class RateDiscountPolicy implements DiscountPolicy {} @Component public class FixDiscountPolicy implements DiscountPolicy {} @Qulifier와 @Primary가 부딪힐 때 우선순위는 전자가 더 높다. 스프링은 자동보다 수동이, 넓은 범위 선택보다 좁은 범위의 선택권이 우선 순위가 높다.\n또한 @Qulifier의 경우, 주입받을 때 반드시 @Qulifier를 매개변수든지 다 붙여야 하지만 @Primary는 그럴 필요가 없다. 그래서 다음과 같이 사용할 수 있다. 메인 데이터베이스의 커넥션을 획득하는 스프링 빈은 @Primary를 적용하고, 서브 데이터베이스가 존재할 경우 서브 데이터베이스의 커넥션 빈응ㄹ 획득할 때 @Qualifier를 명시적으로 획득하는 방식을 사용하면 코드를 깔끔하게 유지할 수 있다.\n","permalink":"http://jeha00.github.io/post/spring/study_3/","summary":"의존관계를 주입하는 여러 방법들에 대해 알아본다.","title":"의존관계를 주입하는 여러 방법들"},{"categories":"Spring","content":"🔆 스프링 빈을 등록하는 또 다른 방법: @ComponentScan 설정 정보에 @Configuration과 @ComponentScan 애노테이션을 추가한다. 그러면 @Component 애노테이션이 붙은 클래스를 스캔해서 스프링 빈으로 등록한다. 아래 코드로 보자면 AutoAppConfig라는 스프링 컨테이너가 생성되고, 이 컨테이너에 @Component 애노테이션이 붙은 클래스가 스프링 빈으로 등록된다.\n1 2 3 4 5 6 7 8 9 10 package SpringBasic.core; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; @Configuration @ComponentScan public class AutoAppConfig { } @Component 애노테이션이 붙은 예시\n1 2 3 4 5 6 7 8 @Component public class MemoryMemberRepository implements MemberRepository {} ... @Component public class RateDiscountPolicy implements DiscountPolicy{} 위 사태로만 등록하면 AutoAppConfig는 AppConfig과 달리 의존관계가 명확히 드러나지 않기 때문에 의존관계를 파악할 수 없다. 그래서, 빈으로 등록되는 클래스 안에서 의존 관계 주입도 해결해야 한다. @Autowired 애노테이션을 등록하려는 빈의 생성자에 추가한다.\n1 2 3 4 5 6 7 8 9 @Component public class MemberServiceImpl implements MemberService { private final MemberRepository memberRepository; @Autowired public MemberServiceImpl(MemberRepository memberRepository) { this.memberRepository = memberRepository; } } 또한, @Autowired를 사용하면 다음과 같이 여러 의존관계도 한 번에 주입받을 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 @Component public class OrderServiceImpl implements OrderService { private final MemberRepository memberRepository; private final DiscountPolicy discountPolicy; @Autowired public OrderServiceImpl(MemberRepository memberRepository, DiscountPolicy discountPolicy) { this.memberRepository = memberRepository; this.discountPolicy = discountPolicy; } } @ComponentScan으로 스프링 빈 등록하는 단계 @ComponentScan은 @Component 애노테이션이 붙은 모든 클래스를 스프링 빈으로 등록한다. 등록하는 과정을 알아보자.\n@Component 애노테이션이 붙은 클래스를 스프링 빈으로 생성한다. 만약 생성자에 @Autowired 애노테이션이 있으면 생성자를 통해 의존 관계를 설정한다. 단, 생성자가 딱 1개만 있으면 @Autowired를 생략해도 자동 주입된다. 스프링 빈에만 해당된다. 의존관계가 있을 경우 스프링 컨테이너에서 타입을 기준으로 찾는다. 동일한 타입이 있으면 해당되는 스프링 빈을 주입하면서 스프링 빈으로 등록한다. 아무리 의존관계가 많아도 스프링 빈 레지스트리에서 다 찾아 자동으로 주입한다. 등록 시 스프링 빈의 이름은 기본적으로 클래스의 맨 첫 글자가 소문자로 바뀌어 등록된다. 예를 들어서 MemberServiceImpl 클래스라면 memberServiceImpl로 등록된다. 만약 이름을 직접 등록하고 싶다면 @Component('memberService') 이름을 부여한다.\n컴포넌트 스캔의 기본 스캔 대상 컴포넌트 스캔이 스캔하는 대상은 다음과 같다.\n@Component @Controller @Service @Repository @Configuration 그런데 @Controller, @Service, @Repository, @Configuration의 소스 코드를 보면 @Component를 포함고 있는 것을 알 수 있다. (애노테이션은 상속되지 않는다. 자바 언어가 지원하는 게 아닌 스프링이 지원하는 기능이다.)\n각 애노테이션마다 스프링이 바라보는 인식이 다르다.\n@Controller: 스프링 MVC의 컨트롤러로 처리 @Repository: 스프링 데이터 접근 계층으로 인식하고, 데이터 계층의 예외를 스프링 예외로 변환한다. @Configuration: 스프링 설정 정보로 인식하고, 스프링 빈이 싱글톤을 유지하도록 추가 처리한다. @Service: 이 애노테이션은 스프링에게 특별히 전달하는 처리는 없지만, 개발자들에게 핵심 비지니스 로직이 여기 있겠구나라고 비지니스 계층 인식에 도움이 된다. 중복 등록과 충돌 스프링 빈을 자동, 수동 모두 등록이 가능하다는 것을 배웠다. 여기서 한 번 생각해볼 부분이 있다. 등록하는 과정에서 충돌이 발생하지 않을까? 과연 한 번에 등록이 잘 될까? 완벽하게 한 번에 되는 것은 불가능하다고 생각된다. 스프링에서는 이 부분을 어떻게 대처했을까?\n자동 vs 자동 이름이 같은 경우 오류(ConflictingBeanDefinitioonException)를 발생시킨다. 두 스프링 빈 객체에 @Component(\u0026lsquo;service\u0026rsquo;)로 등록한 후 테스트를 실행하면 아래 내용을 확인할 수 있다.\n1 org.springframework.beans.factory.BeanDefinitionStoreException: Failed to parse configuration class [SpringBasic.core.AutoAppConfig] 수동 vs 자동 수동 빈 등록과 자동 빈 등록이 충돌될 경우, 수동 빈 등록이 우선권을 가져서 수동 빈이 자동 빈을 오버라이딩한다. @ComponentScan이 있는 설정 정보에 @Bean(name={다른 빈과 동일한 이름}) 으로 추가해보자. 실행하면 다음과 같이 오버라이딩했다는 로그를 확인할 수 있다. 1 Overriding bean definition for bean \u0026#39;memoryMemberRepository\u0026#39; with a different definition: replacing 이러한 설정 정보 충돌은 의도적이기보다는 여러 설정이 꼬여져 만들어지는 경우가 대부분이다. 그래서 스프링 부트에서는 수동과 자동 빈 등록이 충돌되면 오류가 발생하는 것을 기본값으로 두었다.\n무엇을 기준으로 자동, 수동 중 무엇을 사용할까? 기본적으로 자동을 사용하자.\n그러면 언제 수동 빈 등록을 사용할까?\n애플리케이션은 크게 업무와 기술 지원 로직으로 나눌 수 있다고 한다.\n업무 로직에 사용되는 빈은 비지니스 요구사항을 개발할 때 추가또는 변경된다. 기술 지원에 사용되는 빈은 데이터베이스 연결, 공통 로그 처리처럼 업무 로직 지원을 위한 하부 기술이나 공통기술이다.\n업무 로직은 양이 많고, 패턴이 존재하기 때문에 자동 기능을 적극 사용하자. 하지만 애플리케이션에 광범위하게 영향을 미치는 기술 지원 객체는 수동 빈으로 등록해서 딱! 설정 정보에 바로 나타나게 하는 것이 유지보수에 좋다.\n스프링과 스프링 부트에 자동으로 등록된 수 많은 빈은 건들이지 말자.\n필터 @Component만으로 충분하기 때문에 이 필터를 사용할 일은 거의 없다. 최대한 스프링의 기본 설정에 맞추어 사용하는 것을 권장한다.\n이런 내용도 있다는 것만 알아두자.\n다음과 같이 필터를 통해 컴포넌트 스캔에 추가하거나, 제외할 대상을 지정할 수 있다.\n1 2 3 4 @ComponentScan( includeFilters = @Filter(type = FilterType.ANNOTATION, classes =추가할 컴포넌트.class), excludeFilters = @Filter(type = FilterType.ANNOTATION, classes =배제할 컴포넌트.class) ) 필터 타입에는 5가지 옵션이 있다.\nANNOTATION: 기본값, 애노테이션을 인식해서 동작한다. ASSIGNABLE_TYPE: 지정한 타입과 자식 타입을 인식해서 동작한다. ASPECTJ: AspectJ 패턴 사용 REGEX: 정규 표현식으로 지정한다는 의미다. CUSTOM: TypeFilter 이라는 인터페이스를 구현해서 처리한다. 탐색 위치와 기본 스캔 대상 컴포넌트 스캔의 기본 스캔 경로는 @ComponentScan이 붙은 설정 정보 클래스의 패키지가 시작 위치가 되어 하위 컴포넌트를 모두 스캔한다. 이 방식의 단점은 모든 자바 클래스를 컴포넌트 스캔하면 라이브러리도 포함되기 때문에 시간이 오래 걸리기 때문에 다음과 같이 시작 위치를 지정할 수 있다.\n1 2 3 4 @ComponentScan( basePackages = \u0026#34;SpringBasic.core\u0026#34; basePackageClasses = AutoAppConfig.class ) 하지만, 주로 사용하는 방법은 패키지 위치를 지정하지 않고, 설정 정보 클래스의 위치를 프로젝트 최상단에 두는 것이다. 최근 스프링 부트도 이 방식을 기본으로 제공한다. 최상단에 두는 이유는 하위에 있는 모든 것이 자동으로 컴포넌트 스캔의 대상이 되기 때문이다. 그리고, 메인 설정 정보는 프로젝트를 대표하는 정보이기 때문에 프로젝트 시작 루트에 두는 것이 좋다.\nReference 스프링 MVC 1편 - 백엔드 웹 개발 핵심 기술 ","permalink":"http://jeha00.github.io/post/spring/study_2/","summary":"수동으로 스프링 빈을 등록하는 것 다음으로 @ComponentScan을 통한 스프링 빈 자동 등록하는 방법을 알아본다.","title":"스프링 빈 자동 등록 방법: 컴포넌트 스캔"},{"categories":"Spring","content":"1. 스프링 컨테이너와 스프링 빈 1.1 스프링 컨테이너와 스프링 빈이란? 스프링 컨테이너(Spring Container)란 IoC(제어의 역전, Inversion Of Control)와 DI (의존관계 주입, Dependency Injection)를 구현하기 위해 설계된 역할로, 개발자 대신 스프링 프레임워크가(IoC) 의존 관계 객체를 스프링 빈(Spring Bean) 객체로 생성하고 주입(DI)하고, 관리까지 전체적으로 담당해 객체 지향 프로그래밍을 위해 만들어진 도구다. 개발자가 직접하면 생성과 실행이 합쳐서 OCP, SRP가 깨지기 때문이다.\n위 개념에서 언급한 스프링 빈(Spring Bean)은 스프링 컨테이너에 저장된 객체를 의미한다. 스프링이 판단해서 스프링 빈으로 적절한 의존 관계가 주입된다.\n이 스프링 컨테이너 역할은 코드 상으로 BeanFactory 인터페이스를 통해 구현한다. 하지만 보통 BeanFactory 인터페이스를 상속받는 ApplicationContext 객체를 스프링 컨테이너라 부른다.\n스프링 빈(Spring Bean)은 @Configuration 애노케이션이 붙은 객체의 메서드 중 @Bean 애노테이션이 붙은 메서드의 호출 결과로 생성된 객체를 의미한다.\nApplicationContext (스프링 컨테이너) @Configuration @Bean 필요한 객체가 있으면 스프링 컨테이너가 스프링 빈으로 등록된 객체들에서 찾아 의존성 주입을 한다.\n1.2 스프링 빈 생성 및 등록 과정 스프링 컨테이너가 빈을 생성 및 등록하는 과정은 다음과 같다.\n첫 번째, 스프링 컨테이너 인터페이스에 @Configuration 애노케이션이 붙은 객체의 Class 정보를 전달해, 해당 구성 정보를 가지고 있는 스프링 컨테이너를 생성한다.\n스프링 컨테이너에는 Map 타입으로 \u0026lsquo;빈 이름\u0026rsquo;과 \u0026lsquo;빈 객체\u0026rsquo;를 사상하여 저장한다. 설정 정보 객체 1 2 3 4 @Configuration public class AppConfig { ... } 스프링 컨테이너 생성 1 ApplicationContext applicationContext = new AnnotationConfigApplicationContext(AppConfig.class); 두 번째, 이 설정 정보 객체(ex: AppConfig)에 @Bean 데코레이션이 존재하는 메서드를 실행해 메서드의 이름을 \u0026lsquo;Bean 이름\u0026rsquo;으로 하고, 메서드의 반환값으로 생신 객체를 \u0026lsquo;Bean\u0026rsquo;으로 저장한다. 이 때 빈 이름은 중복되면 안된다.\n세 번째, 그후, 설정 정보를 참고해 의존관계를 주입(DI)한다.\n1.3 스프링 컨테이너의 코드 구조 코드에서 ApplicationContext 타입을 클릭해서 들어가면 다음 내용을 확인할 수 있다.\n스프링 컨테이너라 불리는 두 객체(BeanFactory와 ApplicationContext)는 인터페이스(interface)이고, ApplicationContext는 BeanFactory를 상속받는다. 그래서 BeanFactory는 스프링 컨테이너의 최상위 인터페이스다.\nBeanFactory는 Bean을 조회할 때 사용하는 getBean() 메서드를 제공하는 역할을 수행한다. ApplicationContext는 이 BeanFactory를 상속받기 때문에 이 메서드를 사용할 수 있으면서 다양한 인터페이스를 상속받는다.\nApplicationContext의 소스 코드를 보면 BeanFactory 인터페이스를 바로 찾을 수 없다.\nBeanFactory 인터페이스는 이 인터페이스를 상속받는 다른 인터페이스를 통해 제공된다. 바로 ListableBeanFactory, HierarchicalBeanFactory 이 두 인터페이스다.\nListableBeanFactory는 빈을 조회하는데 사용되는 다양한 메서드를 제공한다. HierarchicalBeanFactory는 특정 빈이 존재하는지 확인하는데 사용된다. 그 밖에 다양한 인터페이스를 상속받는다.\nMessageSource: 국제화 기능(한국에서는 한국어로, 영어권에서는 영어로) EnvironmentCapable: 로컬, 개발, 운영 등 구분 ApplicationEventPublisher: 이벤트 발행 및 구독 ResourceLoader: 외부 리소스 조회 그리고 스프링의 설정 정보는 java외에도 Xml 형식으로도 가능하고, 그 외 다양한 형식으로 전달할 수 있다. @Configuration 처럼 어노테이션 방식으로 전달할 때는 AnnotationConfigApplicationContext를 통해서 전달받는다. 그러면 AnnotatedBeanDefinitionReader에 의해 설정 정보를 읽고, 빈의 메타 정보인 BeanDefinition을 생성한다.\nAnnotationConfigApplicationContext 객체의 소스 코드다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 소스 코드 public class AnnotationConfigApplicationContext extends GenericApplicationContext implements AnnotationConfigRegistry { private final AnnotatedBeanDefinitionReader reader; private final ClassPathBeanDefinitionScanner scanner; ... public AnnotationConfigApplicationContext(Class\u0026lt;?\u0026gt;... componentClasses) { this(); this.register(componentClasses); this.refresh(); } public void register(Class\u0026lt;?\u0026gt;... componentClasses) { ... this.reader.register(componentClasses); } } 밑에는 AnnotatedBeanDefinitionReader의 소스 코드다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 소스 코드 public class AnnotatedBeanDefinitionReader { private final BeanDefinitionRegistry registry; // Bean 메타 정보 저장소 ... public void register(Class\u0026lt;?\u0026gt;... componentClasses) { Class[] var2 = componentClasses; int var3 = componentClasses.length; for(int var4 = 0; var4 \u0026lt; var3; ++var4) { Class\u0026lt;?\u0026gt; componentClass = var2[var4]; this.registerBean(componentClass); } } public void registerBean(Class\u0026lt;?\u0026gt; beanClass) { this.doRegisterBean(beanClass, ...) } } 1.4 BeanDefinition 스프링 컨테이너의 설정 정보는 자바 클래스 외에 xml을 사용해서도 생성할 수 있다. 다양한 방법으로 설정 정보를 가질 수 있는 이유는 여기서도 객체 지향의 원리는 역할과 구현을 구분했기 때문이다.\n스프링 컨테이너에 스프링 빈 같은 설정 정보는 BeanDefinition이라는 인터페이스에 의존한다.\n빈 설정에 대한 메타 정보이다. 경로는 package org.springframework.beans.factory.config에 존재한다. @Bean마다 메타 정보가 하나씩 생성된다. 이 정보를 기반으로 스프링 컨테이너에 스프링 빈이 생성 및 등록된다. AnnotationConfigApplicationContext 는 AnnotatedBeanDefinitionReader 를 사용해서 AppConfig.class 를 읽고 BeanDefinition 을 생성한다.\nBeanDefinition에 대해서는 너무 깊이있게 이해하기 보다는, 스프링이 다양한 형태의 설정 정보를 BeanDefinition으로 추상화해서 사용하는 것 정도만 이해하면 된다.\n1.5 스프링 빈 조회하기 등록된 빈도 조회할 수 있다.\ncase 1: Bean 객체로 조회할 수 있다. (getBean(빈 객체 클래스 정보)) getBean(MemberService.class) case 2: 만약 해당 Bean 객체로 된 것이 두 개 이상이면 Bean 객체와 Bean 이름을 함께 사용해 Bean을 조회하면 된다. (getBean(빈 이름, 빈 객체 클래스 정보)) case 3: 조회하는 빈 객체에 여러 자식들이 존재하면 자식들까지 가져온다.(getBeansOfType(특정 타입의 빈 클래스 정보)) case 4: 만약 특정 자식을 조회하고 싶으면 빈 이름을 사용하면 된다. (case2) 2. 싱글톤 레지스트리 2.1 싱글톤 패턴이란? 해당 객체를 서버에서 1개만 생성해 공유해서 사용하도록 설계하는 패턴\n스프링 컨테이너는 싱글톤 방식을 사용한다. 그러면 왜 싱글톤 방식을 사용하는지 이해하기 위해, 이 방식을 사용하지 않을 경우 발생되는 문제점에 대해 알아보자.\n만약 스프링 빈을 사용하는 것 없이 AppConfig의 설정 객체를 가져오려면 AppConfig의 인스턴스를 통해서 메서드를 실행하면 된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 void pureContainer() { AppConfig appConfig = new AppConfig(); //1. 조회: 호출할 때 마다 객체를 생성 MemberService memberService1 = appConfig.memberService(); //2. 조회: 호출할 때 마다 객체를 생성 MemberService memberService2 = appConfig.memberService(); //참조값이 다른 것을 확인 System.out.println(\u0026#34;memberService1 = \u0026#34; + memberService1); System.out.println(\u0026#34;memberService2 = \u0026#34; + memberService2); //memberService1 != memberService2 assertThat(memberService1).isNotSameAs(memberService2); } 각 메서드의 실행 결과 다음 객체를 새로 생성해서 반환한다.\nMemberService OrderService MemberRepository DiscountPolicy 만약 웹 애플리케이션이라면 request 요청이 들어올 때마다 이 서비스 객체를 호출한다면 매번 새로운 객체가 생성된다. 그러면 한 번 사용하고 사용되지 않으면 해당 서비스 객체는 GC에 의해 반복적으로 삭제된다. 이 방식은 \u0026lsquo;메모리 낭비가 심하다\u0026rsquo;는 단점이 존재한다.\n그래서 이에 대한 해결책이 해당 객체를 서버에서 1개만 생성해 공유해서 사용하도록 설계한다. 이러한 패턴을 \u0026lsquo;싱글톤(singleton) 패턴\u0026rsquo;이라 한다. 이러한 싱글톤 패턴의 특징 때문에 객체 인스턴스를 2개 이상 생성하지 못하도록 막아야 하므로 생성자의 접근 제어자를 반드시 private로 지정해야 한다.\n만약 싱글톤으로 사용되어야 하는 객체가 있다면 다음과 같이 코드를 구성하면 된다.\n클래스 변수로 단 하나의 인스턴스만 사용되고, 외부에서 접근하지 못하도록 private static final을 지정한다. 해당 객체를 사용하고 싶으면 특정 메서드를 통해서만 접근하도록 한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class SingletonService { //1. static 영역에 객체를 딱 1개만 생성해둔다. private static final SingletonService instance = new SingletonService(); //2. public으로 열어서 객체 인스턴스가 필요하면 이 static 메서드를 통해서만 조회하도록 허용한다. public static SingletonService getInstance() { return instance; } // 3. 생성자를 private으로 선언해서 외부에서 new 키워드를 사용한 객체 생성을 못하게 막는다. private SingletonService() { } public void logic() { System.out.println(\u0026#34;싱글톤 객체 로직 호출\u0026#34;); } } 2.2 스프링 컨테이너가 싱글톤인지 확인하기 앞서 스프링 컨테이너가 싱글톤 방식을 사용한다고 했는데, 직접 확인해보자. 스프링에서 사용하는 객체 호출 방식을 사용해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Test @DisplayName(\u0026#34;스프링 컨테이너와 싱글톤\u0026#34;) void springContainer() { ApplicationContext ac = new AnnotationConfigApplicationContext(AppConfig.class); //1. 조회: 호출할 때 마다 같은 객체를 반환 MemberService memberService1 = ac.getBean(\u0026#34;memberService\u0026#34;, MemberService.class); //2. 조회: 호출할 때 마다 같은 객체를 반환 MemberService memberService2 = ac.getBean(\u0026#34;memberService\u0026#34;, MemberService.class); //참조값이 같은 것을 확인 System.out.println(\u0026#34;memberService1 = \u0026#34; + memberService1); System.out.println(\u0026#34;memberService2 = \u0026#34; + memberService2); //memberService1 == memberService2 assertThat(memberService1).isSameAs(memberService2); } 출력 결과\n1 2 3 memberService1 = SpringBasic.core.member.MemberServiceImpl@5c2375a9 memberService2 = SpringBasic.core.member.MemberServiceImpl@5c2375a9 스프링 컨테이너는 객체를 하나만 생성해서 계속해서 사용하는 것을 확인할 수 있다.\n2.3 싱글톤 사용 시 단점과 해결책 싱글톤 레지스트리(singleton registry) 디자인 패턴을 적용해 해결한다.\n그러면 위 코드를 봤을 때 싱글톤의 단점을 정리해보자.\n이 패턴을 구현하기 위해 코드 품이 많이 든다. 위 클래스 변수처럼 인터페이스가 아닌 구현체에 의존하므로 DIP와 OCP를 위반한다. private 생성자로 자식 클래스를 만들기 어렵다. 싱글톤은 테스트용 객체를 생성할 수 없기 때문에 테스트가 어렵다. 무엇보다 하나의 객체를 여러 객체에서 사용하기 때문에 상태 유지(stateful)로 설계할 경우, 의도치 않은 값을 얻을 수 있다. 스프링에서는 이 단점을 어떻게 해결하는지 알아보자. 스프링에서는 앞서 스프링 빈으로 확인했을 때 다음 사항을 확인할 수 있다.\n싱글톤으로 코드를 입력하지 않아도, DIP와 OCP 위반 없이, private 생성자로부터 자유롭게, 테스트 코드로도, 싱글톤이 사용되는 것을 확인할 수 있다.\n어떻게 이게 가능한 것일까?\n스프링 컨테이너가 \u0026lsquo;싱글톤 레지스트리(singleton registry) 패턴\u0026rsquo; 방식이기 때문에 가능하다. 싱글톤과 레지스트리는 디자인 패턴의 각각 한 종류다. 싱글톤은 앞서 언급했으니 넘어가면 레지스트리는 객체를 전역적으로 관리하고 제공하는 디자인 패턴을 의미한다. 중앙 저장소(레지스트리)를 통해 객체를 관리하고 필요할 때 조회해 사용하는 방식이라는 의미다. 그래서 싱글톤과 레지스트리 두 가지 패턴을 합쳐서 만든 것이 스프링 컨테이너이다.\n즉, 스프링 빈을 싱글톤으로 관리하는 저장소라는 의미다. 스프링 컨테이너인 ApplicationContext은 Bean이 이미 존재하면 기존에 있던 것을 사용하고, 없으면 새로 생성해서 등록하는 방식을 사용하기 때문에 각 Bean을 싱글톤으로 유지하면서, 싱글톤으로 발생되는 위 4가지 문제점을 해결할 수 있다.\n2.4 아직 해결되지 않은 문제: stateful 필드를 없애는 방향으로 진행하자.\n아직 stateful 문제는 해결되지 않았다. 하나의 객체 인스턴스를 공유하기 때문에 싱글톤 객체는 상태를 유지하게 설계하면 안된다. 무상태로 설계 해야 한다. 이 말은 다음 내용을 의미한다.\n특정 클라이언트에 의존적인 필드가 있으면 안된다. 특정 클라이언트가 값을 변경할 수 있는 필드가 있으면 안된다. 가급적 읽기만 가능해야 한다. 필드 대신 자바에서 공유되지 않는 지역 변수, 파라미터, ThreadLocal 등을 사용해야 한다. 싱글톤으로 공유하는 객체에 수량을 의미하는 amount 필드가 있다고 할 때, A 클라이언트가 이 amount에 10을 저장한다. 그 다음, B 클라이언트가 바로 13을 저장한다. 그후, A 클라이언트가 amount 값을 조회할 때 10이 나와야 하지만, 13이 나오는 문제점이 생긴다.\n그래서 필드를 없애는 방향으로 진행해야 한다.\n2.5 @Configuration에서 싱글톤이 유지되는 이유 바이트코드 조작 라이브러리 때문에 유지가 된다.\n싱글톤 개념에 대해서 알았으니 다시 AppConfig를 확인해보자. 각 메서드가 몇 번 호출되었는지 확인하기 위해 출력 함수로 로그를 추가한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // AppConfig.java @Configuration public class AppConfig { @Bean public MemberService memberService() { System.out.println(\u0026#34;call AppConfig.memberService\u0026#34;); return new MemberServiceImpl(memberRepository()); } @Bean public OrderService orderService() { System.out.println(\u0026#34;Call AppConfig.orderService\u0026#34;); return new OrderServiceImpl(memberRepository(), discountPolicy()); } @Bean public MemberRepository memberRepository() { System.out.println(\u0026#34;Call AppConfig.memberRepository\u0026#34;); return new MemoryMemberRepository(); } @Bean public DiscountPolicy discountPolicy() { System.out.println(\u0026#34;Call AppConfig.discountPolicy\u0026#34;); return new RateDiscountPolicy(); } } 만약 스프링 빈이 생성된다면 MemberRepository는 몇 번 호출될까?\nMemberService에서 한 번 OrderService에서 한 번 마지막 memberRepository에서 한 번 memberRepository가 총 3번이 호출되어 나는 다음 순서로 호출될 것이라 예상했다.\n1 2 3 4 5 6 7 call AppConfig.memberSerivce -\u0026gt; memberService에 의한 호출 call AppConfig.memberRepository -\u0026gt; memberService에 의한 호출 call AppConfig.orderService -\u0026gt; orderService에 의한 호출 call AppConfig.memberRepository -\u0026gt; orderService에 의한 호출 call AppConfig.discountPoilcy -\u0026gt; orderService에 의한 호출 call AppConfig.memberRepository -\u0026gt; memberRepository 의한 호출 call AppConfig.discountPoilcy -\u0026gt; discountPoilcy 의한 호출 하지만 바로 밑의 결과처럼 다른 결과를 확인할 수 있다.\n1 2 3 4 call AppConfig.memberService call AppConfig.memberRepository call AppConfig.orderService call AppConfig.discountPoilcy 어째서 그런 것일까? 아래 코드를 확인해보자.\n테스트 코드\n1 2 3 4 5 6 7 8 @Test void configurationTest() { ApplicationContext ac = new AnnotationConfigApplicationContext(AppConfig.class); AppConfig appConfig = ac.getBean(AppConfig.class); System.out.println(\u0026#34;AppConfig를 getBean으로 가져온 경우: \u0026#34; + appConfig); System.out.println(\u0026#34;AppConfig를 바로 조회한 경우: \u0026#34; + AppConfig.class); } 결과\n1 2 AppConfig를 getBean으로 가져온 경우: SpringBasic.core.AppConfig$$SpringCGLIB$$0@7a55af6b AppConfig를 바로 조회한 경우: class SpringBasic.core.AppConfig ac는 @Configuration을 추가해 스프링 빈으로 등록된 객체다. 하지만 순수한 자바 객체로서의 스프링 빈이 아니다. \u0026lsquo;CGLIB\u0026rsquo;라는 바이트코드 조작 라이브러리를 사용해 @Configuration이 붙은 클래스를 상속받는 클래스를 만들고, 이 클래스 객체를 등록한 것이다. 그래서 CGLIB 라는 문자를 확인할 수 있다.\n이 바이트코드 조작 라이브러리가 스프링 빈을 싱글톤으로 작동되도록 보장한다.\n예를 들어 @Bean이 붙은 메서드마다 스프링 빈 저장소에 해당 빈 이름이 이미 존재한다면 생성하지 않는다. 없다면 생성 후 컨테이너에 등록한다.\n만약 @Configuration 없이 @Bean만 적용하면 스프링 빈으로는 등록이 되지만, 싱글톤으로 유지되지 않는다.\n호출 결과 call AppConfig.memberService call AppConfig.memberRepository call AppConfig.orderService call AppConfig.memberRepository call AppConfig.memberRepository 그래서 항상 스프링 설정 정보는 @Configuration을 사용하자.\n3. 빈 생명주기 3.1 Life cycle 앞서 배운 내용을 통해 프레임워크가 IoC로서 작동하기 위해 스프링 빈이 필요하다는 것을 알았다. 그러면 객체를 스프링 빈으로 등록하는 것이 존재할 것이고, 프로그램이 종료될 때 이 빈이 소멸될 것이다. 하지만 그냥 뚝 프로그램을 끄면 안된다. 보안을 위해서 외부 자원과의 연결을 끊는 과정 같은 것들이 필요하다. 이번 단원에서는 스프링 프레임워크 내부에서 이 빈이 어떻게 생성되고, 어떤 과정을 거쳐서 종료까지 흘러가는지 빈의 생명주기(life cycle) 에 대해 학습한다.\n일반적인 스프링 빈의 생명 주기 실행 순서를 먼저 말하자면 다음과 같다.\n스프링 컨테이너 생성 -\u0026gt; 스프링 빈 생성 -\u0026gt; 의존 관계 주입 -\u0026gt; 초기화 메서드 실행(초기화 콜백 실행) -\u0026gt; 사용 -\u0026gt; 소멸 전 메서드 실행(소멸 전 콜백) -\u0026gt; 스프링 빈 객체 소멸 -\u0026gt; 컨테이너 종료 -\u0026gt; 스프링 종료\n초기화 콜백과 소멸 전 콜백을 통해서 프레임워크에게 초기화 시 실행할 메서드와 소멸 전 실행할 메서드를 알려주어 안전하게 종료 작업을 할 수 있다.\n다만 의존관계를 주입하는 방식에 따라 미묘하게 달라진다. 생성자 주입으로 생성되는 경우, 빈이 생성될 때 의존 관계를 주입 받고 나서 스프링 빈이 생성되고, 이 빈이 필요한 곳에 의존 관계로서 주입된다. 즉, 빈이 완전한 상태로 사용할 수 있는 시점에는 차이가 존재한다.\n또한, 소멸 전 콜백은 반드시 컨테이너 종료 전에만 일어나는 것이 아닌 해당 빈의 사용이 다 종료되면 호출된다. 그래서 싱글톤 빈의 경우 컨테이너의 시작과 종료까지 존재하지만 몇몇 빈은 컨테이너가 종료되지 않아도 소멸 전 콜백이 일어난다.\n3.2 생명주기 학습을 위한 소스 코드 위 콜백 메서드를 전용하기 전에 Network를 사용하는 클라이언트 코드가 있고 이 코드를 사용해 테스트를 진행해보자. 먼저 Network를 사용하는 클라이언트 코드를 보여주겠다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class NetworkClient { private String url; public NetworkClient() { System.out.println(\u0026#34;생성자 호출, url = \u0026#34; + url); connect(); call(\u0026#34;초기화 연결 메시지\u0026#34;); } public void setUrl(String url) { this.url = url; } //서비스 시작시 호출 public void connect() { System.out.println(\u0026#34;connect: \u0026#34; + url); } public void call(String message) { System.out.println(\u0026#34;call: \u0026#34; + url + \u0026#34; message = \u0026#34; + message); } //서비스 종료시 호출 public void disconnect() { System.out.println(\u0026#34;close: \u0026#34; + url); } } 다음으로 위 코드에 대한 테스트 코드다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package SpringBasic.core.lifecycle; import org.junit.jupiter.api.Test; import org.springframework.context.ConfigurableApplicationContext; import org.springframework.context.annotation.AnnotationConfigApplicationContext; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; public class BeanLifeCycleTest { @Test public void lifeCycleTest() { AnnotationConfigApplicationContext ac = new AnnotationConfigApplicationContext(LifeCycleConfig.class); NetworkClient client = ac.getBean(NetworkClient.class); ac.close(); } @Configuration static class LifeCycleConfig { @Bean public NetworkClient networkClient() { NetworkClient networkClient = new NetworkClient(); networkClient.setUrl(\u0026#34;http://hello-spring.dev\u0026#34;); return networkClient; } } } 위 테스트 코드를 실행하면 결과는 다음과 같다. 아래 실행 결과를 보면 당연하게도 url의 값이 null로 나온다.\n1 2 3 생성자 호출, url = null connect: null call: null message: 초기화 연결 메시지 그러면 이제 생명주기 관련 콜백을 적용하면 위 실행결과가 어떻게 바뀌는지 알아보자.\n3.3 생명주기 관련 메서드 콜백 호출 방법 빈의 생명주기 과정에서 사용할 수 있는 콜백 방법은 3가지이지만 권장하는 방식은 @PostConstruct 와 @PreDestroy 애노테이션을 사용하는 방법이다. 이 방법부터 알아보자.\n3.3.1 @PostConstruct 와 @PreDestroy 이 방법은 애노테이션 하나만 붙이면 되므로 매우 편리하다. 초기화 콜백에는 @PostConstruct 를, 소멸 전 콜백에는 @PreDestroy 를 사용하면 된다.\nNetworkClient 객체에 초기화 콜백으로 init() 메서드를, 소멸 전 콜백으로 close()메서드를 추가한다.\n1 2 3 4 5 6 7 8 9 @PostConstruct public void init() { ... } @PreDestroy public void close() { ... } 그러면 코드를 더 자세히 확인해보자.\n생성하는 역할과 초기화 역할을 init() 메서드를 추가해서 분리했으므로 기존 생성자에 있던 코드를 init() 에 옮긴다. 1 2 3 4 5 6 @PostConstruct public void init() { System.out.println(\u0026#34;NetworkClient.init\u0026#34;); connect(); call(\u0026#34;초기화 연결 메시지\u0026#34;); } 생명주기에 관여하는 메서드는 disConnect() 가 아니라 close() 메서드이므로 close() 메서드로 disConnect() 메서드를 감싸서 소멸 전 콜백으로 호출한다. 1 2 3 4 5 @PreDestroy public void close() { System.out.println(\u0026#34;NetworkClient.close\u0026#34;); disConnect(); } 위 코드를 반영해서 실행하면 다음과 같다.\n1 2 3 4 5 6 생성자 호출, url = null NetworkClient.init connect: http://hello-spring.dev call: http://hello-spring.dev message: 초기화 연결 메시지 NetworkClient.close close: http://hello-spring.dev 생성자 호출 초기화 콜백 호출 -\u0026gt; connect()와 call() 메서드 실행 소멸 전 콜백 호출 -\u0026gt; disConnect() 호출 테스트 코드에 위 순서로 코드를 호출하지 않아도 자동으로 호출되는 것을 알 수 있다!\n만약 스프링 빈을 등록되지 않은 것인 외부 라이브러리를 초기화, 종료해야 한다면 바로 밑에 방법을 사용하면 된다.\n3.3.2 @Bean으로 등록하기 이번 방법은 설정 정보에 @Bean(initMethod, destroyMethod)을 추가해 사용한다. initMethod와 destroyMethod에 각각 초기화 콜백 그리고 소멸 전 콜백으로 사용할 메서드 이름을 입력한다.\n기존 코드는 다음과 같다.\n1 2 3 4 5 6 7 8 9 10 11 ... @Configuration static class LifeCycleConfig { @Bean public NetworkClient networkClient() { NetworkClient networkClient = new NetworkClient(); networkClient.setUrl(\u0026#34;http://hello-spring.dev\u0026#34;); return networkClient; } } 위 코드에서 @Bean 대신에 @Bean(initMethod, destroyMethod)을 추가한다. NetworkClient에 초기화 콜백이 init이고, 소멸 전 콜백이 close이면 다음과 같이 작성한다.\n@Bean(initMethod = \u0026quot;init\u0026quot;, destroyMethod = \u0026quot;close\u0026quot;) 이처럼 메서드 이름을 자유롭게 줄 수 있고, 스프링 빈이 스프링 코드에 의존하지 않아서 앞서 말한 것처럼 코드를 고칠 수 없는 외부 라이브러리에도 적용할 수 있다.\n3.3.3 인터페이스 사용하기 마지막은 스프링 초창기에 인터페이스를 사용해 초기화, 종료하는 방법이다. 이 방법은 InitializingBean 과 DisposableBean 인터페이스를 구현하도록 클래스를 수정한다. InitializingBean 인터페이스에는 afterPropertiesSet() 메서드가 있고, DisposableBean 인터페이스에는 destroy() 메서드를 가지고 있기 때문에 이 두 메서드를 재정의해야 한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class NetworkClient implements InitializingBean, DisposableBean { // 첫 번째 방법에서 init() 메서드를 다음과 같이 수정한다. @Override public void afterPropertiesSet() { System.out.println(\u0026#34;NetworkClient.init\u0026#34;); connect(); call(\u0026#34;초기화 연결 메시지\u0026#34;); } // 첫 번째 방법에서 close() 메서드를 다음과 같이 수정한다. @Override public void destroy() { System.out.println(\u0026#34;NetworkClient.close\u0026#34;); disconnect(); } } 실행 결과는 첫 번째 방법과 동일하다. 이 방법보다 3.2.1과 3.2.2를 사용하자.\nReference 스프링 MVC 1편 - 백엔드 웹 개발 핵심 기술 Introduction to the Spring IoC Container and Beans ","permalink":"http://jeha00.github.io/post/spring/study_1/","summary":"스프링 컨테이너와 스프링 빈이 무엇인지 / 빈 생성 및 등록 과정 / 스프링 컨테이너의 인터페이스의 코드 구조 / BeanDefinition / 싱글톤 설계 시 유의사항 / 스프링이 싱글톤 레지스트리가 가능한 이유 에 대해 알아본다.","title":"스프링 컨테이너, 스프링 빈, 싱글톤 레지스트리란?"},{"categories":"Data Structure \u0026 Algorithum","content":"Introduction 프로그래밍을 하다 보면 데이터를 다루는 때가 많고, 이 데이터를 어떠한 구조로 저장해야 하는지 고민하는 시간이 많다. 이 데이터를 저장하는 구조를 \u0026lsquo;자료 구조\u0026rsquo;라 한다.\n자바를 사용해 여러 자료 구조를 구현해 보며 해당 자료구조의 기능별 시간 복잡도가 어떻게 그렇게 나오는지 \u0026lsquo;설명해 줄게!\u0026rsquo; 시리즈를 연재한다.\n[Data structure] ArrayList를 설명해 줄게! [Data structure] Singly LinkedList를 설명해 줄게! [Data structure] List를 설명해 줄게! [Data structure] Hash를 설명해 줄게! [Data structure] HashSet을 설명해 줄게! [Data structure] Set을 설명해 줄게! [Data structure] Map을 설명해 줄게! [Data structure] Stack을 설명해 줄게! [Data structure] Queue를 설명해 줄게! 1. HashSet 구현하기 1.1 HashSet은 사실 HashMap을 사용해 구현한 자료구조 ❗️ 만약 Map 자료 구조에 대해 잘 모르시는 분이라면 1.1은 생략하셔도 됩니다!\nSet을 구현한 자료구조는 실제로 HashMap을 상속받는다. Map은 key, value로 이뤄진 자료 구조인데, Set을 구현한 자료구조는 이 value에 기본값으로 Object를 추가한다.\n아래 코드를 확인해보자. 아래 코드는 HashSet의 소스 코드다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class HashSet\u0026lt;E\u0026gt; extends AbstractSet\u0026lt;E\u0026gt; implements Set\u0026lt;E\u0026gt;, Cloneable, java.io.Serializable { static final long serialVersionUID = -5024744406713321676L; private transient HashMap\u0026lt;E,Object\u0026gt; map; // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); public boolean add(E e) { return map.put(e, PRESENT)==null; } ... } map 변수를 보면 \u0026lt;E, Object\u0026gt; 로 value의 자료형이 Object인 것을 알 수 있다. add() 메서드를 보면 key로 E e를, value로 PRESENT를 넣는 것을 알 수 있고, 이 PRESENT는 new Object로 dummay value라고 주석으로 설명한다. 즉, HashSet은 value가 Object인 key로만 이뤄진 HashMap이다. HashMap은 value의 값을 수정할 수 있지만 관련된 메서드를 HashSet에 구현하지 않음으로 Set을 구현했다.\nSet 인터페이스를 구현한 메서드들도 사실 HashSet의 메서드를 사용해 구현한 것이다.\nadd(): HashSet의 put() 메서드를 사용 remove(): HashSet의 remove() 메서드 사용 contains(): HashSet의 containKey() 메서드를 사용 iterator(): HashSet의 keySet().iterator() 메서드를 사용 등등 HashMap 부터 설명하는 게 코드 구현 순서상 맞지만 Set 자료구조 자체에 대해 알아보기 위해 직접 구현해보며 어떻게 시간 복잡도가 이렇게 나오는지 이해하려 한다.\n1.2 HashSet 구현하기 기본 필드 1 2 3 4 static final int DEFAULT_INITIAL_CAPACITY = 16; private LinkedList\u0026lt;E\u0026gt;[] buckets; private int size = 0; private int capacity = DEFAULT_INITIAL_CAPACITY; DEFAULT_INITIAL_CAPACITY: 기본 용량 값이 16이다. 왜냐하면 HashMap의 기본 크기가 2의 4승인 16이기 때문이다. buckets: Set은 중복 없이 유일한 값만 보관하기 때문에 미리 메모리를 확보할 필요가 없으므로 LinkedList의 참조 방식을 사용한다. 실제 HashMap에서는 값을 노드 방식으로 관리한다. 1 Node\u0026lt;K, V\u0026gt;[] tables tables는 ArrayList의 elementData처럼 값을 보관하는 장소라고 생각하자. 그래서 초기 크기 16에서 75% 정도 차면 이 tables의 크기를 2배로 늘린 후, 재해싱(rehashing)한다. size: 현재 가지고 있는 요소의 개수 capacity: DEFAULT_INITIAL_CAPACITY가 기본값이지만 생성자를 통해 원하는 값으로 변경할 수 있다. 생성자 1 2 3 4 5 6 7 8 public MyHashSet() { initBuckets(); } public MyHashSet(int capacity) { this.capacity = capacity; initBuckets(); } capacity를 직접 입력하는 방식과 기본값을 사용하는 방식으로 나눠진다. 실제 자바 소스 코드에서 생성자를 사용해 내부 필드를 수정하는 방식으로 만들어져 있다.\n내부 필드 buckets이 초기화가 안되어 있으므로 initBuckets() 메서드를 반드시 실행해야 한다.\n초기자 1 2 3 4 5 6 private void initBuckets() { buckets = new LinkedList[capacity]; for (int i = 0; i \u0026lt; capacity; i++) { buckets[i] = new LinkedList\u0026lt;\u0026gt;(); } } 지정한 capacity만큼의 LinkedList 배열을 생성해 buckets에 할당한다. capaicty만큼 순회하며 생성된 새로운 LinkedList를 buckets의 각 요소에 할당한다.\nhashIndex: 비트 연산자와 나머지 연산자 1 2 3 private int hashIndex(Object value) { return Math.abs(value.hashCode()) % capacity; } hashCode() 를 사용해 value을 해시 코드를 계산한다. 해시 코드가 음수일 때가 있으므로 절대값으로 환산하고 capacity를 사용해 해시 인덱스를 계산한다.\n실제 자바 소스 코드에서도 hashCode()를 사용하고 나머지 연산자를 사용한 나머지 연산이 아닌 비트 연산자를 사용해서 구한다.\n1 2 3 4 5 // 실제 소스 코드 // tab은 해시 테이블을 의미한다. // hash는 해시 코드를 의미한다. // n은 해시 테이블의 길이를 의미한다. tab[index = (n - 1) \u0026amp; hash] 나머지 연산자를 사용하는 방식과 비트 연산자를 사용한 방식\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 int capacity = 16; long time = System.currentTimeMillis(); for (int i = 0; i \u0026lt; 3_000_000; i++) { int c = i % capacity; } System.out.println(System.currentTimeMillis() - time + \u0026#34;ms\u0026#34;); time = System.currentTimeMillis(); for (int i = 0; i \u0026lt; 3_000_000; i++) { // 비트 연산자로 나머지를 계산할 때는 나눠지는 숫자를 1 빼야 한다. int c = (capacity - 1) \u0026amp; i; } System.out.println(System.currentTimeMillis() - time + \u0026#34;ms\u0026#34;); 실행 결과\n1 2 5ms 3ms 비트 연산자를 구한 방식이 훨씬 빠르다는 것을 알 수 있다.\nadd 1 2 3 4 5 6 7 8 9 10 public boolean add(E value) { int hashIndex = hashIndex(value); LinkedList\u0026lt;E\u0026gt; bucket = buckets[hashIndex]; if (bucket.contains(value)) { return false; } bucket.add(value); size++; return true; } hashIndex() 메서드를 사용해 value에 해당하는 해시 인덱스를 구한다. 해시 인덱스를 통해 해당되는 bucket 참조값을 얻는다. contains 메서드를 사용해 해당값의 유무를 확인한다. 있으면 false를 반환하고, 없으면 추가한 후 size의 값을 1 증가시킨다. remove 1 2 3 4 5 6 7 8 9 10 public boolean remove(E value) { int hashIndex = hashIndex(value); LinkedList\u0026lt;E\u0026gt; bucket = buckets[hashIndex]; if (bucket.remove(value)) { size--; return true; } else { return false; } } add() 메서드와 구조가 비슷하다. 단지 차이는 LinkedList의 remove() 메서드를 호출한다는 것과 삭제에 성공할 경우 size의 값을 1 감소시킨다는 것이다. contains 1 2 3 4 5 public boolean contains(E value) { int hashIndex = hashIndex(value); LinkedList\u0026lt;E\u0026gt; bucket = buckets[hashIndex]; return bucket.contains(value); } contains도 동일하다.\ngetSize \u0026amp; isEmpty() 1 2 3 4 5 6 7 public int getSize() { return size; } public boolean isEmpty() { return size == 0; } size의 필드가 private이므로 이를 얻으려면 getter를 정의해야 한다. 현재 셋이 비어있는지 확인하기 위해 isEmpty()를 정의한다. clear 1 2 3 4 5 6 public void clear() { for (int i = 0; i \u0026lt; capacity; i++) { buckets[i].clear(); } size = 0; } LinkedList의 clear() 메서드를 사용해 초기화한다. 각 bucket 초기화를 완료하면 size 를 0으로 초기화한다. 2. hashCode()와 equals() 메서드의 영향 2.1 두 메서드를 각각 재정의하지 않을 때 발생되는 문제 hashCode()와 equals() 메서드의 역할을 코드로 확인해보자.\n위 두 메서드를 테스트하기 위한 객체르 하나 만들자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 import java.util.Objects; public class Member { private String id; public Member(String id) { this.id = id; } public String getId() { return id; } @Override public boolean equals(Object o) { if (this == o) return true; if (!(o instanceof Member)) return false; Member member = (Member) o; return Objects.equals(id, member.id); } @Override public int hashCode() { return Objects.hash(id); } @Override public String toString() { return \u0026#34;Member{\u0026#34; + \u0026#34;id=\u0026#39;\u0026#34; + id + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } 두 메서드 모두 구현하지 않은 경우 위 코드에서는 두 메서드가 모두 구현되어 있지만 아래 코드를 실행할 때는 없이 실행했다.\n실행 코드\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 MyHashSet\u0026lt;Member\u0026gt; set = new MyHashSet\u0026lt;\u0026gt;(16); Member m1 = new Member(\u0026#34;A\u0026#34;); Member m2 = new Member(\u0026#34;A\u0026#34;); System.out.println(\u0026#34;m1.hashCode() = \u0026#34; + m1.hashCode()); System.out.println(\u0026#34;m2.hashCode() = \u0026#34; + m2.hashCode()); System.out.println(\u0026#34;m1.equals(m2) = \u0026#34; + m1.equals(m2)); set.add(m1); set.add(m2); System.out.println(set); Member searchValue = new Member(\u0026#34;A\u0026#34;); System.out.println(\u0026#34;searchValue.hashCode() = \u0026#34; + searchValue.hashCode()); boolean contains = set.contains(searchValue); System.out.println(\u0026#34;contains 결과 = \u0026#34; + contains); 실행 결과\nm1.hashCode() = 288665596 m2.hashCode() = 762218386 m1.equals(m2) = false MyHashSet{buckets=[[], [], [Member{id=\u0026#39;A\u0026#39;}], [], [], [], [], [], [], [], [], [], [Member{id=\u0026#39;A\u0026#39;}], [], [], []], size=2, capacity=16} searchValue.hashCode() = 1796488937 contains 결과 = false hashCode()를 재정의하지 않은 결과\n해시 코드는 참조값을 기반으로 생성된다. 두 Member 객체의 참조값은 다르기 때문에 서로 다른 해시 코드가 생성된다. 그래서 논리적으로 동일해도 해시 코드가 달라 해시 인덱스가 다르므로, 다른 bucket에 저장되는 것을 확인할 수 있다. 서로 다른 버킷에 있으므로 contains의 결과가 false가 나온다. equals()를 재정의하지 않은 결과\n검색할 때, 논리적으로 같은 값이 있어도 참조값으로 비교된다. m1과 m2를 비교할 때 false가 나온다. contains() 메서드의 결과도 false가 된다. hashCode()만 구현한 경우 실행 코드는 동일하다.\n실행 결과\nm1.hashCode() = 96 m2.hashCode() = 96 m1.equals(m2) = false MyHashSet{buckets=[[Member{id=\u0026#39;A\u0026#39;}, Member{id=\u0026#39;A\u0026#39;}], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], size=2, capacity=16} searchValue.hashCode() = 96 contains 결과 = false hashCode()를 재정의한 결과\n논리적으로 동일하므로 생성된 hashCode의 결과가 같다. 그래서 동일한 해시 인덱스를 가지기 때문에 같은 bucket에 저장되는 것을 확인할 수 있다. equals()를 재정의하지 않은 결과\n논리적으로 같아 이미 존재하는 값이어도, equals()를 재정의하지 않았기 때문에 참조값 기준으로 다른 값으로 판단되어 값이 중복으로 들어간다. equals()만 구현한 경우 실행 코드는 동일하다.\n실행 결과\nm1.hashCode() = 288665596 m2.hashCode() = 762218386 m1.equals(m2) = true MyHashSet{buckets=[[], [], [Member{id=\u0026#39;A\u0026#39;}], [], [], [], [], [], [], [], [], [], [Member{id=\u0026#39;A\u0026#39;}], [], [], []], size=2, capacity=16} searchValue.hashCode() = 1796488937 contains 결과 = false hashCode()를 재정의하지 않은 결과\n생성되는 hashCode()가 달라서 해시 인덱스 값이 다르므로 논리적으로 같아도 다른 bucket에 저장된다. equals()를 재정의하지 않은 결과\n논리적으로 같아도 참조값으로 비교되어 false로 나온다. 모두 구현한 경우 실행 결과\nm1.hashCode() = 96 m2.hashCode() = 96 m1.equals(m2) = true MyHashSet{buckets=[[Member{id=\u0026#39;A\u0026#39;}], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], size=1, capacity=16} searchValue.hashCode() = 96 contains 결과 = true hashCode가 같아 해시 인덱스가 같다.\n해시 인덱스가 같으므로 m1과 m2의 배정되는 버킷은 동일하다.\nequals()를 재정의해 논리적인 비교가 가능하므로 값이 중복으로 들어가지 않는다.\ncontains의 결과가 true가 나온다.\n2.2 두 메서드의 역할 정리 ❗️ hashCode() 메서드의 역할은 해당 객체의 논리적인 값에 따라 해당 객체가 속한(속할) 버킷을 지정하는 역할입니다.\nequals() 메서드는 두 객체가 동등한지 판단할 수 있도록 비교하는 역할입니다. 재정의하지 않으면 참조값을 기준으로 비교하기 때문에 동등성 비교가 아닌 동일성 비교가 됩니다.\n3. 전체 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 import java.util.Arrays; import java.util.LinkedList; public class MyHashSet\u0026lt;E\u0026gt; { static final int DEFAULT_INITIAL_CAPACITY = 16; private LinkedList\u0026lt;E\u0026gt;[] buckets; private int size = 0; private int capacity = DEFAULT_INITIAL_CAPACITY; public MyHashSet() { initBuckets(); } public MyHashSet(int capacity) { this.capacity = capacity; initBuckets(); } private void initBuckets() { buckets = new LinkedList[capacity]; for (int i = 0; i \u0026lt; capacity; i++) { buckets[i] = new LinkedList\u0026lt;\u0026gt;(); } } public boolean add(E value) { int hashIndex = hashIndex(value); LinkedList\u0026lt;E\u0026gt; bucket = buckets[hashIndex]; if (bucket.contains(value)) { return false; } bucket.add(value); size++; return true; } public boolean remove(E value) { int hashIndex = hashIndex(value); LinkedList\u0026lt;E\u0026gt; bucket = buckets[hashIndex]; if (bucket.remove(value)) { size--; return true; } else { return false; } } public boolean contains(E value) { int hashIndex = hashIndex(value); LinkedList\u0026lt;E\u0026gt; bucket = buckets[hashIndex]; return bucket.contains(value); } private int hashIndex(Object value) { return Math.abs(value.hashCode()) % capacity; } public int getSize() { return size; } public boolean isEmpty() { return size == 0; } public void clear() { for (int i = 0; i \u0026lt; capacity; i++) { buckets[i].clear(); } size = 0; } @Override public String toString() { return \u0026#34;MyHashSet{\u0026#34; + \u0026#34;buckets=\u0026#34; + Arrays.toString(buckets) + \u0026#34;, size=\u0026#34; + size + \u0026#34;, capacity=\u0026#34; + capacity + \u0026#39;}\u0026#39;; } } ","permalink":"http://jeha00.github.io/post/datastructure/hashset/","summary":"해시를 사용해 만든 자료구조 HashSet을 알아보자.","title":"[Data structure] HashSet에 대해 설명해 줄게!"},{"categories":"java","content":"기본형과 참조형 리뷰 이번 포스팅에서는 불변 객체, String 객체 그리고 StringBuilder 객체를 점진적으로 알아가려 한다.\n여태 학습한 내용을 보면 자바에는 자료형이 기본형과 참조형이 있다는 것을 알 수 있다. 자바는 항상 값을 복사해서 대입한다 는 사실을 다시 떠올려보자. 이 사실에 따라 두 자료형 모두 전달하는 값이 존재한다. 기본형은 해당 타입의 실제 값을 복사해서 전달하고, 참조형은 참조값을 복사해서 전달한다. 코드로 확인해 보자.\n기본형\n1 2 3 4 5 6 int a = 10; int b = a; a = 20; System.out.println(\u0026#34;a = \u0026#34; + a); System.out.println(\u0026#34;b = \u0026#34; + b); 1 2 3 // 실행 결과 a = 20 b = 10 b에 할당 연산자를 사용해 a를 전달하면 a와 동일한 값이 전달된다. a의 값을 다른 값으로 수정해도 b에는 영향을 미치지 않는다. 위 결과로 기본형은 타입의 실제 값을 복사해서 전달한다는 것을 알 수 있다. 똑같이 10이어도 동일한 메모리 주소를 가지지 않으므로 하나가 수정되어도 다른 값에 영향을 주지 않는다. 다음으로 참조형을 확인해보자.\n참조형\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class Address { private String value; public Address(String value) { this.value = value; } public void setAddress(String value) { this.value = value; } public String getAddress() { return value; } @Override public String toString() { return \u0026#34;Address{\u0026#34; + \u0026#34;value=\u0026#39;\u0026#34; + value + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } 1 2 3 4 5 6 7 8 9 // 실행 main 메서드 Address a = new Address(\u0026#34;서대문구\u0026#34;); Address b = a; System.out.println(\u0026#34;a = \u0026#34; + a); System.out.println(\u0026#34;b = \u0026#34; + b); a.setAddress(\u0026#34;강남구\u0026#34;); System.out.println(\u0026#34;a = \u0026#34; + a); System.out.println(\u0026#34;b = \u0026#34; + b); 실행 결과\n1 2 3 4 a = Address{value=\u0026#39;서대문구\u0026#39;} b = Address{value=\u0026#39;서대문구\u0026#39;} a = Address{value=\u0026#39;강남구\u0026#39;} b = Address{value=\u0026#39;강남구\u0026#39;} b에 할당 연산자를 사용해 a를 입력하면 기본형과 달리 Address 객체의 참조값이 복사되어 전달된다.\n참조형은 실제 값이 아닌 참조값(메모리 주소 값)을 복사해서 전달하므로 a의 값을 변경하면 b의 값도 변경되는 것을 확인할 수 있다.\n참조형의 사이드 이펙트와 해결책 참조형의 이런 특성 때문에 의도치 않은 변경이 발생할 수 있다. 이 문제를 해결하려면 제일 쉬운 방법은 다른 객체를 생성하는 방법이다. 그러면 예를 들어 a와 b는 서로 다른 참조값을 가지게 되고, a가 수정되어도 b는 그대로다. 하지만 논리적으로 동일한 값을 가지는데\n보다 근본적으로는 객체 공유를 막으면 되지만, 자바문법 상 참조형 변수의 대입은 아무런 문제가 없어서 불가능하다.\n또 다른 방법은 없을까?\n사이드 이펙트가 발생하는 일차적인 원인은 공유된 값이 변경된 것에 있다. 그렇다면 참조값이 가리키는 객체의 정보를 변경할 때 객체 자체를 변경하기보다는 새로운 객체를 생성해서 반환하면 공유 참조로 인한 문제가 발생하지 않을 것이다. 이처럼 객체의 상태(객체 내부 값)가 변하지 않는 객체를 불변 객체(Immutable Object)라 한다.\n그러면 private String value 로 된 부분을 private final String value로 수정한다. setValue() 메서드를 만들지 않는 방법도 있으나 보다 명확하게 의도를 드러내기 위해서 final을 추가한다.\nAddress 객체를 다음과 같이 수정하면 불변 객체로 바꿀 수 있다.\nfinal 추가 setAddress 삭제 생성자를 통해서만 값을 설정할 수 있고, 이후 값 변경은 불가능하다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class Address { private final String value; public Address(String value) { this.value = value; } public String getAddress() { return value; } @Override public String toString() { return \u0026#34;Address{\u0026#34; + \u0026#34;value=\u0026#39;\u0026#34; + value + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } 불변 객체여도 값을 변경해야 한다면? 불변 객체이지만 값을 변경해야 하는 메서드가 필요하다면 \u0026lsquo;변경된 값을 가지는 새로운 불변 객체\u0026rsquo; 를 생성해 반환하면 된다.\n만약 위 Address 객체를 통해서 값을 변경하고 싶다면 아래 메서드를 추가한다.\n1 2 3 public Address setAddress(String value) { return new Address(value); } 1 2 3 4 5 6 7 8 9 // 실행 main 메서드 Address a = new Address(\u0026#34;서대문구\u0026#34;); Address b = a; System.out.println(\u0026#34;a = \u0026#34; + a); System.out.println(\u0026#34;b = \u0026#34; + b); a = a.setAddress(\u0026#34;강남구\u0026#34;); System.out.println(\u0026#34;a = \u0026#34; + a); System.out.println(\u0026#34;b = \u0026#34; + b); 실행 결과 1 2 3 4 a = Address{value=\u0026#39;서대문구\u0026#39;} b = Address{value=\u0026#39;서대문구\u0026#39;} a = Address{value=\u0026#39;강남구\u0026#39;} b = Address{value=\u0026#39;서대문구\u0026#39;} b의 값까지 변경되지 않는 것을 알 수 있다. a 변수의 입장에서는 값이 변경된 거지만, 사실 새로운 불변형 객체를 생성한 것이 정확한 표현이다.\n불변형 객체를 언급한 이유 가변형 객체가 모다 일반적이지만, 언급한 이유는 String 클래스가 바로 불변형 객체이기 때문이다. 그리고 문자열이지만 가변형으로 사용하기 위해 존재하는 것이 StringBuilder 클래스다. 이 두 가지에 대해 다음 포스팅에서 알아보자.\n","permalink":"http://jeha00.github.io/post/java/8_immutable/","summary":"불변형 객체를 사용하지 않을 때 어떠한 실수를 할 수 있는지 알아보자.","title":"불변형 객체를 사용하지 않을 때 발생할 수 있는 사이드 이펙트"},{"categories":"Data Structure \u0026 Algorithum","content":"Introduction 프로그래밍을 하다 보면 데이터를 다루는 때가 많고, 이 데이터를 어떠한 구조로 저장해야 하는지 고민하는 시간이 많다. 이 데이터를 저장하는 구조를 \u0026lsquo;자료 구조\u0026rsquo;라 한다.\n자바를 사용해 여러 자료 구조를 구현해 보며 해당 자료구조의 기능별 시간 복잡도가 어떻게 그렇게 나오는지 \u0026lsquo;설명해 줄게!\u0026rsquo; 시리즈를 연재한다.\n[Data structure] ArrayList를 설명해 줄게! [Data structure] Singly LinkedList를 설명해 줄게! [Data structure] List를 설명해 줄게! [Data structure] Hash를 설명해 줄게! [Data structure] HashSet을 설명해 줄게! [Data structure] Set을 설명해 줄게! [Data structure] Map을 설명해 줄게! [Data structure] Stack을 설명해 줄게! [Data structure] Queue를 설명해 줄게! 1. List와 Set의 차이 리스트에 대해서 알아봤으니 Set에 대해서 알아보자.\n리스트는 앞서 요소들에 순서가 있고 중복이 있는 자료구조 라 했다. 순서가 있어서 \u0026lsquo;인덱스\u0026rsquo;를 사용할 수 있다.\n하지만 셋(Set)은 리스트와 정반대로 요소들에 순서가 없고 중복이 없는 자료구조 다. 순서가 없으므로 인덱스가 없다. 중복이 없다는 건 예를 들어 \u0026lsquo;a\u0026rsquo;라는 문자열이 있으면 동일한 값의 \u0026lsquo;a\u0026rsquo;가 있지 않다는 의미다.\n그래서 리스트의 용도는 다음과 같다.\n리스트에 추가된 순서대로 요소의 순서가 유지해야 할 때 동일한 값이나 객체의 중복 허용이 필요할 때 리스트의 각 요소에 인덱스 접근이 필요할 때 반대로 셋의 용도는 다음과 같다.\n값이나 객체가 유일하게 존재해야 할 때 입력한 순서대로 보장할 필요가 없을 때 빠르게 검색할 필요가 있을 때 그래서 리스트는 장바구니 목록, 셋은 회원 목록 등에 사용할 수 있다.\n이 셋의 특징 핵심에는 해시 알고리즘 이 있는데 이에 대해 알아보자!\n2. 해시 알고리즘: 해시 인덱스 해시 인덱스란? 기존 리스트에 정수형 값 1부터 10까지 추가한 후 원하는 값을 찾으려면 모든 값을 탐색해야 한다. 이는 이전에 학습한 대로 O(n)이 걸린다. 하지만 집합은 값을 찾는 데 배열 인덱스를 사용하지 않아도 O(1)이 걸려야 한다.\n이를 어떻게 구현할 수 있을까?\n데이터의 값을 배열 인덱스와 맞추어 저장하기 만약 값의 크기를 인덱스로 사용한다면 크기를 통해 O(1)로 바로 접근할 수 있을 것이다.\n예시 코드 1 2 3 4 5 6 7 8 9 Integer array[] = new Integer[10]; array[1] = 1; array[3] = 3; array[5] = 5; array[9] = 9; System.out.println(Arrays.toString(array)); // 값 9 찾기 System.out.println(array[9]); 실행 결과\n1 2 [null, 1, null, 3, null, 5, null, null, null, 9] 9 값을 인덱스로 사용해서 저장한 결과 O(1)로 바로 값을 찾을 수 있다. 하지만 전체 배열 출력에서 알 수 있듯이 사용하지 않는 공간이 많다. 만약 입력받으려는 값의 범위가 훨씬 넓다면 그만큼 배열의 크기가 커야 하고 배열에 낭비되는 공간이 많이 발생한다.\n위 문제 예시 코드\n1 2 3 4 5 6 7 Integer array[] = new Integer[50]; array[1] = 1; array[3] = 3; array[9] = 9; array[25] = 25; array[40] = 40; System.out.println(Arrays.toString(array)); 실행 결과\n1 [null, 1, null, 3, null, null, null, null, null, 9, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 25, null, null, null, null, null, null, null, null, null, null, null, null, null, null, 40, null, null, null, null, null, null, null, null, null] 이렇게 데이터의 값을 사용해 저장하려는 위치의 인덱스로 사용할 때 문제점을 파악했다.\n나머지 연산으로 해결하기 메모리가 낭비되는 문제를 해결하기 위해 예를 들어 \u0026lsquo;나머지 연산\u0026rsquo;을 사용해 인덱스 위치를 구할 수 있다. 나머지 연산을 통해 나온 값을 인덱스로 사용하는 것이다.\n나누는 수를 10이라 가정 0 ~ 99까지의 수를 배열에 저장한다고 가정 위 가정으로 나올 수 있는 인덱스의 범위는 0부터 9다.\n1 % 10 = 1 -\u0026gt; 인덱스 1 3 % 10 = 3 -\u0026gt; 인덱스 3 22 % 10 = 5 -\u0026gt; 인덱스 2 40 % 10 = 0 -\u0026gt; 인덱스 0 94 % 10 = 4 -\u0026gt; 인덱스 4 이런 식으로 인덱스를 구한다면 배열의 크기를 많이 크게 잡지 않아도 된다.\n예시 코드\n1 2 3 4 5 6 Integer array[] = new Integer[50]; int[] values = {1, 3, 22, 40, 94}; for (int value : values) { array[value % 10] = value; } System.out.println(Arrays.toString(array)); 실행 결과\n1 [40, 1, 22, 3, 94, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null] 이처럼 배열의 인덱스로 사용할 수 있도록 저장하려는 요소의 값을 계산해 얻은 인덱스를 \u0026lsquo;해시 인덱스(hash index) 라 한다.\nhash index를 사용해서 얻은 장점 입력값의 범위가 넓어도 제한된 배열의 크기에서 값을 저장할 수 있으므로 메모리가 낭비되는 문제를 해결할 수 있다. O(1) 성능으로 데이터를 저장할 수 있다. O(1) 성능으로 데이터를 조회할 수 있다. 해시 인덱스의 한계: 해시 충돌 그런데 지금까지 설명한 해시 인덱스에는 저장할 위치가 충돌할 수 있다 는 한계가 있다.\n예를 들어 다음 연산은 동일한 해시 인덱스를 가진다.\n99 % 10 = 9 9 % 10 = 9 어떤 값을 나중에 하냐에 따라서 인덱스 9에서 얻는 값이 달라진다.\n이 한계를 해결하기 위해 중첩 배열을 사용해 같은 해시 인덱스의 값을 다 저장한다. 이에 따라 해당 해시 인덱스의 배열에서 추가하려는 값이 존재하는지도 탐색해야 한다.\n예를 들어 9, 19, 29, 39, 99 를 통해 나머지 연산 방식의 해시 인덱스를 얻으면 다 \u0026lsquo;9\u0026rsquo;를 얻는다. 그러면 이 값을 저장할 때마다 인덱스 9의 배열에 값이 이미 있는지 탐색해야 하므로 O(n)이 걸린다.\n예시 코드\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // buckets 생성 및 초기화 LinkedList\u0026lt;Integer\u0026gt;[] buckets = new LinkedList[10]; for (int i = 0; i \u0026lt; buckets.length; i++) { buckets[i] = new LinkedList\u0026lt;\u0026gt;(); } // 데이터 추가 int[] values = {1, 3, 22, 40, 9, 19, 99}; for (int value : values) { int hashIndex = value % 10; LinkedList\u0026lt;Integer\u0026gt; bucket = buckets[hashIndex]; if (!bucket.contains(value)) { buckets[hashIndex].add(value); } } System.out.println(Arrays.toString(buckets)); 출력 결과\n1 [[40], [1], [22], [3], [], [], [], [], [], [9, 19, 99]] 중첩 배열을 사용해 해시 충돌이 일어나도 값은 저장할 수 있지만, 저장하기 위해 해당 해시 인덱스의 배열을 모두 탐색해 O(n)이 걸리므로 해시 충돌 발생을 막는 게 좋다. Set의 특징을 구현하려면 해시 인덱스가 필수이므로 해시 충돌을 완전히 피할 수 없다. 그래서 발생 확률을 줄일 수 있는 방법을 찾아야 한다.\n해시 충돌이 발생하는 확률은 배열의 크기와 관련 있다. 입력한 데이터 수보다 배열의 크기가 클수록 충돌 확률은 낮아진다. 그래서 크기 기준을 입력한 데이터의 수가 배열의 크기에서 75%를 채우면 크기를 대략 두 배 증가시킨다.\nHashMap 자료 구조의 설명 부분을 보면 알 수 있다. Set 자료구조의 한 종류인 HashSet은 HashMap의 인스턴스라서 HashMap의 설명 부분을 봤다.\nAn instance of HashMap has two parameters that affect its performance: initial capacity and load factor. The capacity is the number of buckets in the hash table, and the initial capacity is simply the capacity at the time the hash table is created. The load factor is a measure of how full the hash table is allowed to get before its capacity is automatically increased. When the number of entries in the hash table exceeds the product of the load factor and the current capacity, the hash table is rehashed (that is, internal data structures are rebuilt) so that the hash table has approximately twice the number of buckets\n그리고 클래스 변수에서 크기와 관련된 부분이 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 /** * The default initial capacity - MUST be a power of two. */ static final int DEFAULT_INITIAL_CAPACITY = 1 \u0026lt;\u0026lt; 4; // aka 16 /** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two \u0026lt;= 1\u0026lt;\u0026lt;30. */ static final int MAXIMUM_CAPACITY = 1 \u0026lt;\u0026lt; 30; /** * The load factor used when none specified in constructor. */ static final float DEFAULT_LOAD_FACTOR = 0.75f; 기본값은 2의 4승인 16이고, 최대 크기는 2의 30승이다. 로드 팩터는 배열을 증가시키는 기준 값이다. 여기서 보면 0.75로 75%임을 알 수 있다.\n너무 낮아도 안되고 너무 커도 안된다고 설명한다.\nThis implementation provides constant-time performance for the basic operations (get and put), assuming the hash function disperses the elements properly among the buckets. Iteration over collection views requires time proportional to the \u0026ldquo;capacity\u0026rdquo; of the HashMap instance (the number of buckets) plus its size (the number of key-value mappings). Thus, it\u0026rsquo;s very important not to set the initial capacity too high (or the load factor too low) if iteration performance is important.\n데이터가 75%를 차면 데이터를 보관하는 크기가 2배 증가하고, 커진 크기에 맞춰서 재해싱(rehashing)이 일어난다.\n3. 여러 객체의 해시 인덱스 구하기 위와 같이 Integer와 int의 경우 나머지 연산을 통해 해시 인덱스를 계산할 수 있다.\n하지만 String은 어떻고, class를 사용해 직접 정의한 사용자 정의 자료형 객체들은 어떻게 해시 인덱스를 구할까?\n모든 객체는 Object를 상속 받는다. Object 객체는 hashcode() 라는 \u0026lsquo;해시 함수\u0026rsquo;를 통해 해시 코드를 얻는다. 이 해시 코드는 고유한 정수 숫자 값이므로 이 코드를 사용해 해시 인덱스를 구한다. 해시 인덱스는 보통 해시 코드에 배열의 크기를 나눠 계산된 값이다.\nObject.java에서 이 메서드에 대한 설명은 다음과 같다.\nReturns a hash code value for the object. This method is supported for the benefit of hash tables such as those provided by java.util.HashMap \u0026hellip;\n이 메서드는 해당 객체에 대한 정수형의 hash code 값을 반환한다. If two objects are equal according to the equals(Object) method, then calling the hashCode method on each of the two objects must produce the same integer result \u0026hellip;\nObject 객체의 equals() 메서드에 따라 두 객체가 동등하면 hash code 값이 같다는 것을 말한다. It is not required that if two objects are unequal according to the equals(Object) method, then calling the hashCode method on each of the two objects must produce distinct integer results \u0026hellip;\nObject 객체의 equals() 메서드에 따라 두 객체가 동등하지 않으면 hash code 값이 다르다는 것을 말한다. 이미 자바에서 정의해놓은 자료형은 모두 내부에서 hashcode()와 equals() 메서드를 재정의했기 때문에 객체의 값에 따라 해시 코드가 생성되도록 되어 있다. equals도 객체의 정보를 바탕으로 판단되도록 재정의된다.\n그래서 만약 hashcode()와 equals()를 재정의하지 않으면 객체의 참조값을 기준으로 하기 때문에 동등성이 아닌 동일성 비교를 하게 된다. 그래서 반드시 hashcode()와 equals()를 재정의해야 한다.\n이처럼 Set 자료 구조에서 해시는 매우 중요한 핵심이다. 다음 포스팅에서 배운 내용을 바탕으로 직접 HashSet을 구현해보자.\n","permalink":"http://jeha00.github.io/post/datastructure/hash/","summary":"Set 자료구조에서 Hash가 필요한 이유에 관해 설명한다!","title":"[Data structure] Hash에 대해 설명해 줄게!"},{"categories":"Data Structure \u0026 Algorithum","content":"Introduction 프로그래밍을 하다 보면 데이터를 다루는 때가 많고, 이 데이터를 어떠한 구조로 저장해야 하는지 고민하는 시간이 많다. 이 데이터를 저장하는 구조를 \u0026lsquo;자료 구조\u0026rsquo;라 한다.\n자바를 사용해 여러 자료 구조를 구현해 보며 해당 자료구조의 기능별 시간 복잡도가 어떻게 그렇게 나오는지 \u0026lsquo;설명해 줄게!\u0026rsquo; 시리즈를 연재한다.\n[Data structure] ArrayList를 설명해 줄게! [Data structure] Singly LinkedList를 설명해 줄게! [Data structure] List를 설명해 줄게! [Data structure] Hash를 설명해 줄게! [Data structure] HashSet을 설명해 줄게! [Data structure] Set을 설명해 줄게! [Data structure] Map을 설명해 줄게! [Data structure] Stack을 설명해 줄게! [Data structure] Queue를 설명해 줄게! 1. 인터페이스 List 자료 구조는 다형성과 OCP 원칙을 잘 활용할 수 있다. 어떻게 적용되는지 알아보자.\n자바에서 ArrayList와 LinkedList는 List 라는 인터페이스를 구현한다. 역할이 List이고, 구현이 ArrayList와 LinkedList다. 그리고 List는 Collection이라는 인터페이스를 상속 받는다.\n리스트는 [Data structure] ArrayList를 설명해 줄게!에서 언급한 것처럼 순서가 있고, 중복이 가능한 자료구조라 했다. 내가 직접 만든 자료 구조 ArrayList와 LinkedList는 내부 구현만 다를 뿐 동일한 기능을 제공하는 리스트다. 이 둘의 공통 기능을 인터페이스로 뽑아서 추상화하면 다형성을 사용할 수 있다. 인터페이스로 뽑아보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public interface MyList\u0026lt;E\u0026gt; { int size(); void add(E e); void add(int index, E e); E get(int index); E set(int index, E e); E remove(int index); boolean remove(E e); int indexOf(E e); void clear(); } 그리고 위 인터페이스를 여태 학습한 MyArrayList와 MyLinkedList가 MyList 인터페이스를 구현하도록 만들자.\nMyArrayList\n1 2 3 public class MyArrayList\u0026lt;E\u0026gt; implements MyList\u0026lt;E\u0026gt;{ //... } MyLinkedList\n1 2 3 public class MyLinkedList \u0026lt;E\u0026gt; implements MyList\u0026lt;E\u0026gt;{ //... } 재정의한 메서드에는 @Override 애노테이션도 추가한다.\n한 번에 많은 데이터를 뒤에서 추가하는 객체를 개발하고 있다고 하자. 다형성을 사용하지 않으면 다음과 같이 타입을 MyArrayList 또는 MyLinkedList로 지정해야 한다.\n처음 구현할 때 MyLinkedList로 한 후, 데이터를 앞에 추가할 일이 많아진다면 MyLinkedList로 지정한 타입을 MyArrayList로 바꿔야 한다.\n변경 전\n1 2 3 4 5 6 7 8 9 10 public class BatchProcessor { // 다형성 미사용 시, 타입 지정 private final MyLinkedList\u0026lt;Integer\u0026gt; list = new MyLinkedList\u0026lt;\u0026gt;(); public void add(int size) { for (int i = 0; i \u0026lt; size; i++) { list.add(0, i); } } } 변경 후\n1 2 3 4 5 6 7 8 9 10 public class BatchProcessor { // 다형성 미사용 시, 타입 지정 private final MyArrayList\u0026lt;Integer\u0026gt; list = new MyArrayList\u0026lt;\u0026gt;(); public void add(int size) { for (int i = 0; i \u0026lt; size; i++) { list.add(0, i); } } } 이렇게 다형성을 사용하지 않고 \u0026lsquo;구체적인 클래스\u0026rsquo;에 의존한다면 직접 코드도 수정해야 한다. 하지만 다형성을 사용하기 위해 \u0026lsquo;interface\u0026rsquo;를 사용한다면 코드를 수정할 필요 없이 \u0026lsquo;생성자 의존관계 주입\u0026rsquo;으로 사용되는 객체만 바꿔끼면 된다. 역할과 구현으로 나눠서 역할을 그대로 두고 구현체만 바꾼다는 것이다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class BatchProcessor { // 수정 private final MyList\u0026lt;Integer\u0026gt; list; // 추가 public BatchProcessor(MyList\u0026lt;Integer\u0026gt; list) { this.list = list; } // 작업을 위해 사용되는 메서드는 그대로 public void add(int size) { for (int i = 0; i \u0026lt; size; i++) { list.add(i); } } } 그러면 두 리스트로 할 때 각각 시간을 비교해보자. 시간 측정을 위해 add 메서드를 수정한다.\n1 2 3 4 5 6 7 8 public void add(int size) { long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; size; i++) { list.add(0, i); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;크기: \u0026#34; + size + \u0026#34;, 계산 시간: \u0026#34; + (endTime - startTime) + \u0026#34;ms\u0026#34;); } MyArrayList인 경우: 크기: 50000, 계산 시간: 2324ms\n1 2 3 MyArrayList\u0026lt;Integer\u0026gt; list = new MyArrayList\u0026lt;\u0026gt;(); BatchProcessor processor = new BatchProcessor(list); processor.add(50_000); MyLinkedList인 경우: 크기: 50000, 계산 시간: 6ms\n1 2 3 MyLinkedList\u0026lt;Integer\u0026gt; list = new MyLinkedList\u0026lt;\u0026gt;(); BatchProcessor processor = new BatchProcessor(list); processor.add(50_000); LinkedList를 사용할 때가 시간이 훨씬 빠른 것을 알 수 있다!\n다형성과 의존관계 주입을 사용해서 코드의 변경 없이 확장성 있게 사용할 수 있다! 만약 데이터가 뒤에서 추가할 일이 많다면 반대로 MyArrayList를 사용하면 성능이 더 빠를 것이다.\n그러면 두 자료구조의 성능을 비교해보자.\n2. 직접 구현한 리스트의 성능 비교 맨 하단에 있는 \u0026lsquo;성능 비교를 위한 코드 전체본\u0026rsquo;을 실행했을 때 다음과 같은 결과를 확인할 수 있다.\n성능 비교 추가하는 데이터의 수는 50,000개이고 반복 횟수는 10,000번일 때 각 list 실행 시 표로 정리하면 결과는 다음과 같다.\n추가:\n배열 리스트는 앞에 추가할수록 시간이 더 걸리는 것을 알 수 있다. 연결 리스트는 뒤에 추가할수록 시간이 더 걸리는 것을 알 수 있다. 기능 배열 리스트 연결 리스트 앞에 추가 2245ms 5ms 평균 추가 6ms 3273ms 뒤에 추가 2ms 3183ms 삭제\n배열 리스트는 앞에서 삭제할수록 시간이 더 걸리는 것을 알 수 있다. 연결 리스트는 뒤에서 삭제할 수록 시간이 더 걸리는 것을 알 수 있다. 기능 배열 리스트 연결 리스트 앞에서 삭제 877ms 2ms 평균에서 삭제 391ms 1033ms 뒤에서 삭제 0ms 2229ms 조회\n배열 리스트는 어디서 조회하든 매우 빠르다. 연결 리스트는 뒤에서 조회할 수록 시간이 더 걸리는 것을 알 수 있다. 기능 배열 리스트 연결 리스트 앞에서 조회 0ms 1ms 중간에서 조회 0ms 563ms 뒤에서 조회 1ms 1133ms 검색\n배열 리스트와 연결 리스트 모두 뒤에서 검색할수록 시간이 더 걸리는 것을 알 수 있다. 기능 배열 리스트 연결 리스트 맨 앞 값 검색 1ms 1ms 중간 값 검색 156ms 666ms 맨 뒤 값 검색 298ms 1331ms 추가, 삭제 배열 리스트는 인덱스를 통해 추가나 삭제할 위치를 O(1)로 빠르게 찾지만, 추가나 삭제 이후에 데이터를 한 칸씩 밀어야 하므로 O(n)이 걸리므로 총 O(n)이 걸린다.\n연결 리스트는 인덱스를 통해 추가나 삭제할 위치를 찾는데 O(n)이 걸리지만, 추가나 삭제할 때는 간단한 참조 변경으로 O(1)이 걸리므로 총 O(n)이 걸린다.\n앞에 추가(삭제) 배열 리스트는 추가나 삭제할 위치를 찾는데 O(1), 데이터를 한 칸씩 이동 O(n) -\u0026gt; O(n) 연결 리스트는 추가나 삭제할 위치를 찾는데 O(1), 노드를 변경하는데 O(1) -\u0026gt; O(1) 중간에 추가(삭제) 배열 리스트는 추가나 삭제할 위치를 찾는데 O(1), 데이터를 한 칸씩 이동 O(n/2) -\u0026gt; O(n) 연결 리스트는 추가나 삭제할 위치를 찾는데 O(n/2), 노드를 변경하는데 O(1) -\u0026gt; O(n) 뒤에 추가(삭제) 배열 리스트는 추가나 삭제할 위치를 찾는데 O(1), 이동할 데이터가 없으므로 -\u0026gt; O(1) 연결 리스트는 추가나 삭제할 위치를 찾는데 O(n), 노드를 변경하는데 O(1) -\u0026gt; O(n) 인덱스 조회 배열 리스트는 배열의 인덱스를 사용해서 값을 O(1)로 찾을 수 있다. 연결 리스트는 노드를 인덱스 수만큼 이동해야 하므로 O(n)이 걸린다. 검색 배열 리스트와 연결 리스트 모두 데이터를 찾을 때까지 배열과 노드를 순회해야 하므로 O(n)이 걸린다.\n추가로 고려해야할 부분 ArrayList는 배열 기반이라서 메모리 상에 연속적으로 위치하므로 다음 장점이 있다.\nCPU 캐시 효율이 좋다: 메모리에서 읽어서 가져올 때 필요한 데이터의 주변 데이터까지 가져오므로 캐시로 가져올 확률이 높다 메모리 접근 속도가 빠르다 하지만 LinkedList는 산발적으로 존재해서 위와 같은 장점을 얻기가 어렵다.\nArrayList의 CAPCITY를 넘으면 배열을 다시 만들고 복사하는 과정은 한 번에 2배씩 늘어나므로 가끔 발생해 성능에 큰 영향을 주지 않는다.\n그래서 결론을 내리자면 데이터를 앞에서 자주 추가하거나 삭제할 일이 아니면 기본으로 배열 리스트를 사용하는 것이 훨씬 효율적이다.\n3. 자바 Collection 인터페이스 리스트의 성능 비교 직접 만든 List와 차이점 ArrayList\n기본 CAPACITY는 10이다. 기본 크기 값을 넘어가면 배열을 1.5배 증가시킨다. 10 -\u0026gt; 15 -\u0026gt; 22 -\u0026gt; 33 -\u0026gt; 49 메모리 고속 복사 연산을 사용한다. 배열은 값을 추가 및 삭제 시 모든 요소를 한 칸씩 뒤로 이동시켜야 한다. 이 부분을 최적화하기 위해 System.arraycopy()를 사용해 시스템 레벨에서 메모리 고속 복사 연산을 수행한다. LinkedList\nlast 필드가 존재해서 첫 번째 노드와 마지막 노드 둘 다 참조할 수 있다. 이중 연결 리스트로 prev 뿐만 아니라 next도 있어서 다음 노드와 이전 노드 모두 이동할 수 있다. 성능 비교 그러면 이번에는 자바에서 제공하는 ArrayList와 LinkedList를 사용해 성능 비교를 해보자.\n직접 만든 MyList, MyArrayList, MyLinkedList 대신에 아래 콜렉션을 import 해서 사용하면 된다.\n1 2 3 import java.util.ArrayList; import java.util.LinkedList; import java.util.List; 다음은 위 콜렉션을 가져와 사용한 성능 결과다.\n추가:\n배열 리스트가 직접 만든 리스트보다 앞에 추가 시 빠른 이유는 \u0026lsquo;고속 복사\u0026rsquo;를 사용하기 때문이다. 하지만 데이터가 많아지면 느려진다. 이론적으로 중간에 추가하는 것이 연결 리스트가 빠를 것 같지만, 실제는 배열 리스트가 더 빠르다. 고속 복사를 사용하고 메모리가 연속적이서, CPU 캐시 효율이 좋고 메모리 접근 속도가 빠르기 때문이다. 기능 배열 리스트 연결 리스트 앞에 추가 153ms 12ms 중간에 추가 74ms 1647ms 뒤에 추가 4ms 4ms 삭제\n기능 배열 리스트 연결 리스트 앞에서 삭제 56ms 1ms 평균에서 삭제 24ms 505ms 뒤에서 삭제 3ms 1ms 조회\n기능 배열 리스트 연결 리스트 앞에서 조회 2ms 2ms 중간에서 조회 0ms 569ms 뒤에서 조회 1ms 0ms 검색\n기능 배열 리스트 연결 리스트 맨 앞 값 검색 3ms 0ms 중간 값 검색 166ms 703ms 맨 뒤 값 검색 314ms 1399ms 그래서 앞에서 추가, 삭제가 엄청 많은 경우가 아니라면 ArrayList를 사용하는 것이 훨씬 효율적이다.\n4. 전체 코드 MyArrayList 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 import java.util.Arrays; public class MyArrayList\u0026lt;E\u0026gt; implements MyList\u0026lt;E\u0026gt;{ private static final int DEFAULT_CAPACITY = 10; private Object[] elementData; private int size; public MyArrayList() { elementData = new Object[DEFAULT_CAPACITY]; }; public MyArrayList(int initialCapacity) { elementData = new Object[initialCapacity]; } private void grow() { elementData = Arrays.copyOf(elementData, elementData.length * 2); } @Override public void add(E e) { if (size == elementData.length) { grow(); } elementData[size] = e; size++; } @Override public void add(int index, E e) { if (size == elementData.length) { grow(); } shiftFromLeftToRight(index); elementData[index] = e; size++; } public void shiftFromLeftToRight(int index) { for (int i = size; i \u0026gt; index; i--) { elementData[i] = elementData[i - 1]; } } @Override public E remove(int index) { E oldValue = get(index); shiftFromRightToLeft(index); elementData[--size] = null; return oldValue; } @Override public boolean remove(E e) { int index = indexOf(e); if (index == -1) return false; remove(index); return true; } public void shiftFromRightToLeft(int index) { for (int i = index; i \u0026lt; size; i++) { elementData[i] = elementData[i + 1]; } } @Override public int indexOf(E e) { for (int i = 0; i \u0026lt; size; i++) { if (e.equals(elementData[i])) { return i; } } return -1; } @Override public E get(int index) { return (E) elementData[index]; } @Override public E set(int index, E e) { E oldValue = get(index); elementData[index] = e; return oldValue; } @Override public int size(){ return size; } public boolean isEmpty() { return size == 0; } public boolean contains(E e) { return indexOf(e) \u0026gt;= 0 ? true : false; } @Override public void clear() { elementData = new Object[DEFAULT_CAPACITY]; size = 0; } public Object[] toArray() {return Arrays.copyOf(elementData, size);} @Override public String toString() { return Arrays.toString(Arrays.copyOf(elementData, size)) + \u0026#34; size=\u0026#34; + size + \u0026#34;, capacity=\u0026#34; + elementData.length; } } MyLinkedList 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 import java.util.LinkedList; public class MyLinkedList \u0026lt;E\u0026gt; implements MyList\u0026lt;E\u0026gt;{ private Node\u0026lt;E\u0026gt; first; private int size; @Override public void add(E element) { Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(element); if (size == 0) { first = newNode; } else { Node\u0026lt;E\u0026gt; x = getLastNode(); x.next = newNode; } size++; } @Override public void add(int index, E element) { Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(element); if (index == 0) { newNode.next = first; first = newNode; } else { Node\u0026lt;E\u0026gt; prev = getNode(index - 1); Node\u0026lt;E\u0026gt; next = prev.next; prev.next = newNode; newNode.next = next; } size++; } @Override public E remove(int index) { Node\u0026lt;E\u0026gt; removedNode = getNode(index); E removedItem = removedNode.item; if (index == 0) { first = removedNode.next; } else { Node\u0026lt;E\u0026gt; prev = getNode(index - 1); prev.next = removedNode.next; } removedNode.item = null; removedNode.next = null; size--; return removedItem; } @Override public boolean remove(E item) { Node\u0026lt;E\u0026gt; x = first; Node\u0026lt;E\u0026gt; prev = null; while (x != null) { if (x.item.equals(item)) { break; } prev = x; x = x.next; } if (x == first) { remove(0); return true; } if (x == null) { return false; } prev.next = x.next; x.next = null; x.item = null; size--; return true; } @Override public int indexOf(E element) { Node\u0026lt;E\u0026gt; x = first; int index = 0; while (x != null) { if (x.item.equals(element)) { return index; } x = x.next; index++; } return -1; } @Override public E get(int index) { Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; index; i++) { x = x.next; } return x.item; } public Node\u0026lt;E\u0026gt; getLastNode() { Node\u0026lt;E\u0026gt; x = first; while (x.next != null) { x = x.next; } return x; } public Node\u0026lt;E\u0026gt; getNode(int index) { Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; index; i++) { x = x.next; } return x; } public Node\u0026lt;E\u0026gt; getFirstNode() { return first; } @Override public int size() { return size; } public E set(int index, E item) { Node\u0026lt;E\u0026gt; node = getNode(index); E oldValue = node.item; node.item = item; return oldValue; } @Override public String toString() { StringBuilder sb = new StringBuilder(); sb.append(\u0026#34;[\u0026#34;); Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; size; i++) { sb.append(x.item); if (x.next != null) { sb.append(\u0026#34; -\u0026gt; \u0026#34;); } x = x.next; } sb.append(\u0026#34;]\u0026#34;); return sb.toString(); } @Override public void clear() { for (Node\u0026lt;E\u0026gt; x = first; x != null; ) { Node\u0026lt;E\u0026gt; next = x.next; x.item = null; x.next = null; x = next; } first = null; size = 0; } private static class Node\u0026lt;E\u0026gt; { E item; Node\u0026lt;E\u0026gt; next; Node(E item) { this.item = item; } } } 5. 성능 비교를 위한 코드 전체 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 import MyArrayList; import MyLinkedList; import MyList; public class PerformanceTest { public static void main(String[] args) { int size = 50_000; int loop = 10_000; System.out.println(\u0026#34;----- MyArrayList 추가 -----\u0026#34;); addFirst(new MyArrayList\u0026lt;\u0026gt;(), size); addMid(new MyArrayList\u0026lt;\u0026gt;(), size); MyArrayList\u0026lt;Integer\u0026gt; arrayList = new MyArrayList\u0026lt;\u0026gt;(); addLast(arrayList, size); System.out.println(\u0026#34;\\n----- MyLinkedList 추가 -----\u0026#34;); addFirst(new MyLinkedList\u0026lt;\u0026gt;(), size); addMid(new MyLinkedList\u0026lt;\u0026gt;(), size); MyLinkedList\u0026lt;Integer\u0026gt; linkedList = new MyLinkedList\u0026lt;\u0026gt;(); addLast(linkedList, size); System.out.println(\u0026#34;\\n----- MyArrayList 조회 -----\u0026#34;); get(arrayList, loop, 0); // 맨 앞에서 가져올 때 get(arrayList, loop, size / 2); // 중간에서 가져올 때 get(arrayList, loop, size - 1); // 맨 마지막에서 가져올 때 System.out.println(\u0026#34;\\n----- MyLinkedList 조회 -----\u0026#34;); get(linkedList, loop, 0); // 맨 앞에서 가져올 때 get(linkedList, loop, size / 2); // 중간에서 가져올 때 get(linkedList, loop, size - 1); // 맨 마지막에서 가져올 때 System.out.println(\u0026#34;\\n----- MyArrayList 검색 -----\u0026#34;); search(arrayList, loop, 0); search(arrayList, loop, size / 2); search(arrayList, loop, size - 1); System.out.println(\u0026#34;\\n----- MyLinkedList 검색 -----\u0026#34;); search(linkedList, loop, 0); search(linkedList, loop, size / 2); search(linkedList, loop, size - 1); System.out.println(\u0026#34;\\n----- ArrayList 삭제 -----\u0026#34;); removeFirst(arrayList, loop); // 맨 앞의 값을 삭제할 때 arrayList.clear(); add(arrayList, size); // 데이터 재추가 removeMid(arrayList, loop); // 중간 값을 삭제할 때 arrayList.clear(); add(arrayList, size); // 데이터 재추가 removeLast(arrayList, loop); // 맨 뒷 값을 삭제할 때 System.out.println(\u0026#34;\\n----- LinkedList 삭제 -----\u0026#34;); linkedList.clear(); add(linkedList, size); // 데이터 재추가 removeFirst(linkedList, loop); // 맨 앞의 값을 삭제할 때 linkedList.clear(); add(linkedList, size); // 데이터 재추가 removeMid(linkedList, loop); // 중간 값을 삭제할 때 linkedList.clear(); add(linkedList, size); // 데이터 재추가 removeLast(linkedList, loop); // 맨 뒷 값을 삭제할 때 } private static void addFirst(MyList\u0026lt;Integer\u0026gt; list, int size) { long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; size; i++) { list.add(0, i); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;앞에 추가 - 크기: \u0026#34; + size + \u0026#34; 시간: \u0026#34; + (endTime - startTime) + \u0026#34;ms\u0026#34;); } private static void addLast(MyList\u0026lt;Integer\u0026gt; list, int size) { long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; size; i++) { list.add(i); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;마지막에 추가 - 크기: \u0026#34; + size + \u0026#34; 시간: \u0026#34; + (endTime - startTime) + \u0026#34;ms\u0026#34;); } private static void addMid(MyList\u0026lt;Integer\u0026gt; list, int size) { long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; size; i++) { list.add(i / 2, i); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;중간에 추가 - 크기: \u0026#34; + size + \u0026#34; 시간: \u0026#34; + (endTime - startTime) + \u0026#34;ms\u0026#34;); } private static void add(MyList\u0026lt;Integer\u0026gt; list, int size) { for (int i = 0; i \u0026lt; size; i++) { list.add(0); } } private static void get(MyList\u0026lt;Integer\u0026gt; list, int loop, int index) { long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; loop; i++) { list.get(index); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;조회 - index: \u0026#34; + index + \u0026#34;, 반복 횟수: \u0026#34; + loop + \u0026#34;, 시간: \u0026#34; + (endTime - startTime) + \u0026#34;ms\u0026#34;); } private static void search(MyList\u0026lt;Integer\u0026gt; list, int loop, int valueToFind) { long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; loop; i++) { list.indexOf(valueToFind); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;검색 - valueToFind: \u0026#34; + valueToFind + \u0026#34;, 반복 횟수: \u0026#34; + loop + \u0026#34;, 시간: \u0026#34; + (endTime - startTime) + \u0026#34;ms\u0026#34;); } private static void removeFirst(List\u0026lt;Integer\u0026gt; list, int loop) { long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; loop; i++) { list.remove(0); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;첫 번째 삭제 - 반복 횟수: \u0026#34; + loop + \u0026#34;, 시간: \u0026#34; + (endTime - startTime) + \u0026#34;ms\u0026#34;); } private static void removeMid(List\u0026lt;Integer\u0026gt; list, int loop) { long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; loop; i++) { list.remove(list.size() / 2 - 1); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;중간 삭제 - 반복 횟수: \u0026#34; + loop + \u0026#34;, 시간: \u0026#34; + (endTime - startTime) + \u0026#34;ms\u0026#34;); } private static void removeLast(List\u0026lt;Integer\u0026gt; list, int loop) { long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; loop; i++) { list.remove(list.size() - 1); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;마지막 삭제 - 반복 횟수: \u0026#34; + loop + \u0026#34;, 시간: \u0026#34; + (endTime - startTime) + \u0026#34;ms\u0026#34;); } } ","permalink":"http://jeha00.github.io/post/datastructure/list/","summary":"ArrayList와 LinkedList를 비교해 성능 차이를 확인한다.","title":"[Data structure] List에 대해 설명해 줄게!"},{"categories":"Data Structure \u0026 Algorithum","content":"Introduction 프로그래밍을 하다 보면 데이터를 다루는 때가 많고, 이 데이터를 어떠한 구조로 저장해야 하는지 고민하는 시간이 많다. 이 데이터를 저장하는 구조를 \u0026lsquo;자료 구조\u0026rsquo;라 한다.\n자바를 사용해 여러 자료 구조를 구현해 보며 해당 자료구조의 기능별 시간 복잡도가 어떻게 그렇게 나오는지 \u0026lsquo;설명해 줄게!\u0026rsquo; 시리즈를 연재한다.\n[Data structure] ArrayList를 설명해 줄게! [Data structure] Singly LinkedList를 설명해 줄게! [Data structure] List를 설명해 줄게! [Data structure] Hash를 설명해 줄게! [Data structure] HashSet을 설명해 줄게! [Data structure] Set을 설명해 줄게! [Data structure] Map을 설명해 줄게! [Data structure] Stack을 설명해 줄게! [Data structure] Queue를 설명해 줄게! 1. 연결 리스트 (LinkedList) ArrayList와의 차이점 첫 번째, 메모리가 할당되는 방식이 다르다. ArrayList는 배열을 기반으로 하기 때문에 메모리가 연속적으로 할당된다. 반대로 LinkedList는 노드를 기반으로 하기 때문에 참조를 사용한 연결 방식이므로 메모리가 산발적으로 할당된다. 그래서 ArrayList는 배열의 크기를 동적으로 조절하는 방식이므로 메모리 공간에 있어서 낭비되는 것을 피할 수 없다. LinkedList는 참조 형식으로 필요한 만큼만 메모리를 사용하는 장점이 있다.\n두 번째, 시간복잡도 관점 두 자료 구조의 시간 복잡도 차이는 배열 기반으로 한 임의 접근과 노드 참조 기반으로 한 순차 접근으로 인해 발생된다.\n먼저 LinkedList 중 Singly LinkedList를 기반으로 시간 복잡도를 비교한다.\n기능 배열 리스트 연결 리스트 인덱스 조회 O(1) O(n) 검색 O(n) O(n) 앞에 추가(삭제) O(n) O(1) 뒤에 추가(삭제) O(1) O(n) 중간 추가(삭제) O(n) O(n) 인덱스 조회 배열 리스트는 배열 기반으로 임의 접근(random access)으로 인덱스를 사용해 바로 접근할 수 있어 O(1)로 매우 빠르다. 연결 리스트는 노드 기반으로 임의 접근이 불가능한 순차 접근(sequential access)으로 반드시 순차적으로 접근해야지만 n번째 객체에 접근할 수 있어 O(n)이다. 검색: 배열 리스트와 연결 리스트 모두 처음부터 모든 요소에 접근해야 하므로 O(n)이다. 앞에 추가(삭제) 배열 리스트는 인덱스를 사용해 추가(삭제)할 자리를 바로 찾을 수 있으므로 여기까지는 O(1)이다. 하지만, 앞 또는 중간에 데이터를 추가(삭제)하려면 해당 위치에 공간을 확보해야 한다. 이를 위해 추가할 때는 인덱스가 커지는 방향으로 자리를 확보해야 하므로 O(n)이 걸린다. 삭제할 때는 삭제한 후 빈 공간을 메꿔야 하므로 인덱스가 작아지는 방향으로 값을 다 옮겨야 하므로 O(n)이 걸린다. 연결 리스트는 참조 방식이므로 배열 리스트처럼 자리를 확보한다든가, 자리를 다시 메꾸는 것이 불필요하다. 참조값만 변경하면 추가 또는 삭제가 바로 가능하므로 O(1)이다. 하지만 추가(삭제)하기 위한 자리를 찾기까지 순차 접근을 해야 하므로 O(n)이 걸린다. 만약 추가(삭제)해야 하는 자리가 맨 앞이면 O(1)이므로 총 O(1)이 걸린다. 중간에 추가(삭제) 배열 리스트는 \u0026lsquo;앞에 추가(삭제)하는 경우\u0026rsquo;와 동일하게 총 O(n)이 걸린다. 연결 리스트는 중간 자리까지 탐색해야 하므로 O(n)이 걸리므로 총 O(n)이 걸린다. 맨 뒤에 추가(삭제) 배열 리스트 인덱스로 마지막 위치를 바로 찾을 수 있다: O(1) 마지막에 데이터를 추가하므로 이동하지 않는다: O(1) 따라서 O(1)의 성능을 제공한다. 연결 리스트 노드를 마지막까지 순회해야 마지막 노드를 찾을 수 있다: O(n) 데이터를 추가하는 경우 일부 노드의 참조만 변경하면 된다: O(1) 따라서 O(n)의 성능을 제공한다. Doubly LinkedList도 존재한다.\n이 자료구조의 시간 복잡도는 Singly LinkedList의 코드 구조를 먼저 설명한 후 진행하겠다.\n2. 단일 연결 리스트 구현하기 2.1 Node 구현하기 LinkedList는 노드를 사용한 참조 기반 List이므로 노드를 구현해야 한다. 여기서 고려해야 할 점은 다음과 같다.\nLinkedList만 사용하므로 \u0026lsquo;중첩 클래스\u0026rsquo;로 선언한다. 이때 private으로 선언한다. 이 방식이 유지보수를 하기도 편하다. static을 사용한 이유는 다음과 같다. 노드는 LinkedList의 인스턴스를 통해서만 접근해야 하는 객체가 아니다. 즉, 노드를 생성할 때 상위 클래스에 대한 인스턴스 참조 메모리가 불필요하다. static을 사용하지 않으면 각 노드는 LinkedList의 인스턴스를 계속 참조하게 되어 메모리 낭비가 발생한다. 여러 타입을 사용할 수 있도록 제네릭을 사용한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 public class MyLinkedList\u0026lt;E\u0026gt; { ... private static class Node\u0026lt;E\u0026gt; { E item; Node\u0026lt;E\u0026gt; next; Node(E item) { this.item = item; } } } 한 노드의 값이 다음과 같다고 하자.\nitem next 25(int) x002 위 노드의 의미는 다음과 같다.\nitem은 int로 25이고, next에는 다음 노드의 참조값인 x002를 가지고 있어서 다음 노드로 이동할 수 있다. next에는 예를 들어 실제 아파트가 아닌 아파트의 주소가 들어가 있다고 생각하면 된다. 그래서 ArrayList가 Object[] 를 사용하는 방식과 달리 LinkedList는 여러 노드를 체인(chain)처럼 연결한다.\n2.2 MyLinkedList의 필드 선언 1 2 3 4 5 6 public class MyLinkedList \u0026lt;E\u0026gt; { private Node\u0026lt;E\u0026gt; first; private int size; ... } first: 리스트의 가장 첫 노드를 가리키는 포인트로 사용되는 변수를 의미한다. 이 필드가 있어서 맨 앞쪽 데이터에 바로 접근할 수 있어서 O(1)이 걸린다. 이 필드를 통해서 여러 노드에 접근할 수 있다. size: LinkedList가 가지고 있는 요소의 개수를 의미한다. ❗️last 필드 만약 맨 마지막 노드의 참조값을 가지는 last가 존재한다면 맨 마지막에 값을 추가하는 것도 O(1)이 걸린다. 자바에서 제공하는 LinkedList의 소스 코드를 보면 last 필드를 확인할 수 있다. 이러한 LinkedList를 이중 연결 리스트(Doubly Linked List)라 한다.\n2.3 연결 리스트에 노드 추가하기 요소만을 사용해서 추가하기 1 2 3 4 5 6 7 8 9 10 public void add(E element) { Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(element); if (size == 0) { first = newNode; } else { Node\u0026lt;E\u0026gt; x = getLastNode(); x.next = newNode; } size++; } add(E element) 메서드는 맨 마지막에 새로운 노드를 추가하는 메서드다. size가 0이면 새로 추가하는 노드는 first이므로 first 필드에 새로운 노드 참조값을 저장한다. 만약 size가 0이 아니면 getLastNode 메서드를 사용해 제일 마지막 노드를 조회한 후, 해당 노드의 next 필드에 저장한다.\nadd 메서드에 size에 따라 분기 처리를 한 이유는 이 메서드의 역할의 응집도를 높이기 위해서다. addFirst로 나눌 수 있으나, 이런 경우 함수를 호출할 때 size의 값을 조회한 후 사용해야 하므로 위와 같이 메서드 내에서 분기 처리를 하는 게 더 좋다.\n마지막으로 노드를 추가했으므로 반드시 size 값을 증가시킨다.\n그러면 LinkedList에 노드를 추가해 보자.\n메인 코드 1 2 3 4 5 6 7 8 MyLinkedList list = new MyLinkedList(); System.out.println(list); list.add(\u0026#34;a\u0026#34;); // x001이라 하자. System.out.println(list); list.add(\u0026#34;b\u0026#34;); // x002 list.add(\u0026#34;c\u0026#34;); // x003 list.add(\u0026#34;d\u0026#34;); // x004 System.out.println(list); 결과 1 2 3 [] [a] [a -\u0026gt; b -\u0026gt; c -\u0026gt; d] LinkedList size: 4 index 0(first) 1 2 3 Node x001 \u0026mdash;-(link)\u0026mdash;-\u0026gt; x002 \u0026mdash;-(link)\u0026mdash;-\u0026gt; x003 \u0026mdash;-(link)\u0026mdash;-\u0026gt; x004 item a b c d next x002 x003 x004 null 위치를 지정해서 추가하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public void add(int index, E element) { Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(element); if (index == 0) { newNode.next = first; first = newNode; } else { Node\u0026lt;E\u0026gt; prev = getNode(index - 1); Node\u0026lt;E\u0026gt; next = prev.next; prev.next = newNode; newNode.next = next; } size++; } index가 0이면 first 위치이므로 새로운 노드의 next 값에 기존 first 값을 전달한 후, 기존 first에 새로운 노드의 참조값을 전달한다. 이 순서를 지키지 않으면 새로운 노드의 다음 노드는 자기 자신이 된다.\nindex가 0이 아니면 중간에 노드를 추가해야 한다. 참조값만 변경하면 되므로 해당 인덱스 직전의 노드(prev)와 prev의 다음 노드, next 참조값을 얻는다. 다음으로 아래 순서대로 참조값을 변경한다.\nprev의 다음 노드 참조값을 newNode로 변경 newNode의 다음 노드 참조값을 Node의 next로 지정한다. 배열 리스트보다 요소를 추가하는 것이 매우 쉬운 것을 알 수 있다!\n하지만, getNode() 메서드를 볼 때 알 수 있지만 index까지 순차 접근하므로 O(n)이 걸린다.\n마지막으로 노드를 추가하는 것이기 때문에 size의 값을 증가시킨다.\n아래 같은 상황에서 add(2, \u0026quot;e\u0026quot;)를 실행한다고 하자.\nLinkedList size: 4 index 0(first) 1 2 3 Node x001 \u0026mdash;-(link)\u0026mdash;-\u0026gt; x002 \u0026mdash;-(link)\u0026mdash;-\u0026gt; x003 \u0026mdash;-(link)\u0026mdash;-\u0026gt; x004 item a b c d next x002 x003 x004 null 추가되면 다음과 같이 LinkedList는 변경된다.\nLinkedList size: 5 prev newNode index 0(first) 1 2 3 4 Node x001 \u0026mdash;\u0026ndash;\u0026gt; x002 \u0026mdash;\u0026ndash;\u0026gt; x005 \u0026mdash;\u0026ndash;\u0026gt; x003 \u0026mdash;\u0026ndash;\u0026gt; x004 item a b e c d next x002 x003 -\u0026gt; x005 로 변경 x003 x004 null 2.4 연결 리스트에 노드 제거하기 인덱스로 삭제하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public E remove(int index) { Node\u0026lt;E\u0026gt; removedNode = getNode(index); E removedItem = removedNode.item; if (index == 0) { first = removedNode.next; } else { Node\u0026lt;E\u0026gt; prev = getNode(index - 1); prev.next = removedNode.next; } removedNode.item = null; removedNode.next = null; size--; return removedItem; } 인덱스가 0인 경우, first를 삭제하는 것이기 때문에 first의 다음 노드를 first로 지정하면 원래 first 노드를 참조하는 객체가 없어 GC에 의해 삭제된다.\n인덱스가 0이 아닌 경우, 해당 인덱스 직전의 노드(prev)를 조회해 prev의 다음 노드를 해당 인덱스 노드(removedNode)의 다음 노드(next)로 지정한다. 그러면 removedNode를 참조하는 객체는 존재하지 않아 삭제된다.\n삭제이므로 size의 값을 감소시킨다.\nLinkedList의 상황이 다음과 같다고 하자.\nremove(2)를 수행한다면 어떻게 될까?\ngetNode(2)가 실행되어 removedNode에는 x003이 할당된다. removedItem에는 e가 할당된다. index의 값이 0이 아니므로 else 문에 진입한다. index가 2이므로 getNode(1)이 실행되어 prev에는 x005가 할당된다. prev.next는 x003 노드의 다음 노드인 x004가 할당된다. x003 노드의 item과 next에는 null이 할당된다. size의 값은 5에서 4로 감소된다. LinkedList size: 5 prev removedNode index 0(first) 1 2 3 4 Node x001 \u0026mdash;\u0026ndash;\u0026gt; x002 \u0026mdash;\u0026ndash;\u0026gt; x005 \u0026mdash;\u0026ndash;\u0026gt; x003 \u0026mdash;\u0026ndash;\u0026gt; x004 item a b e c d next x002 x005 x003 x004 null 삭제하면 다음과 같이 변한다.\nLinkedList size: 4 index 0(first) 1 2 3 Node x001 \u0026mdash;\u0026ndash;\u0026gt; x002 \u0026mdash;\u0026ndash;\u0026gt; x003 \u0026mdash;\u0026ndash;\u0026gt; x004 item a b c d next x002 x005 -\u0026gt; x003 로 변경 x004 null removedNode의 값은 다음과 같이 되고 GC에 의해 삭제된다.\nNode x003 item null next null 요소 값으로 삭제하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public boolean remove(E item) { Node\u0026lt;E\u0026gt; x = first; Node\u0026lt;E\u0026gt; prev = null; while (x != null) { if (x.item.equals(item)) { break; } prev = x; x = x.next; } if (x == first) { remove(0); return true; } if (x == null) { return false; } prev.next = x.next; x.next = null; x.item = null; size--; return true; } item을 기준으로 Node를 삭제할 수 있다.\n만약 item과 동일한 값이 없으면 삭제할 수 없으므로 false를 반환한다. item과 동일한 값의 Node(x)가 존재한다면 prev의 next에 x의 next를 할당한다. 만약 x가 first면 첫 인덱스 값을 삭제하는 것이므로 remove(0)을 사용해 삭제한다. 삭제이므로 size의 값을 감소시킨다.\n삭제에 성공했으므로 true를 반환한다.\n❗️ Node 삭제 시 item과 next에 null을 할당하는 이유 첫 번째, A 객체가 다른 객체(B)를 참조하고 있으면 GC(Garbage Collector)는 A가 다른 객체를 강하게 참조한다고 간주해서 메모리 회수를 조금 늦게 한다. 그래서 만약 item이나 next의 값에 null을 할당하면 다른 객체 참조를 하지 않기 때문에 메모리 회수를 더 빠르게 할 수 있다.\n두 번째, LinkedList 같이 노드 기반인 자료 구조는 노드를 삭제해도 삭제된 노드를 다른 노드나 외부에서 참조될 수 있는 가능성이 존재한다. 그러면 계속 메모리에 남아 메모리 누수(Memory Leak)가 발생할 수 있으므로 삭제 시 참조를 끊고 불필요한 객체를 메모리에서 안전하게 제거하기 위해 할당한다.\n세 번째, 데이터 유출 방지 목적도 있다. 메모리에 남으면 삭제되어야 하는 데이터가 유출될 수 있기 때문이다.\n2.5 연결 리스트에서 노드 조회하기 인덱스로 해당 노드의 값 조회하기 1 2 3 4 5 6 7 public E get(int index) { Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; index; i++) { x = x.next; } return x.item; } for 문을 사용해 index만큼 반복을 수행한다. 반복을 수행해 나온 x값이 index 번째에 위치한 Node의 item 값이다.\n마지막 노드 조회하기 1 2 3 4 5 6 7 public Node\u0026lt;E\u0026gt; getLast() { Node\u0026lt;E\u0026gt; x = first; while (x.next != null) { x = x.next; } return x; } 이 메서드는 getNode() 메서드와 size를 사용해 대신할 수 있지만 이와 같이 마지막 노드를 위한 메서드를 만들면 굳이 size 조회를 위한 메서드를 사용할 필요 없이 바로 알 수 있다.\n첫 번째 노드 조회하기 1 2 3 public Node\u0026lt;E\u0026gt; getFirstNode() { return first; } first 필드를 사용해 LinkedList의 첫 번째 노드를 조회한다.\n2.6 기타 메서드 indexOf 1 2 3 4 5 6 7 8 9 10 11 12 public int indexOf(E element) { Node\u0026lt;E\u0026gt; x = first; int index = 0; while (x != null) { if (x.item.equals(element)) { return index; } x = x.next; index++; } return -1; } first의 참조값을 x에 복사하는 이유는 x의 값을 다음 노드로 자체 수정하기 위함이다.\nwhile 반복문을 사용해도 되고 for 반복문을 사용해도 된다. 반복문을 진행하면서 x를 다음 노드로 수정하고, index의 값을 증가시킨다. 만일 x의 item이 element와 동일하면 그때 index를 반환한다.\n동일한 값의 노드를 찾지 못하면 -1을 반환한다.\nset 1 2 3 4 5 6 public E set(int index, E item) { Node\u0026lt;E\u0026gt; node = get(index); E oldValue = node.item; node.item = item; return oldValue; } 특정 인덱스의 노드 item 값을 수정할 때 사용한다. 특정 index의 노드를 조회할 때는 get() 메서드를 사용한다. 그리고 이 노드의 item 속성에 직접 접근해 매개변수로 받은 item을 할당한다.\nsize 1 2 3 public int size() { return size; } LinkedList의 size 값을 알기 위해서 필요하다. 필드는 private으로 선언했기 때문이다. 보안을 위해 이 size를 변경하기 위한 별도의 메서드는 존재하지 않는다.\nclear 1 2 3 4 5 6 7 8 9 10 public void clear() { for (Node\u0026lt;E\u0026gt; x = first; x != null; ) { Node\u0026lt;E\u0026gt; next = x.next; x.item = null; x.next = null; x = next; } first = null; size = 0; } LinkedList 인스턴스에 속한 모든 노드를 삭제한다. 삭제하려면 GC에 의해서 삭제되어야 하므로 각 노드에 접근해 null로 초기화한다. 마지막으로 size도 0으로 초기화한다.\ntoString 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Override public String toString() { StringBuilder sb = new StringBuilder(); sb.append(\u0026#34;[\u0026#34;); Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; size; i++) { sb.append(x.item); if (x.next != null) { sb.append(\u0026#34; -\u0026gt; \u0026#34;); } x = x.next; } sb.append(\u0026#34;]\u0026#34;); return sb.toString(); } LinkedList를 출력할 때 호출되는 메서드다. StringBuilder를 사용하는 이유는 가변형으로 String으로 계속 연산하는 것보다 훨씬 빠르다. String은 하나의 값이 추가될 때 기존 객체에 추가되는 것이 아닌 새로운 객체가 생성되는 불변형이라 연산 속도가 느리다. 문자열 연산을 할 때는 StringBuilder를 사용한 후 toString() 메서드를 사용하는 게 훨씬 빠르다. size 수 만큼 반복문을 수행해 노드의 item 값을 sb에 추가한다. 3. 단일 연결 리스트 전체 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 public class MyLinkedList \u0026lt;E\u0026gt; { private Node\u0026lt;E\u0026gt; first; private int size; public void add(E element) { Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(element); if (size == 0) { first = newNode; } else { Node\u0026lt;E\u0026gt; x = getLastNode(); x.next = newNode; } size++; } public void add(int index, E element) { Node\u0026lt;E\u0026gt; newNode = new Node\u0026lt;\u0026gt;(element); if (index == 0) { newNode.next = first; first = newNode; } else { Node\u0026lt;E\u0026gt; prev = getNode(index - 1); Node\u0026lt;E\u0026gt; next = prev.next; prev.next = newNode; newNode.next = next; } size++; } public E remove(int index) { Node\u0026lt;E\u0026gt; removedNode = getNode(index); E removedItem = removedNode.item; if (index == 0) { first = removedNode.next; } else { Node\u0026lt;E\u0026gt; prev = getNode(index - 1); prev.next = removedNode.next; } removedNode.item = null; removedNode.next = null; size--; return removedItem; } public boolean remove(E item) { Node\u0026lt;E\u0026gt; x = first; Node\u0026lt;E\u0026gt; prev = null; while (x != null) { if (x.item.equals(item)) { break; } prev = x; x = x.next; } if (x == first) { remove(0); return true; } if (x == null) { return false; } prev.next = x.next; x.next = null; x.item = null; size--; return true; } public int indexOf(E element) { Node\u0026lt;E\u0026gt; x = first; int index = 0; while (x != null) { if (x.item.equals(element)) { return index; } x = x.next; index++; } return -1; } public E get(int index) { Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; index; i++) { x = x.next; } return x.item; } public Node\u0026lt;E\u0026gt; getLastNode() { Node\u0026lt;E\u0026gt; x = first; while (x.next != null) { x = x.next; } return x; } public Node\u0026lt;E\u0026gt; getNode(int index) { Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; index; i++) { x = x.next; } return x; } public Node\u0026lt;E\u0026gt; getFirstNode() { return first; } public int size() { return size; } public E set(int index, E item) { Node\u0026lt;E\u0026gt; node = getNode(index); E oldValue = node.item; node.item = item; return oldValue; } public void clear() { for (Node\u0026lt;E\u0026gt; x = first; x != null; ) { Node\u0026lt;E\u0026gt; next = x.next; x.item = null; x.next = null; x = next; } first = null; size = 0; } @Override public String toString() { StringBuilder sb = new StringBuilder(); sb.append(\u0026#34;[\u0026#34;); Node\u0026lt;E\u0026gt; x = first; for (int i = 0; i \u0026lt; size; i++) { sb.append(x.item); if (x.next != null) { sb.append(\u0026#34; -\u0026gt; \u0026#34;); } x = x.next; } sb.append(\u0026#34;]\u0026#34;); return sb.toString(); } private static class Node\u0026lt;E\u0026gt; { E item; Node\u0026lt;E\u0026gt; next; Node(E item) { this.item = item; } } } ","permalink":"http://jeha00.github.io/post/datastructure/linkedlist/","summary":"이번에는 LinkedList에 대해 학습한다!","title":"[Data structure] Singly LinkedList 설명해 줄게!"},{"categories":"Data Structure \u0026 Algorithum","content":"Introduction 프로그래밍을 하다 보면 데이터를 다루는 때가 많고, 이 데이터를 어떠한 구조로 저장해야하는지 고민하는 시간이 많다. 이 데이터를 저장하는 구조를 \u0026lsquo;자료 구조\u0026rsquo;라 한다.\n자바를 사용해 여러 자료 구조를 구현해 보며 해당 자료구조의 기능별 시간 복잡도가 어떻게 그렇게 나오는지 \u0026lsquo;설명해 줄게!\u0026rsquo; 시리즈를 연재한다.\n[Data structure] ArrayList를 설명해 줄게! [Data structure] Singly LinkedList를 설명해 줄게! [Data structure] List를 설명해 줄게! [Data structure] Hash를 설명해 줄게! [Data structure] HashSet을 설명해 줄게! [Data structure] Set을 설명해 줄게! [Data structure] Map을 설명해 줄게! [Data structure] Stack을 설명해 줄게! [Data structure] Queue를 설명해 줄게! 1. 배열(array)의 특징 1.1 인덱스 배열의 가장 큰 특징을 꼽자면 \u0026lsquo;인덱스\u0026rsquo;라 생각한다. 배열은 인덱스를 사용할 수 있다. 인덱스를 사용하면 시간복잡도 O(1)로 여러 작업을 수행할 수 있다. 원하는 자료를 바로 찾을 수 있고, 찾아서 수정할 수 있고, 입력할 수 있다.\n인덱스로 편리한 작업이 가능한 이유는 자료형이 고정적이고 생성되는 메모리 위치가 연속적이므로 참조값을 바탕으로 위치를 계산할 수가 있기 때문이다.\n그러면 인덱스를 통해서 어떻게 바로 접근할 수 있을까?\n예를 들어 요소의 자료형이 int형인 배열이 있고 크기가 5라고 하자. int 형은 4byte다. 그러면 이 배열이 메모리에 위치하는 크기는 총 20 byte다.\n4 byte 4 byte 4 byte 4 byte 4 byte 그러면 각 인덱스에 해당하는 메모리 위치를 다음과 같이 계산할 수 있다.\n인덱스 0의 위치: 참조값(x100) + (4 byte * 0) = x100 인덱스 1의 위치: 참조값(x100) + (4 byte * 1) = x104 인덱스 2의 위치: 참조값(x100) + (4 byte * 2) = x108 인덱스 3의 위치: 참조값(x100) + (4 byte * 3) = x112 인덱스 4의 위치: 참조값(x100) + (4 byte * 4) = x116 이런 식으로 한 번의 연산을 통해 바로 필요한 위치를 구할 수 있어서 시간 복잡도 O(1)이다.\n1.2 배열의 검색 하지만, 인덱스가 있어도 배열에서 필요한 값을 찾을 때는 각 위치에 접근해 데이터를 확인해야 한다. 배열의 크기에 비례해서 오래 걸리므로 시간 복잡도 O(n)이다.\n1.3 배열의 데이터 추가 또한, 인덱스가 있어서 데이터를 추가할 때 오래 걸리기도 한다. 배열에서 데이터를 추가하는 경우는 아래 3가지로 분류할 수 있다.\n맨 뒤에 추가 중간에 추가 맨 앞에 추가 아래와 같은 배열이 있다고 하자. int 형 배열은 값이 0으로 초기화된다.\n0 0 0 0 0 위 값을 1, 2, 3, 4, 0으로 초기화하자.\n1 2 3 4 0 맨 뒤에 추가하는 경우 배열의 크기에 여유가 있다면 맨 마지막에 바로 추가할 수 있어서 O(1)이다. 배열의 크기가 정해져 있으므로 1을 뺀 값이 맨 마지막 인덱스다. 인덱스를 사용해 맨 뒤에 5를 추가하자.\n추가한 배열의 상태는 다음과 같다.\n1 2 3 4 5 코드로 구현하면 다음과 같다.\n1 2 3 void addLast(int[] arr, int newValue) { arr[arr.length - 1] = newValue; } 중간에 추가하는 경우 배열의 위치를 찾는 데 O(1)이 걸린다. 인덱스 2에 값 6을 추가한다면 인덱스 2부터의 값들을 뒤로 한 칸씩 밀어야 한다. 맨 마지막 5 값은 배열의 크기를 넘기 때문에 배열에서 삭제된다.\n1 2 3 4 -\u0026gt; 3 5 -\u0026gt; 4 인덱스를 사용해 6을 추가한다.\n1 2 6 3 4 이 경우에 시간복잡도는 다음과 같다.\n배열의 위치를 찾는 데는 O(1)이 걸린다. 하지만 해당 인덱스의 오른쪽에 있는 데이터를 모두 한 칸씩 이동해야 하므로 O(n/2)이 된다. 총 O(1 + n/2) 이지만, 빅오 계산법은 상수를 무시하므로 O(n)이 된다. 만약 중간 인덱스에 추가가 아닌 덮어씌우는 거라면 배열의 위치를 찾고 바로 삽입하면 되므로 O(1)이 된다.\n코드로 구현하면 다음과 같다.\n1 2 3 4 5 6 void addAtIndex(int[] arr, int index, int newValue) { for (int i = arr.length - 1; i \u0026gt; index; i--){ arr[i] = arr[i - 1]; } arr[index] = newValue; } 맨 앞에 추가하는 경우 이번에는 맨 앞에 데이터를 추가해 보자.\n맨 앞에 3를 추가하기 위해 모든 데이터를 한 칸씩 이동한다.\n1 2 - \u0026gt; 1 6 - \u0026gt; 2 3 -\u0026gt; 6 4 -\u0026gt; 3 그 후, 인덱스 0을 사용해 값 3를 추가한다.\n3 1 2 6 3 이 경우, 시간 복잡도는 다음과 같다.\n배열의 위치를 찾는 데 O(1)이 걸린다. 배열의 크기만큼 데이터를 한 칸씩 뒤로 옮기므로 O(n)이 걸린다. 총 O(1 + n)이지만, 빅오이므로 O(n)으로 표기한다. 이처럼 배열은 어디에 데이터를 추가하냐에 따라서 시간 복잡도가 많이 다르다.\n코드로 구현하면 다음과 같다.\n1 2 3 4 5 6 void addFirst(int[] arr, int newValue) { for (int i = arr.length - 1; i \u0026gt; 0; i--) { arr[i] = arr[i - 1]; } arr[0] = newValue; } 1.4 배열의 제일 큰 단점 무엇보다 배열의 큰 단점은 크기를 바꿀 수 없다는 점이다. 미리 여유 있게 큰 크기로 지정할 수 있지만, 더 데이터가 필요하면 이후 새로 생기는 데이터를 추가할 수 없다는 문제점이 생긴다. 그렇다고 너무 큰 배열을 처음부터 확보하면 메모리가 많이 낭비된다.\n그래서 배열처럼 처음부터 정적으로 크기가 정해져 있는 것이 아니라, 언제든지 길이를 늘일 수 있는 자료구조인 리스트(list)가 필요하다.\n1.5 배열 정리 배열의 장점 순서가 있어서 인덱스를 사용할 수 있다. 값을 중복으로 저장할 수 있다. 맨 뒤에 데이터를 추가하는 경우 O(1)이 걸린다. 배열의 단점 크기가 고정적이다. 맨 앞, 중간에 데이터를 추가하는 경우 O(n)이 걸린다. 2. 배열리스트(ArrayList) 2.1 배열과 리스트 배열과 리스트의 차이 이번 섹션에서는 배열리스트에 대해 알아볼 것이다. 배열은 앞서 언급한 대로 순서가 있고, 중복을 허용하지만 크기가 정적으로 고정되어 있다. 리스트도 순서가 있고 중복을 허용하지만 배열과의 차이점은 크기가 동적으로 변할 수 있다.\n리스트의 종류와 메모리 할당 방식의 차이점 이 배열의 단점을 해결하는 리스트 자료 구조를 만들어보자. 리스트도 두 종류: ArrayList와 LinkedList가 있다. ArrayList는 배열을 기반으로 만들어진 리스트다. LinkedList는 배열이 아닌 노드(Node) 기반으로 만들어진 리스트다.\n기반이 되는 구조가 달라서 메모리가 할당되는 방식이 다르다. ArrayList는 배열을 기반으로 하는 만큼 메모리가 연속적으로 할당된다. 하지만 LinkedList는 노드를 기반으로 해서 메모리가 산발적으로 할당된다. 둘 다 객체에 대한 참조값을 요소로 가지지만, 연속적이냐 산발적이냐로 차이가 있다. 그리고 둘 다 heap 영역에 생성된다.\nArrayList 자료구조 특징 요약 연속적인 데이터 리스트 내부적으로 Object[] 배열을 이용해 요소를 저장 배열을 사용하므로 인덱스로 \u0026lsquo;요소에 빠르게 접근\u0026rsquo;할 수 있다. 크기가 고정된 배열과 달리 데이터양에 따라 동적으로 늘릴 수 있다. 이때, 현재 배열보다 더 큰 크기의 배열에 복사하기 대문에 지연이 발생할 수 있다. 시간 복잡도: 데이터를 맨 뒤에 추가 및 삭제할 때 성능이 좋고, 앞이나 중간에 데이터를 추가 삭제할 때 비효율적이다. 데이터 추가 마지막 추가: 제일 마지막으로 인덱스를 통한 접근이 가능해 O(1) 앞, 중간 삭제: 데이터 추가를 위해 요소를 뒤로 밀어내기 때문에 O(n) 데이터 삭제 마지막 삭제: 제일 마지막으로 인덱스를 통한 접근이 가능해 O(1) 앞, 중간 삭제: 삭제 후, 요소를 앞으로 댕기기 때문에 O(n) 인덱스 조회: 인덱스를 사용하므로 O(1) 데이터 검색: 모든 배열을 순회하며 일치 여부를 확인하기 때문에 O(n) 3. 배열리스트 구현해 보기 그러면 배열리스트를 직접 간략히 구현해 보자. 직접 만드는 배열리스트를 MyArrayList 라고 명명하겠다.\nMyArrayList의 전체 코드는 이 포스팅 제일 마지막에 둔다.\n3.1 필드 속성 정의하기 1 2 3 4 private static final int DEFAULT_CAPACITY = 5; private Object[] elementData; private static final Object[] EMPTY_ELEMENTDATA = {}; private int size; 내부 속성에 외부에서 접근하지 못하도록 모두 private으로 지정한다. DEFAULT_CAPACITY: 리스트 생성 시, 기본 할당 용량 10으로 지정한다. 기본 생성자를 통해 객체 생성 시 위 변수에 접근할 수 있도록 static 으로 클래스 변수로 선언한다. 변경되지 않도록 final로 선언한다. elementData: 실제 MyArrayList에 추가하는 데이터를 담는 배열 객체 다양한 타입의 데이터를 보관하기 위해 Object배열을 사용한다. 제네릭을 사용한 E[]로 선언이 불가능하다. size: 현재 elementData 저장된 요소의 총개수 여기서 주목할 것은 size 변수다. size는 실제 elementData의 크기와 다르다는 것이다. 다음과 같은 Object[] elementData가 있다고 하자.\nindex 0 1 2 3 4 5 6 7 8 value x100 x104 x108 x112 null null null null null 위 배열의 크기는 9이지만, 실제로 값이 있는 개수는 4개다. 그래서 size의 값은 4다. 현재 보유하고 있는 요소의 개수 정보를 알면 좋은 이유는 리스트는 여유 있게 배열 크기를 증가시키기 때문에, 정확한 수량을 알 수 없다는 문제가 있는데 이 변수를 사용해 실제 요소 개수를 알 수 있다.\n이 size 값으로 배열의 크기를 늘릴지를 이 값을 기준으로 판단한다. null 값이 있는 위치를 피해서 접근할 수 있으므로 NullPointerException 발생을 막을 수 있다는 것이다. 값을 추가할 때나 삭제할 때 배열은 한 방향으로 밀어내는 작업이 필요한데, 이 size를 사용해서 작업을 수행할 수 있다. 새로 추가할 값의 인덱스를 의미하기도 하다. 3.2 생성자 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public MyArrayList() { elementData = new Object[DEFAULT_CAPACITY]; }; public MyArrayList(int initialCapacity) { if (initialCapacity \u0026gt; 0) { this.elementData = new Object[initialCapacity]; } else if (initialCapacity == 0) { this.elementData = EMPTY_ELEMENTDATA; } else { throw new IllegalArgumentException(\u0026#34;Illegal Capacity: \u0026#34;+ initialCapacity); } } 자바의 ArrayList를 보면 오버로딩을 사용해 생성자에 인자가 있는 경우와 없는 경우 모두 존재한다. 인자가 있으면 정수형 인자 값만큼 배열의 크기를 결정하지만, 없으면 기본으로 설정된 크기(DEFAULT_CAPACITY)로 결정된다. 만약 음수면 예외를 발생시키도록 설계한다.\n유의사항: 제네릭 기반 배열 생성을 하지 않는 이유 여기서 유의해야 할 사항은 new Object[] 다. new E[]를 하는 게 나중에 타입 캐스팅을 하지 않아도 된다\u0026rsquo; 라고 생각할 수 있지만, 제네릭에는 new 예약어를 사용할 수 없다. 그 이유는 제네릭은 런타임 시, 이레이저에 의해 타입 정보가 사라지므로 런타임에 타입 정보가 필요한 생성자에는 사용할 수 없다. 만약 제네릭 기반으로 생성하는 코드를 작동하면 컴파일 오류가 발생한다. 그래서 모든 데이터를 담을 수 있는 Object를 그대로 사용해야 한다.\n3.3 grow() 메서드 1 2 3 private void grow() { elementData = Arrays.copyOf(elementData, elementData.length * 2); } 이 메서드가 배열과 리스트의 가장 큰 차이점인 동적 크기 변화를 만든다. 이 메서드는 다음과 같은 조건일 때 실행된다.\n1 2 3 if (elementData == size) { grow() } 현재 보유하고 있는 요소 개수가 배열 크기와 동일하면 실행해 크기를 동적으로 늘린다.\n3.4 add 구현하기 add는 자료를 추가하는 데 사용하는데 add(E e)와 add(int index, E e) 메서드가 존재한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public void add(E e) { add(size, e) } public void add(int index, E e) { if (size == elementData.length) { grow(); } shiftFromLeftToRight(index); elementData[index] = e; size++; } public void shiftFromLeftToRight(int index) { for (int i = size; i \u0026gt; index; i--) { elementData[i] = elementData[i - 1]; } } add(int index, E e) 메서드 index 위치에 e를 추가하는 메서드다. shiftFromLeftToRight() 메서드 index 위치에 빈 공간을 만들어 값을 추가하려면 요소를 뒤쪽으로 이동시켜야 한다. 그림으로 보면 왼쪽에서 오른쪽으로 이동시켜야 할 때 이 메서드를 사용한다. 옮기기 전 요소의 최대 인덱스는 \u0026lsquo;size - 1\u0026rsquo;이고 오른쪽으로 이동하므로 int i = size에서 시작한다. size의 값이 elementData의 길이와 동일하면 grow() 메서드를 실행한다. 여기서 주목할 점은 size를 인덱스로 사용해서 새로 추가하는 데이터가 들어갈 인덱스를 의미한다. 데이터가 새로 추가되어 size의 값을 증가시키면 이후 다시 새로 추가되는 데이터의 인덱스를 의미한다. 아래 리스트 상태에서 인덱스 1에 값을 추가한다고 하자. (length: 5, size: 3) index 0 1 2 3 4 value \u0026lsquo;A\u0026rsquo; \u0026lsquo;B\u0026rsquo; \u0026lsquo;C\u0026rsquo; null null shiftFromLeftToRight()에 의해서 값이 오른쪽으로 밀린다. index 0 1 2 3 4 value \u0026lsquo;A\u0026rsquo; \u0026lsquo;B\u0026rsquo; \u0026lsquo;C\u0026rsquo; -\u0026gt; \u0026lsquo;B\u0026rsquo; null -\u0026gt; \u0026lsquo;C\u0026rsquo; null 그 다음 값을 추가한다. (length:5, size: 4) index 0 1 2 3 4 value \u0026lsquo;A\u0026rsquo; \u0026lsquo;D\u0026rsquo; \u0026lsquo;B\u0026rsquo; \u0026lsquo;C\u0026rsquo; null add(E e) 메서드 index를 입력받지 않으면 제일 마지막에 데이터를 넣는다.\n위 상태에서 add(E e) 메서드를 실행하면 size가 3을 의미하므로 인덱스 3에 새로운 요소가 추가된다. (length: 5, size: 4)\nindex 0 1 2 3 4 value \u0026lsquo;A\u0026rsquo; \u0026lsquo;B\u0026rsquo; \u0026lsquo;C\u0026rsquo; null -\u0026gt; \u0026lsquo;D\u0026rsquo; null 3.5 remove 구현하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public E remove(int index) { E oldValue = get(index); shiftFromRightToLeft(index); elementData[--size] = null; return oldValue; } public boolean remove(E e) { int index = indexOf(e); if (index == -1) return false; remove(index); return true; } public void shiftFromRightToLeft(int index) { for (int i = index; i \u0026lt; size; i++) { elementData[i] = elementData[i + 1]; } } public int indexOf(E e) { for (int i = 0; i \u0026lt; size; i++) { if (e.equals(elementData[i])) { return i; } } return -1; } remove는 요소를 삭제하는 데 사용하며, remove(int index) 와 remove(E e) 가 있다.\nremove(int index) 메서드 이 메서드는 특정 인덱스의 요소를 삭제합니다. add() 메서드 방식을 거꾸로 구현하면 된다.\n삭제의 경우, 삭제한 인덱스 이후 요소들을 앞으로 댕겨야 하므로 shiftFromRightToLeft() 메서드를 사용한다. 이 메서드도 size 변수를 사용한다. 단 shiftFromLeftToRight()와 달리 인덱스가 커지는 방향으로 진행한다.\n사용 예시를 보자.\nindex 0 1 2 3 4 value \u0026lsquo;A\u0026rsquo; \u0026lsquo;B\u0026rsquo; \u0026lsquo;C\u0026rsquo; \u0026lsquo;D\u0026rsquo; null 위 상태(크기: 5, size: 4)에서 remove(1)을 실행한다.\nindex 0 1 2 3 4 value \u0026lsquo;A\u0026rsquo; \u0026lsquo;B\u0026rsquo; -\u0026gt; \u0026lsquo;C\u0026rsquo; \u0026lsquo;C\u0026rsquo; -\u0026gt; \u0026lsquo;D\u0026rsquo; \u0026lsquo;D\u0026rsquo; -\u0026gt; null null 결과 (크기: 5, size: 3)\nindex 0 1 2 3 4 value \u0026lsquo;A\u0026rsquo; \u0026lsquo;C\u0026rsquo; \u0026lsquo;D\u0026rsquo; null null remove(E e) 메서드 이 메서드는 특정 요소의 값을 기준으로 삭제한다. 하지만 내부 코드를 보면 다음 순서로 진행된다.\nindexOf() 메서드를 사용해 E e가 위치한 인덱스 값을 얻는다. 얻은 인덱스 값을 remove(int index)에 전달해 삭제하고 true를 반환한다. 만약 얻은 인덱스 값이 -1이면 false를 반환한다. indexOf(E e) 메서드 indexOf() 메서드는 전달한 인자와 제일 첫 번째로 일치하는 요소의 인덱스를 반환한다. 일치 여부는 equals() 메서드를 사용하는데, 이 메서드의 기준은 e 객체 내부에서 오버라이딩한 것을 기준으로 사용한다. 여기서 equals()를 사용하는 이유는 논리적으로 같은 것을 찾기 때문이다(동등성). 논리적으로 같아도 동일하지 않을 수 있기 때문이다. 바로 동일한 것을 찾고 싶다면 ==을 사용한다. get / set 구현하기 1 2 3 4 5 6 7 8 9 public E get(int index) { return (E) elementData[index]; } public E set(int index, E e) { E oldValue = get(index); elementData[index] = e; return oldValue; } get() 메서드로 가져올 때는 Object로 저장했기 때문에 E로 형 변환을 한 후 가져 와야 한다. set() 메서드는 get() 메서드로 이전 값을 가져온 후 설정한다. 기타 요소 구현하기 1 2 3 4 5 6 7 8 9 10 11 public void clear() { elementData = new Object[DEFAULT_CAPACITY]; size = 0; } public Object[] toArray() {return Arrays.copyOf(elementData, size);} @Override public String toString() { return Arrays.toString(Arrays.copyOf(elementData, size)) + \u0026#34; size=\u0026#34; + size + \u0026#34;, capacity=\u0026#34; + elementData.length; } size 구현하기 1 2 3 public int size(){ return size; } size 필드는 private이므로 별도의 메서드를 만들어야 클라이언트에서 접근이 가능하다. size가 public이면 외부에서 수정할 경우, 내부 데이터 수와 일치하지 않을 수 있어서 MyArrayList 동작이 이상해버릴 수 있다.\nisEmpty 구현하기 1 2 3 public boolean isEmpty() { return size == 0; } size의 값이 0과 일치하는지 확인해서 리스트가 비어있는지, 아닌지를 확인하는 메서드다.\ncontains 구현하기 1 2 3 public boolean contains(E e) { return indexOf(e) \u0026gt;= 0 ? true : false; } 특정 요소의 존재 유무를 확인하는 메서드다. indexOf는 특정 요소의 인덱스 값을 확인하는 것이므로 다르다. 하지만,indexOf 메서드를 사용해 존재 유무를 확인할 수 있다. indexOf는 값이 존재하면 0 이상의 인덱스를 반환하므로 이에 따라 삼항 연산자를 사용해 true를, 0 미만은 false를 반환하면 된다.\nclear 구현하기 1 2 3 4 public void clear() { elementData = new Object[DEFAULT_CAPACITY]; size = 0; } 모든 요소들을 지우기 위해 반복문으로 순회하며 null을 대입할 수도 있지만, 새로운 배열을 넣어주면 훨씬 간단하다. size도 0으로 수정한다.\ntoString 구현하기 1 2 3 4 @Override public String toString() { return Arrays.toString(Arrays.copyOf(elementData, size)) + \u0026#34; size=\u0026#34; + size + \u0026#34;, capacity=\u0026#34; + elementData.length; } toString 메서드를 만들지 않으면 객체를 출력할 때 리스트와 관련된 내부 값 정보를 확인할 수 없다. 다만, elementData의 모든 값을 보여줄 필요 없이 실제 있는 값만 보여주면 되기 때문에 Arrays.copyOf(elementData, size)를 실행하면 된다.\n제네릭을 도입한 이유 Object로 지정하면 모든 타입을 받을 수 있다.\n내가 원하는 타입을 별도의 지정 없이 다 받을 수 있다. 내가 원하지 않는 타입도 다 받을 수 있다. 그래서 \u0026lsquo;타입 안전성\u0026rsquo;이 좋지 않다.\n또한 반환값이 Object이므로 내가 원하는 타입을 사용하려면 반드시 다운 캐스팅을 해야 한다.\n위 두 가지 이유로 제네릭을 도입했다.\n배열리스트 전체 코드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 public class MyArrayList\u0026lt;E\u0026gt; { private static final int DEFAULT_CAPACITY = 10; private Object[] elementData; private int size; public MyArrayList() { elementData = new Object[DEFAULT_CAPACITY]; }; public MyArrayList(int initialCapacity) { elementData = new Object[initialCapacity]; } private void grow() { elementData = Arrays.copyOf(elementData, elementData.length * 2); } public void add(E e) { if (size == elementData.length) { grow(); } elementData[size] = e; size++; } public void add(int index, E e) { if (size == elementData.length) { grow(); } shiftFromLeftToRight(index); elementData[index] = e; size++; } public void shiftFromLeftToRight(int index) { for (int i = size; i \u0026gt; index; i--) { elementData[i] = elementData[i - 1]; } } public E remove(int index) { E oldValue = get(index); shiftFromRightToLeft(index); elementData[--size] = null; return oldValue; } public boolean remove(E e) { int index = indexOf(e); if (index == -1) return false; remove(index); return true; } public void shiftFromRightToLeft(int index) { for (int i = index; i \u0026lt; size; i++) { elementData[i] = elementData[i + 1]; } } public int indexOf(E e) { for (int i = 0; i \u0026lt; size; i++) { if (e.equals(elementData[i])) { return i; } } return -1; } public E get(int index) { return (E) elementData[index]; } public E set(int index, E e) { E oldValue = get(index); elementData[index] = e; return oldValue; } public int size(){ return size; } public boolean isEmpty() { return size == 0; } public boolean contains(E e) { return indexOf(e) \u0026gt;= 0 ? true : false; } public void clear() { elementData = new Object[DEFAULT_CAPACITY]; size = 0; } public Object[] toArray() {return Arrays.copyOf(elementData, size);} @Override public String toString() { return Arrays.toString(Arrays.copyOf(elementData, size)) + \u0026#34; size=\u0026#34; + size + \u0026#34;, capacity=\u0026#34; + elementData.length; } } ","permalink":"http://jeha00.github.io/post/datastructure/arraylist/","summary":"배열과 리스트의 차이를 학습한 후 배열기반 리스트인 ArrayList를 학습한다.","title":"[Data structure] ArrayList를 설명해 줄게!"},{"categories":"java","content":"모든 객체는 Object를 상속받는다고? 모든 객체는 Object 객체를 상속받으므로 최종 부모는 Object야.\n모든 객체는 Object 객체를 상속받는다. 어떤 객체도 최상위로 올라가면 Object 객체로 끝난다. 마치 파이썬의 type 클래스처럼 말이다.\n\u0026ldquo;에\u0026hellip;? 그런데 자바에서 사용자 정의 자료형인 클래스를 사용해 객체를 생성할 때 extends를 사용해 Object라는 객체를 상속받지 않아~\u0026rdquo;\n이렇게 생각들 수 있다. 왜냐하면 상속도 명확히 드러내서 하는 상속(명시적 상속) 과 드러내지 않고 진행되는 상속(묵시적 상속) 이 있기 때문이다. 명시적 상속은 이름에서 추측할 수 있듯이 여태 배운 상속하는 방법인 extends를 사용하는 상속이다. 그렇다면 대조적으로 \u0026lsquo;묵시적 상속\u0026rsquo;은 extends를 입력하지 않는 것을 알 수 있다. 즉, 입력하지 않아도 컴파일러가 extends Object 코드를 알아서 넣어주기 때문에 Object를 상속받는다. Object가 최상위이므로 null이 출력되는 것을 알 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Test { public static void main(String[] args) { Integer value = new Integer(1); Class cls = value.getClass(); Class superCls = cls.getSuperclass(); Class superSuperCls = superCls.getSuperclass(); System.out.println(cls); System.out.println(superCls); System.out.println(superSuperCls); System.out.println(superSuperCls.getSuperclass()); } } 1 2 3 4 5 # 출력 결과 class java.lang.Integer class java.lang.Number class java.lang.Object null 그러면 모든 클랙스가 상속받는 최상위 클래스를 만든 이유가 뭐야? 2가지 이유로 공통 기능을 제공하고, 다형성을 구현하기 위해서야\n공통 기능 제공하기 객체를 만들어 사용하다 보면 모든 객체에 필요한 공통된 기능이 있다는 것을 알 수 있다. 이 기능을 미리 만들어놓고 상속을 받아 사용한다면 재사용성이 높을 것이다. 하지만, 이런 기능을 객체를 만들 때마다 항상 새로운 메서드로 정의해서 만든다면 상당히 번거롭다. 또한, 만든다고 해도 개발자마다 일관성이 없을 것이다. 어떤 개발자는 toString() 이라 하고, 다른 개발자는 representString() 으로 다른 이름으로 만들 수 있다.\n그래서 Object 라는 최상위 객체를 만들어 모든 객체에 필요한 공통 기능을 제공할 수 있다.\nObject 객체가 제공하는 것 중 대표적으로는 다음 3가지를 꺼낼 수 있다.\ntoString(): 객체의 정보를 표현하는 것 equals(): 객체의 같음을 비교하는 것 getClass(): 객체의 클래스 정보를 제공하는 것 hashcode(): 객체 참조값을 해쉬화해 고유 id를 생성한다. 다형성 구현하기 Object 객체는 최상위 객체이기 때문에 어떠한 객체도 담을 수 있다.\nObject 배열에 모든 타입을 담을 수 있다. 매개변수 타입을 Object로 지정하면 모든 객체를 수용할 수 있다. 1 2 3 4 5 Integer integer = new Integer(1); String str = new String(\u0026#34; \u0026#34;); Character chr = new Character(\u0026#39; \u0026#39;); Object[] objects = {integer, str, chr}; 하지만 한계가 있다. 특정 객체의 메서드를 사용하려면 먼저 해당 객체 타입으로 타입 캐스팅해야 한다. 왜냐하면 다른 객체의 메서드가 정의되어 있지 않아, 메서드 오버라이딩을 활용할 수 없다. 지정된 타입부터 속성과 메서드를 조회하기 때문이다.\n아래 코드는 컴파일 에러가 발생한다.\n1 2 3 public static void print(Object object, int i) { System.out.println(object.charAt(i)); } 1 Cannot resolve method \u0026#39;charAt\u0026#39; in \u0026#39;Object\u0026#39; 다음과 같이 다운 캐스팅을 진행한 후, 사용하면 컴파일 에러가 발생하지 않는다.\n1 2 3 4 public static void print(Object object, int i) { String value = (String) object; System.out.println(value.charAt(i)); } 하지만, Object 객체에서 제공하는 메서드를 오버라이딩한다면 가능하다. 예를 들어 toString() 이나 equals()를 오버라이딩하면 Object 객체로 받아도 오버라이딩된 메서드가 실행된다.\nPerson 객체를 생성해 본다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class Person { String name; Person(String name) { this.name = name; } @Override public String toString() { return \u0026#34;Person{\u0026#34; + \u0026#34;name=\u0026#39;\u0026#34; + name + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } main() 메서드에서 실행한다.\n1 2 3 4 5 6 7 8 public static void main(String[] args) { Person person = new Person(\u0026#34;철수\u0026#34;); print(person) } public static void print(Object object) { System.out.println(object); } 1 Person{name=\u0026#39;철수\u0026#39;} Object 객체가 제공하는 메서드에 대해 알아보자. toString() 파이썬의 __str__() 메서드처럼 객체 정보를 문자열 형태로 제공하는 메서드다. System.out.println() 이나 System.out.print()에 객체 참조값을 전달하면 전달된 객체 내에서 toString()을 호출한다.\nequals(): 동일성과 동등성 프로그래밍에서 \u0026lsquo;객체가 같다\u0026rsquo;는 의미는 2가지로 분리해서 볼 수 있다.\n동일성: == 연산자를 사용해서 두 객체의 참조값이 동일한지를 비교 동등성: equals() 메서드를 사용해 두 객체가 논리적으로 동일한지 비교 1 2 3 4 String str01 = new String(\u0026#34;철수\u0026#34;); String str02 = new String(\u0026#34;철수\u0026#34;); System.out.println(str01 == str02); System.out.println(str01.equals(str02)); 위 두 객체를 기준으로 설명하자면 두 객체는 동등하지만 동일하지 않다.\nString처럼 자바에서 원래 있는 자료형이 아닌 사용자가 만든 자료형이면 어떨까?\nPerson 객체를 만들어보자. 속성은 String 타입의 name 필드만 존재한다.\n1 2 3 4 5 6 7 public class Person { public String name; Person(String name){ this.name = name; } } 그리고 인텔리제이의 도움을 받아 equals() 메서드를 구현한다. 도움을 받는 이유는 이 메서드를 정확히 구현하는 것은 쉽지 않다. 아래 규칙을 다 지켜야 한다.\n반사성: 객체는 자기 자신과 동등해야 한다. x.equals(x) 는 항상 true 다. 대칭성: 두 객체가 서로에 대해 동일하면, 양방향으로 동일해야 한다. x.equals(y)가 true면, y.equals(x)도 true여야 한다. 추이성: 한 객체가 두 번째 객체와 동일하고, 두 번째가 세 번째 객체와 동일하면 첫 번째와 세 번째도 동일해야 한다. 일관성: 객체의 상태가 변경되지 않는 한 항상 동일한 값을 반환해야 한다. null에 대한 비교: 모든 객체는 null과 비교했을 때 false를 반환해야 한다. 그래서 IDE가 만들어주는 것을 대부분 사용한다.\n요약 모든 객체의 최상위 객체는 Object 객체이다. extends Object로 명시적으로 입력하지 않아도 컴파일러가 알아서 입력한다. 최상위 객체가 존재하는 이유는 모든 객체에 특정 메서드들을 공통으로 제공하기 위해서고, 다형성을 구현하기 위해서다.\n타입을 Object로 지정하면 모든 객체를 받을 수 있다. 만약 최상위 객체가 제공하는 메서드를 오버라이딩하는 객체를 생성한다면 Object 타입으로 전달해도 오버라이딩된 메서드가 실행된다. 만약 오버라이딩된 메서드가 없다면 실행하고 싶은 메서드를 가지고 있는 객체로 다운캐스팅을 한 후, 실행해야 한다.\n","permalink":"http://jeha00.github.io/post/java/7_object/","summary":"Object 클래스가 있어야 하는 이유를 정리해보자.","title":"모든 객체가 Object를 상속받아야 하는 이유"},{"categories":"java","content":"최근에 자바를 학습하기 시작하면서 한 예제를 풀어보았다.\n\u0026lsquo;이 예제를 풀었으니 다른 예제를 풀어볼까?\u0026rsquo; 했으나 자바는 객체 지향이 강한 언어라는 특성을 알게 되어 객체 지향 원칙에 대해 조금씩 공부해가고 있다.\n그래서 풀은 이 예제에 객체지향 5원칙 중 \u0026lsquo;단일 책임 원칙\u0026rsquo;인 SRP, Single Responsibility Principle을 적용해보려 한다.\n문제 요구사항 내가 풀은 문제의 요구사항은 다음과 같다.\n문제 이름은 \u0026lsquo;선택한 식재료 총 구매 금액 구하기\u0026rsquo; 다.\n식재료의 종류에는 1) 감자, 2) 옥수수, 3) 수박이 있다. 3가지 중 하나를 입력받아야 한다. 1)을 선택하면 \u0026lsquo;1번 감자를 선택하셨습니다.\u0026rsquo; 라는 문구가 떠야 한다. 나머지 2번과 3번도 동일하다. 식재료를 선택한 후, 식재료에 따라 식재료 가격대를 입력받아야 한다. 이 가격대는 식재료마다 다르다. 감자: 1000원, 2000원, 3000원 옥수수: 4000원, 5000원, 6000원 수박: 10000원, 20000원, 30000원 가격대를 선택하며 예를 들어 \u0026lsquo;감자 1000원어치를 선택하셨습니다.\u0026rsquo; 라는 문구가 출력되야 한다. 그 후, 주문 갯수를 입력받은 후 총 구매 금액을 출력하라. 단일 책임 원칙 미적용 코드 그러면 이 코드를 단일 책임 원칙을 적용하기 전 코드부터 살펴보자. 단 이 코드에는 제약을 두고 작성했다.\nArray, class는 사용하지 못한다. 변수 선언 및 초기화, 조건문, 입력, 메서드만을 사용한다. 자바를 학습하는 과정에서 작성한 코드임을 기억해주시면 감사하겠다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 import java.util.Scanner; public class OrderIngredient { public static void main(String[] args) { int optionForItem, price; String itemName; price = 0; optionForItem = chooseOption(); if (optionForItem == 1) { itemName = \u0026#34;감자\u0026#34;; price = choosePrice(itemName, price); } else if (optionForItem == 2) { itemName = \u0026#34;옥수수\u0026#34;; price = choosePrice(itemName, price); } else { itemName = \u0026#34;수박\u0026#34;; price = choosePrice(itemName, price); } int amount = chooseAmount(itemName, price); System.out.println(itemName + \u0026#34; \u0026#34; + price + \u0026#34;원 어치를 총 \u0026#34; + amount + \u0026#34;개 주문하셨습니다.\u0026#34;); } // 식재료를 선택하는 역할: 받는 인자값은 없고, 선택된 메뉴 번호를 반환 public static int chooseOption() { Scanner input = new Scanner(System.in); System.out.println(\u0026#34;다음 세 가지 중 고르시오.\u0026#34;); System.out.println(\u0026#34;1. 감자. 2. 옥수수. 3. 수박.\u0026#34;); return input.nextInt(); } // 가격 선택 인터페이스를 제공하는 역할 public static int choosePrice(String itemName, int price) { if (itemName.equals(\u0026#34;감자\u0026#34;)) { System.out.println(itemName + \u0026#34;를 선택하셨습니다.\u0026#34;); price = choosePriceOption(1000, 2000, 3000); } else if (itemName.equals(\u0026#34;옥수수\u0026#34;)) { System.out.println(itemName + \u0026#34;를 선택하셨습니다.\u0026#34;); price = choosePriceOption(4000, 5000, 6000); } else { System.out.println(itemName + \u0026#34;을 선택하셨습니다.\u0026#34;); price = choosePriceOption(10000, 20000, 30000); } return price; } // 가격을 선택하는 역할 public static int choosePriceOption(int option1Price, int option2Price, int option3Price) { Scanner input = new Scanner(System.in); int price; System.out.println(\u0026#34;1. \u0026#34; + option1Price + \u0026#34;원 어치. 2. \u0026#34; + option2Price + \u0026#34;원 어치. 3. \u0026#34; + option3Price + \u0026#34;원 어치\u0026#34;); int optionForPrice = input.nextInt(); if (optionForPrice == 1) { price = option1Price; } else if (optionForPrice == 2) { price = option2Price; } else { price = option3Price; } return price; } // 양을 선택하는 역할 public static int chooseAmount(String itemName, int price) { Scanner input = new Scanner(System.in); System.out.println(itemName + \u0026#34; \u0026#34; + price + \u0026#34;원 어치를 선택하셨습니다. 몇 개를 주문하시겠습니까?\u0026#34;); return input.nextInt(); } } 위 코드도 나름 각 메서드마다 역할을 정해서 작성했다.\n하지만 의존성을 띄는 걸 확인할 수 있다. 어디서 의존성을 확인할 수 있을까?\n바로 chooseOption 메서드와 choosePrice 메서드다. chooseOption에 식재료 옵션이 literal로 추가되면 choosePrice도 수정해야 한다.\n이와 같은 관계를 \u0026lsquo;의존성을 띈다\u0026rsquo;고 하며 \u0026lsquo;단일 책임 원칙\u0026rsquo;에 어긋난다.\n단일 책임 원칙 적용 코드 그러면 이제 \u0026lsquo;단일 책임 원칙\u0026rsquo;을 적용해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 import java.util.Scanner; public class OrderIngredient { public static void main(String[] args) { int totalPrice = orderIngredient(); System.out.print(\u0026#34;구매 최종 비용: \u0026#34; + totalPrice); } // 식재료 주문하기 public static int orderIngredient() { Scanner input = new Scanner(System.in); // 식재료 선택 System.out.print(\u0026#34;1.감자 2.옥수수 3.수박: \u0026#34;); int ingredient = input.nextInt(); // 식재료 선택에 따른 전체 주문 가격 얻기 if (ingredient == 1) { System.out.println(ingredient + \u0026#34;번 감자를 선택하셨습니다.\u0026#34;); return getTotalCost(\u0026#34;감자\u0026#34;, 1000, 2000, 3000); } else if (ingredient == 2) { System.out.println(ingredient + \u0026#34;번 옥수수를 선택하셨습니다.\u0026#34;); return getTotalCost(\u0026#34;옥수수\u0026#34;, 4000, 5000, 6000); } else if (ingredient == 3) { System.out.println(ingredient + \u0026#34;번 수박을 선택하셨습니다.\u0026#34;); return getTotalCost(\u0026#34;수박\u0026#34;, 10000, 20000, 30000); } return 0; } // 전체 비용 얻기 public static int getTotalCost(String ingredient, int price1, int price2, int price3) { Scanner input = new Scanner(System.in); // 가격 선택 System.out.print(\u0026#34;1.\u0026#34; + price1 + \u0026#34; 2.\u0026#34; + price2 +\u0026#34; 3.\u0026#34; + price3); int selectedPrice = input.nextInt(); // 선택한 구매가격 안내 및 전체 구매 가격 반환 if (selectedPrice == 1) { return informPriceAndCalculateCost(ingredient, price1); } else if (selectedPrice == 2) { return informPriceAndCalculateCost(ingredient, price2); } else if (selectedPrice == 3) { return informPriceAndCalculateCost(ingredient, price3); } return 0; } // 비용 계산하기 public static int informPriceAndCalculateCost(String ingredient, int price) { Scanner input = new Scanner(System.in); // 선택한 구매가격 안내 System.out.println(ingredient +\u0026#34; \u0026#34; + price + \u0026#34;원어치를 선택하셨습니다.\u0026#34;); // 수량 선택 System.out.print(\u0026#34;몇 개를 주문하시겠습니까?: \u0026#34;); int orderAmount = input.nextInt(); // 전체 구매 가격 반환 return orderAmount * price; } } 단일 책임 원칙을 적용하면서 메서드가 합쳐지면서 메서드 이름도 바뀌었다.\n적용 전 바로 chooseOption 메서드와 choosePrice 메서드가 orderIngredient 메서드로 합쳐졌다. 식재료명을 변수로 전달하여 의존성을 해결했다.\n그 밖에도 orderIngredient 를 수정한다고 하여 getTotalCost 메서드가 수정되는 일이 없다.\n또한, orderIngredient로 합쳐서 불필요한 메서드 분리를 없애서 최소화할 수 있게 되었다.\n그러면 단일 책임 원칙이란 무엇일까? 위 사례를 통해서 내가 느낀 \u0026lsquo;단일 책임 원칙\u0026rsquo;이란 다음과 같다고 볼 수 있을 것 같다.\n이 원칙을 메서드 관점 에서 보자면 각 메서드마다 명확한 역할과 책임을 정하는 것\n이를 코드로 표현하면 어떤 값을 받고, 어떤 값을 반환할지를 결정하는 것, 이는 메서드 이름에서부터 나타나야 한다. 만약 메서드끼리 \u0026lsquo;의존성\u0026rsquo;을 가진다면 각 메서드마다의 역할과 책임을 명확하게 하지 않았기 때문이라 볼 수 있다. 또한, 이를 메서드 관점이 아닌 프로그램 전체적인 설계의 관점 에서 보자면 다음과 같이 생각할 수 있을 것 같다.\n하나의 프로그램은 한 가지 목적을 위해서 만들어졌지만, 이 목적을 위해서 여러 기능들이 포함된다. 이에 따라 이 기능들이 섞이지 않게 잘 구별하는 것 그리고, 추후 변경점이 생겼을 때 유연하게 대처가 가능해야한다는 의미 현실 세계와의 공통점 이는 현실 세계에서 업무 분배를 하기 위해 각 부서마다 업무 범위를 정하고, 각 부서 구성원들끼리도 각자 업무를 맡는 것과 동일한 원리 같다.\n효율적으로 일을 처리하고, 진행하기 위해서는 업무가 중복되면 안된다. 업무가 중복된다는 건 책임이 중복되는 것이고, 이는 책임 회피가 일어날 수 있다.\n회사에서 일할 때나 프로젝트를 할 때나 느낀 바는 다음과 같다.\n\u0026lsquo;인원 전체가 책임을 진다는 건 책임지는 일이 없다는 것과 똑같다.\u0026rsquo;\n정말 이상적으로는 인원 전체 모두가 한 가지 업무에 대해 책임을 져서 모두가 집중하면 좋지만 현실적으로는 여러 업무들이 있기 때문에 간과될 가능성이 있다.\n메서드를 작성할 때도 똑같다. 동일한 역할을 하는 메서드가 또 있다면 둘 중 하나만 사용하게 되고, 불필요한 코드가 발생된 것이다.\n아름다운 객체 지향 \u0026lsquo;객체 지향 설계\u0026rsquo;는 정말 매력적이다. 계속 학습해보자. 자바를 학습해가면서 자동적으로 파고 들어지는 것 같다.\n파이썬도 또한 클래스와 메서드라는 개념이 있지만, 객체지향 원칙에 대한 자료는 자바가 훨씬 많은 것 같다. 자바를 통해 이 내용들을 학습하면서 파이썬과 자바를 모두 잘 사용해서 객체 지향 설계를 좋아하고 잘하는 개발자가 되보자.\n","permalink":"http://jeha00.github.io/post/java/7_srp/","summary":"객체 지향 5원칙인 SOLID 중 단일 책임 원칙인 Single Responsibility principle을 자바 코드에 적용해보자.","title":"객체 지향 5원칙 중 단일 책임 원칙(SRP)을 예제 코드에 적용해보자"},{"categories":"java","content":"객체 지향의 특징과 객체 지향 프로그래밍 객체 지향의 특징에는 4가지가 있다고 학습했다.\n추상화 캡슐화 상속 다형성 추상화는 현실 세계에 존재하는 객체를 소포트웨어적으로 표현하되, 원하는 역할(책임)에 맞게 표현한다. 현실 세계에 존재하는 정보여도 원하는 역할이 아니라면 표현하지 않는다.\n캡슐화는 클라이언트에게 모든 정보를 제공하지 않고, 사용하기 편리하게 필요한 정보만을 제공하여 사용성과 보안을 향상시키는 특징이다.\n상속은 중첩되는 코드를 상속으로 코드 반복을 줄이고, 객체를 체계적으로 표현할 수 있는 특징이다.\n다형성은 위 상속을 사용하여 하나의 객체가 여러 타입의 객체로 취급받을 수 있는 특징을 말한다.\n그렇다면 이 객체 지향을 사용하는 객체 지향 프로그래밍은 무엇인가?\n명령어의 목록으로 바라보는 절차 지향 프로그래밍과 달리, 하나의 단위인 \u0026lsquo;객체\u0026rsquo;들의 모임으로 프로그램을 파악하는 관점이다. 그래서 하나의 객체 안에 객체의 속성과 기능 정보가 모아져 있다. 객체의 이 정보들을 사용해서 다른 객체와 협력한다.\n위 설명에서 중요한 부분이 \u0026lsquo;객체\u0026rsquo;들의 모임으로 프로그램을 파악한다는 것이다. 즉 객체들끼리 협력하여 의도한 프로그램 목표를 수행한다. 그러면 각 객체의 역할을 잘 정의하는게 중요하다.\n이 역할을 정의하여 수행하는 객체를 정의할 때 사용되는 게 \u0026lsquo;다형성\u0026rsquo;이기 때문에 객체 지향 프로그래밍에서 제일 중요한 특성이 다형성이다. 현실 세계에서 다형성이 어떻게 적용되는지 예시를 찾아보자.\n다형성의 예시를 실세계에서 찾아보자 지난 포스팅에서 다형성에 대해 알아보았고, 인터페이스를 받아 구현해봤다. 이 인터페이스를 사용하여 역할 을 정의한다. 인터페이스이므로 구현체가 필요하다고 지난 포스팅에서 학습했으므로, 이 인터페이스를 받아서 만든 실체를 구현 이라 하자.\n현실 세계에서 역할과 구현의 예시를 찾아보자. 더 나아가 이 역할을 사용하는 클라이언트는 누구인지 생각해보자.\n자동차 첫 번째 예로는 자동차가 있다. 이 자동차를 직접적으로 사용하는 건 운전자다. 각 자동차마다 제공하는 자동차의 역할이 동일하기 때문에, 운전자는 여러 종류의 자동차를 운전할 수 있다.\n이 역할에는 정해진 규칙이 있다. 브레이크, 엑셀, 운전대, 변속기 등을 반드시 제공한다는 규칙이다. 여기서 운전자는 자동차의 내부 원리는 알지 못해도 사용할 수 있다. 이 부분이 바로 캡슐화다. 숨길 부분은 숨기고, 드러낼 부분만 드러내서 사용자가 쉽게 사용할 수 있는 인터페이스를 만든다.\n이 자동차의 종류에는 자동차 제조사가 만든 모든 차량들이 해당된다. 차량의 제조사 종류들은 다 다르지만, 운전자는 이 자동차를 다 사용할 수 있다. 왜냐하면 차량의 역할 인터페이스가 다 동일하기 때문이다. 그래서 현재 사용하는 자동차가 망가져도 다른 자동차로 대체할 수 있다.\n자동차의 클라이언트, 역할, 구현은 무엇일까?\n클라이언트: 사용자 역할: 자동차 구현: 자동차 제조사가 만든 모든 차량들 연극 연극을 보면 관람객들이 보고 있고, 여러 개의 역할이 있으며, 하나의 역할을 여러 배우들이 돌아가면서 연기한다. 이게 객체 지향 프로그래밍과 많이 유사하다고 생각한다.\n클라이언트: 관람객 역할:남자 주인공, 여자 주인공, 조연들 구현: 각 배역을 맡은 여러 배우들 항공사 항공사의 비행기도 그렇다. 항공사들은 여러 종류의 여객기를 사용하여 여행을 제공한다.\n클라이언트: 항공사 역할: 여객기 구현: 보잉과 에어버스에서 만든 여러 항공기들 컴퓨터 장치들 클라이언트: 사용자 역할: 키보드, 마우스, 모니터 구현: 각 역할들을 구현하는 실제 장치들의 종류가 많다. 역할, 구현 그리고 협력 클라이언트 관점에서 역할과 구현을 분리하지 않으면 생기는 단점 역할과 구현을 분리하는 이유는 분리하지 않을 때 생기는 문제점을 생각해보면 된다. 가장 마지막에 본 연극인 \u0026lsquo;앙리할아버지와 나\u0026rsquo;를 예시로 든다.\n여기서 여주인공의 역할로는 박소담, 채수빈, 권유리님이 맡으셨다. 할아버지 역할로는 이순재, 신구 선생님이 맡으셨다.\n만약 역할과 구현을 구분하지 않았다면 하나의 역할에 한 명의 배우만 가능하여, 이 배우에게 문제가 발생했을 경우 다른 배우가 대체하지 못한다. 즉, 유연하지 못하다. 그래서 요즘 주연 배우들이 치명적인 이슈를 가지고 있는지가 중요하다. 중도 하차할 경우 매우 비용이 많이 발생하기 때문이다.\n이처럼 역할과 구현을 구분하지 않으면 유연하지 않아 변경이 어렵다.\n클라이언트 관점에서 역할과 구현을 분리하면 생기는 장점 다음으로 사용자(클라이언트)의 관점에서 생각해보자.\n역할과 구현을 분리하면 클라이언트는 이 역할을 무엇이 또는 누가 구현하는지 몰라도 된다. 역할(인터페이스)만 알면 되기 때문이다. 왜냐하면 우리는 이 역할이 제공하는 서비스를 이용하는 클라이언트이기 때문이다.\n연극을 보는데, 자동차를 타는데, 여행을 가는데 있어서 이 구현체(배우, 차 종류, 항공기 종류)가 바껴도 클라이언트에게는 아무런 영향이 없다.\n자동차나 비행기의 작동원리를 몰라도 자동차와 비행기의 역할을 충분히 이용할 수 있다.\n새로운 자동차와 비행기가 나오면서 내부 구조가 변경되어도 자동차와 비행기의 역할을 충분히 이용할 수 있다. 자동차의 동력이 석유에서 전기로 바껴도 충분히 운전할 수 있다.\n그러면 클라이언트 관점에서 생각해본 장점들 을 정리해보면 다음과 같다.\n클라이언트는 대상의 역할(인터페이스)만 알면 된다. 다른 말로 말하자면 클라이언트는 구현 대상의 내부 구조를 몰라도 된다. 그래서 클라이언트는 구현 대상의 내부 구조가 변경되어도 영향을 받지 않는다. 클라이언트는 동일한 역할만 제공하면 구현 대상 자체를 변경해도 영향을 받지 않는다. 위 장점들로 인해 설계가 유연해지고 변경이 편리하다.\n자바에서는 interface 키워드를 사용한 인터페이스를 통해 역할을 정의하고, 이 interface를 받아서 implements 키워드를 사용하여 구현한 클래스를 구현체로 사용한다.\n❗️ 역할을 정의할 때 반드시 인터페이스를 사용하지 않아도 되지만, 여태 학습한 것처럼 인터페이스를 권장한다.\n그러면 역할과 구현을 분리하여 생기는 단점은? 클라이언트와 서비스 제공자가 인터페이스(역할)를 중심으로 연결되어 있기 때문에, 이 인터페이스를 바꾼다면 서비스를 이용하는 클라이언트와 서비스를 제공하는 서버 모두에 큰 변경이 발생한다!\n자동차 이용 방법이 바뀐다면? 컴퓨터의 입출력 장치들의 연결 및 사용 방법이 바뀐다면? 대본 자체가 변경된다면? 그래서 실제 세계에 있는 것을 역할과 구현 관점에서 분석한 후, 다형성을 사용해서 소프트웨어 세계에 추상화한다. 이때 인터페이스 변경이 일어나지 않도록 안정적으로 잘 설계하는 게 중요하다❗️❗️\n협렵이라는 관점에서 이전 포스팅과 위 내용에서는 클라이언트와 하나의 역할 간 관계에 대해서만 고려했다. 이번에는 여러 개의 역할 간 관계에 대해서 고려해보자.\n제공하는 서비스를 이용하는 역할(요청하는 역할)에 속하면 클라이언트, 서비스를 제공하는 역할(응답하는 역할)에 속하면 서버라 생각할 수 있다. 그런데, 이 서버 또한 다른 서버로부터 제공하는 서비스를 이용할 수 있기 때문에 서버이자 클라이언트가 된다.\n클라이언트 -\u0026gt; 서버\n클라이언트 -\u0026gt; 서버 + 클라이언트 -\u0026gt; 서버\n객체 지향 프로그래밍은 프로그램을 객체들 간 협력으로 파악하는 관점이다. 서버가 클라이언트가 될 수 있는 것처럼 객체들 간에도 서비스를 제공하는 객체가 또 다른 서비스를 사용하는 객체가 된다.\n코드 예시 그러면 이제 코드를 통해 이해해보자. 처음에는 역할과 구현을 나누지 않고 코드를 작성해본 후, 다형성을 활용하여 역할과 구현을 분리해본다.\n클라이언트가 역할이 아닌 구현에 의존한다면? 포테이토 피자와 주문자(클라이언트) 클래스를 만든다.\nOrder 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package pizza; public class OrderClient { private PotatoPizza potatoPizza; public void order(PotatoPizza potatoPizza) { System.out.println(\u0026#34;포테이토 피자를 주문합니다.\u0026#34;); this.potatoPizza = potatoPizza; } public void delivery() { potatoPizza.startDelivery(); potatoPizza.onDelivery(); potatoPizza.arrive(); } } PotatoPizza 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package pizza; public class PotatoPizza { public void addIngredient() { System.out.println(\u0026#34;감자 재료를 추가합니다.\u0026#34;); } public void startDelivery() { System.out.println(\u0026#34;배달을 시작합니다.\u0026#34;); } public void onDelivery() { System.out.println(\u0026#34;배달 중입니다.\u0026#34;); } public void arrive() { System.out.println(\u0026#34;배달이 도착했습니다.\u0026#34;); System.out.println(\u0026#34;주문자가 피자를 받았습니다\u0026#34;); } } OrderMain 클래스\n1 2 3 4 5 6 7 8 9 10 11 package pizza; public class OrderMain { public static void main(String[] args) { OrderClient orderClient = new OrderClient(); PotatoPizza potatoPizza = new PotatoPizza(); orderClient.order(potatoPizza); orderClient.delivery(); } } 실행 결과\n1 2 3 4 5 포테이토 피자를 주문합니다. 배달을 시작합니다. 배달 중입니다. 배달이 도착했습니다. 주문자가 피자를 받았습니다 위와 같이 설계를 한다면 PotatoPizza 외 피자를 주문할 수가 없다. 유연한 설계가 불가능하다.\n다형성을 적용한다면? 이제 다형성을 적용한다면 코드를 어떻게 변경해야할지 생각해보자.\n먼저 다형성을 적용하기 위해 역할과 구현 단계를 나눠야 한다. 역할은 자바에서 인터페이스를 통해 만들고, 구현은 이 인터페이스를 받아 만든다.\n인터페이스로 Pizza 인터페이스를 만든다.\n위 PotatoPizza 클래스에서 만들었던 메서드들을 Pizza 인터페이스 내부에 추상 메서드로 각각 선언한다.\n1 2 3 4 5 6 7 8 9 10 package pizza; public interface Pizza { void startDelivery(); void onDelivery() ; void arrive(); } 이 인터페이스를 상속받아 PotatoPizza 를 만든다.\nPotatoPizza 내부에 인터페이스 내부의 추상 메서드를 오버라이딩한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package pizza; public class PotatoPizza implements Pizza{ public void startDelivery() { System.out.println(\u0026#34;배달을 시작합니다.\u0026#34;); } public void onDelivery() { System.out.println(\u0026#34;배달 중입니다.\u0026#34;); } public void arrive() { System.out.println(\u0026#34;배달이 도착했습니다.\u0026#34;); System.out.println(\u0026#34;주문자가 피자를 받았습니다\u0026#34;); } } orderClient 클래스의 인스턴스 변수와 인스턴스 메서드의 타입을 PotatoPizza에서 Pizza 인터페이스로 수정한다.\nOrderMain에서 PotatoPizza 구현체의 인스턴스를 생성하고, 이 인스턴스의 타입은 Pizza 인터페이스로 한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package pizza; public class OrderClient { private Pizza pizza; public void order(Pizza pizza) { System.out.println(\u0026#34;포테이토 피자를 주문합니다.\u0026#34;); this.pizza = pizza; } public void delivery() { pizza.startDelivery(); pizza.onDelivery(); pizza.arrive(); } } 이후에 생성하는 피자 클래스들의 인스턴스 타입도 Pizza 인터페이스로 한다. 그러면 order 메서드에서 매개변수로 받을 때 타입에러가 발생하지 않고, 메서드 오버라이딩에 의해서 인스턴스의 메서드가 실행된다.\nPizza 타입의 인스턴스 변수에 담겨진 참조값을 통해 heap 영역에 생성된 인스턴스를 참조한다. 이 인스턴스의 참조값에 접근하여 인스턴스 메서드의 메모리 위치를 확인 후, 인스턴스 메서드를 실행한다.\n1 2 3 4 5 6 7 8 9 10 11 package pizza; public class OrderMain { public static void main(String[] args) { OrderClient order = new OrderClient(); Pizza potatoPizza = new PotatoPizza(); order.order(potatoPizza); order.delivery(); } } 위 수정들을 통해 \u0026lsquo;역할\u0026rsquo;과 \u0026lsquo;구현\u0026rsquo;이 분리되어 유연한 설계가 가능해진다.\nOCP(Open-Closed Principle) 원칙 강의를 들으면서 OCP 원칙에 대해 처음 들었는데, 객체 지향 설계 원칙 중 하나다.\nOpen for extension: 새로운 기능의 추가나 변경 사항이 생겼을 때, 기존 코드는 확장할 수 있어야 한다. Closed for modification: 기존의 코드는 수정되지 않아야 한다. 위 두 가지 내용을 상충되는 걸로 보인다. 이렇게 상충되는 내용을 발견하면 관점이 다르다는 걸 기억하자.\n첫 번째 \u0026lsquo;Open for extenstion\u0026rsquo;은 새로운 객체가 추가될 수 있어야 한다는 걸 의미한다. 위에 pizza 예시처럼 새로운 피자 종류를 언제든지 추가할 수 있어야 한다. 어떻게? 바로 인터페이스를 통해서 추가한다는 의미다.\n그 다음으로 두 번째 \u0026lsquo;Closed for modification\u0026rsquo;은 첫 번째 원칙에 따라 기존 코드는 확장할 수 있지만, 이 기존 코드에 클라이언트 코드는 포함되어 있지 않아서 클라이언트 코드는 수정하지 않는다. 단, 새로운 객체를 생성하여 클라이언트에게 전달하는 부분은 수정될 수 밖에 없다.\n위 두 가지 모두 \u0026lsquo;다형성\u0026rsquo;을 활용하여 \u0026lsquo;역할\u0026rsquo;과 \u0026lsquo;구현\u0026rsquo;을 잘 분리하면 위 원칙을 준수할 수 있다. 대부분의 코드를 유지할 수 있고, 새로운 객체가 필요하면 구현 부분을 늘리면 된다.\n","permalink":"http://jeha00.github.io/post/java/6_oop/","summary":"자바의 다형적 참조가 객체 지향의 다형성을 어떻게 나타내는지 알아본다.","title":"배운 다형성이 왜 객체 지향의 중요한 특징인가?"},{"categories":"java","content":"객체지향 프로그래밍의 대표적인 특징들과 다형성 객체지향 프로그래밍에는 대표적으로 아래의 3가지 특징을 가진다.\n캡슐화(encapsulation): 객체의 속성과 기능을 객체 안에서 관리하고, 접근 제어자를 사용하여 클라이언트에게 필요한 것만 제공하는 방식\n상속(inheritance): 부모 클래스의 속성과 기능을 자식 클래스가 물려받아 사용하는 방식\n위 2가지는 시각적으로 쉽게 드러나기 때문에 이해하기 쉽다. 하지만 \u0026lsquo;다형성(polymorphism)\u0026lsquo;은 위 2가지 특징보다 조금 어렵다.\n\u0026lsquo;다형성\u0026rsquo;은 크게 2가지 이론: 다형적 참조, 메서드 오버라이딩을 알아야 한다.\n먼저 \u0026lsquo;다형성\u0026rsquo;의 정의에 대해 알아보자면 \u0026lsquo;다형성\u0026rsquo;은 하나의 객체가 여러 타입의 객체로 취급받을 수 있는 특성 을 말한다.\n그러면 이 \u0026lsquo;다형성\u0026rsquo;의 큰 2가지 이론에 대해 알아보자.\n다형적 참조 \u0026lsquo;다형적 참조\u0026rsquo;는 무엇을 의미하는 걸까? \u0026lsquo;다형성\u0026rsquo;이란 의미에서 시작해보자. 하나의 객체가 여러 타입의 객체로 취급받을 수 있는 특성을 말한다고 했으니, 다형적 참조란 여러 타입의 객체로 취급받을 수 있는 참조 방식 을 말하는 것이라 추측할 수 있다.\n그러면 캡슐화, 상속을 이해하기 위해 우리는 코드를 통해 이해한 것처럼 다형적 참조도 코드를 통해 이해해야하는데, 어떤 예시들이 있을까?\n상속을 사용하여 변수를 참조할 때에 어떤 경우들이 있을까?\n자식 인스턴스를 자식 타입의 변수가 참조하는 것 부모 인스턴스를 부모 타입의 변수가 참조하는 것 자식 인스턴스(또는 손자 이하 단계의 인스턴스)를 부모 타입의 변수가 참조하는 것 부모 인스턴스를 자식 타입의 변수가 참조하는 것 위 경우들에서 다형적 참조는 3번과 4번에 해당된다. 다형적 참조를 보다 구체적으로 언급하자면 \u0026lsquo;생성된 인스턴스의 클래스 타입 외에 상속 관계에 있는 다른 클래스 타입으로 참조하는 것\u0026rsquo; 을 말한다.\n하지만 4번은 가능하지 않다. 위 각 경우를 코드로 확인해보자. 그러면 위 각 경우들을 코드로 나타내보자.\n부모 클래스\n1 2 3 4 5 public class Parent { public void ParentMethod() { System.out.println(\u0026#34;Parent.parentMethod\u0026#34;); } } 자식 클래스\n1 2 3 4 5 public class Child extends Parent { public void childMethod() { System.out.println(\u0026#34;Child.childMethod\u0026#34;); } } 인스턴스 생성\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public class ChildMain { public static void main(String[] args) { // 1) 자식 인스턴스를 자식 타입의 변수가 참조하는 경우 System.out.println(\u0026#34;Child instance with Child type\u0026#34;); Child child1 = new Child(); child1.parentMethod(); child1.childMethod(); // 2) 부모 인스턴스를 부모 타입의 변수가 참조하는 경우 System.out.println(\u0026#34;Parent instance with Parent type\u0026#34;); Parent parent1 = new Parent(); parent1.parentMethod(); // 3) 자식 인스턴스를 부모 타입의 변수가 참조하는 경우 System.out.println(\u0026#34;Child instance with Parent type\u0026#34;); Parent parent2 = new Child(); parent2.parentMethod(); // 4) 부모 인스턴스를 자식 타입의 변수가 참조하는 경우 System.out.println(\u0026#34;Parent instance with Child type\u0026#34;); // 컴파일 오류 발생 Child child2 = new Parent(); child2.childMethod() } } 위 인스턴스 생성 코드를 실행하면 Child child2 = new Parent2()에서 다음 에러가 발생한다.\n1 java: incompatible types: example.Parent cannot be converted to example.Child Parent 인스턴스는 Child 타입을 가질 수 없다는 의미다.\n다형적 참조가 가능한 이유 그러면 위 1,2,3번은 가능하고, 4번은 가능하지 않은 이유에 대해 알아보자.\n자식 인스턴스가 메모리에 어떻게 생성되는지 이미지로 확인하고 싶으면 상속과 오버라이딩이 메모리 영역에서 어떻게 이뤄지지?- 상속과 메모리 구조를 확인하자.\n1) 자식 인스턴스를 자식 타입의 변수가 참조하는 경우 인스턴스를 생성할 때, Child의 인스턴스만 생성되는게 아니라 Parent의 인스턴스도 생성된다. 인스턴스는 Child 타입과 Parent 타입을 모두 가지고 있다. 그래서 참조 변수 생성할 때 자식 타입과 부모 타입 모두 가능하다. 그래서 인스턴스의 타입을 자식 위치에 있는 Child로 정할 수 있다.\n메서드 실행의 경우 child1.parentMethod()의 실행은 Child 클래스에서 parentMethod()를 찾지 못하자, 부모인 Parent 클래스로 올라가서 찾아 실행한 경우다.\n2) 부모 인스턴스를 부모 타입의 변수가 참조하는 경우 인스턴스를 생성할 때 Parent의 인스턴스만 생성되고, Child의 인스턴스는 생성되지 않은 경우다. 여기서 parent1.childMethod()를 실행하면 childMethod()를 찾을 수 없다는 에러가 발생한다.\n3) 자식 인스턴스를 부모 타입의 변수가 참조하는 경우 1번에서 인스턴스를 생성할 때 Parent와 Child의 인스턴스가 모두 생성된다고 했다. 그래서 참조 변수의 타입을 Parent로 할 수 있다.\n그러면 1번과의 차이점은 무엇일까? 바로 참조변수의 타입이 이 상속 관계에 있는 클래스들의 조회 시작 위치를 결정하기 때문에 자식 위치에 있는 클래스 정보를 조회할 수 없다.\n작성된 코드를 보면 참조변수의 타입이 바뀐 것이다. 참조변수의 타입이 코드 작동 시 무슨 차이점을 만들까?\n이전 포스팅에서 상속 관계는 자식 클래스에서 부모 클래스 방향으로 올라가면서 조회할 수 있지만, 반대 방향으로는 내려갈 수 없다고 했다.\n참조 변수의 타입이 Parent이기 때문에 클래스 조회 순서가 Parent부터 시작한다. 자식 인스턴스여도 childMethod()를 실행할 수 없다는 의미다. 왜냐하면 상속 관계에 있는 클래스들의 조회방향은 자식에서 부모 방향으로 위로만 갈 수 있기 때문이다.\nParent 클래스가 만약 GrandParent 라는 클래스를 상속받으면 Parent 클래스에서 GrandParent 클래스 방향으로 조회한다. 하지만 현재 위 코드는 Parent가 끝이기 때문에 위로 올라갈 클래스는 없다.\n4) 부모 인스턴스를 자식 타입의 변수가 참조하는 경우 이 인스턴스의 경우, Parent 클래스의 인스턴스만 생성된 경우라서 Child 클래스의 인스턴스 정보는 없다.\n그래서 참조 변수의 타입을 Child로 할 경우, 생성된 인스턴스에 Child 정보가 없기 때문에 다음과 같은 에러가 발생했던 것이다.\n1 java: incompatible types: example.Parent cannot be converted to example.Child 그러면 4번과 같은 상황에서 Child 타입으로 변환하고 싶으면 어떻게 해야할까?\n이 문제를 해결하기 위해서 필요한 게 \u0026lsquo;캐스팅(Casting)\u0026lsquo;이다. 캐스팅에 대해서 알아보자.\n캐스팅(Casting) 캐스팅의 의미는 \u0026lsquo;주조\u0026rsquo;라는 \u0026lsquo;액체 상태의 금속을 원하는 형틀에 부어 넣어 굳혀서 모양을 만드는 작업\u0026rsquo;을 말한다.\n다른 형태로 만드는 것이라고 이해하면 되겠다. 위 내용에서 학습한 것과 이어서 이해하자면 다른 타입으로 변환하는 것 을 캐스팅 이라 이해하자.\n캐스팅에는 \u0026lsquo;Down casting(다운 캐스팅)\u0026lsquo;과 \u0026lsquo;Up casting(업 캐스팅)\u0026lsquo;이 존재한다.\n다운 캐스팅: 상속 관계에 있는 클래스 관계 중 부모 클래스 타입에 속한 변수를 자식 클래스 타입으로 변경하는 것 업 캐스팅: 상속 관계에 있는 클래스 중 자식 클래스 타입을 부모 클래스 타입으로 변경하는 것 그러면 각 캐스팅에 대해 알아보자.\n다운 캐스팅(Down casting) 다운 캐스팅은 위에서 설명한 대로 부모 클래스 타입에 속한 참조 변수를 자식 클래스 타입으로 변경하는 것 을 말한다.\n영구적으로 다운 캐스팅을 하는 방식이 있고, 일시적으로 하는 방식이 있다. 각 방식에 대해 알아보자.\n영구적 다운 캐스팅 어떻게 해서 영구적으로 가능한 것일까? 다운 캐스팅한 결과를 자식 클래스 타입으로 선언한 새로운 참조 변수에 담는 것이다.\nParent 타입을 Child 타입으로 다운 캐스팅하기 위해서는 생성된 인스턴스에 Child 인스턴스가 있어야 가능하다. 즉, Child 클래스의 인스턴스로 생성한 후, Parent 타입으로 참조 변수를 초기화해야 가능하다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class ChildMain { public static void main(String[] args) { ... // 자식 인스턴스를 부모 타입의 변수가 참조하는 경우 System.out.println(\u0026#34;Child instance with Parent type\u0026#34;); Parent parent2 = new Child(); parent2.parentMethod(); // Down casting Child child = (Child) parent2; child.childMethod(); ... } } 위 영구적 다운 캐스팅의 경우도 parent2에 있는 참조값을 복사해서 읽는다. JAVA에서 대입은 항상 기존 것을 절대 손대지 않는다. 그래서 실행순서를 보다 쪼개서 이해하면 다음과 같다.\n1 2 3 4 5 6 7 8 // 첫 번째 Child child = (Child) parent2; // 두 번째 Child child = (Child) x111; // 참조값을 복사해서 읽은 후, 자식 타입으로 지정 // 세 번째 Child child = x111; // 아래 코드를 실행하면 parent2와 child 모두 동일한 참조값을 확인할 수 있다.\n실행 코드\n1 2 System.out.println(child); System.out.println(parent2); 실행 결과\n1 2 example.Child@3cb5cdba example.Child@3cb5cdba 그래서 동일한 참조값을 가지고 있어도, 인스턴스에 변환할 타입 정보가 존재한다면 가능하다.\n영구적 다운 캐스팅 시도 시 오류 발생 만약 정보가 없다면 어떻게 될까?\n1 2 3 4 5 ... // 부모 인스턴스를 자식 타입의 변수가 참조하는 경우 System.out.println(\u0026#34;Parent instance with Child type\u0026#34;); Parent poly = new Parent(); Child c = (Child) poly; 위 poly 참조 변수가 가리키는 인스턴스에는 Parent 클래스의 인스턴스 정보가 가지고 있다. 그래서 위 코드를 실행하면 다음과 같은 에러가 발생한다.\n1 2 class example.Parent cannot be cast to class example.Child (example.Parent and example.Child are in unnamed module of loader \u0026#39;app\u0026#39;) 변환할 수 없다고 뜬다.\n항상 다운 캐스팅을 할 때에는 인스턴스에 변환하려는 타입의 인스턴스 정보가 있는지 먼저 확인하자.\n일시적 다운 캐스팅 일시적으로만 다운 캐스팅해 사용하고 싶다면 어떻게 해야할까?\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package example; public class ChildMain { public static void main(String[] args) { ... System.out.println(\u0026#34;Child instance with Parent type\u0026#34;); Parent parent2 = new Child(); // 영구적 다운 캐스팅 Child child = (Child) parent2; // 일시적 다운 캐스팅 ((Child parent2)).childMethod(); ... } } 위 코드에서 확인할 수 있는 것처럼 ()를 사용해 일시적으로 다운 캐스팅을 할 수 있다. ((Child) x111).childMethod() 라고 생각하자.\n이렇게 일시적 다운 캐스팅을 사용하면 별도의 변수 없이 인스턴스의 자식 타입의 기능을 사용할 수 있다.\n업 캐스팅(Up casting) 이제는 반대로 업 캐스팅(up casting)에 대해 알아보자. 업 캐스팅은 자식 클래스 타입을 부모 타입으로 변경하는 것 을 말한다. 아래 업 캐스팅 코드를 확인해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package example; public class ChildMain { public static void main(String[] args) { // 자식 인스턴스를 자식 타입의 변수가 참조하는 경우 System.out.println(\u0026#34;Child instance with Child type\u0026#34;); Child child1 = new Child(); Parent parent1_casted = (Parent) child1; Parent parent2_casted = child1; parent1_casted.parentMethod(); parent2_casted.parentMethod(); ... } } parent1_casted 와 parent2_casted가 업 캐스팅에 의해 생성된 참조 변수다. 이 참조 변수를 보면 parent1_casted는 (Parent)를 명시했고, parent2_casted는 (Parent)를 생략했다. 업캐스팅은 (타입)을 생략할 수 있다. 다운캐스팅은 생략할 수 없다. 업캐스팅은 매우 자주 사용하기 때문에 생략을 권장한다.\n안전한 업캐스팅, 위험한 다운 캐스팅 그리고 주의사항 그러면 왜 업 캐스팅은 생략할 수 있고, 다운 캐스팅은 생략할 수 없을까?\n업 캐스팅의 경우 인스턴스를 생성하면 해당 타입의 상위 부모 타입은 함께 생성된다. 따라서 상위 타입으로만 변경하는 업캐스팅은 메모리 상에 인스턴스가 모두 존재하기 때문에 캐스팅을 생략할 수 있다.\n하지만 다운 캐스팅의 경우, 인스턴스에 존재하지 않는 하위 타입으로 캐스팅할 경우 컴파일 오류와 런타임 오류 발생할 수 있다. 따라서 개발자가 이런 문제를 인지하고 사용해야 한다는 의미로 명시적으로 캐스팅을 해야한다.\n컴파일 오류(compile error) vs 런타임 오류(runtime error) 다운 캐스팅 시 발생하는 컴파일 오류와 런타임 오류에 대해 확인하기 전에 먼저 이 두 오류 간 차이에 대해 정리해보자.\n컴파일 오류는 변수명 오타, 잘못된 클래스 이름, 변수 이름 등 자바 프로그램을 실행하기 전 컴파일 단계에서 발생하는 오류다. 그래서 오류지만 IDE에서 즉시 확인할 수 있기 때문에 안전하고 좋은 오류라고 볼 수 있다.\n하지만 런타임 오류는 오류 이름대로 프로그램이 실행되고 있는 시점에 발생하는 오류다. 그래서 오류 중에서도 매우 안좋은 오류다. 왜냐하면 고객이 프로그램을 사용하는 중에 발생하기 때문이다. 이 오류는 IDE에서 즉시 확인할 수 없다.\n다운 캐스팅의 컴파일 오류와 런타임 오류 다운 캐스팅 시 런타임 오류가 발생하는 경우는 다운 캐스팅 시도 시 오류 발생 경우를 확인하면 된다. 부모 클래스의 인스턴스를 생성한 후 자식 클래스 타입의 참조 변수에 담을려고 할 때 발생한다. 왜냐하면 부모 클래스의 인스턴스에는 자식 클래스의 인스턴스 정보가 없기 때문이다.\n그렇다면 다운 캐스팅 시도 시 발생할 수 있는 컴파일 오류는 무엇이 있을까?\n이 포스팅 시작 시 언급했던 4가지 경우 중 한 가지인 \u0026lsquo;부모 인스턴스를 자식 타입의 변수가 참조하는 경우\u0026rsquo;의 코드를 보면 알 수 있다.\n1 2 3 4 5 6 7 8 9 public class ChildMain { public static void main(String[] args) { ... // 4) 부모 인스턴스를 자식 타입의 변수가 참조하는 경우 System.out.println(\u0026#34;Parent instance with Child type\u0026#34;); Child child2 = new Parent(); // 컴파일 오류 발생 } } 그러면 Child child2 = new Parent(); 코드에 빨간 밑줄이 생기면서 IDE에 아래 내용의 에러 내용이 생긴다.\n1 Incompatible types. Found: \u0026#39;example.Parent\u0026#39;, required: \u0026#39;example.Child\u0026#39; 이 또한 Parent 인스턴스에는 Child 인스턴스 내용이 없기 때문에 발생하는 에러다.\ninstanceof 그러면 다운 캐스팅 시 위 에러들을 피하기 위해서는 참조 변수가 내가 원하는 클래스의 인스턴스 정보를 가지고 있는지 확인하는 게 필요하다. 이럴 때 사용하는게 instanceof다.\ninstanceof를 사용하기 위한 매개변수는 다음과 같으며, boolean 값을 반환한다.\n1 \u0026lt;인스턴스 참조값\u0026gt; instanceof \u0026lt;확인하려는 타입명\u0026gt; 아래 예시 코드를 보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package example; public class ChildMain { public static void main(String[] args) { // 자식 인스턴스를 자식 타입의 변수가 참조하는 경우 System.out.println(\u0026#34;---- Child instance with Child type ----\u0026#34;); Child child1 = new Child(); System.out.println(child1 instanceof Child); System.out.println(new Child() instanceof Child); // 부모 인스턴스를 부모 타입의 변수가 참조하는 경우 System.out.println(\u0026#34;\\n---- Parent instance with Parent type ----\u0026#34;); Parent parent1 = new Parent(); System.out.println(parent1 instanceof Parent); System.out.println(new Parent() instanceof Parent); // 자식 인스턴스를 부모 타입의 변수가 참조하는 경우 System.out.println(\u0026#34;\\n---- Child instance with Parent type ----\u0026#34;); Parent parent2 = new Child(); System.out.println(parent2 instanceof Parent); System.out.println(parent2 instanceof Child); System.out.println(new Child() instanceof Parent); } } 위 코드를 실행하면 아래와 같다.\n1 2 3 4 5 6 7 8 9 10 11 12 ---- Child instance with Child type ---- true // child1 instanceof Child 의 결과 true // new Child() instanceof Child 의 결과 ---- Parent instance with Parent type ---- true // parent1 instanceof Parent 의 결과 true // new Parent instanceof Parent 의 결과 ---- Child instance with Parent type ---- true // parent2 instanceof Parent 의 결과 true // new Child() instanceof Parent 의 결과 true // parent2 instanceof Child 의 결과 child1 참조 변수는 Child 클래스의 인스턴스 정보를 가지고 있으므로 true다. 그리고 new Child()도 당연히 True다.\nparent1 참조 변수는 Parent 클래스의 인스턴스 정보를 가지고 있으므로 true다. 그리고, new Parent()도 당연히 True다.\nparent2 참조 변수는 Parent 클래스의 인스턴스 정보를 가지고 있으므로 true다.\n아직 언급하지 않은 2가지가 있다. new Child() instanceof Parent와 parent2 instanceof Child 다. 이 2가지의 출력 결과는 true다.\nChild 클래스는 Parent 클래스를 상속받고 있고, 상속받는 클래스의 인스턴스를 생성한다는 걸 확인했다.\nparent2 참조 변수는 타입이 Parent이지만 Child의 인스턴스 정보를 가지고 있는 걸 확인했다. 왜냐하면 parent2는 Child 인스턴스의 참조값을 가지고 있기 때문이다.\n그래서 instanceof를 통해 상속하는 클래스의 인스턴스 정보를 확인 가능하다.\n다형성과 메서드 오버라이딩 다형성을 이루는 이론에는 \u0026lsquo;다형적 참조\u0026rsquo;와 \u0026lsquo;메서드 오버라이딩\u0026rsquo;이 있다. 이번 단원에서 다루는 내용이 \u0026lsquo;메서드 오버라이딩\u0026rsquo;이다. 다형성과 메서드 오버라이딩에서 꼭 기억해야할 점은 오버라이딩된 메서드가 항상 우선권을 가진다 는 점이다.\n오버라이딩(Overriding)은 단어의 의미처럼 기존 기능을 덮어 새로운 기능을 재정의하는 것이다. 이것이 다형성과 어떻게 연결되냐면 자식의 메서드를 정의할 때 부모 메서드를 오버라이딩하여 정의했고, 자식 인스턴스 참조값을 가지고 있는 부모 타입의 참조 변수를 생성한 후, 이 참조 변수로 오버라이딩된 메서드를 실행하면 부모 타입이어도 오버라이딩된 자식 메서드가 실행된다는 것이다.\n그러면 코드를 통해 이 내용을 확인해보자.\n부모 클래스\n1 2 3 4 5 public class Parent { public void method() { System.out.println(\u0026#34;I am a parent\u0026#34;); } } 자식 클래스\n1 2 3 4 5 6 7 public class Child extends Parent { @Override public void method() { System.out.println(\u0026#34;I am a child\u0026#34;); } } 인스턴스 생성\n1 2 3 4 5 6 7 8 9 public class ChildMain { public static void main(String[] args) { Parent parent1 = new Parent(); parent1.introduce(); Parent parent2 = new Child(); parent2.introduce(); } } 실행 결과\n1 2 I am a parent I am a child 실행 결과를 보면 parent1를 통해 introduce 메서드를 실행할 때와 parent2를 통해 introduce를 실행한 결과가 다른 걸 확인할 수 있다. 위 결과를 통해서 생성된 인스턴스에 부모의 메서드를 오버라이딩한 자식의 메서드가 있다면 참조 변수가 부모 타입이어도 오버라이딩한 자식의 메서드가 실행된다는 걸 알 수 있다.\n다형성 활용 이번 단원에서는 다형성의 두 가지 중요한 이론인 \u0026lsquo;다형적 참조\u0026rsquo;와 \u0026lsquo;메서드 오버라이딩\u0026rsquo;을 활용하여 리팩토링하자.\n예시 코드로 4개의 클래스를 만들었다.\nPotatoPizza\n1 2 3 4 5 6 7 8 package pizza; public class PotatoPizza { public void addIngredient() { System.out.println(\u0026#34;감자 재료를 추가합니다.\u0026#34;); } } SweetPotatoPizza\n1 2 3 4 5 6 7 8 package pizza; public class SweetPotatoPizza { public void addIngredient() { System.out.println(\u0026#34;고구마 무스 재료를 추가합니다.\u0026#34;); } } AllMeatPizza\n1 2 3 4 5 6 7 8 package pizza; public class AllMeatPizza { public void addIngredient() { System.out.println(\u0026#34;고기 6종류 재료를 추가합니다.\u0026#34;); } } BaconCheddarCheesePizza\n1 2 3 4 5 6 7 8 package pizza; public class BaconCheddarCheesePizza { public void addIngredient() { System.out.println(\u0026#34;베이컨과 체다 치즈를 추가합니다.\u0026#34;); } } 그리고 각 클래스의 인스턴스를 생성한 후, 메인 재료를 추가하는 작업을 수행한다.\nPizzaMain\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package pizza; public class PizzaMain { public static void main(String[] args) { PotatoPizza potatoPizza = new PotatoPizza(); SweetPotatoPizza sweetPotatoPizza = new SweetPotatoPizza(); BaconCheddarCheesePizza baconCheddarCheesePizza = new BaconCheddarCheesePizza(); AllMeatPizza allMeatPizza = new AllMeatPizza(); potatoPizza.addIngredient(); sweetPotatoPizza.addIngredient(); baconCheddarCheesePizza.addIngredient(); allMeatPizza.addIngredient(); } } 실행 결과\n1 2 3 4 감자 재료를 추가합니다. 고구마 무스 재료를 추가합니다. 베이컨과 체다 치즈를 추가합니다. 고기 6종류 재료를 추가합니다. 하지만 각 피자마다 새로운 피자를 만든다는 작업 안내와 종료 안내를 하고 싶다. .ingredient() 메서드를 실행하기 전과 후 출력문을 추가한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 System.out.println(\u0026#34;새로운 피자를 만듭니다.\u0026#34;); potatoPizza.addIngredient(); System.out.println(\u0026#34;새로운 피자를 만들었습니다.\u0026#34;); System.out.println(\u0026#34;새로운 피자를 만듭니다.\u0026#34;); sweetPotatoPizza.addIngredient(); System.out.println(\u0026#34;새로운 피자를 만들었습니다.\u0026#34;); System.out.println(\u0026#34;새로운 피자를 만듭니다.\u0026#34;); baconCheddarCheesePizza.addIngredient(); System.out.println(\u0026#34;새로운 피자를 만들었습니다.\u0026#34;); System.out.println(\u0026#34;새로운 피자를 만듭니다.\u0026#34;); allMeatPizza.addIngredient(); System.out.println(\u0026#34;새로운 피자를 만들었습니다.\u0026#34;); 위 코드는 계속 반복된다는 문제점이 있다. 이 반복을 줄이기 위해서 어떤 방법들을 사용할 수 있을까?\naddIngredient()에 시작 및 종료 가이드문을 추가한다. 위 인스턴스들을 매개변수로 받으면서, 시작 및 종료 가이드문까지 포함하는 새로운 메서드를 생성한다. 인스턴스들을 한 배열에 담아 반복문을 통해 호출한다. 1번 방법의 경우, addIngredient() 메서드의 역할을 넘어버리기 때문에 1번 방법은 제외한다. 그러면 2번과 3번 방법만을 생각할 수 밖에 없는데, 매개변수를 선언할 때 이 매개변수의 타입을 어떻게 해야하며, 배열 선언 시에도 타입을 어떻게 해야할까? 위 피자 종류들의 타입은 다 다르기 때문에 현재 코드로는 불가능하다. 코드로 확인해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package pizza; public class PizzaMain { public static void main(String[] args) { ... makeNewPizza(SweetPotatoPizza); // 타입이 다른 피자를 makeNewPizza에 넘겼다. } public static void makeNewPizza(PotatoPizza pizza) { System.out.println(\u0026#34;새로운 피자를 만듭니다.\u0026#34;); pizza.addIngredient(); System.out.println(\u0026#34;새로운 피자를 만들었습니다.\u0026#34;); } } 위와 같이 코드를 작성하면 컴파일 에러가 발생한다. 그 이유는 타입이 다르기 때문이다. 이는 다른 피자 타입도 마찬가지다.\n1 \u0026#39;makeNewPizza(pizza.PotatoPizza)\u0026#39; in \u0026#39;pizza.PizzaMain\u0026#39; cannot be applied to \u0026#39;(pizza.SweetPotatoPizza)\u0026#39; 이렇게 타입이 다른 것들을 하나의 타입으로 취급하여 특정 작업을 수행할 필요가 있을 때 \u0026lsquo;다형적 참조\u0026rsquo;를 사용하면 된다.\n위 클래스들을 자식 클래스로 만들도록 부모 클래스 Pizza를 만들어보자.\n1 2 3 4 5 6 package pizza; public class Pizza { public void addIngredient() {} } 그러면 자식 클래스로 만들기 위해 예를 들어 PotatoPizza만 예시로 나타낸다. extends 예약어를 사용하여 Pizza 부모 클래스를 상속받고, @Override를 사용해서 부모 메서드를 오버라이딩한다. 다른 피자 타입들도 상속받는다.\n1 2 3 4 5 6 7 8 9 package pizza; public class PotatoPizza extends Pizza { @Override public void addIngredient() { System.out.println(\u0026#34;감자 재료를 추가합니다.\u0026#34;); } } 그러면 makeNewPizza 메서드의 파라미터 타입을 Pizza로 수정하여 다음과 같이 코드 반복을 줄여보자.\n수정된 코드\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package pizza; public class PizzaMain { public static void main(String[] args) { ... makeNewPizza(potatoPizza); makeNewPizza(sweetPotatoPizza); makeNewPizza(baconCheddarCheesePizza); makeNewPizza(allMeatPizza); } public static void makeNewPizza(Pizza pizza) { // 매개변수 타입 수정 System.out.println(\u0026#34;새로운 피자를 만듭니다.\u0026#34;); pizza.addIngredient(); System.out.println(\u0026#34;새로운 피자를 만들었습니다.\u0026#34;); } } 실행 결과\n1 2 3 4 5 6 7 새로운 피자를 만듭니다. 감자 재료를 추가합니다. 새로운 피자를 만들었습니다. ... 새로운 피자를 만듭니다. 고기 6종류 재료를 추가합니다. 새로운 피자를 만들었습니다. 이렇게 해서 2번 방법을 적용했다. 다음으로 3번 방법인 배열을 적용해보자. 배열도 선언 시 타입을 입력해야하기 때문에 파이썬의 리스트와 달리 동일한 타입들로만 담을 수 있다.\n1 2 3 4 5 Pizza[] pizzaList = {potatoPizza, sweetPotatoPizza, baconCheddarCheesePizza, allMeatPizza}; for (Pizza pizza : pizzaList) { makeNewPizza(pizza); } 동일한 결과를 얻을 수 있고, 반복횟수가 줄어들고, 가독성이 더 향상된 걸 확인할 수 있다!\n다형적 참조 다형성의 두 가지 특징인 \u0026lsquo;다형적 참조\u0026rsquo;와 \u0026lsquo;메서드 오버라이딩\u0026rsquo; 관점에서 위 코드를 다시 봐보자.\n다음과 같은 타입과 변수명으로 참조변수를 만들었다.\nPotatoPizza potatoPizza SweetPotatoPizza sweetPotatoPizza BaconCheddarCheesePizza baconCheddarCheesePizza AllMeatPizza allMeatPizza 다 타입이 다르기 때문에 배열을 선언하거나 메서드에서 매개변수로 객체를 받기가 어려웠다.\n하지만 Pizza 부모 클래스를 만들어 상속으로 다음과 같이 부모 클래스 타입의 배열 선언과, 부모 클래스 타입의 매개변수로 전달할 수 있다.\n배열 선언\n1 Pizza[] pizzaList = {potatoPizza, sweetPotatoPizza ...}; 매개변수로 전달\n1 2 3 4 5 6 7 8 makeNewPizza(potatoPizza); makeNewPizza(sweetPotatoPizza); ... public static void makeNewPizza(Pizza pizza) { //매개변수 pizza의 타입을 Pizza로 지정 ... } 메서드 오버라이딩 메서드 오버라이딩을 사용하지 않는다면 Pizza 타입인 메서드의 매개변수는 Pizza의 addIngredient()가 실행될 것이다. 여기에는 메서드 바디가 없기 때문에 출력될 내용이 없다. 하지만 메서드 오버라이딩을 사용하여 타입은 Pizza인 pizza 매개변수를 통해 pizza.addIngredient()가 실행되었지만, 자식 클래스들의 오버라이딩된 메서드가 실행되어 각 자식 클래스만의 고유한 특징이 반영되서 실행된 걸 확인할 수 있다.\n1 2 3 4 5 6 7 새로운 피자를 만듭니다. 감자 재료를 추가합니다. 새로운 피자를 만들었습니다. ... 새로운 피자를 만듭니다. 고기 6종류 재료를 추가합니다. 새로운 피자를 만들었습니다. Enhanced For Loop에도 사용 또한 다형성과 상관없는 것이지만 Enhanced For Loop에도 지역변수 타입으로 Pizza를 지정하여 pizzaList에 있는 변수들이 사실 Pizza 타입이 아니어도 Pizza를 상속받는 자식 타입이기 때문에 아래와 같이 코드를 작성할 수 있다.\n1 2 3 for (Pizza pizza : pizzaList) { makeNewPizza(pizza); } 문제점 두 가지 첫 번째, 추상적인 개념에 불과한 Pizza 클래스로 인스턴스 생성이 가능해 누군가 실수로 new 키워드로 인스턴스를 생성하는 걸 막을 수 없다.\n내가 정의한 Pizza는 실제로 존재하는 물체가 아닌 \u0026lsquo;추상적인 개념\u0026rsquo;에 불과하다. 실제로 존재하는 건 베이컨 피자, 고구마 피자 등등이다. 더 예시를 들자면 Animal이라는 클래스를 만들었다고 하자. 이 동물 클래스는 실체로 존재하는 게 아닌 추상적인 개념으로만 존재한다. 실체는 이 동물의 예시인 개, 고양이, 소다. 그런데 이 Animal로 실제로 존재하는 인스턴스를 생성한다면 사용할 일이 없기 때문에 메모리만 낭비하게 된다.\n두 번째, 부모 클래스를 오버라이딩 하지 않을 가능성이 존재한다.\n부모 메서드를 반드시 오버라이딩 해야 하는 강제성이 없기 때문에 실수로 오버라이딩하지 않을 경우, @Override를 사용하지 않을 경우 부모의 메서드가 호출되는 문제점이 존재한다.\n추상 클래스 위 두 가지 문제점을 해결하기 위해 사용하는 방법이 \u0026lsquo;추상 클래스(abstract class)\u0026lsquo;다. 추상적인 개념만 제공하기 때문에 실체인 인스턴스가 존재하지 않고, 오직 상속을 목적으로만 사용되기 때문에 부모 클래스 역할을 한다. 그래서 반드시 오버라이딩해야 하는 메서드를 이 부모 클래스에 정의할 수 있다.\n인스턴스 생성 불가능한 추상 클래스 만약 추상 클래스의 인스턴스를 생성하려 한다면 어떻게 되는지 아래 코드와 컴파일 에러를 확인해보자.\n추상 클래스의 인스턴스 생성하기\n1 2 3 4 5 6 7 8 9 package pizza; public class PizzaMain { public static void main(String[] args) { Pizza pizza = new Pizza(); // 추상 클래스의 인스턴스 생성 ... } } 컴파일 에러\n1 \u0026#39;Pizza\u0026#39; is abstract; cannot be instantiated 추상 메서드 다음으로 추상 클래스 안에 정의된 메서드 중 abtract 키워드가 붙어 있는 메서드를 추상 메서드(abstract method) 라 한다. 추상 메서드는 메서드 바디를 가지고 있지 않고, 메서드 시그니처만 존재한다.\n1 2 // 추상 메서드 public abstract void addIngredient(); 컴파일 에러: Abstract methods cannot have a body 이 추상 메서드에 위 코드와 달리 다음과 같이 메서드 바디를 만들 경우, 컴파일 에러가 발생한다. 그래서 추상 메서드는 반드시 메서드 바디가 없어야 한다.\n1 public abstract void addIngredient() {}; 컴파일 에러\n1 Abstract methods cannot have a body 컴파일 에러: 자식 클래스가 추상 메서드를 오버라이딩하지 않는 경우 또한, 이 추상 메서드는 메서드 바디가 없기 때문에 자식 클래스에서 반드시 오버라이딩해야 한다. 오버라이딩을 하지 않으면 다음과 같은 에러가 발생한다.\n만약 추상 메서드와 다른 메서드 이름으로 자식 클래스에 선언할 경우 다음과 같은 컴파일 에러가 발생한다. 또한, 추상 클래스를 상속받는 자식 클래스 내에 어떠한 메서드도 선언하지 않아도 동일한 컴파일 에러가 발생한다.\n1 2 3 4 5 6 7 8 public class PotatoPizza extends Pizza { ... public void add() { // 메서드명이 추상 메서드와 같지 않음 System.out.println(\u0026#34;감자 재료를 추가합니다.\u0026#34;); } } 컴파일 에러\n1 Class \u0026#39;PotatoPizza\u0026#39; must either be declared abstract or implement abstract method \u0026#39;addIngredient()\u0026#39; in \u0026#39;Pizza\u0026#39; 위 상황에서 자식 메서드에 @Override 애노테이션을 추가하면 다음과 같은 컴파일 에러가 발생한다.\n컴파일 에러\n1 Method does not override method from its superclass 그리고 추상 메서드를 사용한다면 굳이 @Override를 사용할 필요가 없는 것 같다.\n컴파일 에러: 일반 클래스 안에 추상 메서드 선언하기 만약 아래 코드처럼 일반 클래스 안에 추상 메서드를 선언하면 다음 에러가 발생한다.\n일반 클래스 안에 추상 메서드 선언\n1 2 3 4 public class Pizza { public abstract void addIngredient(); } 컴파일 에러\n1 Abstract method in non-abstract class 추상 클래스와 추상 메서드 필수 사항 정리 위 내용들을 정리하면 추상 클래스를 만들 때는 반드시 수행해야하는 규칙 3가지가 있다.\n추상 클래스, 추상 메서드를 정의할 때 \u0026lsquo;추상\u0026rsquo;이 들어가는 뭐든지 abstract 키워드를 붙여야 한다. 추상 메서드가 하나라도 있는 클래스는 추상 클래스로 선언해야 한다. 추상 메서드는 메서드 바디가 없는 메서드로, 불완전한 메서드다. 추상 클래스에는 추상 메서드와 추상이 아닌 메서드 모두 존재할 수 있다. 추상 메서드는 메서드 바디가 없기 때문에 자식 클래스가 반드시 오버라이딩해서 사용해야 한다. 위 사항들을 지키지 않으면 앞선 에러 코드 사례처럼 컴파일 오류가 발생한다.\n순수 추상 클래스 위 코드들에서는 추상 메서드가 하나인 경우만을 확인했다. 이번에는 모든 메서드가 추상 메서드인 \u0026lsquo;순수 추상 클래스\u0026rsquo; 경우를 확인해보자.\n1 2 3 4 5 6 7 package pizza; public abstract class Pizza { public abstract void addIngredient(); public abstract void bake(); } 이 Pizza 추상 클래스를 상속받는 자식 클래스는 부모 메서드를 모두 오버라이딩해야 한다.\n순수 추상 클래스의 특징 인스턴스 생성 불가능 상속 시 모든 메서드를 오버라이딩해야 한다. 주로 다형성을 위해 사용된다. 인터페이스 하지만, 자바에서는 이 순수 추상 클래스를 더 편리하게 사용할 수 있도록 \u0026lsquo;인터페이스\u0026rsquo;라는 개념을 제공한다. \u0026lsquo;인터페이스\u0026rsquo;는 클래스명 앞에 예약어로 abstract class가 아니라 interface 키워드를 사용하면 된다.\n메서드는 public abstract 키워드를 생략할 수 있다.\n1 2 3 4 5 6 7 package pizza; public interface Pizza { void addIngredient(); void bake(); } 인터페이스는 위 순수 추상 클래스의 특징에 몇 가지 편의 기능이 추가된다.\n인터페이스의 메서드는 모두 public, abstract이다. 즉 모두 추상 메서드다. 메서드는 public abstract를 생략할 수 있다. 생략이 권장된다. 인터페이스는 다중 상속(구현)을 지원한다. 클래스, 추상 클래스, 인터페이스는 프로그램 코드, 메모리 구조상 모두 동일하다.\n인터페이스는 상속이 아닌 구현이라 한다. 부모 자식 관계에 있는 클래스들을 설명할 때는 부모 클래스를 상속받는 클래스를 자식 클래스라고 한다. 하지만, 인터페이스라면 이 인터페이스를 구현한 클래스라고 한다. \u0026lsquo;상속\u0026rsquo;이라는 단어 대신 \u0026lsquo;구현\u0026rsquo;이라는 단어를 사용한다. 상속은 이름 그대로 부모의 기능을 물려받는 것이 목적이다. 하지만, 인터페이스는 모든 메서드가 추상 메서드이기 때문에, 물려받을 수 있는 기능이 없고, 오히려 모든 메서드를 자식이 오버라이딩해서 기능을 구현해야 한다. 따라서 인터페이스는 메서드 이름만 있는 설계도이고, 이 설계도를 토대로 하위 클래스에서 구현해야 한다.\n그래서 보면 \u0026lsquo;상속\u0026rsquo;과 \u0026lsquo;구현\u0026rsquo; 단어만 다를 뿐 일반 상속 구조와 동일하게 작동한다.\n인터페이스의 구현 그래서 부모 자식 관계에 있는 클래스를 규정 짓는 예약어는 extends 였지만, 인터페이스를 구현하는 클래스 관계를 규정 짓는 예약어는 implements다.\nPizza 인터페이스\n1 2 3 4 5 6 7 package pizza; public interface InterfacePizza { public abstract void addIngredient(); public abstract void bake(); } PotatoPizza\n1 2 3 4 5 6 7 8 9 10 11 12 13 package pizza; public class PotatoPizza implements InterfacePizza { public void addIngredient() { System.out.println(\u0026#34;감자 재료를 추가합니다.\u0026#34;); } @Override public void bake() { System.out.println(\u0026#34;피자를 굽습니다.\u0026#34;); } } 그리고 인터페이스의 인스턴스를 생성하려고 한다면?\nPizzaMain 클래스\n1 2 3 4 5 6 7 8 package pizza; public class PizzaMain { public static void main(String[] args) { InterfacePizza interfacePizza = new InterfacePizza(); } } 컴파일 에러\n1 \u0026#39;InterfacePizza\u0026#39; is abstract; cannot be instantiated 위와 같이 컴파일 에러가 발생하고, 인스턴스를 생성할 수 없다는 에러가 발생한다.\n인터페이스를 사용하는 이유 추상 클래스는 추상 메서드가 아닌 메서드도 존재할 수 있으므로 나중에 메서드를 끼어넣을 수 있다.\n하지만, 인터페이스에 있는 모든 메서드는 추상 메서드이기 때문에, 이 인터페이스를 구현하는 클래스들은 반드시 추상 메서드를 오버라이딩해야 하는 강제성을 부여한다(제약). (첫 번째 이유)\n그리고, 자바에서는 부모 클래스로 하나만 가질 수 있지만 인터페이스를 사용하면 부모를 다중 구현(다중 상속)이 가능하다. 인터페이스는 다중 상속을 허용하는 이유는 모두 다 추상 메서드이기 때문이다. 인터페이스가 아닌 클래스이고, 다중 상속되는 상황이고, 두 부모 클래스 모두 각각 동일한 메서드 시그니처를 가진다면 상속 받는 자식 클래스는 어떤 것을 상속받는 것일지 결정하기 어렵다. 그리고 클래스 계층 구조가 매우 복잡해지기 때문에, 클래스의 다중 상속을 허용하지 않다. 하지만 인터페이스는 모두 다 메서드 바디가 없기 때문에 어떤 인터페이스의 메서드를 구현해도 문제가 되지 않는다. (두 번째 이유)\n파이썬에서는 인터페이스가 존재하지 않고, 여러 개의 클래스를 다중 상속 가능하다.\n다중 구현 예시 그러면 인터페이스를 사용할 때 두 번째 장점인 \u0026lsquo;다중 구현\u0026rsquo;에 대해 알아보자!\nInterfaceA 인터페이스\n1 2 3 4 public interface InterfaceA { void methodA(); void methodCommon(); } InterfaceB 인터페이스\n1 2 3 4 public interface InterfaceB { void methodB(); void methodCommon(); } 위 코드를 보면 interface를 사용하여 인터페이스를 정의한다. 이 안에 정의한 메서드들은 다 추상 메서드 이므로 public abstract는 생략한다.\nChild 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class Child implements InterfaceA, InterfaceB{ @Override public void methodA() { System.out.println(\u0026#34;Child.methodA\u0026#34;); } @Override public void methodB() { System.out.println(\u0026#34;Child.methodB\u0026#34;); } @Override public void methodCommon() { System.out.println(\u0026#34;methodCommon\u0026#34;); } } 인터페이스이므로 다중 구현이 가능하다.\nChildMain 클래스 1 2 3 4 5 6 7 8 9 10 11 public class ChildMain { public static void main(String[] args) { InterfaceA interfaceA = new Child(); interfaceA.methodA(); interfaceA.methodCommon(); InterfaceB interfaceB = new Child(); interfaceB.methodB(); interfaceB.methodCommon(); } } 인터페이스 또한 생성된 인스턴스 안에 정보가 생성되기 때문에 자식 클래스의 인스턴스를 인터페이스 타입으로 지정할 수 있다.\n실행 결과\n1 2 3 4 Child.methodA methodCommon Child.methodB methodCommon 그리고 인터페이스 안에 정의한 추상 메서드들 모두 오버라이딩 되었기 때문에 위와 같은 출력 결과를 확인할 수 있다.\n인터페이스와 추상 클래스 함께 사용하기 AbstractAnimal 추상 클래스\n1 2 3 4 5 6 public abstract class AbstractAnimal { public abstract void sound(); public void move() { System.out.println(\u0026#34;동물이 이동합니다.\u0026#34;); } } Fly 인터페이스\n1 2 3 public interface Fly { void fly(); } Cat 자식 클래스: 추상 클래스만 받음\n1 2 3 4 5 6 7 public class Cat extends AbstractAnimal{ @Override public void sound() { System.out.println(\u0026#34;냐옹~\u0026#34;); } } Crow 자식 클래스: 추상 클래스와 인터페이스 모두 받음\n1 2 3 4 5 6 7 8 9 10 11 public class Crow extends AbstractAnimal implements Fly{ @Override public void sound() { System.out.println(\u0026#34;까악 까악\u0026#34;); } @Override public void fly() { System.out.println(\u0026#34;날개짓\u0026#34;); } } AnimalMain: 자식 클래스들의 인스턴스를 생성하고, 메서드를 추가로 만들어 메서드 매개변수 타입을 추상 클래스와 인터페이스로 지정\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class AnimalMain { public static void main(String[] args) { Cat cat = new Cat(); Crow crow = new Crow(); soundAnimal(cat); soundAnimal(crow); flyAnimal(crow); } public static void soundAnimal(AbstractAnimal animal) { System.out.println(\u0026#34;===== Enter in soundAnimal =====\u0026#34;); animal.sound(); } public static void flyAnimal(Fly animal) { System.out.println(\u0026#34;===== Enter in flyAnimal =====\u0026#34;); animal.fly(); } } 실행 결과\n1 2 3 4 5 6 ===== Enter in soundAnimal ===== 냐옹~ ===== Enter in soundAnimal ===== 까악 까악 ===== Enter in flyAnimal ===== 날개짓 위 실행 결과를 보면 매개변수의 타입은 추상 클래스와 인터페이스지만, 메서드 오버라이딩으로 인스턴스의 메서드가 실행되는 걸 알 수 있다.\n","permalink":"http://jeha00.github.io/post/java/5_polymorphism/","summary":"자바의 메모리 영역과 상속을 토대로 어떻게 다형성이 구현되는지, 다형성을 구현하는 방법 중 하나인 캐스팅, 그리고 효과적으로 다형성을 구현하기 위한 추상 클래스와 인터페이스에 대해 알아본다.","title":"자바의 다형적 참조, 추상 클래스 그리고 인터페이스"},{"categories":"java","content":"상속에 대해서 상속, 부모 클래스, 자식 클래스란? 기존 클래스의 필드와 메서드를 새로운 클래스에서 재사용하도록 물려받는 것을 \u0026lsquo;상속\u0026rsquo;이라 한다.\n이 상속을 통해서 자신의 필드와 메서드를 제공하는 클래스를 부모 클래스 (슈퍼 클래스), 부모 클래스로부터 필드와 메서드를 상속받는 클래스를 자식 클래스 (서브 클래스) 라 한다.\n자바에서 상속은 extends 라는 키워드를 통해서 수행된다. 이 키워드를 통한 상속은 오직 하나의 클래스만 받을 수 있다. \u0026lsquo;다중 상속\u0026rsquo;은 불가능하다. (하지만 이 부분을 해결하는 방법이 있다. 이는 나중에 학습하자.)\n상속의 이점에 대해 알아보자.\n아래에 상속을 받지 않는 TomatoPasta 와 BaconCreamPasta가 있다.\nTamatoPasta 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class TomatoPasta { int price; String name; String sauce; public void cookTomato() { System.out.println(\u0026#34;토마토를 조리합니다.\u0026#34;); } public void complete() { System.out.println(\u0026#34;조리를 완료합니다.\u0026#34;); } public void serve() { System.out.println(\u0026#34;완료된 음식을 서빙합니다.\u0026#34;); } } BaconCreamPasta 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class BaconCreamPasta { int price; String name; String sauce; public void cookBacon() { System.out.println(\u0026#34;베이컨을 조리합니다.\u0026#34;); } public void makeCream() { System.out.println(\u0026#34;크림 소스를 만듭니다.\u0026#34;); } public void complete() { System.out.println(\u0026#34;조리를 완료합니다.\u0026#34;); } public void serve() { System.out.println(\u0026#34;완료된 음식을 서빙합니다.\u0026#34;); } } 위 2개의 클래스에 상속을 적용해보자.\n상속의 부모 클래스로 Pasta 를 만든다. Pasta를 한 이유는 토마토 파스타와 베이컨 크림 파스타 모두 파스타의 구체적인 개념이고, Pasta는 이 두 파스타의 추상적인 개념이기 때문이다.\nPasta 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Pasta { int price; String name; String sauce; public void complete() { System.out.println(\u0026#34;조리를 완료합니다.\u0026#34;); } public void serve() { System.out.println(\u0026#34;완료된 음식을 서빙합니다.\u0026#34;); } } TamatoPasta 클래스\n1 2 3 4 5 6 public class TomatoPasta extends Pasta { public void cookTomato() { System.out.println(\u0026#34;토마토를 조리합니다.\u0026#34;); } } BaconCreamPasta 클래스\n1 2 3 4 5 6 7 8 9 10 public class BaconCreamPasta extends Pasta { public void cookBacon() { System.out.println(\u0026#34;베이컨을 조리합니다.\u0026#34;); } public void makeCream() { System.out.println(\u0026#34;크림 소스를 만듭니다.\u0026#34;); } } 모든 파스타에서 공통으로 가지는 속성과 기능은 Pasta 클래스에서 전달하고, 구체적인 파스타마다 가지는 필드와 기능은 자식 클래스에서 가진다.\n그래서 부모가 가지는 것은 상속을 통해 자식도 당연히 가지고 있지만, 자식이 가지고 있는 건 부모가 가질 수 없다.\n상속과 기능 추가 그러면 상속의 장점을 느껴보자. 부모 클래스를 상속받은 자식 클래스 세 개가 있다.\n이 자식 클래스에 A라는 메서드와 B라는 필드를 추가할려고 할 때, 상속을 사용하지 않는다면 각 자식 클래스마다 A 메서드와, B 필드를 입력해야 한다. 하지만, \u0026lsquo;상속\u0026rsquo;을 사용한다면 자식 클래스가 상속 받은 부모 클래스에 추가한다면 손쉽게 확장할 수 있다.\n예시 코드를 통해 확인해보자. 앞선 예시와 동일한 코드에 속성과 기능을 하나씩 추가하려고 한다.\n속성: 면의 종류 정보를 가지고 있는 noodle 기능: 면을 삶는 기능인 cookNoodles() 상속을 통해 TomatoPasta와 BakonCreamPasta 클래스에 각각 추가하지 않고 Pasta 클래스에 추가한다.\nPasta 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class Pasta { int price; String name; String sauce; String noodle; // 추가된 속성 // 추가된 기능 public void cookNoodles() { System.out.println(\u0026#34;면을 삶습니다.\u0026#34;) } public void complete() { System.out.println(\u0026#34;조리를 완료합니다.\u0026#34;); } public void serve() { System.out.println(\u0026#34;완료된 음식을 서빙합니다.\u0026#34;); } } 나머지 TomatoPasta와 BakonCreamPasta 클래스들은 동일하다.\n만약 새로운 파스타 종류를 추가한다면 Pasta를 상속받아 새로 만드는 파스타만의 속성과 기능만 추가하면 된다.\n새로 추가하는 GarlicAndOliveOilPasta 클래스\n1 2 3 4 5 6 public class GarlicAndOliveOilPasta extends Pasta { public void makeGarlicOilSauce() { System.out.println(\u0026#34;마늘과 올리브 오일을 사용해서 소스를 만듭니다.\u0026#34;); } } 상속과 메모리 구조 🔆 우리는 앞선 포스팅에서 JVM의 메모리 영역에 대해서 학습했다.\n어떻게 메모리에서 상속이 어떻게 구현되고 작동되는지 알아보자.\n위 예시 코드를 기반으로 각 파스타에 대한 인스턴스를 생성한 PastaMain 코드가 있다.\nPastaMain 클래스\n1 2 3 4 5 6 7 8 public class PastaMain { public static void main(String[] args) { TomatoPasta pasta1 = new TomatoPasta(); pasta1.cookTomato(); pasta1.complete(); } } 그리고 TomatoPasta 만의 속성으로 tomatoOrigin 을 추가한다. 이 속성의 값은 Korea로 고정시킨다. 이러면 클래스 변수로 설정하는 게 좋지만, 상속과 메모리 구조 이해를 위해 한다.\nTomatoPasta 클래스\n1 2 3 4 5 6 7 8 public class TomatoPasta extends Pasta { String tomatoOrigin = \u0026#34;Korea\u0026#34;; public void cookTomato() { System.out.println(\u0026#34;토마토를 조리합니다.\u0026#34;); } } 위 코드가 실행되면 다음 그림에 나온 순서처럼 실행된다.\n인스턴스에는 부모와 자식 클래스 정보가 모두 포함되어 있고, 영역이 구분된다. 인스턴스 참조값이 담겨진 참조 변수의 참조값은 하나이지만, 실제로 그 안에는 부모 클래스와 자식 클래스 정보가 공존한다. 즉, 부모 클래스까지 포함해서 인스턴스를 생성한다. 그래서 상속이라고 하여 단순히 물려받는게 아니다. 부모와 자식 클래스의 인스턴스 정보가 모두 생성되고 메모리 영역에서 공간도 구분된다. 부모 클래스의 멤버 필드의 값 정보는 인스턴스의 부모 공간에 생성되고, 자식 클래스의 멤버 필드의 값 정보는 인스턴스의 자식 공간에 생성된다.\n위 내용을 바탕으로 다시 위 그림을 보자. pasta1 참조 변수가 TomatoPasta 클래스의 인스턴스 참조값을 가지고 있다. 이 참조값이 가리키고 있는 heap 영역을 보면 생성된 인스턴스 내부에는 부모 클래스인 Pasta의 영역과 자식 클래스인 TomatoPasta의 영역으로 나눠져 있는 걸 확인할 수 있다. 그래서 단지 TomatoPasta의 인스턴스 속성만 있는 게 아니라, Pasta의 인스턴스 속성도 있는 걸 확인할 수 있다.\n메모리 공간 크기 그래서 메모리 공간 크기의 관점에서 보자면 부모 클래스의 필드와 속성까지 생성되기 때문에 메모리 공간이 더 필요하다.\n위 내용을 바탕으로 다시 위 그림을 보면 왜 메모리 공간 크기가 더 필요한지 직관적으로 받아들여질 수 있다.\n상속 관계 객체 호출 시, 대상 타입 지정 인스턴스 내부에 부모 클래스 속성까지 포함해서 생성되기 때문에, 참조 변수 선언 시 어떤 객체 타입으로 할지를 정확하게 지정해줘야 한다. 왜냐하면 인스턴스에는 부모 클래스에 대한 정보와 자식 클래스에 대한 정보가 모두 포함되어 있기 때문에, 어느 클래스부터 조회할지를 결정해야 한다. 이를 결정하는 방법이 바로 호출하는 변수의 타입(클래스)을 기준으로 선택하기 때문이다.\n위 내용을 바탕으로 그림을 다시 보면 참조 변수 pasta1을 선언할 때 TomatoPasta로 타입을 지정했기 때문에 메서드 실행 시, 첫 번째로 조회하는 클래스 타입이 TomatoPasta임을 알 수 있다.\n참조 방향 지정한 본인 타입에서 기능을 찾지 못하면 상위 부모 타입으로 기능을 찾아서 실행한다. 만약 더 더 상위 부모 타입까지 찾았는데 찾지 못한다면 컴파일 오류가 발생한다. 왜냐하면 참조 방향이 아래에서 위로만 올라가기 때문이다. 처음에는 본인 타입에서 필요한 필드나 메서드를 찾는다. 없으면 부모 타입에서 찾는다. 이렇게 계속 더 상위 부모에서 필요한 정보를 찾는다.\n위 내용을 바탕으로 그림을 다시 보면 pasta1.complete()를 실행할 때 TomatoPasta 클래스에서 찾지 못하자 extends 예약어를 통해서 부모 클래스를 인식하여 Pasta 부모 클래스로 올라가 complete() 메서드를 실행한 걸 확인할 수 있다.\n그러면 위 코드를 수정해서 컴파일 오류를 발생시켜보자.\n1 2 3 4 5 6 7 public class PastaMain { public static void main(String[] args) { Pasta pasta1 = new TomatoPasta(); pasta1.cookTomato(); } } 위와 같이 수정했다. 인스턴스는 TomatoPasta의 인스턴스이기 때문에 인스턴스에는 부모 클래스와 자식 클래스의 인스턴스 속성 정보가 모두 포함되어 있다. 참조 방향이 위에서 아래로 올라간다면 위 코드는 컴파일 에러가 발생되고, 방향 상관없이 찾는다면 에러가 발생하지 않는다.\n수정하니 다음 같이 컴파일 에러가 발생했다.\njava: cannot find symbol symbol: method cookTomato() 위 결과를 통해서 참조 방향은 반드시 아래에서 위로만 올라간다 는 걸 확인했다.\n오버라이딩(Overriding) 부모에서 정의한 기능을 자식이 그대로 사용하는 경우도 있지만, 자식한테 보다 맞는 방식으로 기능을 재정의하고 싶을 때도 있다. 부모에게서 상속 받은 기능을 자식이 재정의하는 것을 메서드 오버라이딩(Overriding)이라 한다. 오버라이딩은 @Override 키워드를 사용한다.\n위 사용한 코드를 바탕으로 오버라이딩을 해보자. Pasta 클래스의 serve() 메서드를 재정의해보자.\nTomatoPasta 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class TomatoPasta extends Pasta { String tomatoOrigin = \u0026#34;Korea\u0026#34;; public void cookTomato() { System.out.println(\u0026#34;토마토를 조리합니다.\u0026#34;); } @Override public void serve() { System.out.println(\u0026#34;완료된 토마토 파스타를 바질 잎과 함께 서빙합니다.\u0026#34;); } } BaconCreamPasta 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class BaconCreamPasta extends Pasta { public void cookBacon() { System.out.println(\u0026#34;베이컨을 조리합니다.\u0026#34;); } public void makeCream() { System.out.println(\u0026#34;크림 소스를 만듭니다.\u0026#34;); } @Override public void serve() { System.out.println(\u0026#34;완료된 베이컨 크림 파스타에 치즈를 뿌려서 서빙합니다.\u0026#34;); } } @Override annotation(애노테이션)이 필요한 이유 @ 이 붙은 부분을 annotation(애노테이션)이라 하며, \u0026lsquo;주석\u0026rsquo;을 의미한다. 하지만 일반적인 주석이 아니라, 프로그램이 읽을 수 있는 특별한 주석이다.\n이 @Override를 통해서 상위 클래스의 메서드를 오버라이드하는 것임을 나타낸다. 그러면 상위 클래스의 어떤 메서드를 오버라이드한 건지를 컴파일러가 확인한다. 오버라이딩 조건을 만족시키지 않으면 컴파일 에러를 발생시켜서 실수로 오버라이딩을 못하는 경우를 방지한다. 예를 들어 위 코드를 기준으로 보자면 부모 클래스에 serve() 메서드가 없다면 컴파일 오류가 발생한다. 그래서 권장하지만 필수로 이 애노테이션을 사용하자.\n컴파일 에러가 발생하는 경우에 대해 더 이야기해보겠다. 부모의 메서드를 오버라이딩한 자식 메서드를 호출하려고 한다. 그런데 파라미터의 타입을 잘못 지정해서 또는 메서드 이름에 오타가 생겨서 자식 클래스의 메서드가 아닌, 부모 클래스의 메서드를 호출하는 경우를 방지하기 위해 @Override 애노테이션을 사용한다. 이 애노테이션이 없어도 오버라이딩은 되지만, 에러를 잡아내지 못하기 때문에 필수로 사용해야 한다.\n오버라이딩과 메모리 구조 애노테이션을 통해서 자식 클래스에 메서드를 재정의했으므로, 참조 변수의 타입이 자식 클래스이면 자식 클래스부터 조회하기 시작하여 부모 타입을 찾지 않고, 원하는 메서드를 찾아 실행된다.\n오버로딩(Overloading)과 오버라이딩(Overriding)의 차이 오버라이딩은 이미 알아봤으니 오버로딩에 대해서만 설명하겠다.\n메서드 오버로딩(method overloading)은 메서드 이름이 같고 매개변수(파라미터)가 다른 메서드를 여러개 정의하는 것을 메서드 오버로딩(Overloading)이라 한다. 오버로딩은 번역하면 과적인데, 과하게 물건을 담았다는 뜻이다. 따라서 같은 이름의 메서드를 여러 개 정의했다고 이해하면 된다.\n메서드 시그니처에 대해 다시 짚어보자. 메서드 시그니처의 의미는 다음과 같다.\n메서드 시그니처 = 메서드 이름 + 파라미터의 타입, 순서, 갯수 등의 정보 오버라이딩은 이름은 같고 파라미터의 타입, 순서, 갯수가 다른 메서드를 만드는 것이기 때문에 결국 메서드 시그니처가 같지 않아 동일한 이름이어도 오버로딩이 가능한 것이다.\n오버라이딩의 조건 메서드 오버라이딩의 조건은 까다롭다. 그러니 최소한 메서드 시그니처가 같아야 오버라이딩이 가능하다 는 사실부터 시작해보자.\n오버라이딩의 조건을 풀어서 설명하겠다.\n메서드 이름: 메서드 이름이 같아야 한다. 메서드 매개변수: 매개변수의 타입, 순서, 갯수가 같아야 한다. 위 내용을 보면 메서드 시그니처가 같아야 한다는 걸 알 수 있다. 여기에 추가로 다음과 같은 조건들이 더 있다.\n반환 타입: 반환 타입이 같아야 한다. 단, 반환 타입이 하위 클래스 타입일 수 있다. 접근 제어자: 오버라이딩 메서드의 접근 제어자는 상위 클래스의 메서드보다 더 제한적이면 안된다. 예를 들어 상위 클래스의 메서드가 protected로 선언되어 있으면 오버라이딩된 하위 클래스의 메서드는 public 또는 protected 로만 가능하다. private과 default로 선언할 수 없다. static, final, private 키워드가 붙은 메서드는 오버라이딩 될 수 없다. static: 클래스 레벨에서 작동하므로 인스턴스 레벨에서 사용하는 오버라이딩은 의미가 없다. 클래스 이름으로 접근하면 되기 때문이다. final: 이 키워드를 사용하면 메서드 오버라이딩을 금지한다. private: 해당 클래스에서만 접근 가능하기 때문에, 하위 클래스에서 보이지 않아 오버라이딩을 할 수 없다. 생성자: 생성자는 오버라이딩할 수 없다. super()를 통해 부모 클래스의 생성자로 값을 전달해야 한다. 조건들이 위와 같이 많지만 이해하면 크게 어려운 게 없다.\nsuper 위 생성자 오버라이딩 관련해서 super 키워드를 언급했다. 이 키워드는 상속 개념과 관련하여 많이 사용되고, 언급되는 키워드다. 이 키워드에 대해 정리해보자.\nsuper 키워드를 통해서 2가지를 사용할 수 있다. \u0026lsquo;부모 참조\u0026rsquo;와 \u0026lsquo;부모 생성자\u0026rsquo;다.\n부모 참조 \u0026lsquo;부모 참조\u0026rsquo;부터 알아보자.\n상속과 오버라이딩을 사용한다고 해도 오버라이딩되지 않은 부모의 메서드를 사용하고 싶거나, 부모의 필드값을 사용하고 싶을 때에는 어떻게 해야할까?\n부모와 자식의 필드명이 같거나 메서드가 오버라이딩 되어 있으면, 자식에서 부모의 필드나 메서드를 호출할 수 없다. 필드명이 같으면 자식의 필드명으로 먼저 인식되어 부모의 필드를 사용할 수 없고, 메서드가 오버라이딩 되어 있으면 부모의 메서드가 아닌 오버라이딩한 자식의 메서드를 사용한다.\n이럴 때 this 처럼 자기 자신 인스턴스를 참조할 때 사용하듯이 부모 클래스를 참조할 때 super 키워드를 사용하면 부모를 참조할 수 있다. super 는 이름 그대로 부모 클래스에 대한 참조를 나타낸다.\n아래 코드를 보자. 부모 클래스의 필드명과 자식 클래스의 필드명 모두에 name이 있다.\n메서드도 serve() 로 자식 클래스에서 오버라이딩 되어 있다. 이때 자식 클래스에서 부모 클래스의 name 과 serve() 를 호출하고 싶다면 super 키워드를 사용하면 된다.\nPasta 클래스 1 2 3 4 5 6 7 8 9 10 11 12 package extends1.pra; public class Pasta { String name = \u0026#34;Pasta\u0026#34;; ... public void serve() { System.out.println(\u0026#34;완료된 음식을 서빙합니다.\u0026#34;); } } TomatoPasta 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package extends1.pra; public class TomatoPasta extends Pasta { String name = \u0026#34;TomatoPasta\u0026#34;; String tomatoOrigin = \u0026#34;Korea\u0026#34;; ... @Override public void serve() { System.out.println(\u0026#34;완료된 토마토 파스타를 바질 잎과 함께 서빙합니다.\u0026#34;); } public void call() { System.out.println(\u0026#34;자식 클래스: \u0026#34; + this.name); System.out.println(\u0026#34;부모 클래스: \u0026#34; + super.name); } this.serve(); super.serve(); } TomatoPasta pasta1 = new TomatoPasta(); 를 통해서 인스턴스 생성 후, pasta1.call()를 실행하면 다음과 결과를 확인할 수 있다.\n결과\n1 2 3 4 자식 클래스: TomatoPasta 부모 클래스: Pasta 완료된 토마토 파스타를 바질 잎과 함께 서빙합니다. 완료된 음식을 서빙합니다. super를 통해서 \u0026lsquo;부모 참조\u0026rsquo;로 자식 클래스에서 부모 클래스 안에 선언된 것들에 접근할 수 있다는 걸 확인할 수 있다. 하지만 이는 정확히 말하자면 접근 제어자로 허용했기 때문이다. 이에 대해서는 이 포스팅의 맨 마지막 단원에서 확인해본다.\n생성자 그 다음으로 super 키워드를 사용하여 자식 클래스에서 부모 클래스의 생성자를 호출해보자.\n상속과 메모리 구조 단원에서 상속 관계의 인스턴스를 생성하면 메모리의 힙 영역에는 부모와 자식 클래스의 인스턴스 정보가 모두 생성된다는 걸 확인했다. 위 코드 예시를 보자면 TomatoPasta를 생성하면 부모인 Pasta까지 함께 만들어진다는 것이다. 따라서 부모와 자식 각각의 생성자가 모두 반드시 호출되어야 한다. 이를 위해서는 자식 클래스의 생성자에서 반드시 부모 클래스의 생성자를 호출해야 한다. 이럴 때 사용하는 게 바로 super(...)다.\n아래 코드를 보자.\nPasta 클래스\n1 2 3 4 5 6 7 8 9 10 public class Pasta { ... public Pasta() { System.out.println(\u0026#34;부모 클래스 Pasta 생성자 호출\u0026#34;); } ... } TomatoPasta 클래스\n1 2 3 4 5 6 7 8 9 10 public class TomatoPasta extends Pasta { String name; public TomatoPasta(String name) { super(); this.name = name; System.out.println(\u0026#34;자식 클래스 TomatoPasta 호출\u0026#34;); } } PastaMain 클래스\n1 2 3 4 5 public class PastaMain { public static void main(String[] args) { TomatoPasta pasta1 = new TomatoPasta(\u0026#34;TomatoPasta\u0026#34;); } } 위 PastaMain 클래스를 실행하면 다음 결과를 확인할 수 있다.\n결과\n1 2 부모 클래스 Pasta 생성자 호출 자식 클래스 TomatoPasta 호출 자식 클래스의 생성자 안에 부모 클래스의 생성자를 super()를 사용해서 호출한 걸 확인할 수 있다.\n그러면 이번에는 super()를 빼고 실행해보자.\nTomatoPasta 클래스\n1 2 3 4 5 6 7 8 9 10 public class TomatoPasta extends Pasta { String name; public TomatoPasta(String name) { // super() 를 주석처리 했다. this.name = name; System.out.println(\u0026#34;자식 클래스 TomatoPasta 호출\u0026#34;); } } 다시 PastaMain을 실행하면 동일한 결과를 확인할 수 있다. 어째서일까? 매개변수가 없는 기본 생성자는 생략이 가능하기 때문에 super()를 입력하지 않아도 자동적으로 부모 클래스의 생성자가 호출된다. 기본 생성자를 많이 사용하기 때문에 이런 기능이 추가되었다.\n그 다음으로 부모의 기본 생성자 호출을 자식 생성자 안에서 첫 줄에 하는 게 아닌 두 번째 줄에다가 해보자.\nTomatoPasta 클래스\n1 2 3 4 5 6 7 8 9 10 public class TomatoPasta extends Pasta { String name; public TomatoPasta(String name) { this.name = name; super(); System.out.println(\u0026#34;자식 클래스 TomatoPasta 호출\u0026#34;); } } 위 코드 상태로 다시 PastaMain을 실행하면 다음과 같은 에러를 확인할 수 있다.\n결과\n1 java: call to super must be first statement in constructor 위 결과를 통해서 부모 클래스의 생성자를 호출하는 건 자식 클래스 생성자의 첫 번째 줄에 선언해야 한다 는 걸 확인할 수 있다.\n그러면 다음으로 기본 생성자가 아닌 사용자 정의 생성자를 사용해보자. 이를 위해서 새로운 코드를 사용하려고 한다. ClassA, ClassB, ClassC를 만들려고 한다. ClassA는 ClassB의 부모 클래스이고, ClassB는 ClassC의 부모 클래스다. super()를 사용해서 ClassC의 생성자에서 ClassB의 생성자를, ClassB의 생성자에서 ClassA의 생성자를 호출할 것이다.\nClassA 클래스\n1 2 3 4 5 6 7 8 public class ClassA { public ClassA(int firstValue) { System.out.println(\u0026#34;===== ClassA 생성자 호출 =====\u0026#34;); System.out.println(\u0026#34;ClassA 생성자의 firstValue: \u0026#34; + firstValue); System.out.println(\u0026#34;===== ClassA 생성자 호출 끝 =====\u0026#34;); } } ClassB 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class ClassB extends ClassA{ public ClassB(int firstValue) { super(firstValue); System.out.println(\u0026#34;===== ClassB 생성자 1 호출 =====\u0026#34;); System.out.println(\u0026#34;ClassB 생성자 1의 firstValue: \u0026#34; + firstValue); System.out.println(\u0026#34;===== ClassB 생성자 1 호출 끝 =====\u0026#34;); } public ClassB(int firstValue, int secondValue) { this(firstValue); System.out.println(\u0026#34;===== ClassB 생성자 2 호출 =====\u0026#34;); System.out.println(\u0026#34;ClassB 생성자 2의 firstValue: \u0026#34; + firstValue); System.out.println(\u0026#34;ClassB 생성자 2의 secondValue: \u0026#34; + secondValue); System.out.println(\u0026#34;===== ClassB 생성자 2 호출 끝 =====\u0026#34;); } } ClassC 클래스\n1 2 3 4 5 6 7 public class ClassC extends ClassB{ public ClassC() { super(1, 2); System.out.println(\u0026#34;===== ClassC 생성자 호출 =====\u0026#34;); } } Main 클래스\n1 2 3 4 5 public class Main { public static void main(String[] args) { ClassC instance = new ClassC(); } } 위 코드를 보면 다음 사항을 다시 알 수 있다.\nextends를 사용하여 부모 클래스로 무엇을 받을지 지정했다. 생성자의 첫 줄에 super()를 사용하여 부모 클래스의 생성자를 반드시 첫 번째로 호출했다. this()를 사용하여 생성자 오버로딩을 했다. 위 코드를 실행하면 결과는 다음과 같다.\n결과\n1 2 3 4 5 6 7 8 9 10 11 ===== ClassA 생성자 호출 ===== ClassA 생성자의 firstValue: 1 ===== ClassA 생성자 호출 끝 ===== ===== ClassB 생성자 1 호출 ===== ClassB 생성자 1의 firstValue: 1 ===== ClassB 생성자 1 호출 끝 ===== ===== ClassB 생성자 2 호출 ===== ClassB 생성자 2의 firstValue: 1 ClassB 생성자 2의 secondValue: 2 ===== ClassB 생성자 2 호출 끝 ===== ===== ClassC 생성자 호출 ===== 메서드 호출마다 스택 영역에 해당 메서드의 스택 프레임이 쌓인다.\n그리고, 스택이므로 후입선출 구조임을 다시 기억하면서 위 결과를 분석해보자.\n생성자 호출 순서는 다음과 같다.\nClassC 생성자 진입 -\u0026gt; ClassB 생성자 2 호출 -\u0026gt; ClassB 생성자 1 호출 -\u0026gt; ClassA 생성자 호출 그래서 호출 후 출력 순서는 위 결과처럼 ClassA부터 시작해서 ClasB 생성자 1 -\u0026gt; ClassB 생성자 2 -\u0026gt; ClassC 생성자 순서로 출력되는 것이다.\n상속과 접근 제어 이번에는 상속 관계의 두 클래스에 접근 제어자를 적용해보자. 개인적으로 접근 제어를 설명하기 위한 예시 코드로 다음 코드가 제일 좋다고 생각한다.\n아래 두 클래스는 서로 다른 패키지에 존재한다.\nParent 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package example.parent; // 패키지 위치 public class ParentClass { private int privateValue; int defaultValue; protected int protectedValue; public int publicValue; private void privateMethod() { System.out.println(\u0026#34;ParentClass privateMethod\u0026#34;); } void defaultMethod() { System.out.println(\u0026#34;ParentClass defaultMethod\u0026#34;); } protected void protectedMethod() { System.out.println(\u0026#34;ParentClass protectedMethod\u0026#34;); } public void publicMethod() { System.out.println(\u0026#34;ParentClass publicMethod\u0026#34;); System.out.println(\u0026#34;publicValue = \u0026#34; + publicValue); System.out.println(\u0026#34;protectedValue = \u0026#34; + protectedValue); System.out.println(\u0026#34;defaultValue = \u0026#34; + defaultValue); System.out.println(\u0026#34;privateValue = \u0026#34; + privateValue); } } Child 클래스\n1 2 3 4 5 6 7 8 9 10 11 package example.child; // 패키지 위치 import example.parent.ParentClass; public class ChildClass extends ParentClass { public void call() { publicMethod(); protectedMethod(); } } ChildMain 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package example; // 패키지 위치 import example.child.ChildClass; public class ChildMain { public static void main(String[] args) { ChildClass child = new ChildClass(); child.defaultMethod(); child.privateMethod(); child.protectedMethod(); child.call(); } } 그러면 위 ChildMain 클래스를 실행해보자.\n결과\n1 2 3 java: cannot find symbol symbol: method defaultMethod() location: variable child of type example.child.ChildClass defaultMethod()를 찾을 수 없다고 끈다. default 이기 때문에 같은 패키지가 아니면 접근할 수 없기 때문이다.\n다음으로 child.defaultMethod()를 주석처리한 후, 실행해보자.\n결과\n1 2 3 java: cannot find symbol symbol: method privateMethod() location: variable child of type example.child.ChildClass private이기 때문에 클래스 외부에서는 접근이 불가능하다는 걸 알 수 있다. 주석처리한 후, 다시 실행해보자. 그러면 인스턴스 생성 후, 첫 번째로 실행되는 코드는 child.protectedMethod()다.\n결과\n1 java: protectedMethod() has protected access in example.parent.ParentClass protected이기 때문에 같은 패키지 또는 상속 받은 클래스에서만 실행할 수 있기 때문에 위와 같은 에러가 발생했다. 그러면 이 코드도 주석처리를 한 후 실행해보자. 그러면 인스턴스 생성 후, 첫 번째로 실행되는 코드는 child.call()이다.\n결과\n1 2 3 4 5 6 ParentClass publicMethod publicValue = 0 protectedValue = 0 defaultValue = 0 privateValue = 0 ParentClass protectedMethod 그러면 코드가 잘 실행되는 거 확인할 수 있다.\n부모의 publicMethod 메서드는 public이기 때문에 호출이 가능하다. 자식 클래스이므로 다른 패키지여도 부모의 protectedMethod()를 호출할 수 있다. 그리고 부모의 publicMethod를 통해 부모의 private, defaul 값도 접근할 수 있다. ","permalink":"http://jeha00.github.io/post/java/4_inheritance/","summary":"자바에서는 상속과 오버라이딩을 어떻게 만드는지와 메모리 영역에서 어떻게 작동되는지 알아본다.","title":"상속과 오버라이딩이 메모리 영역에서 어떻게 이뤄지지?"},{"categories":"thinking","content":"미움 받을 용기가 없었다. 남들이 잘 가지 않는 길을 선택해서 갈 때는 \u0026lsquo;미움 받을 용기\u0026rsquo;가 필요하다.\n과거의 나는 다른 사람들의 시선을 신경쓰지 않고, 내가 하고 싶은 것을 선택했다고 생각했다. 하지만, 내가 했던 선택 또한 그 당시에 사람들이 좋다고 생각하는, 그 시기에 해야만하는 분위기에 휩쓸린 선택이었음을 알았다. 더 나은 사람들을 만나고, 더 나은 환경에 나를 넣기 위해 편입을 했고, 원하는 회사로 노후가 안정적이고 워라벨이 좋은 항공사 기술직 엔지니어를 선택해서 이를 위해 학부 전공 공부를 열심히 했다. 하지만 코로나가 터지면서 항공사로 가는 분은 닫혔고, 항공사 기술직은 나이를 보는 만큼 매우 보수적이기 때문에 기회는 나를 떠나갔다.\n다른 사람들이 하는 그대로 따라가는 것은 잘못된 게 아니다. 그 과정에서 나 자신에 대해 잘 알 수 있고, 나만의 경쟁력을 얻을 수 있다. 내가 말하고자 하는 건 그 분위기 안에서 가고 있을 때는 내 자신에 그것에 얼마나 많은 영향을 받고 있는지 알기 어렵다는 것이다.\n그 분위기 또는 그 단체에서 흔히 하지 않는 도전을 하고 부딪혀야만 그 때 선택이 오로지 나만의 원함으로 된 게 아니라는 걸 안다.\n내가 그 때 그 선택을 한 이유들에 대해 다시 살펴보니, 한 가지 이유로 정리할 수 있는 것 같다. 다른 사람들이 볼 때 그 나이 때 흔히 해야한다고 하는 것들 안에서 살아가는 게 사람들의 시선으로부터 미움받지 않기 때문이다.\n위 긴 문장을 더 짧게 요약하면 아래와 같이 표현할 수 있다.\n나는 \u0026lsquo;미움 받을 용기\u0026rsquo;가 없었다.\n내가 사랑하는 사람들로부터 미움 받을 용기 도전을 하면 나를 응원하는 사람들과 반대하는 사람들이 드러난다. 이 현상은 어느 단체에서든지 나타날 수 있다. 하지만 명확한 결실을 얻지 못하는 기간이 길어지면 나를 응원하는 사람들이 반대하기 시작한다. 반대하는 사람들을 설득하기 위해서는 결실이 있어야 한다. 결실이 없을수록 반대하는 사람들의 주장은 점차 커진다.\n이번 도전을 하면서 위 과정을 가족 내에서, 더 나아가 친척들한테까지 느낄 수 있었다.\n도전을 하면서 내가 사랑하는 사람들로부터 내 선택이 거절되고, 계속해서 도전하는 걸 멈추라는 의견을 들으면 많이 힘들어진다. 내가 멀리할 수 없는 사람이라면 더더욱 힘들어진다. 특히 가족들이 다른 친척들로부터 나의 이야기를 꺼내기 불편해하고, 친척들의 이야기에 힘들어하는 걸 보면 더 힘들다. \u0026lsquo;내가 잘못된 선택을 한 걸까?\u0026rsquo; 라는 생각이 계속해서 든다.\n이처럼 나를 힘들도록 만든 사람들이 나를 사랑하는 사람이라면 나를 힘내게 해주는 사람도 나를 사랑하는 사람이라는 걸 알게 되었다. 어머니, 나의 여자친구 그리고, 친구들은 나의 선택을 계속해서 응원했다. 도움이 필요하면 언제든지 말하라는 그 말을 들을 수록 독기가 생겨갔다.\n나를 믿고 응원해주는 사람들을 위해서 나를 증명하고 싶다는 독기가\n미움 받을 용기가 없는 사람과 있는 사람 이와 같은 경험을 하면서 오히려 내가 상대방의 선택에 대해 지지 또는 건설적인 조언을 하지 않고 반대한 적이 있었나 생각해보았다.\n내 기억으로는 없었다. 그 선택에 대해 단점과 문제점을 고려하여 더 나은 선택이 있는지 의논한 적은 있어도, 그 시기에 그 나이에 해야하는 것들에 저항하는 선택에 대해서는 명시적으로 말로 반대한적은 없었다.\n하지만, 학생으로서 있을 때 마음 속으로 이런 저항하는 선택을 하는 주변 사람들을 좋게 생각하지는 않았던 것 같다. 당연히 학생 때는 열심히 공부해서 전공 안에서 내가 하고 싶은 것을 선택해서 취업하는 것 밖에 없다고 생각했다. 그래서 전공 공부를 열심히 하지 않고, 준비하지 않는 학생들을 보면 좋게 생각하지 않았다.\n이와 같은 학생들 중에는 정말 아무것도 하지 않고, 학교 전공 공부를 안한 것일 수도 있다. 하지만 그중에서는 그 또래에 흔히 하는 것에서 벗어나 도전하는 사람들이 있었을 수도 있다. 난 그런 사람이 아니었기에 내 주변에는 도전하는 사람은 없었다. 난 이런 사람들을 쉽게 이해할 수 없었다. 그래서 오히려 나의 생각이 짧았고, 너무 교만했다. 사람들의 인생 방향은 매우 다양하기에 쉽게 재단할 수 없다. 그 때부터 이미 의도적으로 또는 비의도적으로 자신만의 경쟁력을 구축하기 위해 노력한 것일 수도 있다.\n진정 그 사람들이야말로 \u0026lsquo;미움 받을 용기\u0026rsquo;가 있는 사람들일 수 있다.\n강한 의지를 주는 마법은 없다. 용기, 굳센 의지를 잠깐 가질 수 있다. 하지만 지속해서 가지는 건 어렵다. 계속해서 의지를 유지하는 방법은 무엇일까? 특별한 방법은 없는 것 같다. 그냥 단지 부딪히고 넘어져도 다시 일어나고, 계속해서 견디는 것 밖에 없다. 계속 참고 인내하면서 무덤덤해진다. 무덤덤해진거지만 사실은 단단해진거다.\n마법은 없고 흔한 방법은 있다 그러면 이 과정을 본래의 문제가 아닌 작은 문제에서부터 지속적으로 경험해보면 의지를 키울 수 있다. 사람마다 여러 가지 방법이 있겠지만, 운동이 이 과정을 명확하게 담고 있다고 생각한다. 운동을 하면서 한계에 봉착하고, 이 한계를 깨기 위해서 부딪힌다. 부딪히면서 익숙해지고 결국 그 한계를 극복하게 된다. 이를 지속적으로 하면 큰 문제가 있어도 작은 문제를 극복해가는 과정에서 의지가 회복되고 다시 도전할 수 있다.\n본래의 문제가 아닌 작은 문제에서 이 과정을 꾸준히 경험하는 것\n특정 문제를 해결할 때, 이 문제를 작은 문제로 쪼개는 단계를 진행한다. 그리고 이 작은 문제들을 하나씩 해결해가면 큰 문제는 해결하는 원리다. 이처럼 작은 문제로 극복하는 과정을 지속적으로 경험하는게 의지를 유지하기 좋은 방법이다.\n성경에도 작은 일에 신실한 자가 큰 일이에도 신실하다고 한 것처럼 작은 것에 중요성을 말하고 있다. 작은 일을 통해 회복되면서 다시 큰 일에 도전한다. 작은 일에 대한 경험으로 큰 일을 해결한다. 만약 내가 생각한 작은 문제가 나한테 크게 다가온다면 보다 더 작은 것을 꾸준히 하는 것으로 접근한다.\n내가 계속해서 포기하지 않고 꾸준히 하는 작은 일을 만드는 것\n좌절될 때 극복하기 위해 되새기는 3가지 하지만 지속적으로 해도 의지가 꺾일 때가 있다. 그럴 때는 다시 의지를 살리기 위해 내가 왜 열심히 하는지, 왜 이것을 해야하는지 그 이유를 되짚어보는게 나한테는 좋은 방법이었다.\n내가 되시기는 마음가짐 3가지다.\n첫 번째, 이 일에 대해 하고 싶은 열정\n두 번째, 나를 믿는 사람을 실망시키지 않고, 나를 믿지 않는 사람들에게 나의 선택을 증명하고자 하는 독기\n세 번째, 마지막으로 아무리 생각해도 이 일 외에 나에게 맞는 최고의 선택지는 없다는 선택과 포기\n이 3가지를 계속 되새기면서 지속적으로 운동하는 것이 나에게 최고의 방법이었다.\n과한 미움 받을 용기는 잘못된 방향으로 이끈다. 하지만 이 \u0026lsquo;미움 받을 용기\u0026rsquo;가 너무 과하면 독선적이고 다른 사람의 조언을 무시하게 되고, \u0026lsquo;나는 남들과 달라\u0026rsquo;라는 의도하지 않은 우월감을 가지게 된다.\n하지만 이 용기가 과하면 다른 사람의 좋은 조언을 수용하지 않을 수 있다. \u0026lsquo;나는 남들과 다른 길을 갈거야\u0026rsquo;라는 생각이 의도치 않은 우월감을 나 자신에게 준다. 이를 깨달은 이유는 회고를 하면서 \u0026lsquo;이 부분에 있어서 나의 생각을 고집하기 보다는 이 조언을 받아들였으면 어땠을까?\u0026rsquo; 라는 생각이 들었기 때문이다.\n이것을 깨닫고 나서 넓은 시야를 가지려 하고, 이를 유지하려 한다.\n잘못된 방향성은 비효율을 초래한다.\n그래서 조언을 아주 적극적으로 찾아 구하고, 의도하지 않은 조언도 고려해보고, 아픈 조언도 고려해야한다. 그리고 도전한 결과가 아주 아파도 실패임을 받아들이고 방향성을 재고해야 한다.\n","permalink":"http://jeha00.github.io/post/thinking/courage/","summary":"미움 방을 용기가 없었다 / 강한 근성과 강한 인내심을 갖는 마법은 없다 / 과한 미움받을 용기는 잘못된 방향으로 이끈다 / 과한 미움받을 용기는 잘못된 방향으로 이끈다","title":"[Thinking] 미움 받을 용기가 없었다"},{"categories":"java","content":"Introduction 이번 포스팅에서는 자바의 JVM(Java Virtual Machine) 메모리 구조가 어떤 영역으로 구성되어 있고, 자바의 메서드와 변수들이 이 메모리에 어떻게 생성되고 사라지는지 알아본다.\nJAVA 프로그램을 실행하면 컴퓨터 메모리에는 OS, JVM, other applications 들이 올라간다. 그러면 .java 파일을 javac 컴파일러에 의해서 .class 파일로 컴파일된다. .class는 바이트 코드다. 그러면 JVM의 Class Loader System에 의해서 이 .class 파일을 읽어 Runtime Data Area 에 여러 값들이 올라가고, 생성되면서 실행된다.\n.java \u0026mdash;(javac compiler)\u0026mdash;\u0026gt; .class (byte code) \u0026mdash;\n그래서 오늘 배울려고 하는 자바의 메모리 구조가 JVM의 이 Runtime Data Area 메모리 공간 구조에 대해 이야기하려는 것이다.\nJVM 메모리 영역의 구성과 각 영역의 역할 JVM의 Runtime Data Area는 아래와 같은 메모리 영역을 가지고 실행한다.\n자바의 메모리 구조는 메서드(method) 영역, 스택(stack) 영역, 힙(heap) 영역 3개로 나눌 수 있다.\n아래 내용의 출처: 김영한의 실전 자바 - 기본편\n아래 내용이 어려우면 내가 만든 코드 예시를 보면서 이해해보자.\n스택 영역부터 이해하고 싶으면 여기부터, 메서드 영역까지 포함해서 이해하고 싶으면 여기부터 보자. 메서드 영역 또는 정적 영역 (method 또는 static area) 클래스 레벨의 정보를 저장하기 때문에, 프로그램을 실행하는데 필요한 공통 데이터를 관리한다고 볼 수 있다. 이 영역은 프로그램의 모든 영역에서 공유하며 아래 정보들이 섞여 저장된다. 크게 2가지로 분류할 수 있다.\n클래스 정보: 클래스의 실행 코드, 필드, 메서드(인스턴스 메서드, 클래스 메서드 포함), 생성자 코드 등 모든 실행 코드 존재\n클래스 정보의 일부로서 static 변수들도 보관한다. 런타임 상수 풀: 프로그램을 실행하는데 필요한 \u0026lsquo;공통 리터럴 상수\u0026rsquo;를 보관한다. (자바의 최적화 영역)\n스택 영역 (stack area) 자바 실행 시, 하나의 실행 스택이 생성된다. 각 스택 프레임은 지역 변수, 중간 연산 결과, 메서드 호출 정보 등을 포함한다.\n스택 프레임: 스택 영역에 쌓이는 네모 박스가 하나의 스택 프레임이다. 메서드를 호출할 때마다 하나의 스택 프레임이 쌓이고, 메서드가 종료되면 해당 스택 프레임이 제거된다.\n각 쓰레드별로 하나의 실행 스택이 생성된다. 쓰레드 수 만큼 스택 영역이 생성된다.\n힙 영역 (heap area) 객체(인스턴스)와 배열이 생성되는 영역이다. GC가 이루어지는 주요 영역이며, 더 이상 참조되지 않는 객체는 GC에 의해 제거된다.\n메모리 할당에 대한 추가적인 내용 동적 메모리 할당 객체와 배열이 힙 영역에 생성되는 이유는 객체와 배열같은 참조형은 기본형과 달리 크기가 동적으로 바뀌기 때문이다. 이를 \u0026lsquo;동적 메모리 할당\u0026rsquo;이라 한다. 그래서 기본형과 달리 복잡한 데이터 구조를 만들고 관리할 수 있다.\n하지만 기본형은 사용할 값을 직접 저장하는 이유는 크기가 정해져 있기 때문이다. 이에 따라 더 빠르게 메모리를 관리할 수 있지만 참조형처럼 복잡한 데이터 구조를 관리할 수 없다.\n메서드에 대한 메모리 할당 같은 클래스로 부터 생성된 객체라도, 인스턴스 내부의 변수 값은 서로 다를 수 있지만, 메서드는 공통된 코드를 공유한다. 따라서 객체가 생성될 때, 인스턴스 변수에는 메모리가 할당되지만, 메서드에 대한 새로운 메모리 할당은 없다.\n메서드는 메서드 영역에서 공통으로 관리되고 실행된다. 인스턴스 메서드도 메서드 영역에 생성되지만, 인스턴스 생성 시 메서드 영역에 만들어진 메서드를 연결해서 사용한다. 인스턴스에는 메서드 영역에 있는 인스턴스 메서드의 메모리 주소만 알고 있다고 생각하자.(인프런 질문 - 메서드 영역)\n메서드 영역 안에 있는 클래스 정보를 바탕으로 new 연산자를 만날 때마다 힙 영역에 새로운 인스턴스를 만든다. 그리고, 인스턴스마다 각각 멤버변수를 가지고 있다.\n스택 영역과 힙 영역 이해하기 먼저 스택 프레임에 대해 이해하기 위해서 아래 코드를 보자. 자료구조 스택에 대한 설명은 생략한다.\n클래스\n1 2 3 4 5 6 7 8 9 10 11 12 public class Car { private String name; public Car(String name) { this.name = name; } public String getName() { return name; } } 인스턴스 및 main\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class CarMain { public static void main(String[] args) { System.out.println(\u0026#34;main start\u0026#34;); method1(); System.out.println(\u0026#34;main end\u0026#34;); } static void method1() { System.out.println(\u0026#34;method1 start\u0026#34;); Car car1 = new Car(\u0026#34;black\u0026#34;); method2(car1); System.out.println(\u0026#34;method1 end\u0026#34;); } static void method2(Car car) { System.out.println(\u0026#34;method2 start\u0026#34;); System.out.println(\u0026#34;car.name= \u0026#34; + car.getName()); System.out.println(\u0026#34;method2 end\u0026#34;); } } 호출결과\n1 2 3 4 5 6 7 main start method1 start method2 start car.name= black method2 end method1 end main end main() -\u0026gt; method1() -\u0026gt; method2()를 호출하는 코드다.\nmethod1()에서 Car의 인스턴스를 생성한다. 생성한 인스턴스의 참조값을 method2()에 넘겨서, .getName() 메서드를 호출한다.\n그러면 스택 영역에 어떻게 생기는지 그림으로 확인해보자.\n과정 1 ~ 3 과정 1: 처음 main() 메서드를 실행하여, main() 스택 프레임이 생성된다. 과정 2: main()에서 method1()을 호출하여 method1()의 스택 프레임이 생성된다. method1에서 Car 클래스의 인스턴스를 \u0026lsquo;힙 영역\u0026rsquo;에 생성한다. 참조값은 car1에 보관한다. 과정 3: car1에 보관하고 있는 참조값을 복사하여 method2()의 매개변수 car에 전달한다. car1과 car 모두 힙 영역에 생성된 동일한 Car 인스턴스를 참조하고 있다. 인스턴스에는 인스턴스 변수의 메모리 위치 정보를 가지고 있기 때문에, 이 인스턴스를 통해서 .getName()이 실행된다. 과정 4 ~ 6 과정 4: method2() 가 종료된다. method2() 스택 프레임이 제거되면서 car도 제거된다. Car 인스턴스를 참조하지 않게 되었다. 과정 5: method1() 이 종료된다. method1() 스택 프레임이 제거되면 car1도 제거된다. Car 인스턴스를 참조하지 않게 되었다. 과정 6: 이제 Car 인스턴스를 참조하는 곳이 더 없기 때문에 사용되는 곳도 없다. 프로그램에서 사용되지 않는 개체이기 때문에, GC에 의해서 제거된다. 최종적으로 main()도 종료되면서 main() 스택 프레임도 제거된다.\n스택이라는 자료구조처럼 마지막에 들어온 게 먼저 종료되는 방식임을 확인할 수 있다.\n정리 위 내용을 정리하면 다음과 같다. 자바는 스택 영역을 사용해서 메서드 호출과 지역 변수(매개변수 포함)를 관리한다.\n메서드를 계속 호출하면 이 메서드에 대한 스택 프레임이 추가되면서 스택 프레임이 쌓인다. 지역 변수(매개변수 포함)는 스택 영역에서 관리한다. 스택 프레임이 종료되면 지역 변수도 함께 제거된다. 스택 프레임이 모두 제거되면 프로그램도 종료된다. 메서드 영역까지 합쳐서 이해하기 이제는 클래스 메서드(정적, static 메서드)와 인스턴스 메서드에서 사용한 코드 중 일부를 가져와 메서드 영역까지 합쳐서 이해해보자.\n클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class Car { private String name; // 인스턴스 변수 private int price; // 인스턴스 변수 private static int count; // 클래스 변수(정적 변수) public Car(String name, int price) { this.name = name; this.price = price; count++; } // 클래스 메서드 public static int getCount() { System.out.println(\u0026#34;생성된 총 차 댓수: \u0026#34; + count); return count; } // 클래스 메서드 public static void callClassMethod() { System.out.println(\u0026#34; --- Enter in callClassMethod ---\u0026#34;); getCount(); // 클래스 메서드 내에서 클래스 메서드 호출 } // 인스턴스 메서드 public String getName() { System.out.println(\u0026#34; --- Enter in getName ---\u0026#34;); getCount(); // 인스턴스 메서드 내에서 클래스 메서드 호출 return name; } // 인스턴스 메서드 public int getPrice() { System.out.println(\u0026#34; --- Enter in getPrice ---\u0026#34;); getCount(); // 인스턴스 메서드 내에서 클래스 메서드 호출 return price; } } 인스턴스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public class CarMain { public static void main(String[] args) { System.out.println(\u0026#34;=========== main start ===========\u0026#34;); Car car1 = new Car(\u0026#34;k3\u0026#34;, 10000); System.out.println(\u0026#34;Car name = \u0026#34; + car1.getName()); method1(); System.out.println(\u0026#34;=========== main end ============\u0026#34;); } public static void method1() { System.out.println(\u0026#34;========== method1 start ==========\u0026#34;); Car car2 = new Car(\u0026#34;k5\u0026#34;, 20000); System.out.println(\u0026#34;Car price = \u0026#34; + car2.getPrice()); method2(car2); System.out.println(\u0026#34;========== method1 end ==========\u0026#34;); } public static void method2(Car car) { System.out.println(\u0026#34;========== method2 start ==========\u0026#34;); Car.callClassMethod(); System.out.println(\u0026#34;Car price = \u0026#34; + car.getPrice()); System.out.println(\u0026#34;Car name = \u0026#34; + car.getName()); System.out.println(\u0026#34;========== method2 end ==========\u0026#34;); } } 그러면 위 코드가 main -\u0026gt; method1 -\u0026gt; method2로 실행되면서 각 영역마다 어떻게 진행되는지 확인해보자.\n1) main 메서드 시작 main 스택 프레임 생성 후, heap 영역에 인스턴스 생성 코드가 실행되면서 메서드 영역에 클래스 정보들이 다 올라간다. main이 실행되고 스택 영역에 main 스택 프레임이 생성된다. heap 영역에 Car 인스턴스가 생성된다. 즉, 이 인스턴스의 참조값이 생긴다. car1의 name은 \u0026lsquo;k3\u0026rsquo; 이고, price는 10000이다. 출력 코드\n1 =========== main start =========== getName 스택 프레임 생성 car1.getName 호출한다. car1에 담겨진 참조값을 통해 힙 영역에 있는 인스턴스에 접근하고, 이 인스턴스 안에서 getName 메서드의 메모리 위치 정보를 얻어 접근한다. 이후 인스턴스 메서드 호출하는 순서는 생략한다. getName 스택 프레임이 스택 영역에 쌓인다. 이 때 getName 호출에 사용한 해당 인스턴스의 참조값이 getName 스택 프레임에 저장된다. getName() 메서드를 실행하기 위해 메서드 영역에 있는 getName() 인스턴스 메서드 코드를 읽고, println 출력문부터 실행된다. 출력 코드 1 2 =========== main start =========== --- Enter in getName --- getCount 스택 프레임 생성 및 제거 getName() 메서드 코드를 읽는 과정에서 getCount() 클래스 메서드가 호출되어 스택 프레임에 쌓인다. 메서드 영역에서 getCount()를 실행하여 정적 변수인 count의 값을 반환한다. 출력 코드\n1 2 3 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 그러면 getCount()에 대한 실행이 끝나므로 아래 이미지처럼 이 클래스 메서드에 대한 스택 프레임은 사라진다. getName 스택 프레임 제거 getCount() 메서드가 종료되었기 때문에 getName() 메서드는 인스턴스의 name을 반환하면서 종료된다. 이에 따라 스택 영역의 해당되는 스택 프레임이 사라진다. name을 반환했기 때문에 main 메서드에서 println이 다음과 같이 출력된다. 출력 코드\n1 2 3 4 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 Car name = k3 힙 영역에서 Car 인스턴스 제거 car1 참조 변수가 가리키는 인스턴스를 아무도 참조하고 있지 않으므로 GC에 의해서 삭제된다. 2) method1 시작 method1 스택 프레임 생성 그리고 코드가 작성된 순서 따라서 method1()이 호출되면서 method1()에 대한 스택 프레임이 스택 영역에 쌓인다. 출력 코드\n1 2 3 4 5 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 Car name = k3 ========== method1 start ========== 힙 영역에서 인스턴스 생성 method1이 실행되면서 new 예약어를 사용하여 Car 클래스의 인스턴스가 heap 영역에 생성된다. 인스턴스 객체에 대한 참조값이 car2 변수에 담겨진다. getPrice 스택 프레임 생성 car2.getPrice()가 호출되면서 이 인스턴스 메서드에 대한 스택 프레임이 생성된다. 이 스택 프레임에는 car2에 담겨진 인스턴스 참조값이 담겨있다. 그래서 메서드 영역에 있는 getPrice() 코드가 이 메서드의 스택 프레임에 있는 인스턴스 참조값을 사용하여 해당 인스턴스에게 접근하여 인스턴스 변수의 정보들을 얻어 실행된다. 출력 코드 1 2 3 4 5 6 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 Car name = k3 ========== method1 start ========== --- Enter in getPrice --- getCount 스택 프레임 생성 및 제거 getPrice() 메서드 코드를 읽는 과정에서 getCount() 클래스 메서드가 호출되어 스택 프레임에 쌓인다.\n메서드 영역에서 getCount()를 실행하여 정적 변수인 count의 값을 반환한다.\n출력 코드\n1 2 3 4 5 6 7 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 Car name = k3 ========== method1 start ========== --- Enter in getPrice --- 생성된 총 차 댓수: 2 그러면 getCount()에 대한 실행이 끝나므로 아래 이미지처럼 이 클래스 메서드에 대한 스택 프레임은 사라진다. getPrice 스택 프레임 제거 getCount() 호출이 종료되었으므로 price 값을 반환하면서 실행이 종료되어 이 메서드에 대한 스택 프레임이 스택 영역에서 사라진다. 출력 코드\n1 2 3 4 5 6 7 8 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 Car name = k3 ========== method1 start ========== --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 3) method2 시작 method2와 callClassMethod 스택 프레임 생성 그 다음으로 method2() 가 호출되면서 스택 영역에 이 메서드에 대한 스택 프레임이 생성된다. 이 스택 프레임에는 car 매개변수에 대한 정보가 저장되어 있다. method1()에서 생성된 인스턴스 정보가 car 매개변수에 가지고 있다. 그래서 car1과 달리 GC에 의해서 삭제되지 않는다.\n메서드 영역에서 정적 메서드인 callClassMethod() 코드를 찾아 실행한다. 스택 영역에 callClassMethod() 스택 프레임이 스택 영역에 쌓인다.\n출력\n1 2 3 4 5 6 7 8 9 10 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 Car name = k3 ========== method1 start ========== --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 ========== method2 start ========== --- Enter in callClassMethod --- getCount 스택 프레임 생성 및 제거 후, callClassMethod 스택 프레임 제거 callClassMethod 안에서 getCount() 정적 메서드가 또한 호출되면서 getCount() 스택 프레임이 스택 영역에 쌓인다.\ngetCount() 메서드가 실행되기 위해 메서드 영역에서 이 메서드의 코드 정보를 읽어오고, 정적 변수인 count 정보를 반환한다.\n출력 1 2 3 4 5 6 7 8 9 10 11 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 Car name = k3 ========== method1 start ========== --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 ========== method2 start ========== --- Enter in callClassMethod --- 생성된 총 차 댓수: 2 getCount() 메서드 실행이 끝나서 getCount()의 스택 프레임이 제거된다.\n스택 프레임에서 getCount() 스택 프레임이 사라진 후 callClassMethod() 스택 프레임이 사라진다.\ngetPrice 스택 프레임 생성 및 제거 그리고 getCount 스택 프레임 생성 및 제거 그 다음에 method2() 스택 프레임이 가지고 있는 car 참조 변수를 통해서 힙 영역에 있는 인스턴스에 접근하여 getPrice() 호출한다.getPrice() 스택 프레임이 스택 영역에 쌓인다.\ngetPrice() 메서드 안에 진입하면서 getCount()를 호출하여, getCount() 스택 프레임이 스택 영역에 쌓인다.\n그러면 여태 했던 것처럼 똑같이 메서드 영역에 있는 getCount() 코드가 실행된다.\n종료되면 스택 영역에서 getCount()의 스택 프레임은 사라진다. 그리고, getPrice() 실행도 끝나서 getPrice() 스택 프레임이 다시 사라진다. 출력\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 Car name = k3 ========== method1 start ========== --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 ========== method2 start ========== --- Enter in callClassMethod --- 생성된 총 차 댓수: 2 --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 getName 스택 프레임 생성 그리고 getCount 스택 프레임 생성 및 제거 그 다음으로 getName() 호출되어 스택 영역에 스택 프레임이 쌓인다.\ngetName() 안에서 getCount() 클래스 메서드를 호출한다.\ngetCount() 메서드에서 메서드 영역에 있는 정적 변수 값인 count를 반환한다.\n출력 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 Car name = k3 ========== method1 start ========== --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 ========== method2 start ========== --- Enter in callClassMethod --- 생성된 총 차 댓수: 2 --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 --- Enter in getName --- 생성된 총 차 댓수: 2 Car name = k5 실행이 끝나면 getCount() 스택 프레임이 제거된다. 또한, getName() 실행 종료에 따라 이 메서드의 스택 프레임도 사라진다. 4) 각 메서드 종료 method2 스택 프레임 제거 후, method1 스택 프레임 제거 method2() 실행이 다 끝났기 때문에 method2() 스택 프레임이 사라진다. 출력 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 Car name = k3 ========== method1 start ========== --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 ========== method2 start ========== --- Enter in callClassMethod --- 생성된 총 차 댓수: 2 --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 --- Enter in getName --- 생성된 총 차 댓수: 2 Car name = k5 ========== method2 end ========== method1() 종료되면서 method1()의 스택 프레임도 사라진다. 출력 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 Car name = k3 ========== method1 start ========== --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 ========== method2 start ========== --- Enter in callClassMethod --- 생성된 총 차 댓수: 2 --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 --- Enter in getName --- 생성된 총 차 댓수: 2 Car name = k5 ========== method2 end ========== ========== method1 end ========== 힙 영역에 인스턴스 제거 이에 따라 car2 참조 변수가 가지고 있는 참조값의 대상인 인스턴스가 힙 영역에서 GC에 의해 삭제된다. 이 인스턴스를 참조하는 게 이제 아무도 없기 때문이다. main 스택 프레임 제거 그리고, 프로그램 종료 마지막으로 main 메서드 실행도 종료되면서 main 스택 프레임도 스택 영역에서 사라진다. 출력 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 =========== main start =========== --- Enter in getName --- 생성된 총 차 댓수: 1 Car name = k3 ========== method1 start ========== --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 ========== method2 start ========== --- Enter in callClassMethod --- 생성된 총 차 댓수: 2 --- Enter in getPrice --- 생성된 총 차 댓수: 2 Car price = 20000 --- Enter in getName --- 생성된 총 차 댓수: 2 Car name = k5 ========== method2 end ========== ========== method1 end ========== =========== main end ============ 프로그램이 종료된다. 변수와 생명 주기 그러면 위 학습한 내용을 변수의 관점에서 정리해보자.\n지역변수(매개변수 포함) 위 내용에서 학습한 대로 지역 변수는 스택 영역에 있는 스택 프레임 안에 보관된다. 호출된 메서드가 종료되면 스택 프레임도 제거 되는데 이때 해당 스택 프레임에 포함된 지역 변수도 함께 제거된다. 따라서 지역 변수는 생존 주기가 짧다.\n인스턴스 변수 인스턴스에 있는 멤버 변수를 인스턴스 변수라 한다. 인스턴스 변수는 힙 영역을 사용한다. 힙 영 역은 GC(가비지 컬렉션)가 발생하기 전까지는 생존하기 때문에 보통 지역 변수보다 생존 주기가 길다. 이 인스턴스 객체에 대한 참조 횟수가 0이 되면 GC에 의해서 삭제된다.\n클래스 변수 클래스 변수(static 변수, 정적 변수)는 메서드 영역의 static 영역에 보관되는 변수다. 메서드 영역은 프로그램 전체에서 사용하는 공용 공간이다. 클래스 변수는 해당 클래스가 JVM에 로딩되는 순간 생성된다. 그리고 JVM이 종료될 때 까지 생명주기가 어어진다. 따라서 가장 긴 생명주기를 가진다.\n클래스 변수에 static이 붙는 이유 🔆 static 이 정적이라는 이유는 바로 위 클래스 변수에 대한 설명에 답이 있다. 힙 영역에 생성되는 인스턴스 변수는 동적으로 생성되고 제거된다. 반면에 static 인 정적 변수는 거의 프로그램 실행 시점에 딱 만들어지고, 프로그램 종료 시점에 제거된다. 정적 변수는 이름 그대로 정적이다.\nnull과 GC 이번 챕터에서는 null에 대해서 알아보자. null 값은 참조형 변수에서 아직 가리키는 대상이 없으면 넣는 값으로, 값이 존재하지 않다는 걸 말한다. 비유하자면 택배를 보내기 위해서 주소지에 주소를 입력해야하는데, 아직 결정되지 않아서 주소지를 공란으로 냅둔 상태로 볼 수 있다.\n코드로 확인해보자.\n클래스\n1 2 3 public class Data { int value; } 인스턴스 및 main\n1 2 3 4 5 6 7 8 9 10 public class DataMain { public static void main(String args[]) { Data data = null; System.out.println(\u0026#34;1. data = \u0026#34; + data); data = new Data(); System.out.println(\u0026#34;2. data = \u0026#34; + data); data = null; System.out.println(\u0026#34;3. data = \u0026#34; + data); } } 실행 결과\n1 2 3 1. data = null 2. data = Week5.Data@17f6480 3. data = null 위 코드에서 확인한 것처럼 인스턴스 참조값을 받은 변수에 다시 null을 할당받을 경우, 기존에 생성한 인스턴스는 어떻게 될까?\n이 인스턴스를 참조하는 변수는 존재하지 않는다. 아무도 참조하지 않는 상황이다. 이런 상황이 되면 이 인스턴스의 참조값을 다시 구할 방법은 없다. 해당 인스턴스에 다시 접근할 방법이 존재하지 않는다. 이런 경우 메모리의 입장에서는 사용되지 않고 메모리 공간만 차지하기 때문에 불필요하다. 그래서 JVM의 GC(Garbage Collector)가 더 이상 사용하지 않는 인스턴스라고 판단되면 자동으로 메모리에서 제거해준다. 힙 영역에 생성되었다가 제거된다.\n하지만, 어딘가에서 한 군데라도 계속 참조하고 있다면 계속 힙 영역에서 계속 생존한다.\n인스턴스를 참조하는 static 변수 static 변수는 뒤에서 설명하겠지만 한 번 생성되면 프로그램이 종료될 때까지 유지된다. 이 static 변수가 특정 인스턴스의 참조값을 가지고 있다면(참조하고 있다면) 이 인스턴스는 프로그램이 종료될 때까지 GC에 의해서 제거되는 일이 발생되지 않는다.\n하지만 이 static 변수에 null을 할당하면 참조되었던 인스턴스는 다른 변수가 참조하는 일이 없기 때문에 GC에 의해서 삭제된다.\nNullPointerException 다음으로 Null과 관련된 에러인 NullPointerException에 대해 알아보자.\n참조값이 존재한다고 판단하여 참조값을 통해 특정 값에 접근했는데, 사실 그 참조값은 존재하지 않는 null이어서 발생되는 에러다.\n코드로 화인해보자.\n클래스\n1 2 3 public class Data { int value; } 인스턴스 및 main\n1 2 3 4 5 6 7 public class DataMain { public static void main(String args[]) { Data data = null; System.out.println(\u0026#34;1. data = \u0026#34; + data); data.value = 1; } } 결과\n1 2 3 1. data = null Exception in thread \u0026#34;main\u0026#34; java.lang.NullPointerException at Week5.DataMain.main(DataMain.java:7) 코드에서 알 수 있듯이 null은 참조할 주소가 존재하지 않는다는 뜻이다. 이 null에 접근하여 value 값에 값을 할당하려고 했으니 위와 같은 결과가 발생했다.\n단지 변수에 null 을 할당하는 것까지는 문제가 발생되지 않는다. null을 할당받은 변수를 통해 속성과 행위에 접근하려고할 때 에러가 발생된다.\nfinal final로 선언된 클래스 변수와 인스턴스 변수 모두 클래스 안에 선언된 정보이기 때문에 \u0026lsquo;메서드 영역\u0026rsquo;에 생성된다.\n","permalink":"http://jeha00.github.io/post/java/3_memory/","summary":"메모리의 각 메서드 영역, 스택 영역, 힙 영역에 무엇이 생성되는지 알아보고,  NullPointerException이 왜 발생하는지 알아본다.","title":"자바의 클래스는 메모리 영역에서는 어떻게 생성될까?"},{"categories":"java","content":"생성자 객체를 생성하면 객체의 속성마다 특정 값으로 초기화를 한다.\n클래스\n1 2 3 4 5 public class Food { public int cost; public int price; public String name; } 인스턴스\n1 2 3 4 5 6 7 8 public class FoodMain { public static void main(String[] args) { Food food1 = new Food(); food1.name = \u0026#34;제육볶음\u0026#34;; food1.price = 12000; food1.cost = 9000; } } 객체를 추가로 생성하여 초기화 작업을 수행해보자.\n인스턴스 1 2 3 4 5 6 7 8 9 10 11 12 13 public class FoodMain { public static void main(String[] args) { Food food1 = new Food(); food1.name = \u0026#34;제육볶음\u0026#34;; food1.price = 12000; food1.cost = 9000; Food food2 = new Food(); food2.name = \u0026#34;김밥\u0026#34;; food2.price = 11000; food2.cost = 5000; } } 위 작업을 효율적으로 하기 위해서 메서드로 모듈화를 해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class FoodMain { public static void main(String[] args) { Food food1 = new Food(); initFood(food1, \u0026#34;제육볶음\u0026#34;, 12000, 9000); Food food2 = new Food(); initFood(food2, \u0026#34;김밥\u0026#34;, 11000, 5000); } public static void initFood(Food food, String name, int price, int cost) { food.name = name; food.price = price; food.cost = cost; } } 하지만 이 방식은 이전 챕터에서 언급한 것처럼 객체 지향적이지 않으므로 객체 클래스 안에 이 작업을 하는 메서드를 추가해보자.\n아래와 같이 코드를 작성했다. 그러면 어떤 게 속성이고, 어떤 게 메서드를 통해 전달하려는 값인지 구분할 수 있을까?\n1 2 3 4 5 6 7 8 9 10 11 public class Food { public int cost; public int price; public String name; public void initFood(String name, int price, int cost) { name = name; price = price; cost = cost; } } 위 코드의 경우, 멤버 변수와 매개변수 이름이 같다. 메서드 안에서는 지역 변수의 매개변수가 멤버 변수보다 우선순위를 가진다. 그래서 좌우 모두 매개변수로 인식되어 멤버 변수에 할당되지 못 한다.\n1 2 3 4 5 6 7 8 9 10 public class FoodMain { public static void main(String[] args) { Food food1 = new Food(); Food food2 = new Food(); food1.initFood(\u0026#34;제육볶음\u0026#34;, 12000, 9000); food1.initFood(\u0026#34;김밥\u0026#34;, 11000, 5000); System.out.println(food1.name); }} 출력 결과로 null이 나온다.\n1 null 멤버변수에 할당되지 못한 걸 확인할 수 있다.\nthis 키워드가 있는 이유 그래서 멤버 변수와 매개변수를 구분하기 위해서 \u0026rsquo;this\u0026rsquo; 키워드를 사용해야 한다.\nthis는 인스턴스 자신의 참조값을 가리킨다. 파이썬으로 보자면 self와 같다.\n1 2 3 4 5 6 7 8 9 10 11 public class Food { public int cost; public int price; public String name; public void initFood(String name, int price, int cost) { this.name = name; this.price = price; this.cost = cost; } } 하지만 다음과 같이 속성과 매개변수의 이름이 다르면 사용하지 않아도 된다. 자동적으로 구분해서 인식한다.\n1 2 3 4 5 6 7 8 9 10 11 public class Food { public int cost; public int price; public String name; public void initFood(String name_parameter, int price_parameter, int cost_parameter) { name = name_parameter; price = price_parameter; cost = cost_parameter; } } 생성자의 정의와 장점 매번 이 작업을 위해서 별도의 메서드를 만들어야하는 문제점을 해결하기 위해서 객체 지향이 반영된 프로그래밍 언어에는 이 문제를 해결하기 위해 \u0026lsquo;생성자\u0026rsquo; 라는 게 존재한다.\n그러면 생성자는 무엇이라 정의를 내릴 수 있을까? 생성자로 얻을 수 있는 더 다양한 장점들이 있을까?\n생성자는 인스턴스 생성 직후 초기화를 포함한 여러 작업을 한 번에 할 수 있는 도구다. 이 생성자를 통해 3가지 장점을 얻을 수 있다.\n중복 호출 제거 생성자 호출 필수 - 개발자 실수로 초기화 작업을 놓칠 수 없음 2번으로 필수값 입력 보장 특히 2번의 장점이 크다. 생성자 호출을 필수로 하기 때문에 예를 들어 회원 정보가 미입력되는 일이 없다.\n그러면 생성자에 대해 알았으니 바로 생성자 코드라 언급하겠다. 생성자 코드를 작성해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 public class Food { public int cost; public int price; public String name; // 생성자 public Food(String name, int price, int cost) { this.name = name; this.price = price; this.cost = cost; } } 위 작성한 코드를 보면 메서드와 비슷하지만 다음과 같은 차이가 있다.\n생성자의 이름은 클래스 이름과 같아야 한다. 따라서 첫 글자도 대문자로 시작한다. 생성자는 반환 타입이 없다. 비워둬야 한다. void도 없어야 한다. 나머지는 메서드와 동일하다. 생성자 호출 시점 그러면 생성자는 언제 호출되는 걸까?\nnew 클래스명() 을 사용하여 인스턴스를 생성하자마자 바로 생성자가 실행된다. 이게 인스턴스 생성 시 클래스명에 호출자 연산을 사용하는 이유다. new 생성자명()으로 이해하면 된다.\n기본 생성자 그러면 사용자 정의 생성자가 없으면 new 클래스명()을 사용할 수 없는 걸까?\n앞선 예제들에서 사용할 수 있는 걸 확인했다.\n클래스\n1 2 3 4 5 public class Food { public int cost; public int price; public String name; } 인스턴스 생성\n1 2 3 4 5 6 public class FoodMain { public static void main(String[] args) { Food food1 = new Food(); System.out.println(food1); }} 출력 1 practice.Food@5a39699c 생성자 코드를 작성하지 않았는데 왜 인스턴스가 생성된 걸까?\n그 이유는 사용자가 생성자를 만들지 않으면 자바가 알아서 기본 생성자를 만들어 실행하기 때문이다.\n1 2 3 4 5 6 7 8 9 10 public class Food { public int cost; public int price; public String name; // java가 생성한 기본 생성자 public Food() { } } 자바가 생성하는 기본 생성자는 다음과 같은 특징이 있다.\n매개변수가 없는 생성자를 기본 생성자라 한다. 클래스에 생성자가 하나도 없으면 자바 컴파일러는 매개변수가 없고 메서드 바디가 없는, 작동하는 코드가 없는 생성자를 만든다. 하지만 생성자가 하나라도 있으면 기본 생성자를 만들지 않는다. 그래서 사용자 정의 생성자가 없어도 인스턴스 생성이 가능한 이유가 위와 같다.\n파이썬으로 보자면 __init__ 를 자동적으로 생성 및 호출하여 인스턴스를 생성하는 것과 같다.\n생성자 오버로딩 자바에서는 메서드 오버로딩처럼 생성자 또한 오버로딩이 가능한데, this를 통해서 할 수 있다.\nthis를 단지 자기 자신 인스턴스의 참조값을 참조하는 키워드로만 학습했지만 this()로 호출 연산자를 사용하면 해당 매개변수 갯수와 타입에 맞는 생성자에게 전달된다.\n위 예시에서 든 생성자를 1번 생성자라 하자.\n1번 생성자 1 2 3 4 5 6 7 8 9 10 11 12 public class Food { public int cost; public int price; public String name; // 1번 생성자 public Food(String name, int price, int cost) { this.name = name; this.price = price; // 판매가격 this.cost = cost; // 제조가격 } } 2번 생성자를 추가한다.\n2번 생성자: 무료 음식 생성자\n1 2 3 4 // 2번 생성자 public Food(String name, int cost) { this(name, 0, cost); } 2번 생성자를 사용하고 싶다면 Food food2 = new Food(\u0026quot;free\u0026quot;, 5000);로 입력한다. 그러면 this()에 넘긴 인자들의 갯수와 각 인자의 타입을 분석해서 이에 맞는 생성자로 전달하는 게 this() 의 역할이다.\n다음 코드의 출력 결과를 보면 food2.price의 값이 0인 걸 알 수 있다.\n1 2 3 4 5 6 7 8 9 public class FoodMain { public static void main(String[] args) { Food food1 = new Food(\u0026#34;제육볶음\u0026#34;, 12000, 9000); // 1번 생성자 Food food2 = new Food(\u0026#34;free\u0026#34;, 5000); // 2번 생성자 System.out.println(food1.price); // 출력 결과: 12000 System.out.println(food2.price); // 출력 결과: 0 } } 다음으로 3번 생성자를 추가해보자.\n3번 생성자: 휴게 시간에 혼자서 해먹는 음식에 대한 생성자\n1 2 3 public Food(String name) { this(name, 0); } 3번 생성자를 사용하고 싶으면 Food food3 = new Food(\u0026quot;볶음밥\u0026quot;)로 입력한다.\n1 2 3 4 5 6 7 8 9 10 11 12 public class FoodMain { public static void main(String[] args) { Food food1 = new Food(\u0026#34;제육볶음\u0026#34;, 12000, 9000); // 1번 생성자 Food food2 = new Food(\u0026#34;free\u0026#34;, 5000); // 2번 생성자 Food food3 = new Food(\u0026#34;볶음밥\u0026#34;); // 3번 생성자 System.out.println(food1.price); // 출력 결과: 12000 System.out.println(food2.price); // 출력 결과: 0 System.out.println(food3.price); // 출력 결과: 0 System.out.println(food3.cost); // 출력 결과: 0 } } 출력결과 볶음밥을 생성할 때는 cost, price 모두 입력하지 않았지만 값이 담겨져 있는 걸 알 수 있다.\n3번 생성자의 this()는 2번 생성자에 전달되고, 2번 생성자의 this()는 1번 생성자에 전달되어 최종적으로 인스턴스가 생성된다. int의 초기화값이 0이라서 헷갈릴 수 있으니 10으로 수정해서 다시 출력해보자.\n12000 10 10 10 원하는 대로 this()가 잘 작동되는 걸 알 수 있다.\nthis() 유의사항 this()를 사용하는데 있어서 유의사항이 있다.\n생성자 코드의 첫 줄에만 작성할 수 있다.\n위 유의사항으로 다음 코드는 실행되지 않고 컴파일 에러가 발생된다.\n1 2 3 4 public Food(String name) { System.out.println(\u0026#34;This will be not operated\u0026#34;); this(name, 10); } 발생된 컴파일 에러 내용이다.\nCall to \u0026#39;this()\u0026#39; must be first statement in constructor body this()는 반드시 생성자의 첫 줄에만 작성해야 한다. 다른 코드를 먼저 실행했다가 에러가 발생하면 인스턴스를 생성할 수 없기 때문에 이런 조치를 취한 것으로 이해된다. 좋은 코드는 제약이 없는 코드가 아닌 제약이 어느 정도 있는 코드라고 생각되기 때문에, 이와 같은 제약은 개인적으로 좋다고 생각된다.\n접근 제어자 접근 제어자란? 해당 클래스 외부에서 특정 필드나 메서드에 접근하는 것을 허용하거나 제한하는 예약어 를 말한다.\n이 예약어가 필요한 첫 번째 이유는 \u0026lsquo;보안\u0026rsquo;이다. 필드에 직접 접근하여 값을 수정하는 걸 막기 위해서다.\n예를 들어 빵을 하루 최대 공장에서 100개만 생성하도록 했다. 그래야 기계가 망가지지 않는다. 그런데 다른 직원이 이를 모르고 최대 150개로 생성하도록 설정했을 경우, 공장 기계는 망가진다.\n이런 비지니스 로직이 아래 코드와 같이 메서드에 담겨져 있어서, 직접 수정이 아닌 메서드를 통해서만 주문이 가능하다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class BreadFactory { public int count; public void order(int orderCount){ if (orderCount \u0026lt; count) { System.out.println(\u0026#34;빵을 주문합니다.\u0026#34;); count += orderCount; } else { System.out.println(\u0026#34;빵을 주문할 수 없습니다.\u0026#34;); } } } 하지만 아래 코드와 같이 어느 직원이 임의의로 직접 수정하면 주문은 들어갔으니 기계는 돌아가고 아무도 모른다.\n1 2 3 4 5 6 7 8 9 public class BreadFactoryMain { public static void main(String[] args) { BreadFactory breadFactory = new BreadFactory(); breadFactory.order(50); // 이 방식으로는 가능 breadFactory.count = 150; // 이렇게 직접 수정하면 문제 발생 } } 그러면 count 필드를 접근 제어자 private을 사용하여 직접 접근을 막아보자.\n1 2 3 4 5 6 7 8 package practice.a; public class BreadFactory { private int count; // public int 에서 private int로 수정 ... } 다시 main 코드를 실행하보면 다음 컴파일 에러가 발생된다.\n1 java: count has private access in practice.BreadFactory 그래서 직접 특정 필드나 메서드에 접근하는 걸 제한하고자 필요한 게 \u0026lsquo;접근 제어자\u0026rsquo;다. 이보다 더 중요한 이유인 캡슐화 가 있는데, 이는 접근 제어자의 마지막 소챕터에서 나눠보도록 한다.\n접근 제어자의 종류 접근 제어자의 종류에는 4종류가 있다.\nprivate: 모든 외부 호출을 막는다. default: 같은 패키지 안에서 호출은 허용한다. (아무것도 적지 않는 게 default) protected: 같은 패키지 안에서 호출과 다른 패키지여도 상속 관계의 호출을 허용한다. public: 모든 외부 호출을 허용한다. 차단 정도는 private \u0026gt; default \u0026gt; protected \u0026gt; public 순서로 오면서 줄어든다. private이 가장 많이 차단하고, public이 가장 많이 허용한다. proteced를 설명하기 위해서는 \u0026lsquo;상속\u0026rsquo; 개념을 알아야하기 때문에 상속에 대해 학습할 때 같이 설명한다.\n접근 제어자가 사용되는 곳: 멤버 변수(Field), 메서드 접근 제어자는 멤버 변수 그리고 메서드에 사용된다. 지역 변수에는 사용되지 못한다.\n그럼 아래 코드로 알아보자!\n접근 제어자를 학습할 때는 아래 코드로 학습하는 게 개인적으로 제일 낫다고 생각된다.\n각기 다른 접근 제어자가 입력된 멤버변수와 메서드가 있다. 그리고 모든 메서드들을 호출하는 하나의 메서드가 존재한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package practice.a; public class AccessData { public int publicField; int defaultField; private int privateField; public void publicMethod() { System.out.println(\u0026#34;==== publicMethod 호출: \u0026#34; + publicField); } void defaultMethod() { System.out.println(\u0026#34;==== defaultMethod 호출: \u0026#34; + defaultField); } private void privateMethod() { System.out.println(\u0026#34;==== privateMethod 호출: \u0026#34; + privateField); } public void innerAccess() { System.out.println(\u0026#34;내부 호출\u0026#34;); publicField = 100; defaultField = 200; privateField = 300; publicMethod(); defaultMethod(); privateMethod(); } } 같은 패키지에서 호출 그러면 외부에서 위 코드를 호출해보자. 패키지 위치는 같은 패키지로 \u0026lsquo;practice.a\u0026rsquo;다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package practice.a; public class AccessMain { public static void main(String[] args) { AccessData data = new AccessData(); data.publicField = 1; data.publicMethod(); data.defaultField = 2; data.defaultMethod(); // private은 호출 불가능 data.privateField = 3; data.privateMethod(); data.innerAccess(); } } 위 코드의 다음 2가지 부분에서 에러가 발생한다.\ndata.privateField data.privateMethod() 발생된 에러는 다음과 같다.\n1 java: privateField has private access in practice.AccessData 그러면 에러가 난 부분을 주석처리하고 다시 컴파일한 후 결과는 다음과 같다.\n1 2 3 4 5 6 ==== publicMethod 호출: 1 ==== defaultMethod 호출: 2 ==== 내부 호출 ==== publicMethod 호출: 100 ==== defaultMethod 호출: 200 ==== privateMethod 호출: 300 위 결과를 통해서 다음 내용들을 확인할 수 있다.\npublic은 어디서든지 접근할 수 있어서 public member 변수와 method가 모두 접근 가능했다.\ndefault는 같은 패키지에서만 접근 가능하다. 위 두 코드는 같은 패키지이기 때문에 접근 가능하다.\n그래서 public과 default로 설정한 메서드와 변수 모두 직접 접근하여 수정이 가능했고, 메서드를 통해서 수정이 가능했다.\nprivate의 경우 클래스 내부에서만 접근이 가능하기 때문에, 클래스 내부 메서드에서 private 멤버 변수와 메서드에 접근할 수 있다. 그래서 외부에서 직접 접근할 수 없다는 걸 에러로 확인했고, innerMethod()를 통해서 호출된 privateMethod()를 확인할 수 있다.\n다른 패키지에서 호출 패키지 위치는 다른 패키지로 \u0026lsquo;practice.b\u0026rsquo;다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package practice.b; import practice.a.AccessData; public class AccessMain { public static void main(String[] args) { AccessData data = new AccessData(); data.publicField = 1; data.publicMethod(); // default 호출 불가능 // data.defaultField = 2; // data.defaultMethod(); // private은 호출 불가능 // data.privateField = 3; // data.privateMethod(); data.innerAccess(); } } private은 이전과 동일한 에러가 발생된다. 다른 패키지에서 호출하니 다음과 같은 다른 에러가 발생했다.\n1 java: defaultField is not public in practice.a.AccessData; cannot be accessed from outside package default 키워드에서 발생된 에러다. 동일한 패키지가 아니어서 접근할 수 없다는 내용이다. 위 에러를 바탕으로 default는 동일한 패키지 내에서만 접근할 수 있는 걸 확인했다.\n클래스에도 사용되는 접근 제어자 접근 제어자는 멤버 변수, 메서드 그리고 클래스에도 사용된다.\n아래 코드를 실행하면 같은 패키지이기 때문에 에러가 발생되지 않는다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package practice.a; public class PublicClass { public static void main(String[] args) { PublicClass publicClass = new PublicClass(); DefaultClass1 class1 = new DefaultClass1(); DefaultClass2 class2 = new DefaultClass2(); } } // 접근 제어자: default class DefaultClass1 { } // 접근 제어자: default class DefaultClass2 { } 하지만 위 코드 내용을 package practice.b로 위치시켜서 호출하면 다음 에러가 발생한다.\n1 java: practice.a.DefaultClass1 is not public in practice.a; cannot be accessed from outside package 동일한 패키지가 아니어서 접근할 수 없다는 내용이다. 이처럼 클래스에도 적용된다.\n그래서 이게 왜 필요한 건데? 객체 지향 프로그래밍을 적용하면서 객체 중심으로 데이터와 해당 데이터를 처리하는 메서드를 하나로 묶은다.\n여기서 한 가지 더 나아가는 게 \u0026lsquo;캡슐화\u0026rsquo;다. 보안과 편리한 인터페이스 제공하기 위해 데이터는 모두 숨기고, 외부에 노출시킬 필요가 있는 기능(메서드)만을 드러낸다. 이를 위해 필요한 게 바로 \u0026lsquo;접근 제어자\u0026rsquo; 다.\n그래서 캡슐화는 다음과 같이 3가지로 정리할 수 있다.\n객체의 속성(데이터)은 가장 필수로 숨긴다. 객체의 내부에서만 사용하는 기능도 숨긴다. 외부에 노출시킬 필요가 기능(메서드)만 드러낸다. 반드시 객체의 데이터는 객체가 제공하는 기능인 메서드를 통해서만 접근해야 한다.\n캡슐화가 잘된 코드를 하나 확인해보자.\nFood 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package practice; public class Food { private String name; private int price; private int quantity; public Food(String name, int price, int quantity) { this.name = name; this.price = price; this.quantity = quantity; } public String getName() { return name; } public int getTotalPrice() { return calculateTotalPrice(); } private int calculateTotalPrice() { return price * quantity; } } FoodCart 클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package practice; public class FoodCart { private Food[] foods = new Food[5]; private int foodCount; public void addFood(Food food) { if (foodCount \u0026gt;= foods.length) { System.out.println(\u0026#34;음식을 더 담을 수 없습니다.\u0026#34;); return; } foods[foodCount] = food; foodCount++; } public void displayItems() { System.out.println(\u0026#34;장바구니 음식 출력\u0026#34;); for (int i = 0; i \u0026lt; foodCount; i++) { Food food = foods[i]; System.out.println(\u0026#34;음식명: \u0026#34; + food.getName() + \u0026#34;, 합계: \u0026#34; + food.getTotalPrice()); } System.out.println(\u0026#34;전체 가격 합: \u0026#34; + calculateTotalOrderPrice()); } public int calculateTotalOrderPrice() { int totalPrice = 0; for (int i = 0; i \u0026lt; foodCount; i++) { Food food = foods[i]; totalPrice += food.getTotalPrice(); } return totalPrice; } } 캡슐화의 최종 장점 클라이언트에게 좋다.\n만든 수 백개의 메서드를 그대로 노출시키면 클라이언트의 사용성이 좋지 않다. 그래서 좋은 캡슐화 설계는 클라이언트의 사용 경험을 높인다.\nfinal 키워드 이 final 키워드는 \u0026lsquo;초기화 후 값 변경 불가능\u0026rsquo;을 의미한다. 그리고 이 키워드는 variable에 붙일 수 있다.\nfinal 키워드는 멤버 변수에 사용할 수 있다.\n결론부터 말하자면 멤버 변수가 초기화가 안된 경우라면 초기화된 후 값 변경이 불가능하다. 초기화가 이미 된 경우라면 상수로 취급되어 생성자를 통해서 초기화가 될 수 없다.\n초기화가 안된 경우 음식점을 개업하면서 \u0026lsquo;김밥\u0026rsquo; 메뉴의 가격은 물가가 올라도 안올리겠다는 다짐으로 가격을 나타내는 멤버 변수에 final을 추가했다. 메뉴 이름은 초기화되면 변경할 필요가 없다.\n클래스\n1 2 3 4 5 6 7 8 9 10 11 public class Food { int cost; final int price; final String name; public Food(String name, int price, int cost) { this.name = name; this.price = price; this.cost = cost; } } 인스턴스 생성\n1 2 3 4 5 6 7 8 public class FoodMain { public static void main(String[] args) { Food food1 = new Food(\u0026#34;김밥\u0026#34;, 8000, 4000); System.out.println(\u0026#34;food1.name: \u0026#34; + food1.name); System.out.println(\u0026#34;food1.price: \u0026#34; + food1.price); } } 출력 결과 1 2 food1.name: 김밥 food1.price: 8000 하지만 인플레이션과 금리 인상으로 판매가를 높일려고 했으나 수정할 수가 없다.\n1 food1.price = 10000; 다음과 같은 에러가 발생된다.\n1 java: cannot assign a value to final variable price final 키워드가 붙은 변수는 초기화되면 수정할 수가 없다.\n초기화가 된 경우 이번에는 이미 변수가 초기화 후 수정하려는 경우를 확인해보자.\n장사가 안되서 폐업을 결정했다. 남은 재료들을 빨리 소진하기 위해 모든 메뉴 5000원을 결정하여 다음과 같이 코드를 작성했다.\n클래스\n1 2 3 4 5 6 7 8 9 10 public class Food { int cost; final int price = 5000; final String name; public Food(String name, int cost) { this.name = name; this.cost = cost; } } 인스턴스\n1 2 3 4 5 6 7 8 public class FoodMain { public static void main(String[] args) { Food food1 = new Food(\u0026#34;김밥\u0026#34;,4000); System.out.println(\u0026#34;food1.price: \u0026#34; + food1.price); } } 출력 결과 1 food1.price: 5000 그러다가 갑자기 폐업하지 말라는 시민들의 요청이 있어서 메뉴 가격을 다시 수정하려고 한다.\n1 food1.price = 10000; 위 코드를 실행하면 다음과 같은 결과를 또 확인할 수 있다.\n1 java: cannot assign a value to final variable price final 예약어로 선언된 변수가 한 번 초기화되면 수정될 수 없다.\nstatic 사용 시 final 고려하기 만약 인스턴스 변수이고, 인스턴스마다 동일한 값으로 초기화가 되면 이는 static 변수로 만드는 낫다. 모든 인스턴스가 같은 값을 사용하기 때문에 메모리 낭비다. 또한 같은 값이 계속 생성되는 건 명확한 중복이기 때문이다.\n아래 코드를 보면 한 묶음에 붕어빵 2000원 어치에 3개 정보라는 인스턴스를 생성했다. 붕어빵 2000원 어치에 3개는 고정된 정보다. 무조건 한 묶음만 판다고할 때 굳이 인스턴스를 생성할 때마다 정보를 입력받는 건 중복된 값을 사용하기에 메모리 낭비다. 이런 경우 static 과 final 을 사용하는게 현명하다.\n클래스\n1 2 3 4 5 6 7 8 9 10 public class FishShapedBun { public int price; public int count; public FishShapedBun(int price, int count) { this.price = price; this.count = count; } } 인스턴스\n1 2 3 4 5 6 7 public class FishShapedBunMain { public static void main(String[] args) { FishShapedBun bundle1 = new FishShapedBun(2000, 3); // price, count FishShapedBun bundle2 = new FishShapedBun(2000, 3); FishShapedBun bundle3 = new FishShapedBun(2000, 3); } } 그래서 다음과 같이 클래스 코드를 수정해보자.\n1 2 3 4 5 6 public class FishShapedBun { public static final int price = 2000; public static final int count = 3; } 아래의 값을 확인하면 2000, 300을 확인할 수 있고 변경할 수 없다.\n1 2 3 4 5 6 7 8 9 10 11 package practice; public class FishShapedBunMain { public static void main(String[] args) { FishShapedBun bundle1 = new FishShapedBun(); System.out.println(bundle1.count); System.out.println(bundle1.price); bundle1.price = 2; // 에러 발생 } } 발생한 에러 내용은 다음과 같다.\n1 java: cannot assign a value to final variable count 상수의 이점 위에서 알아본 대로 final 키워드를 사용해서 변하지 않는 값을 만들 수 있다. 이 수를 \u0026lsquo;상수\u0026rsquo; 라고 한다. 애플리케이션 안에는 다양한 상수가 존재할 수 있다. 수학, 시간 등등 실생활에서 사용하는 상수부터, 애플리케이션의 다양한 설정을 위한 상수들도 있다. 아래 코드를 통해 여러 예시들을 확인해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Constant { // 애플리케이션 설정 상수 public static final int MAX_COUNTS = 500; // 수학 상수 public static final double PI = 3.14; // 시간 상수 public static final int DAYS_IN_WEEK = 7; public static final int HOURS_IN_DAY = 24; public static final int MINUTES_IN_HOUR = 60; public static final int SECONDS_IN_MINUTE = 60; } 이런 상수들은 애플리케이션 전반에서 사용되기 때문에 public을 자주 사용한다. 반드시 이래야하는 건 아니고, 특정 위치에서만 접근된다면 이에 맞는 접근 제어자를 사용하면 된다.\n그러면 애플리케이션 설정 상수를 사용하는 장점에 대해 알아보자.\n1 2 3 4 5 6 7 public static void make(int currentCount) { if (currentCount \u0026lt; 500) { System.out.println(\u0026#34;붕어빵을 만듭니다.\u0026#34;); } else { System.out.println(\u0026#34;붕어빵이 소진되었습니다.\u0026#34;); } } 위와 같이 코드를 작성하면 500이란 숫자가 뭘 의미하는지 모른다. 이럴 때 상수를 사용하면 무슨 의미인지 바로 알 수 있다.\n상수를 사용하여 또 다른 상수를 표현할 수도 있다.\n1 2 3 4 5 6 7 public class Constant { ... public static final int MINUTES_IN_HOUR = 60; public static final int SECONDS_IN_MINUTE = 60; public static final int SECONDS_IN_HOUR = SECONDS_IN_MINUTE * MINUTES_IN_HOUR; } 기본형과 참조형의 관점에서 기본형의 경우, 기본형의 값을 변경할 수 없다는 건 위 예시들을 통해서 알았다.\n이번에는 참조값을 저장하는 참조형에 대해 final을 사용해보자.\n참조형은 참조값을 변경할 수 없다 참조형은 변수 선언 시점에 참조값을 할당했으므로 더는 참조값을 변경할 수 없다. 다른 객체를 참조할 수 없다. 하지만 참조 대상의 객체 값은 변경할 수 있다.\n클래스\n1 2 3 4 public class FishShapedBun { public int price = 2000; public int count = 3; } 인스턴스\n1 2 3 4 5 6 public class FishShapedBunMain { public static void main(String[] args) { final FishShapedBun bundle1 = new FishShapedBun(); bundle1 = new FishShapedBun(); } } 실행 결과\n1 java: cannot assign a value to final variable bundle1 하지만 bundle1.count = 5 로 수정 가능하다.\n1 2 3 4 5 6 7 8 9 10 public class FishShapedBunMain { public static void main(String[] args) { final FishShapedBun bun1 = new FishShapedBun(); // bun1 = new FishShapedBun(); System.out.println(bun1.count); bun1.count = 5; System.out.println(bun1.count); } } 실행 결과는 다음과 같다.\n1 2 3 5 참조값 주소를 담은 변수에 final 선언을 하면 참조값 주소는 변경할 수 없다. 그리고 이 final 선언이 이 주소가 가리킨 객체의 속성까지 영향을 주지 않는다.\n이번 포스팅 주제에 관한 파이썬과의 차이점 단지 호기심의 관점으로 자바와 파이썬을 비교해본다\n생성자 언어 파이썬 자바 인스턴스 참조값 키워드 self this 생성자 이름 __init__ class 이름 기본 생성자 유무 O O 생성자 오버로딩 유무 X O 파이썬에는 기본적으로 오버로딩이 내장되어 있지 않다. 하지만 packing, unpacking 개념을 사용해서 이 부분을 구현할 수 있다.\n상수 파이썬은 별도의 상수 선언을 위한 키워드는 존재하지 않고, 상수 취급하는 변수의 네임 컨벤션만 존재한다.\n","permalink":"http://jeha00.github.io/post/java/2_2_class/","summary":"생성자, 접근 제어자, 상수 변환 예약어에 대해 알아본다.","title":"자바의 클래스에 대해 알아보자 - 2"},{"categories":"java","content":"클래스가 필요한 이유 파이썬은 리스트가 컨테이너형으로 여러 데이터 타입을 담을 수 있다. 하지만 여태 학습한 자바의 데이터 타입 종류로는 파이썬의 리스트처럼 하는 건 불가능하다. 아래의 예시처럼 배열도 한 가지 타입으로 여러 개를 담을 수 있다.\n1 2 int [] scores = {70, 80, 90, 100} String [] names = {\u0026#34;jeha\u0026#34;, \u0026#34;seo\u0026#34;, \u0026#34;kim\u0026#34;, \u0026#34;hoho\u0026#34;} 한 종류의 데이터 타입으로 모을 수 있지만, 한 학생의 데이터가 두 개의 배열에 나누어져 있기 때문에 데이터를 관리하기가 어렵다. 만약 배열에서 값을 얻고자 했다면 각 배열마다 인덱싱으로 얻어내야하는 번거로움이 있다. 학생의 수가 적을 때는 문제가 안되지만 많아지면 문제가 된다. 한 학생의 데이터를 수정해야 한다면 각 배열마다 정확하게 그 학생 정보가 있는 인덱스로 접근하여 수정해야 한다. 이런 방식은 실수할 가능성이 매우 높다.\n이럴 때 사용해야하는 게 바로 클래스다. 한 객체와 관련된 데이터를 타입이 달라도 한 곳에 모아놓는 방식이다.\n한 학생과 관련된 데이터를 한 곳에 모아놓는 방식이다. 아래 코드와 같이 클래스 안에 관련된 데이터를 모아놓기 때문에 관리하기 좋다.\n1 2 3 4 5 public class Student { private int score; private String name; } 클래스, 객체, 인스턴스 용어 정리 클래스(class), 객체(object), 인스턴스(instance)의 의미는 파이썬과 동일하다.\n클래스 클래스는 class 예약어로 선언된 코드를 의미하는데, 코드 문자적인 의미 말고 실제 설계할 의미로 보자면 인스턴스(또는 객체)를 생성하기 위한 \u0026lsquo;설계도\u0026rsquo; 또는 \u0026lsquo;틀\u0026rsquo;이다. 그래서 객체 또는 인스턴스가 가져야할 속성(변수)과 기능(메서드)을 정의한다.\n흔히들 클래스를 붕어빵 틀에 비유한다. 붕어빵 틀은 먹을 수 있는 붕어빵과는 다르다. 하지만 붕어빵이라 부를 수 있는 특징들을 잡아준다.\n설계도에 비유한다면 집의 설계도를 생각해보자. 설계도는 실제 집이 아니다. 이 설계도를 토대로 지어진 집이 실제다.\n객체 객체는 클래스에서 정의한 속성과 기능을 가진 구현체다. 붕어빵 틀에 의해 생성된 붕어빵, 설계도에 의해 건설된 집이다. (하지만, 때로는 우리가 살아가고 있는 세상에서 sw로 구현할 대상을 의미하기도 한다.)\n인스턴스 그렇다면 이 인스턴스는 무엇인가? 무엇을 중점으로 두고 말하냐에 따라 객체냐 인스턴스냐가 결정된다. 현업에서는 객체와 인스턴스를 대부분 혼용해서 사용한다. 그래서 나눠서 비교할 때는 학습할 때 많이 나눠서 비교한다. 그러면 이 두 가지의 차이는 무엇일까?\n[인스턴스와 객체의 차이]\n첫 번째, 초점의 차이로 설명하면 다음과 같다. 객체와 동일한 구현체지만 설명할 때 \u0026lsquo;클래스와의 관계\u0026rsquo;에 초점을 둔다면 인스턴스, \u0026lsquo;생성된 구현체\u0026rsquo;에 초점을 둔다면 객체로 언급한다.\n두 번째, 메모리 할당 유무의 차이로 설명하면 다음과 같다. 객체는 클래스에서 정의한 속성과 기능을 가진 구현체라고 학습했는데, 이 구현체가 메모리에 할당되어 실제로 사용되기 시작한 상태가 되면 \u0026lsquo;인스턴스\u0026rsquo;라고 한다.\n하지만, 현업에서는 첫 번째 이유로 사용되므로 객체와 인스턴스를 같은 의미로 생각하자.\n그러면 코드로 위 개념들을 확인해보자.\n클래스\n자바는 모든 게 클래스로 작성되지만 아래 클래스는 인스턴스 객체를 생성하기 위한 클래스다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 public class Car { public String brand; public String name; public int price; // 생성자라 합니다. 나중에 학습합니다. public Car(String brand, String name, int price) { this.brand = brand; this.name = name; this.price = price; } // 메서드라 합니다 public String getBrand() { return brand; } public String getName() { return name; } public int getPrice() { return price; } } 인스턴스 및 객체\n위에서 선언한 클래스를 가지고 new 예약어를 사용하여 인스턴스를 생성한다. 아래 코드에서 생성된 car1 과 car2가 인스턴스이자 객체다. 비유하자면 붕어빵이고 건물이다. 메모리의 관점에서 보자면 실제 메모리에 만들어진 실체가 인스턴스 또는 객체다. new라는 예약어가 메모리에 새로 생성하라는 의미다. 변수 챕터에서 확인했듯이 인스턴스가 생성되면서 car1과 car2에는 메모리에 생성된 참조값 주소가 담겨진다. (기본형과 참조형의 변수 대입) 1 2 3 4 5 6 public class CarMain { public static void main(String[] args) { Car car1 = new Car(\u0026#34;kia\u0026#34;, \u0026#34;k3\u0026#34;, 10000); Car car2 = new Car(\u0026#34;kia\u0026#34;, \u0026#34;k5\u0026#34;, 20000); } } 멤버 변수 이번에는 \u0026lsquo;멤버 변수\u0026rsquo;에 대해서 알아본다.\n멤버 변수는 클래스 안에 선언되고, 메서드 밖에 선언된 변수를 말한다. 멤버 변수를 다른 말로 \u0026lsquo;필드(Field)\u0026rsquo; 라고도 한다.\n위 Car 클래스의 brand, name, price가 멤버 변수에 속한다.\n변수 챕터에서도 언급했지만 변수는 멤버 변수와 지역 변수로 나눠지고 이에 따라 자동 초기화 유무가 결정된다. 어떻게 결정되는지는 자바에서의 변수는 어떨까? - 항상 초기화를 직접 해줘야 하나?을 확인하자.\n메모리의 관점에서 보자면 인스턴스가 생성될 때 이 멤버 변수를 사용하는데 필요한 메모리 공간도 함께 확보한다.\n이 멤버 변수는 인스턴스 변수와 정적 변수(클래스 변수)로 나눠지는데 어떻게 해서 구분할 수 있는지 알아보자.\n멤버 변수의 종류 인스턴스 변수 위 Car 클래스에서 선언된 멤버변수 brand, name, price 들은 인스턴스 변수이다.\n클래스 변수, 정적(static) 변수 static 이라는 키워드가 있어야 정적 변수 또는 클래스 변수로 인식된다.\n정적 변수가 필요한 이유는 인스턴스마다 다른 값을 가지고 있는 독립적인 인스턴스 변수보다, 모든 인스턴스에서 동일한 값을 공유하기 위해 클래스 변수(정적 변수)를 사용한다. 그리고 메모리 사용 관점에서도 효율적이기 때문이다.\n그러면 이를 코드로 확인해보자. 생성된 차가 총 몇 대인지를 알고 싶다.\n클래스\n1 2 3 4 5 6 7 8 9 10 11 12 public class Car { public static int count; // 정적 변수 public String brand; // 인스턴스 변수 public String name; // 인스턴스 변수 public int price; // 인스턴스 변수 public Car() { count++; } } 실행 코드\n1 2 3 4 5 6 7 8 9 10 public class CarMain { public static void main(String[] args) { Car car1 = new Car(); Car car2 = new Car(); Car car3 = new Car(); System.out.println(car1.count); System.out.println(Car.count); } } 출력 결과 1 2 3 3 만약 이를 인스턴스 변수로 총 생성 카운트를 세고 싶다면 생성 갯수를 담당하는 별도의 외부 인스턴스를 생성해야 한다.\n생성 갯수를 담당하는 클래스\n1 2 3 4 public class Counter { public int count; // 인스턴스 변수 } Car 클레스\n1 2 3 4 5 6 7 8 9 10 11 public class Car { public String name; // 인스턴스 변수 public int price; // 인스턴스 변수 public Car(String name, int price, Counter counter) { this.name = name; this.price = price; counter.count++; } } 실행 코드\n1 2 3 4 5 6 7 8 9 10 public class CarMain { public static void main(String[] args) { Counter counter = new Counter(); Car car1 = new Car(\u0026#34;k3\u0026#34;, 10000, counter); Car car2 = new Car(\u0026#34;k3\u0026#34;, 20000, counter); System.out.println(counter.count); } } 결과 1 2 코드가 훨씬 복잡해지는 걸 알 수 있다. 그래서 이런 문제를 해결하기 위해서는 정적 변수를 쓰는게 효율적이다.\n변수마다 접근하는 방식 그러면 멤버 변수를 어떻게 읽을 수 있을까?\n인스턴스 변수 위 예시 코드에서 이미 확인했겠지만 인스턴스 변수의 경우 인스턴스 고유의 값이기 때문에 .(dot) 키워드를 사용하여 인스턴스 변수가 가지고 있는 참조값을 통해 접근하여 인스턴스 변수 값을 읽을 수 있다.\n1 2 car1.name car1.price 클래스 변수, 정적(static) 변수 클래스 변수, 정적 변수, static 변수도 인스턴스를 통해서 접근이 가능하다. 하지만 이런 접근은 인스턴스 변수라는 착각을 일으키기 때문에, 클래스명을 통해서 static 변수에 접근하는 걸 권장한다.\n1 Car.count 클래스 변수의 메모리 사용과 주소 관점의 설명은 이 부분을 참고하라.\n메서드 메서드 기본 학습 멤버 변수에 대해 알아봤으니 다음으로 클래스의 메서드를 알아보자.\n메서드(Method)는 클래스 안에 정의된 함수다. 그래서 함수와 메서드란 개념이 프로그래밍 언어에는 보통 존재한다. 하지만, 자바의 경우 모든 게 클래스이기 때문에 함수라는 개념은 없고 \u0026lsquo;메서드\u0026rsquo;란 개념만 존재한다.\n메서드 구성, 호출, 용어 정리 메서드는 크게 \u0026lsquo;메서드 선언부(Method Declaration)\u0026lsquo;과 \u0026lsquo;메서드 본문(Method Body)\u0026lsquo;으로 나눌 수 있다.\n주문한 음식의 가격과 수량 정보를 받아 전체 비용을 반환하는 메서드를 만들었다.\n1 2 3 public static int getFoodTotalPrice(int count, int price) { return count * price; } 그러면 어디가 선언부이고 본문인지 분석해보자.\npublic static int getFoodTotalPrice(int count, int price) 가 메서드 선언부\npublic: 접근 제어자로 나중에 학습한다. static: 이전 챕터에서 학습한 것처럼 객체를 생성하지 않고 사용할 수 있는 정적(클래스) 메서드라는 의미다. int: 반환값을 의미한다. getFoodTotalPrice: 해당 메서드의 이름으로, 이 이름과 호출 연산자를 사용하여 호출한다. (int count, int price): 메서드를 호출할 때 전달하는 입력 값 매개변수들을 정의한다. 나머지 부분은 메서드 본문이다.\n메서드가 수행해야하는 코드 블록 코드 블록이 실행되면 순서대로 실행된다. 메서드를 호출하는 곳에서는 메서드 선언부만 알고 본문은 모른다. 메서드에서 생성된 값을 메서드 외부로 주기 위해서는 return을 사용해야 한다. 메서드를 호출하기 위해서는 메서드 호출 시 인자의 갯수와 각 타입이 메서드 선언부의 매개변수의 갯수와 각 타입이 모두 일치해야 한다.\n정확하게 갯수와 타입이 일치한 경우: getFoodTotalPrice(0, 0) -\u0026gt; 호출 O 타입이 일치하지 않은 경우: getFoodTotalPrice(\u0026quot;Hello\u0026quot;, \u0026quot;Java\u0026quot;) -\u0026gt; 호출 x 갯수가 일치하지 않은 경우: getFoodTotalPrice(0) -\u0026gt; 호출 x 인자와 매개변수가 뭔지 모른다면 아래 정리를 읽어보자.\n인수(Argument): 인자라고도 하며 메서드 호출 시 괄호 안에 넘기는 값을 의미한다. 매개변수(parameter): \u0026lsquo;매개\u0026rsquo;와 \u0026lsquo;변수\u0026rsquo;의 합성어로 메서드 호출부와 메서드 본문 사이에서 값을 전달하는 역할을 하는 변수라는 의미다. 메서드를 포함하여 함수를 호출하는 부분인지, 함수를 선언하는 부분인지에 따라 결정된다.\n메서드의 매개변수와 반환값 위 예시 메서드처럼 반드시 매개변수가 있어야하는 것이 아니고, 반환값이 있어야 하는 게 아니다.\n매개변수가 없으면 getFoodTotalPrice() 처럼 빈 괄호로 선언하면 된다.\n반환값이 없으면 메서드 선언부에 public static int에서 int를 void로 바꿔야 한다. void는 반환값이 없다는 의미다. 이런 경우 return을 사용하지 않아도 된다.\npublic static void 입력값과 반환값이 없는 메서드를 작성해보자.\n1 2 3 4 // 바로 밑에 void를 작성한 걸 확인하자 public static void introduceMe() { System.out.println(\u0026#34;Hello my name is jeha\u0026#34;); } 출력은 하지만 반환값은 없다.\n만약 int를 반환한다면?\n1 2 3 public static int returnInteger() { return 1; } 만약 boolean을 반환한다면?\n1 2 3 public static boolean returnBoolean() { return true; } 만약 String을 반환한다면?\n1 2 3 public static String returnString() { return \u0026#34;Hello\u0026#34;; } 반환값이 있으면 반드시 return을 써서 메서드 선언부에 일치하는 값을 반환해야 한다.\n메서드의 return 문 메서드는 return문을 만나면 그 즉시 해당 메서드를 빠져나간다. 그래서 조건문에 따라 return문을 작성한다면 모든 조건문에 작성해야하므로 매 마지막에 작성하는 것도 좋은 방법이다.\n아래와 같이 작성하면 age가 20이상인 경우 해당 메서드에서 빠져나올 수 없다.\n1 2 3 4 5 6 7 8 9 10 11 12 public static boolean isAdult() { Scanner input = new Scanner(System.in); int age = input.nextInt(); if (age \u0026gt;= 20) { System.out.println(\u0026#34;성인 입니다.\u0026#34;); } else { System.out.println(\u0026#34;성인이 아닙니다.\u0026#34;); return false; } } 다음과 같이 return true;를 추가하거나 result 변수에 담아서 마지막에 return result 방식으로 하는 2가지 방식이 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 public static boolean isAdult() { Scanner input = new Scanner(System.in); int age = input.nextInt(); if (age \u0026gt;= 20) { System.out.println(\u0026#34;성인 입니다.\u0026#34;); return true; } else { System.out.println(\u0026#34;성인이 아닙니다.\u0026#34;); return false; } } 또는\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public static boolean isAdult() { Scanner input = new Scanner(System.in); int age = input.nextInt(); boolean result; if (age \u0026gt;= 20) { System.out.println(\u0026#34;성인 입니다.\u0026#34;); result = true; } else { System.out.println(\u0026#34;성인이 아닙니다.\u0026#34;); result = false; } return result; } 작성하려는 메서드의 목적에 따라 하나를 골라 작성하면 된다.\n메서드 시그니처(method signature) 메서드 오버로딩에 대해 알아보기 전에 \u0026lsquo;메서드 시그니처\u0026rsquo;에 대해 알아보자.\n메서드 시그니처는 자바에서 메서드를 구분할 수 있는 고유한 식별자나 서명을 의미하는데, 메서드의 이름과 매개변수 타입(순서 포함)까지 포함되어 있다. 반환값은 시그니처에 포함되지 않는다.\n그래서 이 메서드 시그니처가 다르면 메서드 이름이 같아도 다른 메서드로 간주한다.\n메서드 오버로딩(method overloading) 메서드 오버로딩은 이 메서드 시그니처를 이용하는데, 메서드 이름은 동일하지만 매개변수의 타입 또는 갯수 또는 둘 다 다른 메서드를 여러 개 정의하는 걸 말한다.\n그러면 한 가지 기능을 하는 메서드에 대해 오버로딩을 적용해보자.\n입력받은 팀원을 소개하는 문자열을 반환한다.\n1 2 3 public static String introduce(String member) { return \u0026#34;내 팀원은 \u0026#34; + member + \u0026#34; 입니다.\u0026#34;; } 출력 결과는 다음과 같습니다.\n1 내 팀원은 홍길동 입니다. 매개변수가 하나 늘어난 메서드 오버로딩\n1 2 3 public static String introduce(String member1, String member2) { return \u0026#34;내 팀원은 \u0026#34; + member1 + \u0026#34; \u0026#34; + member2 + \u0026#34; 입니다.\u0026#34;; } 출력 결과 1 내 팀원은 홍길동 김제하 입니다. 타입이 다른 메서드 오버로딩\n1 2 3 public static String introduce(int member) { return \u0026#34;내 팀원은 \u0026#34; + member + \u0026#34; 입니다.\u0026#34;; } 출력 결과 1 내 팀원은 1 입니다. 타입과 갯수가 모두 다른 메서드 오버로딩\n1 2 3 public static String introduce(String member1, int member2) { return \u0026#34;내 팀원은 \u0026#34; + member1 + \u0026#34; \u0026#34; + member2 + \u0026#34; 입니다.\u0026#34;; } 출력 결과 1 내 팀원은 홍길동 1 입니다. 모두 다 한 번에 실행이 가능하다. 하지만 완전히 동일한 메서드가 2개 존재하면 에러가 발생된다. 만약 세 번째 introduce의 매개변수 int memeber를 String member로 수정할 경우 다음과 같은 에러가 발생한다.\nAmbiguous method call: both \u0026#39;CarMain.introduce(String)\u0026#39; and \u0026#39;CarMain.introduce(String)\u0026#39; match 그래서 \u0026lsquo;메서드 시그니처\u0026rsquo;가 다른 메서드만이 오버로딩이 가능하다.\n클래스 메서드(정적, static 메서드)와 인스턴스 메서드 이제 static에 대해서 알았으니 얘기하자면 static이 붙은 메서드가 정적 메서드, statc method, 클래스 메서드이고, static이 안붙은 메서드가 인스턴스 메서드다.\n주로 클래스 메서드는 클래스 변수에 접근하기 위해 사용되고, 인스턴스 메서드는 인스턴스 변수에 접근하기 위해 사용된다.\n메서드를 설명하기 위해 다음 코드와 같이 함께 본다.\n클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 public class Car { public String name; // 인스턴스 변수 public int price; // 인스턴스 변수 public static int count; // 클래스 변수(정적 변수) public Car(String name, int price) { this.name = name; this.price = price; count++; } // 클래스 메서드 public static int getCount() { System.out.println(\u0026#34;생성된 총 차 댓수: \u0026#34; + count); return count; } // 클래스 메서드 public static void callClassMethod() { System.out.println(\u0026#34; ===== Enter in callClassMethod =====\u0026#34;); getCount(); // 클래스 메서드 내에서 클래스 메서드 호출 } // 인스턴스 메서드 public String getName() { System.out.println(\u0026#34; ===== Enter in getName =====\u0026#34;); getCount(); // 인스턴스 메서드 내에서 클래스 메서드 호출 return name; } // 인스턴스 메서드 public int getPrice() { System.out.println(\u0026#34; ===== Enter in getPrice =====\u0026#34;); getCount(); // 인스턴스 메서드 내에서 클래스 메서드 호출 return price; } } 인스턴스\n1 2 3 4 5 6 7 8 9 10 11 12 public class CarMain { public static void main(String[] args) { Car car1 = new Car(\u0026#34;k3\u0026#34;, 10000); Car.getCount(); // 클래스를 통한 클래스 메서드 접근 Car.callClassMethod(); // 클래스를 통한 클래스 메서드 접근 car1.getCount(); // 인스턴스를 통한 클래스 메서드 접근 car1.getName(); // 인스턴스를 통한 인스턴스 메서드 접근 car1.getPrice(); // 인스턴스를 통한 인스턴스 메서드 접근 } } 인스턴스 메서드 호출 단 인스턴스 메서드는 반드시 생성된 인스턴스를 통해서만 호출할 수 있다. 클래스명으로는 접근할 수 없다.\n만약 Car.getName() 으로 접근하려고 한다면 다음과 같은 에러가 발생된다.\nnon-static method getName() cannot be referenced from a static context 클래스를 통한 메서드 호출은 static 예약어가 붙은 것만 가능하다는 의미다. 왜 그런건지는 클래스와 인스턴스가 생성되는 메모리 영역에 대해 알면 쉽게 이해할 수 있다. 클래스에 대해 생성되는 메모리 영역과 인스턴스가 생성되는 메모리 영역이 다르기 때문이다. 더 자세한 내용은 이 부분을 참고하자.\n클래스 메서드, 정적(static) 메서드 호출 위 코드에서 확인할 수 있듯이 인스턴스 메서드와 달리 정적 메서드는 클래스 이름과 인스턴스 이름을 통한 접근 모두 가능하다. 이 정적 메서드는 주로 객체 생성 없이 메서드의 호출만으로 필요한 기능을 수행할 때 주로 사용한다. 예를 들어 간단한 메서드 하나로 끝나는 메서드에 사용된다.\n메서드 간 호출 위 코드에 작성한 것처럼 다음 순서로만 호출이 가능하다\n인스턴스 메서드 -\u0026gt; 클래스 메서드 호출 O 클래스 메서드 -\u0026gt; 인스턴스 메서드 호출 x 클래스 메서드 -\u0026gt; 클래스 메서드 호출 O 클래스와 인스턴스의 메모리 영역에 대해서 알면 쉽게 이해할 수 있다. 설명은 이 부분을 보자.\n그래서 위 코드를 실행하면 다음 출력을 볼 수 있다. 화살표는 출력된 게 아니라 내 설명이다.\n생성된 총 차 댓수: 1 \u0026lt;--- Car.getCount()의 결과 ===== Enter in callClassMethod ===== \u0026lt;--- Car.callClassMethod에 진입 생성된 총 차 댓수: 1 \u0026lt;--- Car.callClassMethod 내부에서 getCount 클래스 메서드 호출 생성된 총 차 댓수: 1 \u0026lt;--- car1.getCount()의 결과 ===== Enter in getName ===== \u0026lt;--- car1.getName에 진입 생성된 총 차 댓수: 1 \u0026lt;--- getName 인스턴스 메서드 내부에서 호출한 getCount 클래스 메서드 ===== Enter in getPrice ===== \u0026lt;--- car1.getPrice에 진입 생성된 총 차 댓수: 1 \u0026lt;--- getPrice 인스턴스 메서드 내부에서 호출한 getCount 클래스 메서드 클래스 메서드에서 인스턴스 메서드를 호출하는 방법이 있긴 하다. 바로 클래스 메서드 매개변수로 인스턴스를 받아서 클래스 메서드 내부에서 이 인스턴스를 통해 인스턴스 메서드에 접근하면 된다.\n하지만 클래스 메서드에서 인스턴스 메서드를 호출하는 건 좋지 못하다. 클래스 메서드는 클래스와 관련된 메서드이기 때문에 적절하지 않다.\n절차 지향 프로그래밍과 객체 지향 프로그래밍 이 두 프로그래밍 방식은 서로 대치되는 개념이 아니다. 단지 무엇에 더 중점을 두냐의 다양한 관점들일 뿐이다. 그러면 이 두 가지 방식에 대해 알아보자.\n절차 지향 프로그래밍 절차 지향 프로그래밍은 명칭 그대로 \u0026lsquo;절차\u0026rsquo;를 중요하게 여기는 방식이라서 프로그램의 흐름을 작성한 코드 순서대로 따르면서 처리하는 방식이다. 그래서 \u0026lsquo;어떻게 \u0026lsquo; 를 중심으로 프로그래밍한다.\n객체 지향 프로그래밍 객체 지향 프로그래밍은 명칭 그대로 \u0026lsquo;객체\u0026rsquo;를 중요하게 여긴다. 우리가 살아가는 세상에서 존재하는 사물이나 사건을 객체로 보고, 이 객체들 간의 상호작용을 중심으로 프로그래밍하는 방식이다. 그래서 \u0026lsquo;무엇 \u0026lsquo; 을 중심으로 프로그래밍한다.\n그러면 위 차이점들이 코드에서 어떻게 드러날까? 절차 지향 방식으로 코드를 작성했다가 객체 지향 방식으로 리팩토링하면서 어떤 문제점들이 해결되는지 코드로 확인해보자.\n클래스\n1 2 3 4 5 6 public class Car { public int velocity; public boolean isOn; } 인스턴스 및 main\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 public class CarMain { public static void main(String[] args) { Car car = new Car(); // 시동 걸기 turnOn(car); // 속도 올리기 velocityUp(car); velocityUp(car); velocityUp(car); // 속도 내리기 velocityDown(car); velocityDown(car); velocityDown(car); // 시동 끄기 turnOff(car); } public static void turnOn(Car car) { System.out.println(\u0026#34;시동을 겁니다\u0026#34;); car.isOn = true; } public static void turnOff(Car car) { System.out.println(\u0026#34;시동을 끕니다\u0026#34;); car.isOn = false; } public static void velocityUp(Car car) { System.out.println(\u0026#34;속도를 10 높입니다\u0026#34;); car.velocity += 10; } public static void velocityDown(Car car) { System.out.println(\u0026#34;속도를 10 내립니다\u0026#34;); car.velocity -= 10; } } 위 절차 지향으로 작성된 코드는 데이터와 기능이 분리되어 있다. 데이터는 Car에 있지만 기능은 CarMain에 있다. 데이터와 이 데이터를 사용하는 기능은 매우 연관되어 있기 때문에, 데이터가 변경되면 이 데이터를 사용하는 기능들도 함께 변경해야 한다. 이렇게 분리되어 있으면 유지보수 관점에서도 관리 포인트가 두 곳으로 늘어난다.\n그러면 객체 지향 방식으로 리팩토링을 해보자. Car라는 개념을 객체로 온전히 만드는 게 중요하다. \u0026lsquo;객체 지향\u0026rsquo;의 말처럼 객체를 지향하자. 그래서 프로그램을 실행하는 순서(절차)보다 이 자동차 클래스가 어떤 속성(데이터)를 가지고 어떤 기능(메서드)를 제공하는지에 초점을 두고 작성해야 한다.\n클래스\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public class Car { public int velocity; public boolean isOn; public void turnOn() { System.out.println(\u0026#34;시동을 겁니다\u0026#34;); isOn = true; } public void turnOff() { System.out.println(\u0026#34;시동을 끕니다\u0026#34;); isOn = false; } public void velocityUp() { System.out.println(\u0026#34;속도를 10 높입니다\u0026#34;); velocity += 10; } public void velocityDown() { System.out.println(\u0026#34;속도를 10 내립니다\u0026#34;); velocity -= 10; } } 인스턴스 및 main\n1 2 3 4 5 6 7 8 9 10 11 12 13 public class CarMain { public static void main(String[] args) { Car car = new Car(); car.turnOn(); // 객체야 시동 켜라 car.velocityUp(); // 객체야 속도 높여라 car.velocityUp(); car.velocityUp(); car.velocityDown(); // 객체야 속도 낮춰라 car.velocityDown(); car.velocityDown(); car.turnOff(); // 객체야 시동 꺼라 }} 리팩토링한 후 다음 변화들을 느낄 수 있다.\n객체의 속성과 기능은 객체 하나로 묶었다. 유지보수의 관점에서 보자면 한 곳으로 줄어들었다. 이 말은 변경도 더 쉬워졌다는 의미다.\n객체를 생성하고 필요한 기능(메서드)만을 호출하면 된다. 이 객체를 사용하는데 필요한 모든 건 객체 안에 있다. 그래서 사용자는 이 객체 내부에 대한 정보를 몰라도 이 객체가 제공하는 기능을 단지 호출해서 사용할 수 있다.\n실제 실행코드도 훨씬 짧아지고, 코드 읽기가 더 쉬워졌다.\n절차 지향과 객체 지향의 차이: 캡슐화 실행되는 main 코드를 보면 절차 대로 작성된 것을 또한 알 수 있다. 절차 지향과 객체 지향은 서로 대치되는 방식이 아닌 단지 무엇에 더 중점을 두고 프로그래밍을 하느냐의 차이일 뿐이다. 그러면 이 차이를 한 단어로 요약하자면 캡슐화 의 유무라고 판단된다.\n캡슐화란 속성과 기능을 하나로 묶어서, 필요한 기능을 메서드를 통해 외부에 선별적으로 제공하는 것을 말한다.\n캡슐화의 관점에서 보자면 객체의 속성과 행위를 어떻게 두냐에 따라 절차 지향인지 객체 지향인지를 알 수 있다. 절차 지향 프로그래밍은 객체의 속성과 행위를 따로 두는 방식 이고, 객체 지향 프로그래밍은 객체의 속성과 행위를 묶은 방식 이다.\n하지만 위 객체 지향 방식으로 작성한 코드는 완전히 캡슐화를 담아내지 못한 코드다. 캡슐화의 \u0026lsquo;선별적으로\u0026rsquo; 라는 부분을 담아내지 않았기 때문이다. 이 부분은 \u0026lsquo;접근 제어자\u0026rsquo; 부분에서 정리한다.\n이번 포스팅 주제에 관한 파이썬과의 차이점 단지 호기심의 관점으로 자바와 파이썬을 비교해본다\n타입 강제 자바에서는 메서드의 매개변수의 타입과 반환값 타입을 반드시 입력해야 한다. \u0026lsquo;강제성\u0026rsquo;이 존재하지만 파이썬에서는 그렇지 않다. 자바가 엄격하다가 느낄 수 있지만 사람이기에 이런 엄격함은 필요하다고 생각한다.\n메서드 오버로딩 파이썬은 오버로딩 개념이 없다. 하지만 팩킹과 언팩킹을 사용하여 받은 변수의 갯수를 가변적으로 받아서 한 메서드에서 여러 개의 변수를 받을 수 있다.\n멤버 변수와 메서드 구분 방식 파이썬에서 클래스의 멤버 변수는 자바와 동일하게 클래스와 인스턴스 변수로 나눠졌다. 하지만 메서드의 경우, self 인자를 받는 메서드는 인스턴스 메서드, cls 인자와 @classmethod 데코레이터를 받는 클래스 메서드, 아무런 인자를 받지 않고 @staticmethod라는 데코레이터를 받은 메서드는 정적 메서드라 한다.\n하지만 자바에서는 정적 메서드와 클래스 메서드를 동일하게 불렀고, 인스턴스 메서드와 클래스 메서드를 구분하는 방법이 받는 인자가 아닌 static 예약어의 사용 유무인 것도 신기했다.\n언어 파이썬 자바 인스턴스 변수 키워드 self x 클래스 변수 키워드 x static 인스턴스 메서드 키워드 self x 클래스 메서드 키워드 cls, @classmethod static 정적 메서드 키워드 @staticmethod 클래스 메서드와 정적 메서드가 같음 메서드 간 호출 인스턴스와 클래스에서 클래스 메서드 그리고 인스턴스 메서드를 호출하는 것도 다르다.\n인스턴스로 클래스 메서드 호출: 자바와 파이썬 모두 가능 클래스로 인스턴스 메서드 호출: 자바는 불가능, 파이썬은 인스턴스 메서드에 인자로 인스턴스를 넘기면 가능 또한 다른 종류의 메서드들끼리 호출하는 것도 다르다\n인스턴스 메서드 -\u0026gt; 인스턴스 메서드 자바에서는 매개변수 없이 호출 가능하지만, 파이썬에서는 self 매개변수를 통해 호출 가능 인스턴스 메서드 -\u0026gt; 클래스 메서드 자바에서는 매개변수 없이 호출 가능하지만, 파이썬에서는 __class__ 매직 메서드를 통해 호출 가능 클래스 메서드 -\u0026gt; 클래스 메서드 자바에서는 매개변수 없이 호출 가능하지만, 파이썬에서는 cls 매개변수를 통해 호출 가능 클래스 메서드 -\u0026gt; 인스턴스 메서드 자바는 클래스 메서드의 인자로 인스턴스를 받아야 호출 가능하지만, 파이썬에서는 불가능하다. ","permalink":"http://jeha00.github.io/post/java/2_1_class/","summary":"클래스가 필요한 이유, 클래스 멤버 변수 그리고 메서드, 절차 지향과 객체 지향의 차이점에 대해 알아본다.","title":"자바의 클래스에 대해 알아보자 - 1"},{"categories":"java","content":"변수 생성 관점에서의 차이 Java는 python과 달린 선언과 초기화 작업이 나눠진다.\n1 2 3 4 5 6 7 8 9 10 11 package variable; public class Variable { public static void main(String[] args){ // 변수 선언 int a; // 변수 초기화 a = 1; } } 하지만 파이썬은 다음과 같이 동시에 진행된다.\n(놀라지 마세요. 변수 사용하는데 필요한 모든 걸 다 작성했습니다.)\n1 a = 1 하지만 메모리 관점에서 보면 매커니즘은 다르다.\n자바는 선언한 데이터 타입에 맞는 데이터 크기만큼 메모리에 a라는 자리를 만든 후, 이 a라는 자리에 1을 담는다.\n하지만 파이썬은 1이라는 정수 객체를 생성한 후, a 변수가 이 객체를 가리키도록 한다.\n자바는 특정 이름을 가진 그릇을 먼저 만든 후 값을 담는다면 파이썬은 먼저 만들어진 값을 가진 그릇에 특정 이름으로 라벨링한다는 그림이다. [TIL] Python basic 40: Call by object reference을 참고하자.\n초기화 작업이 필요한 이유? 그러면 왜 초기화 작업이 필요할까?\n변수 초기화를 해야하는 이유는 변수를 선언한 메모리 위치에 \u0026lsquo;의미 없는 그리고 의도하지 않는 값\u0026rsquo;이 담겨진다. 그래서 이상한 값이 출력될 수 있다. 이 문제를 예방하기 위해서 자바는 변수 초기화를 강제한다.\n그래서 자바에서는 초기화하지 않은 변수를 사용할 경우 컴파일 에러가 발생한다.\n1 2 3 4 5 6 7 8 9 10 package variable; public class Variable { public static void main(String[] args){ // 변수 선언 int a; System.out.println(a); } } 위 코드를 실행해보면 java: variable a might not have been initialized 이와 같은 컴파일 에러가 발생한다.\n파이썬을 다루면서 몰랐지만 컴파일 언어의 컴파일 과정에서 에러를 미리 잡아주는 건 너무 좋은 것 같다.\n그래서 이걸 학습한 관점에서 파이썬을 봤을 때 파이썬에서는 별도의 초기화 작업이 없는 이유가 내 셍긱이지만 어차피 초기화를 반드시 해야해서 그런 게 아닌가 싶다.\n항상 초기화를 직접 해줘야 하나? 위 자바 코드를 보면 개발자가 직접 초기화 작업을 진행했다.\n그러면 매번 이렇게 해야할까?\n변수의 종류에 따라 초기화 작업 유무가 결정되는데 지역 변수인 경우 개발자가 직접 초기화를 해주어야 한다. 하지만, 멤버변수는 자바가 자동으로 초기화를 진행해준다.\n변수의 종류 변수의 종류에는 2가지가 있다.\n지역 변수(Local Variable): Local scope에 선언된 변수로 그 예에는 메서드 바디에 선언된 변수와 메서드의 매개변수가 있다. 멤버 변수(필드): 클래스에 선언된 변수로 그 예에는 클래스 변수, 인스턴스 변수가 있다. 지역 변수의 초기화 예시는 위에서 확인해봤으니 클래스 변수의 예를 확인해보자.\nStudent 클래스를 하나 생성하고, 이 클래스의 인스턴스를 하나 만들어보자.\n클래스\n1 2 3 4 5 6 7 8 package variable; public class Student { int number; float grade; String name; boolean graduated; } 인스턴스\n1 2 3 4 5 6 7 8 9 10 11 package variable; public class StudentMain { public static void main(String[] args) { Student student = new Student(); System.out.println(\u0026#34;grade: \u0026#34; + student.grade); System.out.println(\u0026#34;name: \u0026#34; + student.name); System.out.println(\u0026#34;number: \u0026#34; + student.number); System.out.println(\u0026#34;graduated: \u0026#34; + student.graduated); } } 위 인스턴스를 출력하면 다음과 같다.\ngrade: 0.0 name: null number: 0 graduated: false 초기화 작업을 하지 않았어도 int는 0으로, float는 0.0으로 string은 null로, boolean은 false 초기화가 되어 있는 걸 알 수 있다.\n그래서 멤버변수의 자동 초기화값은 다음과 같다. int: 0 float: 0.0 String: null boolean: false 변수 명명법 다음으로 자바에서 변수 컨벤션은 무엇일까?\n파이썬에서는 클래스는 PascalCase, 변수는 snake나 lowerCamelCase를 사용한다. 하지만 상수의 경우 대문자로만 입력하여 단어 구분은 언더바(_)를 사용한다.\n자바 또한 이와 비슷하다.\n클래스는 UpperCamelCase (PascalCase)를 사용하고, 변수를 포함한 나머지는 lowerCamelCase를 사용한다.\n상수의 경우 snake case처럼 언더바(_)를 사용하지만 대문자로만 입력한다. 패키지는 모두 소문자를 사용한다. 변수의 종류 그러면 자바에서 변수의 종류와 범위는 어떻게 될까?\n먼저 파이썬에서는 어떤지 간단히 리뷰를 해보자.\n파이썬에서는 변수의 값은 하나 하나가 객체이기 때문에 그 종류가 정말 무수히 많다. 그래도 기본적인 타입들만 언급하자면 다음과 같다.\n정수형(int), 실수형(float), 복소수(complex), 참거짓(boolean), 문자열(string, \u0026ldquo;\u0026ldquo;와 \u0026lsquo;\u0026lsquo;모두 사용가능)\n그리고 데이터를 담는 container의 관점에서 정말 기본적인 것만 보자면 list, tuple, dictionary, tuple 이 있다.\n하지만 다시 말하자면 파이썬에서 모든 값들은 다 객체이기 때문에 매우 많다. 위 기본타입을 바탕으로 발전된 것들도 많다.\n자바에서는 다음과 같다.\n[값의 종류를 기준으로 나눈 변수의 종류]\n정수형 byte: -128 ~ 127 (1byte, 2의 8승) short : -32,768 ~ 32,767 (2byte, 2의 16승) int : -2,147,483,648 ~ 2,147,483,647 (약 20억) (4byte, 2의 32승) long : -9,223,372,036,854,775,808 ~ 9,223,372,036,854,775,807 (8byte, 2의 64승) 숫자를 입력할 때 int 범위를 넘는 값을 입력할 때는 L 을 입력해야 한다. 소문자도 가능하지만 1과 헷갈리므로 대문자로만 입력하자. ex: 12345678910L 실수형 float : 대략 -3.4E38 ~ 3.4E38, 7자리 정밀도 (4byte, 2의 32승) double : 대략 -1.7E308 ~ 1.7E308, 15자리 정밀도 (8byte, 2의 64승) long 과 동일하게 끝에 f를 붙여야 한다. ex: 1233123.023f 기타 boolean: true, false (1byte, 2의 8승) char: 문자 하나 (2byte, 2의 16승(8 x 2) ) + 홀따옴표(\u0026rsquo;\u0026rsquo;) 사용 String: 문자 길이에 따라 메모리 사용량이 동적으로 달라진다 + 쌍따옴표(\u0026rdquo;\u0026quot;)를 사용 하지만 실무에서 실제로 사용하는 것들은 boolean, int, double, String 이라 한다. short로는 너무 범위가 좁고, float로는 정밀도가 낮기 때문이다. 그리고, char 처럼 문자 하나만을 표현하는 일은 거의 없기 때문이다.\n모든 변수 종류를 모두 암기하기는 어렵다. 하지만 자주 사용하는 변수 종류들의 범위만이라도 외워두자.\n자바는 변수를 어떻게 전달할까? 변수 종류를 나누는 기준으로는 위에 언급된 것처럼 \u0026lsquo;값의 종류\u0026rsquo; 뿐만 아니라 \u0026lsquo;값을 전달하는 방식\u0026rsquo;에 따라 나눠지기도 한다.\n바로 \u0026lsquo;기본형(Primitive Type)\u0026rsquo; 과 \u0026lsquo;참조형(Reference Type)\u0026rsquo; 이다.\n기본형: int, long, boolean 처럼 변수에 사용할 값을 직접 넣는 데이터 타입 참조형: 클래스, 배열과 같이 데이터에 접근하기 위한 참조값(주소)를 저장하는 데이터 타입 즉, 기본형은 실제 사용하는 값을 변수에 담고, 참조형은 실제 사용하는 값을 변수에 담는 게 아니라 객체 또는 배열의 참조값(주소)을 저장한다.\n참조형의 경우 객체의 경우 .(dot) 나 배열의 경우 [] 를 통해서 메모리 상에 생성된 객체 또는 배열에 찾아가야 사용할 수 있다.\n기본형과 참조형의 연산 기본형은 실제 값이 들어있기 때문에 그대로 계산에 사용할 수 있지만, 참조형은 실제 값이 아닌 참조값이서 연산에 직접적으로 사용할 수 없다. 주소지에 가야 실체가 있기 때문에, 주소지에 접근해야 사용하라 수 있다. 주소지만 가지고 어떻게 연산이 가능하겠는가?\n1 2 3 // 기본형 int a = 10; b = 20; int sum = a + b; 위처럼 기본형 연산은 가능하다.\n1 2 3 4 5 6 7 8 public class StudentMain { public static void main(String[] args) { Student student1 = new Student(); Student student2 = new Student(); System.out.println(student1 + student2); } } 하지만 만약 참조형으로 연산을 할려고 시도한다면 컴파일 시 다음과 같은 에러를 확인할 수 있다.\njava: bad operand types for binary operator \u0026#39;+\u0026#39; first type: Student second type: Student 만약 참조형이 가지고 있는 값을 계산하고 싶다면 다음과 같이 접근해서 계산해야 한다.\n1 2 3 4 5 6 7 8 9 public class StudentMain { public static void main(String[] args) { Student student1 = new Student(); Student student2 = new Student(); // 수정된 부분 System.out.println(student1.grade + student2.grade); } } 기본형과 참조형의 변수 대입 🔆 위 연산 과정을 통해 기본형과 참조형의 차이를 이해할 수 있었다. 그러면 위 차이가 변수를 대입할 때 어떻게 이뤄지는지 확인해보자.\n결론부터 말하자면 다음과 같다.\n자바는 항상 변수의 값을 복사해서 대입한다.\n그래서 기본형의 경우 실제 사용하는 값이 복사해서 전달된다. 그런데 참조형의 경우 실제 사용하는 객체가 아니라 객체의 위치를 가리키는 참조값만 복사된다. 쉽게 이야기해서 건물이 복사되는 게 아닌 건물의 위치인 주소만 복사되는 것이다.\n그러면 기본형의 경우부터 예시를 보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public class Variable { public static void main(String[] args) { int a = 50; int b = a; System.out.println(); System.out.println(\u0026#34;a = \u0026#34; + a); System.out.println(\u0026#34;b = \u0026#34; + b); a = 30; System.out.println(); System.out.println(\u0026#34;변경 a = 30\u0026#34;); System.out.println(\u0026#34;a = \u0026#34; + a); System.out.println(\u0026#34;b = \u0026#34; + b); b = 10; System.out.println(); System.out.println(\u0026#34;변경 b = 10\u0026#34;); System.out.println(\u0026#34;a = \u0026#34; + a); System.out.println(\u0026#34;b = \u0026#34; + b); System.out.println(); System.out.println(\u0026#34;메서드 호출 전\u0026#34;); changeValue(a); System.out.println(\u0026#34;메서드 호출 후 a = \u0026#34; + a); } public static void changeValue(int x) { x = 100; } } 위 코드를 컴파일하면 다음과 같다.\na = 50 b = 50 변경 a = 30 a = 30 b = 50 변경 b = 10 a = 30 b = 10 메서드 호출 전 메서드 호출 후 a = 30 a의 값을 변경하면 b의 값은 변경되지 않는다. b의 값을 변경해도 a의 값은 변경되지 않는다. 즉, 변수 b에 a를 할당할 때 참조값이 아닌 실제 값을 복사해서 전달한다는 걸 알 수 있다. 만약 참조값을 복사해서 전달한다면 a와 b값 모두 동시에 수정된다.\n메서드를 호출할 때에도 메서드에서는 100으로 수정했지만 a의 값을 호출하면 그대로 30이다. 이는 변수에 들어있는 실제 값을 복사해서 전달했다는 걸 알 수 있다.\n다음으로 참조형의 예시를 보자. 똑같이 Student 클래스를 사용한다.\n클래스\n1 2 3 4 5 6 7 package variable; public class Student { int number; float grade; String name; } 인스턴스\n1 2 3 4 5 6 7 8 9 10 11 12 13 package variable; public class StudentMain { public static void main(String[] args) { Student student1 = new Student(); Student student2 = student1; Student student3 = new Student(); System.out.println(\u0026#34;student1: \u0026#34; + student1); System.out.println(\u0026#34;student2: \u0026#34; + student2); System.out.println(\u0026#34;student3: \u0026#34; + student3); } } 위 코드를 실행하면 다음 결과를 알 수 있다.\nstudent1: Week3.Student@22f71333 student2: Week3.Student@22f71333 student3: Week3.Student@13969fbe 각 인스턴스의 참조값이 출력된다. student2의 경우 student1를 할당하면서 동일한 참조값이 복사 및 전달된 걸 확인할 수 있고, student3는 새로 생성했기 때문에 다른 참조값을 가진 걸 알 수 있다.\n현재 Student의 인스턴스들에는 기본값으로 초기화되어 있다. 그래서 이를 다른 값으로 수정하려고 한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package variable; public class StudentMain { public static void main(String[] args) { Student student1 = new Student(); Student student2 = student1; Student student3 = new Student(); student1.name = \u0026#34;kim\u0026#34;; System.out.println(\u0026#34;student1.name: \u0026#34; + student1.name); System.out.println(\u0026#34;student2.name: \u0026#34; + student2.name); System.out.println(\u0026#34;student3.name: \u0026#34; + student3.name); } } 위 코드는 name 값만 다른 값으로 초기화했다. 출력하면 다음과 같다.\nstudent1.name: kim student2.name: kim student3.name: null student1 과 student2는 동일한 참조값을 가지고 있기 때문에, student1.name만 변경했지만 student2.name도 변경되었다. student3는 다른 참조값을 가지고 있기 때문에 그대로 기본값인 null을 가지고 있다.\n그러면 메서드를 통해 수정할 때는 어떨까?\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package variable; public class StudentMain { public static void main(String[] args) { Student student1 = new Student(); Student student2 = student1; Student student3 = new Student(); System.out.println(\u0026#34;변경 전 student1.grade: \u0026#34;+ student1.grade); changeGradeValue(student1); System.out.println(\u0026#34;변경 후\u0026#34;); System.out.println(\u0026#34;student1.grade: \u0026#34; + student1.grade); System.out.println(\u0026#34;student2.grade: \u0026#34; + student2.grade); System.out.println(\u0026#34;student3.grade: \u0026#34; + student3.grade); } public static void changeGradeValue(Student student) { student.grade = 100; } } changeGradeValue 메서드를 추가했다. 위 코드를 실행하면 다음과 같다.\n변경 전 student1.grade: 0.0 변경 후 student1.grade: 100.0 student2.grade: 100.0 student3.grade: 0.0 student1 객체만 changeGradeValue에 전달했지만 student2.grade의 값도 변경되었다. 즉, 동일한 참조값을 참조한다는 걸 알 수 있다.\n그래서 객체를 매개변수로 전달할 때에는 이 원리를 항상 유의해야 한다.\n자바 변수에서 제일 중요한 원칙을 다시 읽어보며 이번 포스팅을 끝내도록 한다.\n🫡 자바는 항상 변수의 값을 복사해서 대입한다.\n","permalink":"http://jeha00.github.io/post/java/1_variable/","summary":"자바에서의 변수는 파이썬과 어떻게 다른지 알아보자.","title":"자바에서의 변수는 어떨까?"},{"categories":"retrospect","content":"Introduction Plant engineer에서 SW engineer로 전향하기로 결정한 후, 노력한 2022년부터 2023년까지 해온 것들에 대한 것을 각각 회고해본다.\n시간 순서대로 노력한 것과 노력한 것에 대한 회고를 작성해나간다.\n회고에 대한 마인드적인 부분만을 보고 싶으시다면 도전에 대한 최종 회고 부분만을 보시면 된다.\n2022년 첫 번째: 개발자로서 무엇을 준비해야하는가? 커리어 강의 개발자로서 커리어를 진행하기 위해 무엇을 준비해야하는지 알고 싶었다. 그래서 인프런 플랫폼에서 \u0026lsquo;한정수\u0026rsquo;님이 만들어주신 패키지 강좌를 처음부터 들으면서 정말 많은 것을 알려줬다. 그래서 개발자로 커리어를 바꾸는데 있어서 무엇이 중요한지 알 수 있다. 이 분의 커리어 강의를 추천한다!\n개발자로서 어떤 마인드로 공부를 해야하는지 어떤 회사에 가는 걸 권장하는지 포트폴리오로서 어떤 게 중요한지 기술 블로그를 반드시 만들어야 하는 이유 위 강의에서 기술 블로그를 만들어야 한다는 내용을 들은 후, 위 강의 수강과 함께 기술 블로그를 만들기 시작했다. Github 으로 만들기 시작하여 현재 이 기술 블로그를 만들게 되었다. 이 때 기술 블로그를 만든 건 정말 좋은 판단이었다. 이후에 내 기술 블로그를 다른 분들한테 보여줄 때마다 잘 정리되어 만들었다는 평을 들을 수 있었으니 말이다.\n파이썬 강의 그리고, 위 강의를 학습하면서 친구 개발자의 권유로 첫 프로그래밍 언어로 \u0026lsquo;파이썬\u0026rsquo;을 선택하여 학습하기 시작했다.\n처음에는 시중에 풀린 파이썬 기본 문법 책을 통해 학습을 학습했다. 재밌어서 이제 더 깊은 문법을 학습하기 원해서 인프런에서 level별로 구성된 파이썬 강의를 선택하여 듣기 시작했다. 이 때 좋은 강사님을 만나서 작성할 때 어떤 자세로 코드를 작성해야하는지, 어떤 점을 신경써야 하는지 등을 알려주셔서 도움이 많이 되었다. 이 분의 파이썬 강의는 추천한다!\nhtml, css 학습 노마드 코더를 통해서 html, css로 카카오톡 클론 코딩을 진행했다. 챌린지 형식으로도 같이 진행하여 과제가 오기 때문에 이 과제를 해결하면서 개념을 손 쉽게 익힐 수 있었다.\n확실히 처음 익힐 때는 과제 형식으로 계속 접근하는게 효과적이다.\n회고 해당 강의를 커리어 전향하기 초반에 들은 건 매우 잘했다고 판단된다.\n내 자신 너무 잘했어! 👍\n지금 생각해보면 막 개발 해보겠다고 한 애가 한 번도 다뤄본 적 없는 git도 다뤄보고, 영어 문서도 찾아서 읽어보고, 구글링해보면서 문제를 해결해서 혼자서 기술 블로그도 만들려고 시도해본 내 자신..신기하다. 여러 블로깅 수단들이 있는데 진입 장벽은 높지만 자유도가 높은 걸 선택해서 시도했다니 대견하다!!\n이렇게 도전할 수 있던 건 영어를 읽는 것에 큰 부담이 없고, 검색해서 찾아보는 게 많이 익숙해서 그런 것 같다. 학교 다닐 때도 여러 키워드로 검색하여 찾아봤고, 편입 영어를 공부했고, 영어 원서로도 전공을 공부해서 그나마 영어에 대해 부담이 없었던 것 같다.\n토익 시험을 봐도 LC는 잘 못봐도 RC 점수가 높았던 것을 보면 \u0026lsquo;편입 영어\u0026rsquo;를 공부했던 게 정말 인생을 살면서 큰 밑바탕이 되었다고 판단된다.\n[자료구조와 알고리즘을 일찍 시작하기]\n파이썬을 공부할 때 기본 문법을 익혔으면 바로 자료구조와 알고리즘을 함께 익혔으면 좋지 않았을까 싶다. 이 CS 과목은 일찍 시작할수록 좋다고 판단된다.\n[다른 언어를 살펴보는 것 없이 바로 파이썬을 주 개발 언어로 택한 것]\n파이썬 기본 문법을 했으면 java나 javascript도 기본 문법까지만 다뤄보면 어땠을까 싶다. 너무 파이썬만을 생각하고 흘러온 것 같다. 나중에 부트캠프에서 js 기본 문법 정도를 익혀서 fetch를 사용하여 화면 렌더링하는 것까지 하지만, 요즘은 Typescript를 사용해서 백엔드 개발을 하는 비중이 많고 서비스 규모가 커져도 Typescript와 Nest.js로 잘 대응하는 경우를 많이 봤다. 그리고 js를 익히면 프론트와 백엔드 모두 혼자서 가능하니 초반에 익히면 정말 좋다고 판단된다. 비전공자한테는 정적 언어가 개념을 익히기에는 더 좋지 않을까? 그래서 java 와 spring을 익히는 것도 좋다고 판단된다. java, spring을 먼저 익히면 좋다고 판단되는 이유 중 또 다른 하나는 한국의 많은 소스들이 이를 기반으로 작성되어 있어서 많은 sw 개념들을 익힐 수 있다고 판단된다.\n하나의 언어를 익히면 또 다른 언어를 익히는 건 쉽다고 많이들 말씀하시는데 동의하지만, 이를 깊은 레벨까지 익히는 건 그래도 쉽지는 않은 것 같다. 그래서 파이썬으로 바로 주 개발 언어로 택한게 개인적으로 아쉽다.\n파이썬 문법을 더 깊이 파고드는 것보다 바로 미니 웹 개발 프로젝트를 시도해보는 것 일주일 기간이어도 간단한 웹 개발 프로젝트를 해보는 게 앞으로의 sw 분야 공부 방식을 익히는데 더 좋다고 판단된다.\n이 기간에 나는 아직까지도 시험 공부처럼 이론을 먼저 다 익힌 후, 실습을 해야한다고 생각했다. 하지만 부트캠프 시기를 통해서 이론과 실습을 빠르게 스위칭하면서 하는 게 더 빠르다는 걸 알았다.\n두 번째: 기본을 위해 CS 과목들 공부하자. 그 다음으로 컴퓨터 공학 전공 과목들을 공부해보기로 결정했다. 이 생각을 한 이유는 컴공은 아니지만 기계공학 전공생으로서 \u0026lsquo;기본 전공의 중요성\u0026rsquo;은 정말 정말 중요하다고 판단하기 때문!\n기본 전공이 부족하면 그 위에 점차 심화 전공들이 쌓일 때 흡수하는 능력이 정말 달라진다.\n그래서 \u0026lsquo;급할수록 돌아가자\u0026rsquo; 라는 마인드로 기본 전공 내용을 수강하기 시작했다.\n이 CS 지식들을 바탕으로 프로젝트가 진행되기 때문에 먼저 학습했다.\n\u0026lsquo;운영체제\u0026rsquo; -\u0026gt; \u0026lsquo;네트워크: http\u0026rsquo; -\u0026gt; 데이터베이스 및 SQL 순서로 학습했다.\n운영체제는 KOCW 대학강의에서 이화여대 교수님 강의를 들었다. 이게 상당히 긴 시간이 걸렸다. 네트워크는 인프런의 김영한 강사님의 http 강의를 들었다. db 및 sql은 인프런의 얄코 강사님의 MySQL 강의를 들었다. 회고 먼저 CS를 학습한 후, 이후 여러 프로젝트를 진행했지만 지식을 아는 것과 적용하는 것은 정말 다른 문제임을 깨닫는다. 이 부분에서는 어떤 지식이 적용되는지 알기가 어렵다. 이래서 멘토링이 필요하다.\n아는 것과 적용하는 것은 다른 종류의 문제다.\n각 과목을 학습하는 방법에 있어서 회고는 다음과 같다.\n[os 학습]\n대학강의를 들을려는 마음가짐은 좋았지만, 지금 생각해보면 과한 시도이지 않나 싶다. 왜냐하면 이 대학 강의를 다 듣는데 생각보다 2 ~ 3개월 정도의 많은 시간이 걸렸다. 학교에서 전공 과목을 들을 때에도 이 정도 시간이 걸렸지만, 혼자서 했기 때문에 학습 속도와 집중력이 쳐지는 부분이 많았던 것 같다. 그래서 필수적인 os 지식 내용이 있다면 이를 바탕으로 공부해나가는게 더 효율적이지 않을까 싶다.\n[네트워크 학습]\n이를 듣고 나서 네트워크 HTTP 강의를 들었는데, 지금 이 강의를 보면 네트워크의 전체 흐름을 이야기하기보다는 HTTP 에 집중해서 설명하는 강좌여서 바로 이 강의를 듣는 것은 좋은 선택이 아니고, 먼저 전체 네트워크 흐름을 쉽게 이해할 수 있는 책을 사서 시도하는 게 좋다고 판단된다. \u0026lsquo;성공과 실패를 결정하는 1%의 네트워크 원리\u0026rsquo; 책을 학습했지만, 너무 자세해서 소화하기가 어려웠다. 아니면 이를 쉽게 설명해주는 유튜브 채널을 찾아서 이와 병행했으면 더 좋았을 것 같은데, 책만 계속 팠다.\n[sql]\n생각해보니 db를 책으로 학습하지는 않았고, 단지 sql만 학습했다는 걸 알았다. 그런데 애플리케이션을 만들 때, 데이터베이스 부분이 많이 중요하다고 하는데 이 부분을 간과한 게 아닌가 싶다. 그래서 원티드에서 MySQL를 기반으로 여러 개념을 학습했지만, 이를 프로젝트에 녹여내는 게 부족하다고 판단된다.\n[자료구조와 알고리즘]\n이 때도 자료구조와 알고리즘을 익히는 게 시간을 많이 쏟지 않았다.\n항상 무엇이든 효율적으로 할 수 있도록 전략을 짜자.\n세 번째: 간단한 프로젝트 시도해보기 먼저 fastapi를 사용해서 간단한 크롤링 프로젝트를 만들어봤다. 이는 이력서에 올리지는 않았지만, 교보문고 사이트에서 책 이미지, 제목, 소개 내용을 가져와 저장한 후 프론트 화면에 표 형식으로 렌더링하는 것을 만들었다.\n이 프로젝트는 강의를 통해서 만들었는데, 해당 강의에서 파이썬의 GIL로 인한 멀티쓰레드 문제점을 다루었기 때문에, 동기, 비동기, 멀티쓰레딩, 멀티 프로세싱, GIL 에 대해 학습할 수 있는 계기가 되었다.\n그 다음으로 django를 사용해서 sns를 만드는 인프런 강좌를 수강하기 시작했지만, 처음부터 이론이 많아서 사용 경험이 없는 나로서는 지루하고 소화하기가 어려웠다.\n회고 [python framework를 사용한 클론 코딩 시도]\n한 번도 프레임워크를 가지고 프로젝트를 해본 경험이 없어서, 클론 코딩으로 프로젝트를 진행했다. 프레임 워크의 전체 흐름 개념 없이 마냥 강의를 따라 친 것 같고, 인프런의 django 강의를 보고 진행했지만 프레임워크를 처음 사용하는 것이기 때문에 처음에 보고 하기에는 너무 이론이 많아서 이 강의보다는 노마드 코드의 django 강의를 보고 진행하는게 더 좋은 방법이지 않았을까 싶다.\n지금을 기준으로 이 때를 생각하면 정말 아무 생각없이 프로젝트를 진행한 것 같다. 나름 메모를 하면서 왜 이걸 이렇게 했는지 이해하면서 들었지만, 그래도 혼자서 스스로 생각해내는 것에 비하면 부족하다.\n아마 몇 년뒤에 2023년 프로젝트를 한 나를 보면 똑같은 생각이 들지 않을까 라는 생각도 든다 😹\n하지만 지금에 와서야 인프런에서 이진석님의 django 강의를 보면 잘 만드셨다는 생각이 들 정도로 정리를 잘해주셨다. 이후 과제 전형을 할 때마다 이 자료로 정리하고 복습을 했는데, 많은 도움이 되었다.\n이런 생각이 드는 걸 보면 내가 성장하긴 했나보다. 소화하기 어려운 내용을 이제 쉽게 이해할 수 있으니 말이다.\n개발은 한 번에 이룰려고 하기보다는 단계별로 진행될 수 밖에 없는 것 같다. 단계별 경험이 쌓이고 나서야 한 번에 가능하다고 판단된다.\n[독학으로 지친 마음]\n이 시기 때 혼자서 계속 공부하는 것에 대해서 지쳤다. 이게 부트캠프를 참여하게 된 계기가 되었다.\n그런데 생각해보면 굳이 부트캠프를 참여하지 않아도 스터디 그룹을 찾아서 참여하면 됐을텐데 아쉬움이 있다.\n매번 판단을 내릴 때 정말 이것 밖에 해결책이 없는지 생각해보는 습관이 중요한 것 같다.\n네 번째: 부트캠프 참여 혼자 공부하는 게 지쳐서 부트캠프를 참여해보기로 했다. 하지만 이 당시에 python, django를 주 기술 스택으로 하는 웹 개발 국비 부트캠프는 없었다. 그래서 사비로 운영하는 부트캠프에 참여했다. 대략 4개월 정도 운영되는 부트캠프였다.\n이 부트캠프로 기술 스택의 관점에서 docker, aws 배포, django drf 내용을 얻을 수 있었고, 소수 인원 부트캠프였지만 그 중에서 몇 명의 개발자 동료를 얻게 되어 좋았다.\ndjango, drf docker, aws 배포 네트워크 독학으로 js 자료구조와 알고리즘 프로젝트 관점에서는 협업 프로젝트를 진행하면서 프론트부터 백엔드 그리고 배포까지의 경험을 얻을 수 있어서 좋았다. 여기서 내가 새로운 언어를 배우는데 거부감이 없고 좋아한다는 것과 여러 가지를 응용해서 잘 만드는 걸 알게 되었다. 제대로 한 첫 프로젝트치고 1인분의 역할을 비교적 잘 했다고 판단했다.\n주변 동료들과 멘토한테도 그리 평가를 받아서 기분이 좋았다. 하지만 아쉬움이 많은 첫 팀 프로젝트다. 프로젝트 전체 퀄리티를 보면 좋지 않다.\n마지막으로 이 때 처음으로 \u0026lsquo;맥북\u0026rsquo;을 얻게 되어 맥북의 매력을 알게 되었다. 맥북은 정말 사랑이다 👍. 윈도우로 개발하다가 맥북을 사용하게 되니 여러 라이브러리나 프로그램을 설치하는 것이 매우 간단해지고, UI/UX 도 더 세련되고 눈에 잘 들어온다. 개발할려면 맥북이 최고다.\n회고 첫 부트캠프이고, 여러 부트캠프들을 알아보고 여러 판단하에 지원했기 때문에 기대가 컸다. 하지만 결과적으로 이야기하자면 부트캠프에사 배운 걸로 취업하는 건 옛날처럼 채용 황금기 시기가 아니라면 불가능하다고 생각한다.\n이 부트캠프에 참여했던 인원들 중 취업한 인원은 이미 경력이 있는 사람이었다. 1기였기 때문에 커리큘럼의 부족함이 많았다. 기업 과제로 한다고 설명이 적혀있었지만, 전혀 그런 건 없었고 이걸로 취업 자체에 도움이 되지는 않았다.\n수료하고 나서 프로젝트 수준이 좋지 않기 때문도 있다고 판단된다. 그리고, 취업 연계로 동일한 기술스택의 연계는 들어오지 않았다.\n2번에서 3번 정도 전혀 다른 기술 스택을 권하고 끝났다. 요즘 부트캠프들과 비교하면 취업 연계까지 해주는 곳이 있기 때문에 여기는 그런 관점에서 무책임하다고 볼 수 있고 수료 후 케어하는 건 없다. 또한, 수료 후 프로젝트 퀄리티가 전체적으로 경험 없는 분들이 많아서 그걸로 취업하기는 어렵다고 판단된다.\n여기 부트 캠프에서는 미리 다른 부트캠프를 수료하신 분들이 계셔서 알고리즘의 경우 수준 차이가 많이 나서 어려웠다.\n이 부트캠프로 취업을 생각한다면 추천하지 않고, 기본기를 다지는 시간을 갖는다면 추천한다.\n그래서 django 과제전형을 진행할 때 해당 부트캠프에서 배운 게 도움이 되었다. 하지만 취업에서는 그것보다 더 높은 수준을 원하기 때문에 django로 개인 프로젝트를 시도해서 기술 수준을 높이는 걸 추천한다. 자신이 취업을 생각하는 부트캠프를 원한다면 다른 것에 투자하는 게 낫다. 부트캠프는 그 시기에 유행하는 기술 스택에 참여하는게 빠른 취업과 연결된다고 판단된다.\n2023년 첫 번째: 새로운 프로젝트 - SNS 부트캠프에서 같이 했던 프로젝트를 팀원들과 함께 리팩토링하며 기능을 확장해갈려고 했지만, 여러 문제로 프로젝트를 진행하기 어렵게 되어 개인 프로젝트를 이번 기회에 해보고 싶은 생각이 들었다.\n나만의 SNS 를 만들고 싶었기 때문에, 기본적인 SNS 기능을 만들고 이를 특정 소재로 결합하는 기획으로 진행했다.\n이 때 멘토링을 해주기로 한 개발자 친구의 권유로 FastAPI로 프레임워크를 진행했다. 이 친구의 PR 리뷰를 바탕으로 프로젝트가 진행되었다. 실제로 개발을 진행하는 건 나 혼자서 해야했기 때문에 책임감이 컸다. 그래서 요약하자면 다음과 생각들로 프로젝트를 진행했다.\n코드 신뢰성을 높이기 위한 수단으로 \u0026lsquo;테스트 코드\u0026rsquo; 작성을 시도했고, 지금은 매번 항상 테스트 코드를 작성하고 있다. 아무런 생각 없이 api를 설계하기보다는 유지보수와 직관성을 위해 \u0026lsquo;RESTful api\u0026rsquo; 방식을 적용했다. 코드의 유지보수성을 위해서 과도한 결합성과 부족한 응집성 문제를 해결하기 위해서, 마지막으로 소통 비용을 줄이기 위해 DDD를 적용했다. 회원 가입 시 적은 정보로 회원 가입을 진행하기 위해 \u0026lsquo;이메일 인증\u0026rsquo;을 도입했다. 조회 속도를 높이기 위해 redis를 사용해서 캐싱을 적용했다. 유저 경험성을 높이기 위해 non-blocking 을 적용하려고 FastAPI의 background task를 적용했다. 알림 기능을 추가하기 위해서 polling, long polling, sse, websocket 중 네트워크 비용 문제와 실시간성을 해결하기 위해서 sse로 알림 기능을 구현했다. 불필요한 sql 문이 발행되는 것을 방지하기 위해 쿼리 개선을 했다. 이외에 코드 가독성에 신경을 많이 썼고, 주석과 타입 힌트에도 신경을 많이 썼다. 코드 퀄리티를 높이기 위해 계속해서 리팩토링을 진행했다. 리팩토링을 진행하면서 느낀 거는 리팩토링을 하면서 코드 관점이 넓어지고, 여러 코드를 볼 때마다 이런 방식으로 작성하는 게 더 좋지 않을까 라는 나만의 가치관이 생기는 것 같다.\n이게 무슨 느낌이냐면 내가 작성한 글을 계속해서 수정하여 더 가독성 있고, 더 구조가 좋은 글을 만드는 과정과 동일하다. 내가 작성한 글을 수정해서 더 좋게 만드는 과정은 행복하다. 나라는 캐릭터가 레벨업 되는 기분이다!!\n이 프로젝트는 단지 취업을 위한 프로젝트라기보다는 내 평생 계속 가지고 가고 싶은 프로젝트다. 그래서 더 애착이 있고, 실제로 많은 사람들이 사용해줬으면 하는 바람이 있다.\n그리고 SNS 라는 특성상 E-commerce보다 기능의 확장성이 좋다고 판단되어 더 즐거운 것 같다. 하지만, E-commerce가 금액을 다루는 만큼 안정성과 데이터 정합성에 더 신경을 써야하니 이 부분에서도 배울게 많다고 생각든다.\n회고 [프로젝트가 길어진 문제점]\n해당 프로젝트 기간이 상당히 길다. 그 이유는 첫 번째로 무엇보다 프로젝트 규모가 혼자서 하기에는 컸다.\n계속해서 가져갈 사이드 프로젝트라고 너무 규모가 컸다.\n프로젝트 규모가 너무 크지도 않고, 정말 실생활의 문제를 해결하면서, 독창적인? 프로젝트 찾기가 어려운 것 같다.\n이외의 이유로는 다음과 같다.\n협업하는 사람들의 개인 일정으로 인해 프로젝트 개발 속도가 많이 늦춰져 개발 기간이 계속 길어졌다. 코테 공부로 다른 언어인 c++에 빠져 프로젝트 개발이 한 달 반 정도 늦춰졌다. 바쁜 시간에 코드 멘토링을 해주는 건 정말 값지다. 정말 고맙지만, 취업의 관점에서 보자면 취준 기간이 길어지기 때문에 많이 힘들어졌다.\n또한, 엄연히 배포 및 운영 경험을 하기 위해서는 프론트가 작업이 되어야 하는데 프론트 작업을 해준다는 친구의 말을 믿고 계속 기다렸지만, 너무 오래 기다렸다. 진행도가 너무 느리다.\n이럴 거면 혼자서 프론트를 하는 게 훨씬 더 낫겠다는 생각을 많이 한다.\n[CS를 기반으로 한 프로젝트 고민들]\n보다 프로젝트를 cs 기반으로 고민들을 많이 하고 싶은데, 생각만큼 많이 하지 못 했다.\n쿼리를 짤 때 시간 복잡도 background task를 적용하면서 non-blocking 개념 sse로 동기 비동기 개념 이에 따라 쓰레드, 프로세스 http 프로토콜 기반 통신 방식을 생각하면서 동기, 비동기, blocking, non-blocking 을 분류 db의 transaction 그리고 FastAPI에서 동기를 사용하기 때문에 event loop를 사용하는 게 아닌 별도의 30개 쓰레드를 사용하므로 프로레스 수를 늘릴 생각 더 많은 것을 고려하고 싶은데 그러지 못 했다. 어느 부분에서 어는 것을 고려해야하는지 더 알고 싶지만 아쉽다.\n이를 멘토링을 통해서 채워나가고 싶었지만 멘토인 친구는 db와 네트워크 지식이 부족한 편이라고 한다. 이 부분보다는 디자인 패턴과 코드 가독성 부분, 시간 복잡도 부분에 신경을 많이 쓰는 타입이라고 판단된다. 그래서 코드적인 측면에서는 많이 배웠지만, CS와 연결된 측면에서는 많이 부족하다.\nOS와 연결된 측면에서는 생각을 했지만, 나머지와는 연계성이 부족한 것 같다.\n그래서 이 cs를 바탕으로 보다 고민하기 위해서는 배포 및 운영하면서 부딪히면서 얻어내야하지 않을까 싶다.\n두 번째: 기업 과제 전형 탈락 및 합격 프로젝트를 진행하면서 많이는 아니지만 몇 몇 회사에 지원을 했고, 과제 전형을 진행했었다. 주로 django로 과제전형을 진행했다. 별도로 django로 프로젝트를 하지 않았지만, 그래도 계속하다보니 기존에 경험한 게 있어서 처음에는 떨어졌지만 결국에는 과제전형을 통과했었다. 꾸준히 하면 정말 뭐라도 된다는 걸 느낀 경험이었다.\n그리고 과제전형을 할 때에도 그냥 하는 게 아닌 메모를 하면서 진행하고, 끝나고 나서 반드시 다시 한 번 막힌 부분을 해결하니 점차 레벨업이 되었다.\n과제전형을 응시했던 날짜는 다음과 같다.\n2023년 2월 탈락 -\u0026gt; 2023년 8월 탈락 -\u0026gt; 2023년 11월 합격 처음에는 거의 하나도 구현하지 못 했지만, 8월에는 django만으로 다 구현했고, 11월에는 drf를 사용해서 api 구축을 완료했다. 기업마다 요구사항이 다른 것도 있었지만 큰 발전이라 생각한다.\n회고 django로 프로젝트를 진행했더라면 보다 바르게 잘 구현하지 않았을까 싶다. 11월 과제 전형은 통과했었지만 django 관련 orm 지식이 부족하고, 실제 배포 경험이 없어서 인터뷰에서 탈락했다.\norm을 공부할 때, 실제 sql 문 각각에 해당하는 orm을 매핑해서 공부해두는 게 orm을 익히기 빠른 방법인 것 같다.\n세 번째: 이력서 돌리기 프로젝트가 1차적으로 마무리 된 후, 이력서를 돌렸다. 76군데를 돌렸고, 7군데 정도 서류를 통과했다. 하지만 갑자기 서류 통과를 취소한 회사들도 존재했다. 결국 면접은 2군데에서만 진행했다.\n모두 다 좋은 경험을 얻게 되었다. 내가 부족한 부분들이 뭔지 알게 되었다. 해당 회사의 채용 공고의 맡은 업무들에 대해 study를 좀더 했어야 했다. 하지만 이 업무 부분은 내가 프로젝트에서 해보지 않았던 부분이라 몇 번 깊은 레벨의 질문을 해도 어려웠을거라 판단했다.\n그래서 면접을 보면서 느낀 건 내가 준비한 것과 해당 회사의 핏이 정말 잘 맞는 겻은 어렵다는 걸 느꼈다. 아무리 준비를 잘한다고 해도 이 부분은 \u0026lsquo;운\u0026rsquo;의 영역이지 않을까 싶다. 마치 소개팅처럼 말이다.\n다른 신입 지원자들과 달리 내가 이력서를 돌리고 나서 한 \u0026lsquo;특별한 행동\u0026rsquo;은 이메일로 피드백 을 요청했다.\n안줘도 어쩔 수 없다는 마음으로 요청했다.\n큰 기대는 안했는데 지원자 회사 수에 비하면 적지만 피드백을 주신 분들이 계셨다.\n피드백 주신 분들의 이메일은 아직도 다 보관하고 있다.\n피드백을 주신 회사들에 다시 한 번 감사의 말씀을 전한다.\n부족한 부분을 언급해주시는 것과 함께 공통적으로 많이 들은 말은 이 말이다.\n개발자로서 재능이 있으니 포기하지 말고 계속 정진하라.\n나에게 정말 큰 위로가 되었고, 포기하고 싶은 상황에서 계속해서 이 말을 되새긴다.\n회고 피드백을 받으면서 나에게 먼저 부족한 것들이 공통적으로 발견되었다.\n신입이라서 그런지 대부분 들어온 답변은 \u0026lsquo;경력 없음\u0026rsquo; 이 제일 컸다.\n두 번째는 주 프레임워크 기술이 다르다. 우리는 \u0026lsquo;django\u0026rsquo;를 원하지만 \u0026lsquo;FastAPI\u0026rsquo;를 주로 쓰시는 것 같아 어렵다.\n라는 게 주 답변이다. 이 말은 내가 django 프로젝트를 가지고 있지만 이 프로젝트로만 봤을 때는 큰 실력을 기대가 안된다고 판단이 되는 것 같다.\n내 실력을 제대로 보여줄 django 개인 프로젝트가 필요하다는 생각이 들었다.\n도전에 대한 최종 회고 꾸준함은 강력한 힘을 가진다. 냉정하게 신입은 취업을 위해서 기술 트렌드를 따라가야만하는 것 같다.\n취업 준비기간이 길어질수록 정신적으로 너무 힘들어진다. 그래도 지금까지 계속 유지하고 버틸 수 있던 거는 \u0026lsquo;좋은 방향으로의 꾸준함\u0026rsquo; 인 것 같다. 나에게 좋은 거라면 꾸준히 한다. 기본적으로 개발은 꾸준히 하는 거고 이것만으로는 부족하다. \u0026lsquo;운동\u0026rsquo;도 꾸준히 해야한다. 아침마다 이불 정리도 꾸준히 하고, 사먹는 것보단 내가 뭔가를 요리해서 먹는 것도 꾸준히 한다. 계속해서 내 자존감을 지키고 유지할 수 있는 것들을 꾸준히 하는 것 같다.\n좋은 방향으로 꾸준히 하는 종류들이 늘어날수록 삶의 질이 높아지고 장기적으로 극복할 수 있는 힘이 생기고, 삶의 안전망 수준이 올라간다.\n커리어적인 관점에서도 그렇고, 사람과의 관계에서도 그렇고, 성품의 성장에서도 그렇다.\n반대로 나쁜 것을 꾸준히하면 그만큼 삶은 피폐해지고, 삶의 에너지도 떨어져 삶의 안전망 수준이 떨어진다. 사람과의 관계는 끊어지고, 우울해지고, 부정적으로 변한다. 예를 들어 뭐가 있을까? 여러 가지가 있지만 \u0026lsquo;시간을 잘 못 쓰는 것\u0026rsquo; 이라고 할 수 있다. 같이가 아닌 혼자 도전하는 것일수록 개인의 \u0026lsquo;자제력\u0026rsquo;이 매우 중요하다. 성공하시는 분들의 공통점으로 이 자제력이 크다는 건 매우 공감간다. 살아남기 위해서는 자기 스스로 자제해야만 한다. 책임질게 늘어날수록 말이다.\n도전에는 막막함과 비판이 따라온다. 아무리 다른 분야에서 개발자로 커리어를 바꾸는 사람이 많다고 해도, 흔하게 찾을 수 있는 도전이라고 해도 IT 외 분야에서는 한국에서는 아니다. 그만큼 이 도전을 탐탁치 않게 생각하시는 분들도 계신다.\n뭔가를 도전한다는 건 이런 것 같다. 남들이 흔히 가지 않는 길을 가는 건 정말 쉽지 않다. 막막함과 주변으로부터의 비판이 끊기지 않는다. 하지만 내가 가는 방향이 틀린 길이 아니라면 맞는 길이라면 묵묵히 가야한다.\n그래서 결과로 반드시 보여줘야한다는 마음이 크다. 결과로 보여주면 아무말도 하지 않는다. 하지만 이 결과가 쉽게 나오지가 않으니 너무 어려운 것 같다.\n이를 극복하기 위해서는 내가 근본적으로 해야하는 건 \u0026lsquo;자신감\u0026rsquo;을 갖는 것이다.\n내 스스로가 할 수 있다고 믿자.\n효율적인 학습 방법: 4가지 옛날에는 모르는 부분이 있으면 그 부분에 대해서 모든 걸 다 알려고 했다. 나름의 완벽주의자 성향이 있어서 더 그랬다.\n하지만 개발 공부를 하면서 다음과 같이 원칙을 바꿨다.\n문제가 해결될 만큼만 학습한다. (빠른 스위칭) 그 다음에 또 다른 문제가 부딪히면 추가적으로 학습한다. 왜냐하면 다 학습하고 넘어가도 문제와 바로 연결되는 부분이 아니면 잊혀지기 쉽다. 문제를 해결할 때 옆에 메모 애플리케이션을 두고, 과정 하나 하나를 다 메모해가며 진행한다. 나중에 이 개념에 대해 블로깅을 한다. 필요한 만큼 학습하되, 학습한 것은 확실히 기억하도록 노력하자.\n실패를 받아들이기 엄연히 내 목표를 기준으로 할 때 난 실패했다. 목표한 바를 기간 내에 성취하지 못했다. 이는 아래 2가지 사실로 나에게 큰 불안감을 줬다.\n내 인생이 실패했구나 이 실패를 난 받아들이기가 싫다. 부인할래. 하지만, 문득 옛날에 들은 성공하신 분들의 이야기를 들은 내용이 기억이 낫다.\n수 천번의 실패 끝에 단 한 번의 성공으로 이룰 수 있었다.\n재수해서 실패한 것? 원하는 만큼의 성적을 얻지 못한 것? 대기업에 취업하지 못한 것? 내가 원하는 회사를 취업하지 못한 것? 위 3가지는 인생에서 인생 모든 게 무너질만큼 치명적인 실패는 아니라고 본다.\n오히려 학교 졸업 후에 겪었던 아래 경험이 치명적인 실패다.\n\u0026lsquo;코로나로 인해 내가 3년 동안 집중적으로 준비한 모든 게 날라가고, 발휘할 수 있는 기회조차 없는 것\u0026rsquo;\n하지만 이미 이 실패를 한 번 극복했지 않았는가?\n2년 동안의 노력 끝에 취업 시장에 도전할 결과 \u0026lsquo;실패\u0026rsquo; 를 얻게 되었고, 2년이라는 기간이 길어지는데는 외부적인 요인들도 많았지만, 이는 이 도전에 대한 실패인 거지 \u0026lsquo;내 인생\u0026rsquo; 에 대한 실패는 아니다.\n그래서 입 밖으로 다음과 같이 말했다.\n\u0026ldquo;난 실패했네\u0026rdquo;\n\u0026ldquo;\u0026hellip;\u0026rdquo;\n\u0026ldquo;후우 다시 일어서면 되잖아. 다시 하자. 그래 다시하자.\u0026rdquo;\n\u0026ldquo;다시 도전하자.\u0026rdquo;\n그러면 2024년은 어떻게 보낼 건데? 확실하게 결과를 내자. 그래도 성급해하지 말자\nFastAPI는 해외에서는 모르겠지만, 한국에서는 아직도 많이 사용되고 있지 않다. Python을 주 개발로 하는 곳에서는 한국에서는 django가 아직까지 많다.\n하지만 django는 프로젝트 구조가 자유롭지 않아서 한계가 있지만 스타트업의 입장에서는 \u0026lsquo;생산성\u0026rsquo;이 압도적으로 중요해서 django를 많이 선호하는 편이다.\n아니면 java, spring으로 잡고 바꾸는 방법도 있을 것 같다.\n그러면 다음과 같이 정리할 수 있다.\n만들어둔 SNS 프로젝트를 배포 및 운영까지 하기 위 프로젝트 진행 시 겪은 문제과 개념들 블로깅 하기 금전적인 문제를 해결하기 위해 위 프로젝트에 광고 붙여보기 그리고 나서 4번을 실행해보자.\n프로젝트 아이디어 선정하기 단 중간 규모보다 작은 프로젝트여야 하고, 실제로 내가 필요하고 사용하기 위해 만든 프로젝트여야 하고, 또는 내가 외주를 받아 제작하는 프로젝트여야 하고, 프론트까지 확실하게 만들어야하는 프로젝트여야 한다. 4번까지 정해지고 나서 기술 스택을 고민해보자.\n\u0026ndash; 회고 끝 \u0026ndash;\n","permalink":"http://jeha00.github.io/post/memorior/2022_2023/","summary":"2022년부터 2023년까지의 일을 회고해보았다.","title":"2022 ~ 2023 동안 노력에 대한 회고"},{"categories":"Network","content":"네트워크 학습 내용 순서 [TIL]Web Application Basic study: OSI 7 layer outline [TIL] Network OSI 7 layer: 1계층 [TIL] Network OSI 7 layer: 2계층 [TIL] Network OSI 7 layer: 3계층 [TIL] Network OSI 7 layer: 4계층 이번 장에서는 OSI 7 계층에서 5, 6, 7 계층이며, TCP/IP model로는 제일 윗 계층인 application layer를 학습해본다.\n1. Application 응용 계층 개요 이번 장에서 학습하는 계층은 OSI 7 layer에서는 3개의 계층이지만, TCP/IP model 로는 한 개의 계층이다.\n3개의 계층이 묶여서 TCP/IP 모델에서 하나의 계층으로 표현되는 이유는 OSI 7 layer의 session layer, presentation layer, application layer가 대체로 하나로 묶여서 작동되는 경우가 많기 때문이다.\n그러면 먼저 OSI model을 기준으로 5, 6, 7계층의 역할을 각각 알아본 후, 하나로 엮어서 학습해보자.\nOSI model 기준 5, 6, 7 계층 7 계층 Application layer: HTTP/FTP/gRPC 실제 애플리케이션이 작동하는 layer로 서버 애플리케이션 또는 브라우저가 이에 해당된다.\n여기서 사용하는 프로토콜은 HTTP, FTP, gRPC가 이에 해당된다.\n6 계층 Presentation layer: Encoding, Serialization, Decoding, Deserialization \u0026lsquo;표현\u0026rsquo;이라는 단어의 의미와 연관지어서 생각해보면 데이터가 어떻게 \u0026lsquo;표현\u0026rsquo;되는지, 즉 어떠한 방식으로 인코딩되고 해석되는지를 관리하는 계층이다. 또한, 데이터의 압축이나 암호화가 이루어지는 계층이 이 표현 계층이다.\n이 계층의 예시로는 여러 언어에서 사용되는 json serialization library가 이 layer에 해당된다. 그래서 JSON을 byte strings으로 직렬화하거나, byte strings을 JSON으로 역직렬화하는 계층이다.\n5 계층 Session layer: Connection establishment, TLS Session layer는 어플리케이션 프로세스 간의 연결을 관리하고 통신 세션의 설정이나 관리 종료를 하는 역할을 한다. 그래서 데이터 교환의 시작과 끝을 정의한 후, 장애 발생 시 복구 매커니즘을 제공한다.\n그러면 여기서 궁금증이 있다. 여러 네트워크 책을 보면 응용 프로그램 내부에 \u0026lsquo;소켓 라이브러리\u0026rsquo; 같은 게 있어서 이 라이브러리를 통해 OS 내부의 프로토콜 스택을 호출하여 하위 계층으로 데이터를 전달하거나 하위 계층으로부터 데이터를 받는데, 이 과정이 세션 레이어에 해당되는 것일까?\n이 과정에서 통신 세션을 관리하게 되는데 필요에 따라 세션을 재개하거나 복구하는 역할을 바로 이 세션 레이어가 해준다.\n이처럼 응용 프로그램 레벨에서는 \u0026lsquo;소켓 프로그래밍\u0026rsquo;을 써서 데이터 전송을 시작하는데, 소켓은 네트워크 상에서 서버와 클라이언트가 서로 주고 받을 수 있게 하는 엔트포인트라고 생각하면 편하다. 이 계층의 역할을 수행하는 것은 OS kernel, file descriptor가 그 예시다.\n[프레임워크 내부에 내장되어 있는 소켓 라이브러리]\n그런데 생각해보자. 프레임 워크로 웹 개발을 통해 나는 \u0026lsquo;소켓 라이브러리\u0026rsquo;를 만든 적이 없다.\n그러면 어떻게 이뤄지는 것일까?\n대부분의 프로그래밍 언어나 프레임워크에서는 네트워크와 관련된 소켓 라이브러리가 내장되어 있다고 보면 된다.\npython에서는 socket 라이브러리가 있고, java에서는 \u0026lsquo;java.net.socket\u0026rsquo; 같은 것들이 네트워크 통신을 위한 api를 제공한다. 그래서 개발자가 소켓 기반의 네트워크 프로그램을 손 쉽게 개발할 수 있도록 도와준다.\nTCP/IP model 기준 application layer 그러면 이제 TCP/IP model을 기준으로 학습해보자.\n응용 계층은 애플리케이션에 대한 서비스를 제공하기 위해서 클라이언트가 요청한 서비스를 통신 대상인 서버가 인식하도록 데이터를 변환하는 계층이다.\n컴퓨터 사용자라면 여러 서비스를 사용하고 싶어하는데, 이를 위해서 각 서비스에 맞는 프로토콜들을 사용해야 원하는 서비스를 제공하는 서버와 통신할 수 있다.\n응용 계층에서의 주요 프로토콜 종류에는 DHCP, DNS, HTTP, SMTP, POP3, IMAP, SNMP, FTP 등이 있다.\nHTTP: 웹 사이트 접속 DNS: 주소 해석 SMTP: 메일 송신 POP3: 메일 수신 FTP: 파일 전송 DHCP IMAP SNMP 이 계층에서의 데이터 단위는 메시지 다.\n메시지 = 응용 헤더 + user data 2. DHCP (Dynamic Host Configuration Protocol) DHCP란? 컴퓨터의 IP 주소를 할당하는 방법에는 \u0026lsquo;정적 할당\u0026rsquo;과 \u0026lsquo;동적 할당\u0026rsquo; 이 있다.\n정적 할당: 수동 설정 동적 할당: 자동으로 주소를 할당하는 설정 여기서 동적 할당 방식에서 사용되는 프로토콜이 DHCP다. IP 주소, 서브넷 마스크, 기본 게이트웨이 등을 자동으로 설정하는 프로토콜 이다. 그래서 사용자가 직접 할당하지 않아도 된다.\nDHCP 동작 설명 임대 요청(DHCP DISCOVER) -\u0026gt; 임대 제공(DHCP OFFER) -\u0026gt; 임대 선택(DHCP REQUEST) -\u0026gt; 임태 확인(DHCP ACK)\nDHCP 동작은 위 4가지로 설명할 수 있다. 여기서 \u0026lsquo;임대\u0026rsquo;라는 단어에 집중하면 동작 방식 이해가 쉬울 것이다.\n이 또한 프로토콜이므로 DHCP 클라이언트와 서버가 존재한다.\n1) 임대 요청(DHCP DISCOVER) IP 주소를 할당하기 전이기 때문에 IP 주소는 0.0.0.0 이다. 그리고 목적지 IP 주소는 255.255.255.255인데, 그 이유는 DHCP는 브로드캐스트 방식을 사용하기 때문이다.\n2) 임대 제공(DHCP OFFER) 그래서 이 임대 요청을 받은 DHCP 서버는 TCP/IP 설정을 응답으로 보낸다.\nIP 주소, 임대 기간, 서브넷 마스크 DNS 주소 등이 포함된다.\n그리고 브로드캐스트 방식으로 보낸다고 했는데, 여러 개의 DHCP 서버에게 응답이 왔다면 가장 먼저 도착한 응답 메시지를 선택한다.\n3) 임대 선택(DHCP REQUEST) 응답을 받은 DHCP 클라이언트는 이 설정을 사용하게 해달라는 요청을 보낸다.\n4) 임대 확인(DHCP ACK) DHCP 서버가 확인 응답을 보내면서 IP 주소 동적 할당 과정이 종료된다.\n즉 위 4단계를 거쳐서 주소를 임대해주는 역할을 한다.\n3. DNS (Domain Name Service) 도메인 이름과 IP 주소를 모두 사용하는 이유 평소 url 창에 주소를 입력할 때 우리는 숫자가 아니라 알파벳으로 구성되는 \u0026lsquo;도메인 이름\u0026rsquo;을 입력하여 이동한다.\n\u0026lsquo;도메인 이름\u0026rsquo; 이란 IP 주소에 매핑되는 텍스트 문자열을 말한다.\n컴퓨터는 숫자가 친숙하지만 도메인 이름을 사용하는 이유는 사람에게 더 친숙하고 기억을 잘할 수 있는 방식이기 때문이다. 그러면 차라리 IP 주소 보다 이름으로 기억하면 더 좋지 않냐라는 생각을 할 수 있지만, IP 주소는 32bit 즉, 4 byte에 해당하는 갯수 밖에 없지만, 도메인 명은 최대 255 byte까지의 문자를 취급해야하기 때문에 그러면 그만큼 라우터가 부하되어 데이터 운반 동작에 시간이 더 걸려서 네트워크 속도가 느려진다.\nName resolution (이름 해석) 그래서 DNS를 통해 도메인 이름을 기반으로 IP 주소를 알아내는 name resolution(이름 해석) 이 필요하다.\n그러면 웹 브라우저에 네이버 주소를 입력하면 \u0026lsquo;이름 해석\u0026rsquo; 과정이 어떻게 이뤄질까?\n웹 브라우저 url 창에 네이버 주소를 입력하면 이 네이버 주소에 해당하는 IP 주소를 DNS에 요청한다.\nDNS에서 웹 브라우저에게 네이버 주소에 해당하는 IP 주소를 알려준다.\n웹 브라우저는 DNS에서 받은 IP 주소로 접속한다.\n이 3가지 과정이 일어나서 네이버로 이동한다.\n정방향 조회와 역방향 조회 위와 같이 도메인 이름을 통해서 IP 주소를 조회하는 방식을 정방향 조회 라고 하고, 반대로 IP 주소를 통해서 도메인 이름을 얻는 방식을 역방향 조회 라고 한다. 일반적으로는 \u0026lsquo;정방향 조회\u0026rsquo;를 대부분 사용한다.\nDNS 계층 구조 DNS는 호스트를 식별하고 관리하기 위해서 domain name space(도메인 네임 공간)라는 계층 구조를 가진다. 이 계층 구조는 다음과 같이 트리형 이므로 여러 층 개념을 가진다. 그리고 이 계층은 DNS의 . 들이 계층을 구분한다. 예를 들어서 www.lab.cyber.com 이라고 하면 com 이라는 도메인 아래에 cyber 라는 도메인이 있고, 그 아래에 lab 이라는 도메인이 있다. 이 lab 도메인 안에 www 라는 도메인이 있는 것이다. 이처럼 계층적 구조를 가진다.\nTLD, SLD 그리고 Sub domain 맨 위 층에 최상위 도메인은 Top Level Domain(TLD) 이라 부른다. \u0026lsquo;TLD\u0026rsquo; 바로 밑에는 SLD(Second Level Domain) 이라 하여 \u0026lsquo;2차 도메인\u0026rsquo; 이라 한다. 그 아래부터는 sub domain 이라 칭한다.\n국가 도메인과 일반 도메인 국가마다 가지고 있는 고유의 도메인이 존재한다. 이 도메인을 \u0026lsquo;국가 도메인\u0026rsquo;이라 하며 다음과 같이 구성되어 있다. 국가 코드 최상위 도메인을 확인하면 알 수 있다. 그래서 위 이미지에 \u0026lsquo;kr\u0026rsquo;은 국가 도메인에 속함을 알 수 있다.\n이외에도 국가 기관이 아닌 일반 플랫폼들은 \u0026lsquo;일반 도메인\u0026rsquo;에 속한다.\n반복적 쿼리와 재귀적 쿼리 \u0026lsquo;이름 해석\u0026rsquo; 단계가 총 3단계인 것으로 확인했다. 그러면 트리 구조로 된 DNS가 어떻게 IP 주소를 알려줄 수 있는 것일까?!\nIP 주소를 알기 위해서 DNS client가 DNS 서버에 질의를 보낸다. 질의 방식에는 \u0026lsquo;재귀적 질의\u0026rsquo; 와 \u0026lsquo;반복적 질의\u0026rsquo;가 있다.\n반복적 질의 local DNS 서버가 다른 DNS 서버에게 쿼리를 보내어, 쿼리를 받은 DNS 서버가 자신이 직접 관리하지 않는 질의 요청일 경우, 질의에 응답 가능한 DNS 서버 IP 주소 목록을 응답하는 방식\n브라우저의 url 창에 www.lab.glasscom.com 을 입력하여 로컬 DNS 서버에 먼저 질의 로컬 dns server란 가장 가까운 dns 서버를 의미 로컬 DNS 서버에서 모를 경우, Root DNS 서버에 질의한다. (www.lab.glasscom.com의 IP 주소는?) 그러면 Root DNS 서버에서 com 의 IP 주소를 로컬 DNS 서버에 응답한다.\n로컬 DNS 서버는 com TLD DNS 서버에 동일하게 질의한다. 그러면 com TLD DNS 서버에서 glasscom의 IP 주소를 로컬 DNS 서버에 응답한다.\n로컬 DNS 서버는 glasscom DNS 서버에 동일하게 질의한다. 그러면 glasscom DNS 서버에서 lab의 IP 주소를 로컬 DNS 서버에 응답한다.\n로컬 DNS 서버는 lab DNS 서버에 동일하게 질의한다. 그러면 lab DNS 서버에서는 www.lab.glasscom.com의 IP 주소를 로컬 DNS 서버에 응답한다.\n로컬 DNS 서버는 클라이언트에게 10번에서 얻은 IP 주소를 전달\n출처: 성공과 실패를 결정하는 1%의 네트워크 원리에서 그림 1-16 재귀적 쿼리 반복적 쿼리와 달리 local DNS 서버가 아닌 상위 DNS 서버가 직접 하위 DNS 서버를 탐색하여 결과값을 반환한다.\n재귀적 질의 동작은 다음과 같다.\n클라이언트가 로컬 DNS 서버를 통해 루트 DNS 서버에 요청\n루트 DNS 서버에서 해당 도메인 이름이 등록되어 있는지 확인한다.\n루트 DNS 서버에서 바로 해당되는 TLD 서버에 질의한다.\n3번의 TLD 서버에서 가장 가까운 서브 도메인 서버에 질의한다.\n이렇게 계속 더 하위 계층으로 질의하여 진행되며, 최종적으로 원하는 IP를 얻을 경우 왔던 계층들로 다시 올라가서 루트 DNS 서버에서 로컬 DNS 서버에게 최종적으로 구한 IP 주소를 보낸다.\n로컬 DNS 서버가 클라이언트에게 이 IP 주소를 전달한다.\n4. HTTP 그러면 HTTP에 대해 간략히 알아보자. HTTP는 Hyper Text Transfer Protocol의 약어로, 웹에서 Hyper Text 문서를 요청하고 응답하기 위한 프로토콜이다. Hyper Text 문서라 함은 HTML(Hyper Text Markup Language)로 작성된 웹 문서를 말한다. 그래서 HTTP 요청과 응답을 주고 받으며 웹 사이트를 구성하는 HTML 파일을 전송한다. 이 때 사용하는 포트 번호는 80번이다.\nHTTP를 사용하기 위해서는 웹 url을 입력해야 한다. 이 url 구성은 간략하게 보자면 다음과 같다.\n예를 들어 https://www.inflearn.com/roadmaps을 입력한다고 하자.\nhttps: 어떤 프로토콜을 사용하는지 www.inflearn.com: 호스트 이름을 의미하며, 어떤 웹 서버를 필요로 하는지 나타낸다 roadmaps: 경로명 그리고 HTML 문서는 HTTP request와 response를 통해 보내지므로 HTTP request와 response에 대해 알아보자.\nHTTP request 는 request line, message header, entity body 등의 부분으로 나눠지는데, 여기서 request line에 대해서 보자면 다음과 같다.\nrequest line = 사용되는 메서드 + URL + HTTP 버전 메시지 헤더: 키 - 값 형식으로 여러 정보가 담겨져 있음 HTTP response 는 response line, message header, entity body 등으로 나눠지는데, 여기서 response line에 대해서 보자면 다음과 같다.\nresponse line = HTTP 버전 + 상태 코드 + 상태 메세지 상태 코드: 웹 서버의 처리 결과를 나타낸 세 자리 숫자 더 상세한 HTTP 내용은 Network에서 확인해보자.\n5. 쿠키 웹서버 애플리케이션에서 웹브라우저에 특정 정보를 저장해두는 기술\n이 HTTP 쿠키를 이용하여 특정 사이트에 접속할 때 로그인 정보, 웹페이지 열람 이력, 쇼핑몰 상품 열람 기록, 장바구니 정보 등을 기록할 수 있다.\n쿠키가 동작하는 과정은 다음과 같다.\n브라우저의 요청에 대해 웹 서버에서 HTTP 응답을 보낼 때 쿠키를 포함하여 보낸다. 이 때 쿠키 정보는 HTTP Set-Cookie header에 포함된다. 웹브라우저에 쿠키를 받을 수 있도록 허용된 상태라면 쿠키를 저장한다. 이후에 HTTP request를 보낼 때 쿠키 정보도 함께 보내진다. 6. 프록시 서버 (Proxy server) Proxy(프록시)는 \u0026lsquo;대리인\u0026rsquo;, \u0026lsquo;대리자\u0026rsquo;라는 의미를 가진 용어로 proxy server는 의미 그대로 웹 서버 접속을 \u0026lsquo;대신\u0026rsquo; 해주는 서버를 말한다. 그렇다면 왜 대리를 둬야할까?\n프록시 서버를 두는 이유를 이해하기 위해 먼저 프록시 서버가 있는 웹 브라우저와 웹 서버의 흐름을 파악해보자.\n프록시 서버는 웹 브라우저와 웹 서버 사이에 존재한다. 그래서 웹 브라우저가 웹 서버에 요청하면 먼저 프록시 서버가 이를 받는데, 이 때 포트번호도 프록시 서버의 포트 번호로 설정해야 한다. 주로 프록시 서버의 포트 번호는 \u0026lsquo;8080\u0026rsquo; 이다. 요청을 받은 프록시 서버는 웹 서버 포트 번호로 웹 서버에게 이 요청을 전달한다. 이 요청에 대한 응답으로 서버에서 응답을 보내면 프록시 서버가 먼저 이 응답을 받은 후, 웹 브라우저에 전달한다.\n이렇게 프록시 서버는 웹 브라우저와 웹 서버 중간에 위치하기 때문에, 기업에서는 \u0026lsquo;감시\u0026rsquo; 하기 위해 둔다. 직원이 업무 시간 도중 업무와 무관한 내용으로 구글을 검색하거나, 유튜브에 들어가는 짓을 확인할 수 있다. 또 다른 이유로는 프록시 서버를 통해 유해 사이트에 접속하는 것을 제한할 수 있다. 이를 \u0026lsquo;URL 필터링\u0026rsquo; 혹은 \u0026lsquo;웹 필터링\u0026rsquo;이라 한다.\n7. 네트워크 실습 DNS server DNS(Domain Name System)이란? 웹 사이트의 IP 주소와 도메인 주소를 이어주는 시스템\n터미널을 열어서 nslookup www.naver.com을 입력해보자.\nNon-authoritative answer: 아래 항목들 중에서 Address를 보면 www.naver.com의 IP 주소를 확인할 수 있다. Address: 223.130.200.104 를 입력하면 네이버로 이동할 것이다. url을 입력하면 DNS server에서 이 url에 해당되는 IP 주소를 보내주고, 이 IP 주소로 입력되어 해당 서버에 요청하여 화면에 보여지는 것\n맥에서 DNS 확인 cat /etc/hosts을 입력\n위 명령어를 입력하면 아래창을 확인할 수 있다. 1 2 3 127.0.0.1 localhost 255.255.255.255 broadcasthost ::1 localhost 127.0.0.1은 localhost다. broadcasthost 는 255.255.255.255 다. DNS에다가 추가하고 싶은 IP 주소를 추가할 수 있다는 것 Reference 나노디그리 러닝스푼즈: Python \u0026amp; Django backend course 네트워크, 그림으로 이해해자 성공과 실패를 결정하는 1%의 네트워크 원리 ","permalink":"http://jeha00.github.io/post/network/osi_7_layer/5-7_layer/","summary":"OSI 7 layer의 5, 6, 7계층에 대해 알아보자.","title":"[TIL]OSI 7 layer: 5 ~ 7계층"},{"categories":"Network","content":"네트워크 학습 내용 순서 [TIL]Web Application Basic study: OSI 7 layer outline [TIL] Network OSI 7 layer: 1계층 [TIL] Network OSI 7 layer: 2계층 [TIL] Network OSI 7 layer: 3계층 이번 장에서는 전송(Transport) 계층인 4계층에 대해 알아보자.\n❗️ 패킷(packet)이란 용어에 대해서\n패킷이란 용어는 3계층의 데이터 단위임을 학습했다. 하지만 이 \u0026lsquo;패킷\u0026rsquo;이란 용어는 네트워크 전체적으로 데이터를 지칭하는 용어로도 사용되기도 한다. 그래서 이번 4계층 학습에서 언급되는 패킷들은 세그먼트가 맞지만, 3계층에서 IP 패킷으로 캡슐화되기 때문이거나 범용적으로 데이터를 나타내는 용어라고 생각하자.\n1. Transport 전송 계층 개요 3계층은 한 네트워크에서 다른 네트워크로 데이터를 전송하는 과정에 중점을 두고 맞춰져있다. 그러나, 네트워크 환경은 기본적으로 비신뢰성 환경이기 때문에 전송된 패킷이 정상적응로 전달되지 않을 수도 있고, 중간이 패킷이 유실되거나 손실될 수도 있다. 또한, 여러 패킷으로 나눠서 전달될 때 순서가 잘못될 수도 있다.\n이에 대한 해결책으로 4계층은 목적지에 신뢰할 수 있는 데이터를 전송할 수 있는가? 에 초점을 맞춘다. 이에 따라 역할, 전송방식이 정해진다.\n1) 4계층의 역할 목적지까지 신뢰할 수 있는 데이터를 전송하는 역할 오류 점검 및 데이터의 목적지가 어떤 애플리케이션인지 식별하는 역할 2) 4계층의 전송 방식 위 역할에 따랏 4계층의 전송 방식은 \u0026lsquo;연결형 통신\u0026rsquo; 과 \u0026lsquo;비연결형 통신\u0026rsquo; 2가지로 나눠진다.\n연결형 통신\n신뢰성과 정확성 연결 필요 사용되는 프로토콜: TCP (Transmission Control Protocol) stateful 비연결형 통신\n효율성: 빠르게 일방적인 통신 (연결 불필요) 사용되는 프로토콜: UDP ex) 동영상 스트리핑 서비스 stateless 3) 4계층의 캡슐화, 역캡슐화 그리고 데이터 단위 4계층은 TCP 헤더 의 캡슐화, 역캡슐화가 일어나는 계층으로 이 때 데이터 단위는 segment(세그먼트) 다.\nTCP header + Application header + User data ❗️ 다시 한번 언급: 패킷(packet)이란 용어에 대해서\n패킷이란 용어는 3계층의 데이터 단위임을 학습했다. 하지만 이 \u0026lsquo;패킷\u0026rsquo;이란 용어는 네트워크 전체적으로 데이터를 지칭하는 용어로도 사용되기도 한다. 그래서 이번 4계층 학습에서 언급되는 패킷들은 \u0026lsquo;세그먼트\u0026rsquo;가 맞지만, 3계층에서 IP 패킷으로 캡슐화되기 때문이거나 범용적으로 데이터를 나타내는 용어라고 생각하자.\n2. TCP segment TCP segment는 응용 계층의 데이터에서 TCP 헤더를 캡슐화하거나, 네트워크 계층의 패킷에서 IP 헤더를 역캡슐화를 하면 되는 데이터 단위다.\n이 TCP 헤더에는 여러 정보들이 담겨있지만 주요 필드만을 언급하자면 다음과 같다.\n출발지 포트 번호, 목적지 포트 번호 일련 번호, 확인 응답 번호 TCP 플래그, 윈도우 크기 더 자세한 필드는 다음과 같다.\n출발지 포트 번호 (16 bit), 목적지 포트 번호 (16 bit) 일련 번호(sequence number) (32 bit) 송신자가 지정하는 순서 번호 고유한 번호 확인 응답 번호(acknowledgement number) (32 bit) 데이터를 정상적으로 수신했을 시 보내는 번호 일련 번호에 1을 더한 값이므로, 다음 데이터의 일련 번호라고도 볼 수 있다. 일련 번호 + 1 헤더 길이(header length) (4 bit) 옵션 필드가 가변적이라서 정확히 헤더의 길이를 파악하기 위해 사용 예약 영역 (6 bit) 나중에 사용하기 위해 남겨둔 영역 TCP 플래그 (코드 비트) (6 bit) 6개 비트로 구성: SYN, ACK, FIN, URG, PSH, RST 3 way handshake와 4 way handshake 와 관련 윈도우 크기(window size) (16 bit) 한 번에 전송할 수 있는 데이터의 양 TCP 흐름 제어와 관련 체크섬(checksum) (16 bit) 데이터를 보내는 중에 발생할 수 잇는 에러를 항상 검사하는데, 데이터에 대해 체크섬 방식으로 계산한 결과값을 이 필드에 저장 긴급 포인터(urgent pointer) (16 bit) TCP 플래그의 코드 비트 URG 비트 설정과 함께 사용 TCP 옵션 ❗️ IP 헤더는 포트 번호가 아닌 \u0026lsquo;출발지/목적지 IP 주소\u0026rsquo; 였던 것을 기억하자.\n3. 3-way handshake \u0026amp; 4-way handshake 3.1 TCP flag (code bit) 위 2개의 handshake 는 TCP 헤더의 TCP flag 코드 비트 와 관련있다.\nTCP의 연결 확립 과정과 연결 종료 과정에서 TCP flag 코드 비트가 중요한 역할을 한다.\n그러면 코드 비트에 대해 자세히 확인해보면 다음과 같이 6 bit가 존재한다.\nURG ACK PSH RST SYN FIN 0 0 0 0 0 0 각 1bit를 의미한다. 각 초기 비트 값은 0이며 각 과정에서 활성화되어 1로 바뀌어 전송된다.\n그리고 각 단어는 다음 의미를 가진다.\nURG: Urgent\nACK: Acknowledgement\nPSH: Push\nRST: Reset\nSYN: Synchronize\nFIN: Finish\n3.2 3-way handshake TCP는 연결을 확립하기 위해 3-way handshake 과정을 거친다. 이 때 SYN, ACK 두 비트를 사용한다.\n이 과정의 총 세 단계 순서는 다음과 같다.\n상황: 클라이언트와 서버가 존재하고, 클라이언트가 서버에 \u0026lsquo;세션 연결 확립\u0026rsquo;을 위해 요청을 보내려는 상황\n1) 연결 요청 - client \u0026ndash;\u0026gt; server with SYN: 1 클라이언트가 서버에게 연결 확립을 요청한다. 이 때 SYN이 1로 활성화된 세그먼트를 서버에 전송한다.\nURG ACK PSH RST SYN FIN 0 0 0 0 1 0 2) 확인 및 연결 요청 - client \u0026lt;\u0026ndash; server with SYN: 1, ACK: 1 클라이언트가 보낸 세그먼트를 서버가 확인하면서 서버에서도 연결을 요청하기 위해 SYN과 ACK bit가 1로 활성화된 세그먼트를 클라이언트에게 보낸다.\nURG ACK PSH RST SYN FIN 0 1 0 0 1 0 3) 확인 - client \u0026ndash;\u0026gt; server with ACK: 1 서버가 보낸 세그먼트를 클라이언트가 확인하고, 이에 응답하기 위해 ACK bit가 1로 활성화된 세그먼트를 서버에게 보낸다.\nURG ACK PSH RST SYN FIN 0 1 0 0 0 0 3.3 4-way handshake TCP는 연결을 종료하기 위해 4-way handshake 과정을 거친다. 이 때 FIN, ACK 두 비트를 사용한다.\n상황: 클라이언트와 서버 간 연결을 종료하기 위해 요청을 보내려는 상황\n1) 연결 종료 - client \u0026ndash;\u0026gt; server with FIN: 1 클라이언트가 서버에게 연결 종료를 요청한다. 이 때 FIN이 1로 활성화된 세그먼트를 전송한다.\nURG ACK PSH RST SYN FIN 0 0 0 0 0 1 2) 확인 - client \u0026lt;\u0026ndash; server with ACK: 1 서버는 클라이언트에게 연결 종료에 대한 응답을 하기 위해 ACK이 1로 활성화된 세그먼트를 전송한다.\nURG ACK PSH RST SYN FIN 0 1 0 0 0 0 3) 연결 종료 - client \u0026lt;\u0026ndash; server with FIN: 1 서버도 클라이언트에게 연결 종료를 요청한다. 이 때 FIN이 1로 활성화된 세그먼트를 전송한다.\nURG ACK PSH RST SYN FIN 0 0 0 0 0 1 4) 확인 - client \u0026ndash;\u0026gt; server with ACK: 1 클라이언트는 서버에게 연결 종료에 대한 응답을 하기 위해 ACK이 1로 활성화된 세그먼트를 전송한다.\nURG ACK PSH RST SYN FIN 0 1 0 0 0 0 3.5 handshake의 캡슐화와 역캡슐화 handshake 과정도 캡슐화와 역캡슐화가 진행된다.\n3-way handshake A 컴퓨터와 B 컴퓨터의 3-way handshake 과정을 들어보자.\nA 컴퓨터에서 \u0026lsquo;캡슐화\u0026rsquo;를 통해 SYN 비트가 1로 활성화된 데이터를 \u0026lsquo;전송\u0026rsquo;\nB 컴퓨터에서 \u0026lsquo;역캡슐화\u0026rsquo;를 통해 SYN 비트가 1로 활성화된 데이터를 받았음을 \u0026lsquo;확인\u0026rsquo;\nB 컴퓨터에서 \u0026lsquo;캡슐화\u0026rsquo;를 통해 다른 세그먼트로 SYN 비트 + ACK 비트가 1로 활성화된 데이터를 \u0026lsquo;전송\u0026rsquo;\nA 컴퓨터에서 \u0026lsquo;역캡슐화\u0026rsquo;를 통해 SYN 비트 + ACK 비트가 1로 활성화된 데이터를 받았음을 \u0026lsquo;확인\u0026rsquo;\nA 컴퓨터는 \u0026lsquo;캡슐화\u0026rsquo;를 통해 마지막으로 ACK 비트가 1로 활성화된 데이터를 \u0026lsquo;전송\u0026rsquo;\n4-way handshake A 컴퓨터와 B 컴퓨터의 4-way handshake 과정을 들어보자.\nA 컴퓨터에서 \u0026lsquo;캡슐화\u0026rsquo;를 통해 FIN 비트가 1로 활성화된 데이터를 \u0026lsquo;전송\u0026rsquo;\nB 컴퓨터에서 \u0026lsquo;역캡슐화\u0026rsquo;를 통해 FIN 비트가 1로 활성화된 데이터를 받았음을 \u0026lsquo;확인\u0026rsquo;\nB 컴퓨터에서 \u0026lsquo;캡슐화\u0026rsquo;를 통해 FIN 비트가 1로 활성화된 데이터를 \u0026lsquo;전송\u0026rsquo;\nA 컴퓨터에서 \u0026lsquo;역캡슐화\u0026rsquo;를 통해 FIN 비트가 1로 활성화된 데이터를 \u0026lsquo;확인\u0026rsquo;\n이 과정 뿐만 아니라 컴퓨터의 모든 데이터는 전송할 때 캡슐화해서 전송하고, 받은 데이터를 뜯어볼 때는 역캡슐화한다고 보면 된다.\n🔆 나중에 wireshark 프로그램을 다운로드 받으신 후 패킷 분석을 해보자.\n4. TCP 에러 제어 에러 제어 개요 TCP는 전송된 세그먼트가 손실되거나 순서가 어긋났을 때 혹은 중복되었을 경우, 이에 대한 처리를 수행하는데 그 중 하나의 방법이 TCP 에러 제어 다. 이 제어를 통해 신뢰성 있는 데이터를 전송한다.\n에러 제어는 에러를 검출(detection)한 후, 에러를 정정(correction)하는 과정을 거친다. 에러 검출과 에러 정정 과정에는 다음과 같은 방법들이 존재한다.\n에러 제어 에러 검출(detection) CRC (Cyclic Redundancy Check) Checksum(체크섬): TCP 헤더의 체크섬 필드가 데이터에 대한 에러를 검사하는 기능이 있어, 세그먼트가 전송되는 도중 에러 발생 유무를 확인 에러 정정(correction): ARQ(Automatic Repeat reQuest) 방식을 사용하며, 이 방식의 종류는 다음과 같다. Stop and Wait ARQ Go-Back-N ARQ Selective Repeat ARQ 그러면 에러 정정 방법들에 대해 자세히 알아보자.\n에러 정정: Stop-and-Wait ARQ 매번 전송한 패킷에 대해 확인 응답을 받고 나서 그 다음 패킷을 전송하는 방식이다. 만약 일정 시간 동안 ACK을 받지 못하여 Timeout이 되었을 경우, 해당 패킷부터 재전송한다. 또한, 패킷 간 식별을 위해 0과 1의 패킷 혹은 ACK를 번걸아 가면서 전송한다.\n확인 응답을 받을 때까지 멈춰서 기다리는 방식이기 때문에 비효율적이다.\n위 그림을 기준으로 설명하자면 1, 2, 3번 패킷으로 구분되는 것이 아니라 0, 1, 0, 1번으로 구분된다.\n에러 정정: Go-Back-N ARQ 패킷이 도착하지 않아 타임아웃되었을 시, 이 패킷부터 다시 차례대로 재전송하는 방식이다.\n위 그림을 통해서 구체적인 예시를 들어보자.\nA 에서 패킷 0번, 1번, 2번 패킷을 전송한다. 이중 1번을 제외한 패킷들을 수신했다. 수신한 패킷에 대해 ACK을 보내는데 1번 패킷을 받지 못 했으므로, 그 이후에 2번, 3번 패킷을 B가 받아도 받은 패킷을 폐기한 후, 0번 ACK을 B가 재전송한다. 1번 패킷에 대한 확인 응답 ACK이 도착하지 않아 타임아웃되어 A가 패킷을 재전송할 때 다시 순서대로 1번 패킷, 2번 패킷, 3번 패킷을 보낸다.\n이처럼 뒤로 돌아가서 순서대로 다시 재전송하는 방식을 Go-Back-N 재전송 방식이다.\n에러 정정: Selective Repeat ARQ 패킷이 도착하지 않아 타임아웃되었을 시 수신하지 못한 패킷만을 선택적으로 재전송하는 방식이다.\n수신한 패킷에 대해 선택적으로 ACK 전송이 가능하며, 선택적 전송이 가능한 이유는 중간 패킷이 수신되지 못했을 경우 소실된 패킷 이후 패킷을 버퍼에 기록하기 때문이다. 소실된 패킷에 대한 확인 응답이 A에게 도착하지 않아 타임아웃되면 A에서 소실된 패킷이 재전송된다.\n소실된 패킷이 도착되면 소실된 패킷과 그 이후에 보내진 패킷들을 함께 상위계층으로 올린다.\n위 그림을 기준으로 설명해보자.\nA에서 초기에 0번, 1번, 2번 패킷이 전송된다. B에 정상적으로 도착한 건 1번 패킷을 제외한 나머지다. B에서는 수신한 패킷에 대해 선택적 ACK을 전송한다. 1번 패킷을 받지 못 했으므로, 1번 패킷 이후의 패킷은 버퍼에 저장된다. A에서는 이어서 3번, 4번 패킷이 전송된다. B에 정상적으로 도착했고, 이를 버퍼에 저장한다. 그리고, 이에 대해 선택적 ACK인 3번 ACK, 4번 ACK을 전송한다. 1번 패킷에 대한 확인응답이 A에게 도착하지 않아 타임아웃되면 A에서는 1번 패킷을 재전송한다. B에서는 이에 대한 1번 ACK을 전송하여 A는 확인응답을 받는다. B는 1번 패킷과 함께 버퍼에 저장된 2번, 3번, 4번 패킷을 상위 계층에 전송한다. 5. TCP 흐름 제어(TCP Flow Control) 송수신지의 데이터 처리 능력이 달라서 데이터가 유실될 수가 있는데 이를 방지하는 기법이다.\n흐름 제어 기법에는 두 가지 방법이 있지만, 주로 슬라이딩 윈도우 기법을 사용한다.\nStop-and-Wait 슬라이딩 윈도우(Sliding window): 윈도우 광고 기법 Stop-and-Wait Stop-and-Wait은 \u0026lsquo;TCP 에러 제어 챕터\u0026rsquo; 에서 설명한 것처럼 모든 패킷에 대해 확인 응답을 받아야만 다음 패킷을 전송하는 방식이기 때문에 비효율적이라는 단점이 있다.\nSliding window 반면 슬라이딩 윈도우는 송수신지에 있는 슬라이딩 윈도우 를 활용하는 방식으로 Stop-and-wait 방식과 달리 송신측에서 응답을 받지 않아도 연속적으로 전송할 수 있다. 단지 연속적으로 전송하는 게 아니라 송수신측의 윈도우 크기를 서로 알려주기 때문에 데이터 유실을 방지할 수 있는 방식이다.\n즉 슬라이딩 윈도우 방식은 수신측과 송신측의 윈도우 크기를 서로 알리면서 윈도우 크기가 변한다. 먼저 윈도우 에 대해 알아보자면 송수신 각 측에서 만들어진 버퍼의 크기를 말한다.\n송신측 윈도우: Congestion window로, \u0026lsquo;Cwnd\u0026rsquo; 라고 표기 수신측 윈도우: Receiver window로 \u0026lsquo;Rwnd\u0026rsquo; 라고 표기 그러면 슬라이딩 윈도우 기법을 통한 TCP 흐름 제어를 살펴보자.\n위 이미지와 아래 설명을 함께 보자.\n송수신측의 윈도우 크기 모두 250이라 가정해보자.\n(0 - 250) 송신지(A)에서 100 바이트 데이터를 수신측(B)에 보낸다.\nB에서는 이 데이터를 받아 버퍼에 저장했기 때문에, 수신측 윈도우 크기는 250에서 \u0026lsquo;150\u0026rsquo;이 된다. 그리고 좌측 윈도우 경계선은 101로 이동된다. (101 - 250)\n그리고, B에서 확인 응답으로 \u0026lsquo;ACK 101\u0026rsquo; 과 수신측의 현재 윈도우 크기 150을 보낸다.\n101인 이유는 100바이트 데이터를 수신했기 때문에 그 다음 시퀀스 번호를 나타내기 위해서다. A에서 이 정보를 받아 동일하게 101부터 시작해서 윈도우 크기를 150에 맞추고, 시작 경계선을 101로 맞춘다. 송신지 윈도우의 크기는 수신지 윈도우 크기에 맞춰서 수신측이 받을 수 있도록 크기를 맞춘다. 맞춘 후, A에서 다시 B에게 50 바이트를 전송한다.\nB에서 50 바이트 데이터를 버퍼에 저장한다. 윈도우 크기는 100으로 줄어들고, 좌측 윈도우 경계선이 151로 이동된다. (151 - 250)\n하지만 응용 프로세스가 B의 윈도우에 저장된 50 바이트 데이터를 처리하여 윈도우는 (151 - 300) 으로 이동되어 윈도우 크기는 150으로 늘어난다.\n이 때 응용 프로세스가 저장된 데이터를 사용할 때 FIFO 방식으로 처리하기도 하지만, 마지막으로 받은 데이터를 처리하기도 하므로 처리되는 데이터의 순서는 때에 따라 다르다. B에서 A에게 확인 응답 ACK 151 과 window 크기는 150이라는 정보를 전달한다.\nB에서 보내진 정보를 A가 받아 B 윈도우 크기에 맞춰 A도 수정한다.\n위와 같은 작업 방식으로 진행된다.\n6. TCP 혼잡 제어 TCP 혼잡 제어는 네트워크 내의 데이터를 조절하여 오버플로우(overflow) 현상을 방지하는 기술 이다. 보다 구체적으로 얘기하자면 다음과 같다.\n네트워크는 항상 잔잔한 상태가 아니다. 때로는 데이터의 수가 과도하게 증가하기도 하고, 데이터가 유실되기도 한다. 이런 상황을 혼잡 상황 이라 하는데, TCP는 이 혼잡 상황을 방지하거나 해결하는 제어 기능을 제공한다.\n혼잡 상황이 발생하기 전과 후에 따라 제어 방식이 각각 다르다.\n혼잡 상황 발생 전 제어 방식: 혼잡 회피 Slow Start Additive Increase 혼잡 상황 발생 후 제어 방식: 혼잡 상황 해결 Multiplicative Decrease: ssthresh 값을 cwnd 1/2로 축소 TCP가 혼잡 상황으로 인식하는 경우 TCP가 어떤 기준으로 \u0026lsquo;혼잡 상황\u0026rsquo;을 인식하냐면 다음과 같이 2가지 경우에 \u0026lsquo;혼잡 상황\u0026rsquo;으로 인식한다.\n세그먼트를 송신하고 타임아웃되어 재전송하는 경우 동일한 ACK을 3번 이상 수신하는 경우 1. 세그먼트를 송신하고 타임아웃되어 재전송하는 경우 TCP는 segment들을 slow start 방식으로 하나씩 전송한다. 이 때 cwnd의 값은 1이다.\n전송하기 시작할 때 cwnd의 값은 1이며, 1, 2, 4, 8 식으로 윈도우의 값을 지수적 증가 방식으로 윈도우 크기를 늘려 점점 세그먼트 수용량의 임계치를 늘려간다. (지수 그래프를 생각하자)\n이 때 임계값은 Slow Styled Threshold, SSThresh 라는 단어를 사용한다. 그래서 SSThresh = 1, 2, 4, 8, 16 으로 임계치를 늘려간다. cwnd가 점점 높아지면서 송신지가 설정한 임계값에 도달하여 혼잡 상황으로 갈 위험이 높다고 TCP가 판단하면 \u0026lsquo;Additive Increase\u0026rsquo; 기법을 적용한다. Additive Increase 기법은 cwnd를 하나씩 증가하면서 혼잡을 회피하는 방식 이 방식을 사용하다가 결국 혼잡 상황을 감지하면 cwnd를 다시 1로 수정하고, 송신지가 설정한 임계값의 수치를 혼잡이 감지된 SSThresh 값의 절반으로 설정한다. 즉, Multiplicative Decrease을 적용한다.\n다시 Slow Start와 Additive Increase 방식을 적용한다.\n❗️ RTT(Round Trip Time): 네트워크 요청을 시작한 후 응답을 받는데 걸리는 시간\n2. 동일한 ACK을 3번 이상 수신하는 경우 이 상황에서는 Multiplicative Decrease을 적용한다.\n이후에는 Additive Increase 방식으로 slow start는 안하고, Additive Increase(혼접 회피)만 수행한다. 즉 cwnd가 지수적 증가를 하지 않는다.\n7. 포트 번호 전송 계층(transport layer)는 연결 확립을 하고, 재전송도 가능하고, 버퍼를 통한 제어도 가능한 계층이다. 이 외에도 보내지는 데이터가 어느 어플리케이션에게 가야하는지 구분하는 기능도 가진다.\n포트 번호가 바로 데이터의 목적지가 어떤 어플리케이션인지 구분 하는 기능 을 가진다. 네트워크 계층인 3계층에서는 데이터를 전송하기 위해서 상대방의 IP 주소를 필요로 했다면 전송 계층의 포트 번호는 어떤 애플리케이션이 사용되고 있는지 구분해주는 역할을 한다.\n3계층인 네트워크 계층에서의 IP 헤더에는 출발지 IP 주소와 목적지 IP 주소가 있다. 그리고 현재 학습 중인 4계층인 전송 계층에서의 헤더에는 \u0026lsquo;출발지 포트 번호\u0026rsquo; 와 \u0026lsquo;목적지 포트 번호\u0026rsquo; 정보를 가진다.\n그러면 미리 알아두면 좋은 포트 번호에 대해 정리해보자.\n애플리케이션 포트 번호 설명 SSH 22 파일전송 TELNET 23 파일 전송 SMTP 25 메일 전송 DNS 53 도메인 네임 서비스 POP3 110 메일 수신 IMAP 143 메일 수신 HTTP 80 웹 서비스 HTTPS 443 웹 서비스(보안 강화) 8. UDP (User Datagram Protocol) 앞선 내용들을 학습하면서 TCP는 신뢰성과 정확성에 초점을 두고, UDP는 효율성에 초점을 둔다고 했다. 그래서 TCP는 연결 확립 절차를 거치고, UDP는 비연결형 통신으로 동영상 스트리밍 방식에 사용된다.\nTCP segment처럼 UDP 헤더가 데이터에 붙게되면 UDP 세그먼트 라고 칭한다.\nUDP segment = UDP header + 응용 헤더 + User data 그러면 UDP header에 대해 봐보자. TCP 헤더와 달리 UDP 헤더는 간단하다. 다음과 같다.\n출발지 포트 번호 (16 bit) 목적지 포트 번호 (16 bit) 길이 (16 bit) 체크섬 (16 bit) 그래서 이 헤더에 있는 포트 번호를 통해 특정 애플리케이션에 UDP 세그먼트를 보낸다.\nTCP 세그먼트는 3 way handshake와 4 way handshake 과정을 통해서 연결을 확립하고 종료하는 과정을 거쳤지만, UDP segment 송신은 그런 절차 없이 일방적으로, 일괄적으로 보낸다.\nUDP의 이런 특성 때문에 LAN 안에 있는 모든 컴퓨터의 데이터를 일괄적으로 보낼 수 있다. 그래서 UDP는 이러한 브로드캐스트 방식의 통신에 적합하다. 하지만 TCP는 연결 확립 및 종료 과정이 있기 때문에 이 방식에는 적합하지 않다.\n그래서 UDP에 대해 정리하자면 다음과 같다.\n효율성 비연결형 통신으로 연결 확립 절차 x 브로드 캐스팅 전송 Reference 나노디그리 러닝스푼즈: Python \u0026amp; Django backend course 네트워크, 그림으로 이해해자 ","permalink":"http://jeha00.github.io/post/network/osi_7_layer/4_layer/","summary":"OSI 7 layer에서 신뢰성 있는 통신을 구현하는 4계층에 대해 더 알아보자.","title":"[TIL]OSI 7 layer: 4계층 전송 계층"},{"categories":"CI/CD","content":"0. Introduction CI/CD를 위한 github action study basic CI/CD를 위한 github action study: Activity type, filters, caching, environment variables and secrets 프로젝트를 진행하면서 새로 작성된 또는 수정된 코드를 repository에 push하면 자동적으로 테스트를 실행하고, 통과되면 합쳐지고 아니면 에러를 발생시키는 workflow를 적용하고 싶어서 예전부터 공부하고 싶었던 github action에 대해 study를 시작한다.\n국내에서는 github action에 대한 강의나 서적을 찾지 못하여 멘토링을 찾았지만 시간 대비 너무 비싸서 포기했다. 그래서 udemy를 찾던 중 저렴한 가격에 좋은 퀄리티 강의를 찾게 되어 이 강의를 중심으로 학습을 진행한다.\n해당 강좌에서 사용되는 소스 코드를 사용하는 부분들은 빼고 블로그에 정리한다.\n해당 소스 코드를 사용하는 부분이 있다면 그 부분이 없어도 해당 블로그만 봐도 익힐 수 있도록 정리해놓는다.\n이미 알고 있는 개념들도 있지만, 놓치고 있는 부분을 확인하고자 정리해본다.\n🔆 첨부된 링크는 구글에 github actions {keyword} 로 입력하면 제일 첫 번째로 나온다.\n1. Controlling Workflow \u0026amp; Job Execution 1.1 if and continue-on-error workflow의 job들이 의존적으로 되어있고 실행 흐름 중간에 에러가 발생되면 그 이후 단계는 실행되지 않는다.\n그런데 에러가 발생해도 뒷 작업이 실행되야한다면 어떻게 해야할까?\nif field를 사용해서 조건을 부여하여 이를 제어할 수 있다.\n이 field와 함께 사용할 github actions 함수 몇 가지를 알아보자.\n특별한 조건 함수들 failure(): 한 job의 step이 실패하면 true를 반환 success(): 이전 Step, Job이 성공하면 true를 반환 always(): 이전 step이나 job이 취소되도 언제나 true를 반환 cancelled(): workflow가 취소된 경우 true를 반환 code 그러면 위 내용들을 code에 적용해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 name: Demo on: push: branches: - main jobs: lint: runs-on: ubuntu-latest steps: ... test: runs-on: ubuntu-latest steps: ... - name: Test code # code 추가 id: run-tests # run: npm run test - name: Upload test report # code 추가 if: failure() \u0026amp;\u0026amp; steps.run-tests.outcome == \u0026#39;failure\u0026#39; # uses: actions/upload-artifact@v3 with: name: test-report path: test.json build: needs: test runs-on: ubuntu-latest steps: ... deploy: needs: build runs-on: ubuntu-latest steps: ... test.json 추가 프로젝트 .github과 동일한 level로 test.json을 생성한다. 그래서 Upload test report가 실행되면 test.json이 artifacts로서 다운받을 수 있다.\n그리고 name 필드는 artifacts의 이름을 지정한다.\nif 와 id field 적용 그리고 outputs 사용 내가 원하는 workflow 흐름은 Test code 단계 step이 실패하면 Upload test report step이 진행되기를 원한다. 이를 위해서 if 필드를 적용했다. 그리고 확실하게 어느 step인지를 지정하기 위해서 github actions context:steps 문서를 참고하여 id 필드를 적용했다.\n이 id 필드를 사용해서 steps.\u0026lt;step_id\u0026gt;.outputs 나 steps.\u0026lt;step_id\u0026gt;.conclusion을 사용하기 위해서다.\n위 코드에서 conclusions 말고 outcome을 사용한 이유는 continue-on-error 없이 사용하기 위해서다. 먼저 없는 거를 진행해본 후 continue-on-error를 적용해보자.\nfailure() 적용 그리고 failure() 이라는 함수를 추가한 이유는 이전 step들에서 실패하면 Upload test report가 진행되지 않기 때문이다. failure()를 추가하면 해당 step이 반드시 평가되기 때문에 진행된다.\n그러면 failure()만 하면 되지 왜 steps.run-tests.outcome을 추가한 것일까?\nfailure는 바로 직전 step 뿐만 아니라 그 전 step까지 포함하기 때문에 run-test에서 실패하지 않고 그 이전에 실패해도 실행된다. 하지만 내가 원하는 건 Test code 단계에서 실패할 경우이기 때문에 직전 step 실패를 적용하고자 \u0026amp;\u0026amp; 연산자를 추가했다.\nJob과 Step은 if field를 통해서 실행을 조절할 수 있다.\nStep은 continue-on-error filed를 통해서 error를 무시할 수 있다. 그래서 이 표현들을 통해서 조건들을 평가한다.\n그러면 failure()를 또 다른 job에 적용해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 name: Demo on: push: branches: - main jobs: lint: ... test: ... build: ... deploy: ... report: needs: [lint, deploy] if: failure() runs-on: ubuntu-latest steps: - name: Output information run: | echo \u0026#34;Something went wrong\u0026#34; echo \u0026#34;${{github}} 위 report job에서 needs field를 추가한 이유는 이 field를 추가하지 않으면 github action에서는 다른 job이 끝나기를 기다려주지 않기 때문에 강제적으로 선행 job을 지정해야 한다. 그리고 needs에 lint, deploy job만을 지정한 이유는 첫 번째 job이고, 마지막 job을 지정하여 처음과 끝 job 까지 다 거쳐서 그 과정에서 실패할 경우 해당 report job을 실행하도록 했다.\n이 needs를 사용하여 실행한 결과 다음 이미지의 job 순서를 확인할 수 있다. needs를 선정하지 않았다면 lint와 병렬적으로 실행하여 실패한다.\ncache에 if 적용하기 지난 챕터에서 caching을 사용해서 dependency 설치 시간을 감소했다. 하지만 더 좋은 방법은 이미 dependency를 설치하는 캐쉬 데이터가 있다면 해당 step을 진행하지 않는 게 더 좋지 않을까?\n그래서 다음과 같은 코드를 추가하자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 build: needs: test runs-on: ubuntu-latest steps: - name: Cache dependencies id: cache uses: actions/cache@v3 with: path: ~/.npm key: deps-node-modules-${{ hashFiles(\u0026#39;**/package-lock.json\u0026#39;) }} - name: Install dependencies # 코드 추가 if: steps.cache.outputs.cache-hit != \u0026#39;true\u0026#39; run: npm ci # 실행하면 다음과 같이 Install dependencies가 실행되지 않은 걸 알 수 있다.\ncontinue-on-error 적용하기 다음으로 continue-on-error field에 대해 알아보자. 이를 test job에 추가한다. 그러면 test 단계에서 error가 발생해도 다음 단계인 build job이 실행된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 name: continue on: push: branches: - main jobs: lint: runs-on: ubuntu-latest steps: ... test: runs-on: ubuntu-latest steps: - name: Get code ... - name: Test code # 코드 추가 continue-on-error: true # id: run-tests run: npm run test - name: Upload test report ... build: needs: test runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 - name: Cache dependencies id: cache uses: actions/cache@v3 with: path: ~/.npm key: deps-node-modules-${{ hashFiles(\u0026#39;**/package-lock.json\u0026#39;) }} - name: Install dependencies if: steps.cache.outputs.cache-hit != \u0026#39;true\u0026#39; run: npm ci ... deploy: ... report: ... continue-on-error가 추가되지 않고 test에서 에러가 발생할 경우 이후 작업은 다 생략된다.\ncontinue-on-error가 추가되고, test에서 에러가 발생할 경우, 이후 작업은 진행된다.\n1.2 Matrix를 사용해서 Job 실행하기 Github actions에서 Matrix란? 이번에는 Matrix에 대해 알아보자.\nMatrix는 runs-on filed로 지정한 운영체제가 만약 여러 종류이고, programming language의 여러 버전을 이라면 이 모든 경우의 수를 모두 workflow를 진행하고자 할 때 사용되는 방식이다.\n새롭게 matrix.yml을 생성하여 다음 코드를 작성해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 name: Matrix Demo on: push jobs: # matrix 미 사용 시 build job build: runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 - name: Install NodeJS uses: actions/setup-node@v3 with: node-version: 14 - name: Install Dependencies run: npm ci - name: Build project run: npm run build # matrix 사용 시 build job build: # 추가된 코드 strategy: matrix: version: [12, 14, 16] os: [ubuntu-latest, windows-latest] runs-on: ${{ matrix.os }} # steps: - name: Get code uses: actions/checkout@v3 - name: Install NodeJS uses: actions/setup-node@v3 with: node-version: 14 node-version: ${{ matrix.version }} - name: Install Dependencies run: npm ci - name: Build project run: npm run build matrix가 추가된 workflow를 실행하면 다음과 같은 결과를 확인할 수 있다.\njob이 진행되는 걸 보면 matrix: build 를 확인할 수 있다. matrix로 진행되는 job들은 병렬적으로 진행된다. continue-on-error 가 없기 때문에 선행된 job이 실패해서 이후 job이 canceled 되었다. 하지만 continue-on-error를 job level에서 추가하면 다음과 같이 error가 발생되도 진행되는 걸 알 수 있다.\nmatrix의 include와 exclude matrix는 입력된 key에 대한 모든 조합을 실행한다. 그런데, 이 조합들 중에서 어떤 경우의 수는 배제하면 좋겠고, 어떤 경우의 수는 key에 포함되지 않지만 추가해서 수행되기를 원할 경우 어떻게 해야할까?\n이럴 때는 include와 exclude를 사용한다. 아래와 같이 코드를 작성한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 name: Matrix Demo on: push jobs: build: continue-on-error: true strategy: matrix: version: [12, 14, 16] os: [ubuntu-latest, windows-latest] # 추가된 코드 include: - version: 18 os: ubuntu-latest exclude: - version: 12 os: windows-latest # runs-on: ${{ matrix.os }} steps: - name: Get code uses: actions/checkout@v3 - name: Install NodeJS uses: actions/setup-node@v3 with: node-version: ${{ matrix.version }} - name: Install Dependencies run: npm ci - name: Build project run: npm run build 실행된 결과는 다음 이미지와 같다.\n이전 이미지를 보면 node 12 version과 windows-latest 인 조합일 때 build 작업을 수행했지만, exclude로 입력하고 나서는 수행되지 않는 걸 확인할 수 있다. 그리고, include로 추가한 version 18과 windows-latest 조합이 수행된 걸 확인할 수 있다. version 18과 ubuntu-latest는 include에 포함되어 있지않고, matrix.version에 18이 없기 때문에 수행되지 않을 걸 확인할 수 있다.\n1.3 workflow 재 사용하기 workflow_call 이용하기 이번 장에서는 A, B workflow가 존재할 때 한 workflow에서 다른 workflow를 가져와 사용하는 방식을 알아보고자 한다.\n예를 들어 workflow reusable.yml 과 use-reuse.yml이 있다. use-reuse.yml에서 reusable.yml을 호출해서 사용할려고 한다.\n그렇다면 reusable.yml의 on field를 다음과 같이 작성해야 한다.\n1 2 3 4 5 6 7 8 9 10 # reusable.yml name: Reusable Deploy on: workflow_call jobs: deploy: runs-on: ubuntu-latest steps: - name: Output information run: echo \u0026#34;Deploying \u0026amp; uploading...\u0026#34; workflow_call은 workflow_dispatch와 달리 workflow가 호출되면 실행되는 event trigger다.\n그리고 reusable.yml을 호출하여 사용할 use-reuse.yml에 아래 코드를 추가한다.\n1 2 3 4 5 6 7 8 # use-reuse.yml jobs: build: ... deploy: needs: build uses: ./.github/workflows/reusable.yml 위 코드를 추가하여 실행한 결과 다음과 같이 deploy / deploy를 확인할 수 있다.\nreusable.yml의 job name이 deploy이고, 이 reusable.yml을 호출한 job이 use-reuse.yml의 deploy이기 때문이다.\nworkflow_call 시 artifacts file name 건네주기 workflow를 호출할 때, 단순히 호출하는 것을 넘어서 특정 값을 전달하여 호출된 workflow가 사용하도록 할 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 # reusable.yml name: Reusable Deploy on: workflow_call: inputs: artifact-name: description: The name of the deployable artifact files required: false default: dist type: string jobs: deploy: runs-on: ubuntu-latest steps: - name: Get code uses: actions/download-artifact@v3 with: name: ${{ inputs.artifact-name }} - name: List files run: ls - name: Output information run: echo \u0026#34;Deploying \u0026amp; uploading...\u0026#34; # use-reuse.yml name: Demo on: push: branches: - main jobs: test: runs-on: ubuntu-latest steps: ... - name: Upload test report uses: actions/upload-artifact@v3 with: name: dist-files path: dist deploy: needs: build uses: ./.github/workflows/reusable.yml # 추가된 코드 with: artifact-name: dist-files # report: needs: [lint, deploy] if: failure() runs-on: ubuntu-latest steps: - name: Output information run: | echo \u0026#34;Something went wrong\u0026#34; echo \u0026#34;${{github}}\u0026#34; required: false이면 workflow는 value를 제공하지 않아도 호출되는 게 가능하다는 의미다. default: artifact-name의 default 값이 dist라는 의미 type: 입력되는 타입은 string 문자열이라는 의미 ${{inputs.artifact-name}}으로 해당 값을 가져와서 artifact의 name으로 지정한다.\n2. Github actions with Docker container Docker container 안에서 github action을 실행하는 이유 github actions는 여러 개의 job을 가질 수 있는데, 하나의 job마다 실행 환경 runners를 입력해야만 한다. 이는 우분투, 윈도우, 리눅스, MacOS가 있지만 이는 이미 만들어져있는데 기성품 같은 것이기 때문에 우리가 모든 환경을 조절할 수 없다. 그래서 docker container 너를 각 job의 실행 머신 os로 지정한다면 docker image를 정의한 작성자가 훨씬 더 많은 걸 조절할 수 있기 때문에, docker container를 runners로 지정하는 걸 추천한다.\n기존에 제공하는 os를 사용하면 이에 따라 여러 가지 세팅들을 제공하기 때문에 충분할 수 있으나, 그렇지 않은 상황에서는 container를 추천한다.\n그리고 container를 사용하면 container를 재사용할 수 있다.\nReference github actions - steps context github actions - ","permalink":"http://jeha00.github.io/post/ci_cd/github_action/lecture_03/","summary":"계속 작업 중","title":"CI/CD를 위한 github action study: workflow와 job 실행 제어하기 \u0026 Jobs 와 Docker containers"},{"categories":"CI/CD","content":"0. Introduction CI/CD를 위한 github action study basic 프로젝트를 진행하면서 새로 작성된 또는 수정된 코드를 repository에 push하면 자동적으로 테스트를 실행하고, 통과되면 합쳐지고 아니면 에러를 발생시키는 workflow를 적용하고 싶어서 예전부터 공부하고 싶었던 github action에 대해 study를 시작한다.\n국내에서는 github action에 대한 강의나 서적을 찾지 못하여 멘토링을 찾았지만 시간 대비 너무 비싸서 포기했다. 그래서 udemy를 찾던 중 저렴한 가격에 좋은 퀄리티 강의를 찾게 되어 이 강의를 중심으로 학습을 진행한다.\n해당 강좌에서 사용되는 소스 코드를 사용하는 부분들은 빼고 블로그에 정리한다.\n해당 소스 코드를 사용하는 부분이 있다면 그 부분이 없어도 해당 블로그만 봐도 익힐 수 있도록 정리해놓는다.\n이미 알고 있는 개념들도 있지만, 놓치고 있는 부분을 확인하고자 정리해본다.\n🔆 첨부된 링크는 구글에 github actions {keyword} 로 입력하면 제일 첫 번째로 나온다.\n1. Activity type and Filters 학습하기 지난 학습을 통해서 on: [push, workflow_dispatch]로 events를 정의해놓으면 모든 push마다 workflow가 진행된다는 걸 알게 되었다.\n그런데 이를 보다 더 정밀하게 event를 정의하고 싶다면 어떻게 해야할까?\n그럴 때는 Activity type 또는 filter를 적용해야 한다. event의 Activity types 과 filters에 대해 알아보자.\nActivity type에는 예를 들어서 event가 pull_request라면 activity type에는 opened, closed, edited 가 존재한다.\nFilters는 push event라고 한다면 target branch에 대해 조건을 걸 수 있다.\ngithub actions events를 보면 여러 event와 activity type가 나와있다. 해당 event를 사용할 때는 Note를 반드시 읽어보도록 하자. types를 입력하는 3가지 방식과 types가 존재할 때 여러 event를 입력하는 방식 1 2 3 4 5 6 7 8 9 10 11 12 13 14 name: Events Demo 1 on: pull_request: # types를 입력하는 3가지 방식: 반드시 types 이어야 한다. types: [opened, edited] types: opened types: - opened workflow_dispatch: jobs: deploy: runs-on: ubuntu-latest steps: ... 그러면 아래와 같이 작성했다고 하면 수동적으로 실행했을 때와 PR을 open했을 때 workflow가 진행된다.\n1 2 3 4 5 6 7 8 9 10 11 name: Events Demo 1 on: pull_request: types: - opened workflow_dispatch: jobs: deploy: runs-on: ubuntu-latest steps: ... 아래 이미지를 통해 실행되는 걸 확인할 수 있다.\n하지만 types: closed 인 경우에는 PR이 닫혀지고 나서 실행된다.\n이처럼 types를 무엇으로 지정하냐에 따라서 workflow 진행 유무 기준을 구체적으로 정할 수 있다.\npush에 대한 filter 적용 push를 할 때 내가 원하는 branch와 원하는 경로에 들어올 때만 실행하는 방법도 있다.\npush keyword에 branches keyword를 입력해보자.\n1 2 3 4 5 6 7 name: Events Demo 1 on: push: branches: - main - \u0026#39;dev-*\u0026#39; - \u0026#39;feat/**\u0026#39; 위 workflow의 의미는 다음과 같다.\nmain branch와 dev-로 시작하는 branch와 feat/ 로 시작하는 branch 위 3가지 branch에 push를 할 경우에만 workflow를 실행한다. 만약 feature/ 로 시작한다면 실행되지 않는다.\nworkflow 경로에 따라 실행하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 name: Events Demo 1 on: push: paths-ignore: - \u0026#39;.github/workflows/*\u0026#39; jobs: deploy: runs-on: ubuntu-latest steps: - name: Output event data run: echo \u0026#34;${{toJSON(github.event)}}\u0026#34; - name: Get code uses: actions/checkout@v3 - name: Install dependencies run: npm ci - name: Test code run: npm run test - name: Build code run: npm run build - name: Deploy project run: echo \u0026#34;Deploying...\u0026#34; 이 상황에서 만약 main branch로 push를 할 경우 Events Demo 1은 실행되지 않는다.\nForked Pull Request Workflows 만약 누군가 repository를 fork하고 main branch에 push할 경우, forked repository가 아닌 원래 repository에서 경고 표시로 workflow 가 뜨면서 진행되지 않는다.\n이렇게 된 이유는 모든 사람들이 repository를 fork할 수 있는데, 악의적으로 workflow를 실행시켜서 cost를 과도하게 유발시키 수 있기 때문에, forked repository에서 main으로 push한 경우에는 바로 workflow가 진행되지 않는다.\n진행 중인 workflow 취소하기 기본적으로 workflow가 진행 중이다가 실패하면 workflow는 당연히 취소된다.\n또한, 수동적으로 직접 workflow를 취소할 수도 있다.\n아래 이미지의 오른쪽 위를 보면 Cancel workflow button을 통해서 중지할 수 있다.\nworkflow skip 하기 참고할 공식 문서는 여기 다.\n위 문서에 따르면 commit message를 작성할 때 다음 메세지를 작성하면 된다.\n[skip ci] [ci skip] [no ci] [skip actions] [actions skip] 그러면 main branch에 push는 했지만 github actions는 실행되지 않는 걸 확인할 수 있다.\n2. Job Data \u0026amp; Outputs \u0026amp; Caching What is Job Artifacts Job Artifacts란 Job에 의해 생긴 결과물로 예를 들어서 log file이나 website files 등이 있다.\n이 Job Artifacts를 Github UI나 REST API를 사용하여 수동적으로 다운받아 사용하는 방식이 있고 Job을 통해 Action으로 Job Artifacts를 다운받고 사용하는 방식이 있다.\n예를 들어서 npm run build로 실행하여 생긴 dist folder는 build job에 의해서 생긴 artifacts다.\n그러면 이 Artifacts를 upload 및 download 하도록 해보자.\n이 작업이 필요한 이유는 각 job 단계에서의 runner machine은 다르기 때문에 같은 runner machine 정의를 가진다고 해도 각 runner machine에서는 그 파일을 가지고 있지 않는다. 그래서 job이 build -\u0026gt; deploy 순서로 존재한다고 할 때 build 단계에서 업로드한 파일을 deploy 단계에서 가지기 위해서는 \u0026lsquo;다운로드\u0026rsquo;를 진행해야 한다. 그리고 이를 위해서 업로딩이 필요하다.\nJob artifacts를 업로딩하기 이 Actions를 통해 생긴 결과물인 Job artifacts를 사용할 수 있다. workflow를 다음과 같이 작성한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 name: Deployment Exercise 2 on: push: branches: - main jobs: test: runs-on: ubuntu-latest ... build: needs: test runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 - name: Install dependencies run: npm ci - name: Build website run: npm run build # 이 부분을 추가 - name: Upload artifacts uses: actions/upload-artifact@v3 with: name: dist-files path: | dist package.json # package.json은 경로를 여러 개 입력하는 방법을 보여주기 위해 입력한 예시 deploy: needs: build ... 아래 이미지처럼 Artifacts가 생성된다. 이를 클릭하면 수동으로 다운 받을 수 있다.\n자동으로 다운받아지기 위해서는 deploy job 단계에서 다운받는 step을 추가한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 ... build: needs: test ... # 이 부분을 추가 - name: Upload artifacts uses: actions/upload-artifact@v3 with: name: dist-files # 이 부분은 수정한다. # path: | # dist # package.json path: dist deploy: needs: build runs-on: ubuntu-latest steps: # 추가한 단계 - name: Get build artifacts uses: actions/download-artifact@v3 with: name: dist-files # - name: Output contents run: ls - name: Deploy run: echo \u0026#34;Deploying...\u0026#34; 아래 이미지를 보면 Output contents step 단계에서 ls를 실행하여 파일 목록을 확인했다.\n다운로드 시 Github에서 제공하는 Action을 사용하여 할 수 있다. 이 때 설정을 추가해야 한다. 업로드 했던 파일의 이름을 name key로 value를 입력한다. 그러면 deploy job이 실행되는 folder 안에 dist-files 내부 파일들이 바로 담겨진다.\nArtifacts와 Job Outputs \u0026lsquo;Artifacts\u0026rsquo;는 log file이나 website files로 사용된다면 \u0026lsquo;Job Outputs\u0026rsquo;는 순차적으로 일어나는 다음 job 들에 사용되는 값들을 말한다. 예를 들어서 이전 step 단계에서 생성된 파일의 이름을 말한다. 그러면 Job Outputs를 확인해보자.\n아래 yml은 Job Output을 이용하는 workflow다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 name: Demo on: push: branches: - main jobs: test: runs-on: ubuntu-latest steps: ... build: needs: test runs-on: ubuntu-latest # 추가한 key: outputs outputs: script-file: ${{ steps.publish.outputs.file-name }} # steps: ... # 추가한 step - name: Publish JS filename id: publish run: find dist/assets/*.js -type f -execdir echo \u0026#39;file-name={}\u0026#39; \u0026gt;\u0026gt; $GITHUB_OUTPUT \u0026#39;;\u0026#39; # ... deploy: needs: build runs-on: ubuntu-latest steps: ... # 추가한 steps - name: Needs run: echo \u0026#34;${{ needs }}\u0026#34; - name: Build run: echo \u0026#34;${{ needs.build }}\u0026#34; - name: Output run: echo \u0026#34;${{ needs.build.outputs}}\u0026#34; - name: Output filename run: echo \u0026#34;${{ needs.build.outputs.script-file }}\u0026#34; - name: Deploy run: echo \u0026#34;Deploying...\u0026#34; # build job의 Publish JS filename step steps라는 context name은 아래 공식문서에서와 같은 의미를 가지고 있어서 steps를 통해 해당 step의 정보를 얻을 수 있다.\nInformation about the steps that have been run in the current job. 위 단계에서 아래 command를 실행했다.\nfind dist/assets/*.js -type f -execdir echo 'file-name={}' \u0026gt;\u0026gt; $GITHUB_OUTPUT ';'\n위 명령어의 의미는 다음과 같다.\ndist/assets/*.js인 데이터를 찾는데, 이 데이터의 타입은 f로 파일이고, execdir을 사용해서 해당 파일이 있는 경로에서 echo 커맨드를 실행한다. file-name key에 해당하는 value를 $GITHUB_OUTPUT에 저장한다. $GITHUB_OUTPUT은 outputs에 선언된 key 값에 연결된다. file-name key의 value에 저장된다. script-file이 file-name을 가리키기 때문에 script-file에 저장된다. 다른 job의 output 이용하기 deploy job을 보면 여러 개의 환경 변수들을 출력하고 있다\nneeds, needs.build, needs.build.outputs, needs.build.outputs.script-file 아래 image를 보면 해당 step name 별로 출력된 결과를 볼 수 있다.\nneeds.build.outputs.script-file로 적어뒀던 Output filename step만 다른 값을 출력한 걸 확인할 수 있다.\n이처럼 github output에 값을 담아두면 다른 job에서도 꺼내서 사용할 수 있는 걸 알 수 있다.\n그리고, Artifacts와 outputs의 차이 를 확실히 알게 되었다. Artifacts는 외부에서 다운받을 수 있는 결과물이지만, outputs는 단순한 값이라는 걸 확인했다.\ncache를 사용하여 Dependency 설치 시간을 단축시키기 여태 실습한 workflow는 간단하기 때문에 1분 내외지만 복잡한 workflow를 하게 되면서 시간이 많이 걸리게 된다.\n이번 섹션에서는 이 workflow 실행 시간을 줄이는 것에 초점을 둔다.\n실행 시간을 줄이는 방법 중 하나는 각 Step 마다 반복되는 부분을 빠르게 진행하는 것이다.\n반복되는 부분을 확인해보자.\nTest job: Get code =\u0026gt; Install Dependencies =\u0026gt; Test App\nBuild job: Get code =\u0026gt; Install Dependencies =\u0026gt; Build Project\n여러 step 중에서 Get code 부분이 반복된다. 하지만 이 부분은 \u0026lsquo;1s\u0026rsquo; 밖에 걸리지 않기 때문에 이는 많이 느리지 않는다.\n또한, Install dependencies 부분이 반복된다. 이 부분은 \u0026rsquo;12s\u0026rsquo;나 걸리기 때문에 많이 느리다.\n그렇다면 dependencies 를 설치할 때 매 step마다 달라지는가? 얼마나 달라지는가?\ndependencies는 자주 바뀌지 않는다. 그렇기 때문에 이 부분을 공통적으로 사용해도 문제가 없다. 이 부분을 단축한다면 전체 workflow 실행 시간이 줄어들 것이다. dependencies를 설치하는 부분의 시간을 \u0026lsquo;cache\u0026rsquo; 를 사용하여 단축해보자.\n각 job마다 실행되는 runner (os)가 다른데 어떻게 cache를 사용할 수 있을까?\ngithub actions - cache 를 사용하여 해당 job이 끝나면 지정한 폴더 또는 파일을 저장하여 다른 job이 실행될 때 이를 꺼내서 사용하는 방식으로 cache가 저장 및 사용된다.\n코드는 다음과 같다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 jobs: test: runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 # 추가된 코드 - name: Cache dependencies uses: actions/cache@v3 with: path: ~/.npm key: deps-node-modules-${{ hashFiles(\u0026#39;**/package-lock.json\u0026#39;) }} # - name: Install dependencies run: npm ci - name: Lint code run: npm run lint - name: Test code run: npm run test 위 추가된 코드에 대해 설명하자면\n~/.npm은 npm 에서 생성한 자체 cache folder인데, 이 folder를 actions를 사용하여 다른 workflow 또는 job 공용으로 사용하기 위해 github server에 있는 github cloud에 저장한다.\nkey는 미래에 이 cache data를 가져올 때 필요하다.\nhashFiles를 사용한 이유는 혹시 dependency가 업데이트되었을 때, 중복되면 않되기 때문에 고유 식별자 역할을 하기 위해 사용한다.\n**/package-lock.json 인 이유는 경로 상관없이 package-lock.json을 저장할 것이기 때문이다.\ntest job에 작성된 Cache dependencies를 다음 단계 job인 build에도 추가한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 build: needs: test runs-on: ubuntu-latest outputs: script-file: ${{ steps.publish.outputs.file-name }} steps: - name: Get code uses: actions/checkout@v3 # add code - name: Cache dependencies uses: actions/cache@v3 with: path: ~/.npm key: deps-node-modules-${{ hashFiles(\u0026#39;**/package-lock.json\u0026#39;) }} # - name: Install dependencies run: npm ci ... 그러면 실행 결과를 확인해보자. 아래 이미지는 test job에서의 이미지다.\nCache dependencies 단계에서는 해당 key를 발견할 수 없다고 떴지만 Post Cache dependencies 단계에서 해당 key 값으로 cache에 저장된 걸 알 수 있다.\n위 이미지에서는 안보이지만 test job에서 Install dependencies 단계에서는 \u0026rsquo;11s\u0026rsquo;가 걸렸다.\n그러면 test 다음 job인 build job일 때 설치 시간, Cache dependencies를 확인해보자.\nCache dependencies 단계에서 다음 메세지를 확인할 수 있다.\ncache restored from key: deps-node-modules-... test 단계에서는 해당 key를 발견할 수 없다고 떴지만, 그 다음 build 단계에서는 해당 key로 cache에서 꺼낸 걸 알 수 있다.\n그리고 그 다음 step인 Install dependencies 단계의 설치 시간은 \u0026lsquo;5s\u0026rsquo;로 줄어든 걸 확인할 수 있다.\n다른 workflow에도 똑같은 Install dependencies step이 존재한다면 실행 시간이 짧아진 거를 확인할 수 있을 것이다.\nSummary Artifacts Job 실행에 의한 결과물로 공유되거나 분석될 수 있다. Artifacts 또는 Job artifacts라고 불린다. Github Actions에서 제공하는 action을 통해 uploading 과 downloading을 제공한다. Outputs Steps 실행에 의해 생성된 결과물이고 단순한 값들이며, Job 간에 공유될 수 있다.\n\u0026lsquo;steps\u0026rsquo; context를 통해서 Jobs들은 이를 사용 및 공유할 수 있다.\necho '{output-name}={output-value}' \u0026gt;\u0026gt; $GITHUB_OUTPUT 명령어로 key-value로 저장한다.\n위 command를 사용하는 step의 경우 id를 key를 입력해야 한다.\n다른 job에서 이를 사용할 경우, steps.{step_id}.outputs.{key}로 사용가능하다.\n1 2 3 4 5 6 7 8 9 build: needs: test runs-on: ubuntu-latest outputs: script-file: ${{ steps.publish.outputs.file-name }} steps: - name: Publish JS filename id: publish run: find dist/assets/*.js -type f -execdir echo \u0026#39;file-name={}\u0026#39; \u0026gt;\u0026gt; $GITHUB_OUTPUT \u0026#39;;\u0026#39; caching 반복되고, 느린 step들의 속도를 증가시킬 수 있다. 전형적으로 사용되는 경우는 dependency 설치지만, 어느 파일과 폴더 모두 가능하다. ❗️ 하지만 artifacts를 caching하여 사용하지 말자. 용량이 크다. 3. Enviroment variables \u0026amp; Secrets 사용하기 왜 github actions에 환경 변수가 필요할까? 왜냐하면 tesing 시 db와 production 시 db에 대한 password가 다른데 이를 환경 설정으로 다르게 해야 workflow를 진행 시 의도한 대로 정확하게 진행할 수 있기 때문이다.\nEnvironments variables code 상에서 사용할 수 있는 동적 값으로 다음과 같이 workflow 전체 범위로도, 해당 Job에 대해서만으로도, step에 대해서만으로도 할 수 있다. 환경 변수를 사용하기 위해서는 env 라는 내장 키워드를 통해서 접근할 수 있다.\nworkflow, job, step에 대해서 환경 변수 선언하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 name: Deployment on: push: branches: - main # on과 같은 level에서 선언: workflow 전체 범위로 선언 env: DB_NAME: test jobs: test: # 해당 job에 대해서만 선언 env: DB_USERNAME: project DB_PASSWORD: 1234 runs-on: ubuntu-latest steps: - name: # 해당 step에 대해서만 선언 env: APPLE: 1234 uses: 위 코드에서 \u0026lsquo;DB_NAME\u0026rsquo;은 workflow 전체 범위로 선언한 이유는 db name은 test이든 production이든 잘 변하지 않기 때문이다. 환경 변수 사용하기 그러면 환경 변수를 사용하기 위해 workflow를 작성해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 name: Demo on: push: branches: - main env: DB_NAME: test jobs: test: env: DB_USERNAME: project DB_PASSWORD: 1234 runs-on: ubuntu-latest steps: ... # 추가된 코드 - name: Check DB information run: | echo \u0026#34;DB_NAME: ${{ env.DB_NAME }}\u0026#34; echo \u0026#34;DB_USERNAME: $DB_USERNAME\u0026#34; echo \u0026#34;DB_PASSWORD: $DB_PASSWORD\u0026#34; # build: needs: test runs-on: ubuntu-latest outputs: script-file: ${{ steps.publish.outputs.file-name }} steps: ... # 추가된 코드 - name: Check DB information run: | echo \u0026#34;DB_NAME: ${{ env.DB_NAME }}\u0026#34; echo \u0026#34;DB_USERNAME: $DB_USERNAME\u0026#34; echo \u0026#34;DB_PASSWORD: $DB_PASSWORD\u0026#34; # DB_NAME은 workflow 전역으로 선언 DB_USERNAME, DB_PASSWORD는 job 범위로 선언 위 코드를 실행한 결과 중 test job의 실행 결과는 다음과 같다.\n모든 값이 다 출력되었고, 일치한다.\n그러면 build job의 실행 결과를 확인해보자.\nworkflow level에서 선언한 DB_NAME만 출력되고 다른 job에서 선언했던 DB_USERNAME과 DB_PASSWORD는 출력되지 않은 걸 알 수 있다.\n위 결과 workflow level에서 선언한 환경 변수에 접근하기 위해서는 ${{env.{key name}}}을 사용하여 접근하면 되고, job 내에서 선언한 환경변수는 $key_name을 통해 접근하면 된다는 걸 확인했다.\nSecrets 사용하기 Environment variables 처럼 동적 값이지만 노출되지 않아야 하는 값들은 Secrets으로 사용하면 된다. 예를 들어 API key, db 관련 정보들이 해당된다. 이 값을 사용하기 위해서는 secrets 라는 내장 키워드를 통해서 사용될 수 있다.\ngithub에는 이러한 secrets를 저장할 공간이 존재한다. Github 해당 repository -\u0026gt; Settings tab -\u0026gt; Security 의 Actions에 접근하면 아래 이미지 화면을 확인할 수 있다.\n위 화면을 확인했다면 secret을 추가하기 위해서 위 \u0026lsquo;New repository secret\u0026rsquo; 버튼을 클릭하여 추가한다.\n예를 들어 DB_NAME: test 를 추가하고 싶다면 위 버튼을 클릭 후 \u0026lsquo;Name\u0026rsquo;에는 \u0026lsquo;DB_NAME\u0026rsquo;을 입력하고, \u0026lsquo;Secret\u0026rsquo;에 \u0026rsquo;test\u0026rsquo;를 입력한다. 추가하면 다음 이미지처럼 확인할 수 있다.\n그러면 DB_USERNAME: project와 DB_PASSOWRD: 1234도 다 추가해보자. 그 다음에 secrets으로부터 값을 가져오기 위해서 해당 workflow의 env를 다음과 같이 수정한다.\n1 2 3 4 5 6 7 8 9 ... env: DB_NAME: ${{secrets.DB_NAME}} jobs: test: env: DB_USERNAME: ${{secrets.DB_USERNAME}} DB_PASSWORD: ${{secrets.DB_PASSOWRD}} ... 위와 같이 수정된 후 실행 결과를 확인해보면 이전과 달리 \u0026lsquo;*\u0026rsquo; 라는 문자로 값이 드러나지 않는 걸 확인할 수 있다.\nJob마다 같은 용도지만 다른 값을 가진 secret 사용하기 위 소제목에 나온 대로 secret을 사용하고 싶다면 저장하는 secret name을 다르게 저장할 수 밖에 없다.\n이를 job마다 동일한 이름으로 분류하고 싶다면 아래 내용인 Github Actions Environments를 보도록 하자.\nGithub Actions Environments github repository에 code and automation tab에 Environments를 사용하여 job마다 다른 github action environment를 참고할 수 있다. 즉, Environment마다 다른 secret 값을 가질 수 있다.\ngithub profile의 settings가 아닌 repository들어가 보이는 Settings 여야 한다.\n그러면 \u0026rsquo;testing\u0026rsquo;에 사용하는 secrets를 만들어보자.\n위 이미지에서 \u0026lsquo;New environment\u0026rsquo;를 클릭하여 \u0026rsquo;testing\u0026rsquo; 을 입력하여 \u0026rsquo;testing\u0026rsquo;이란 이름의 environment를 생성해보자. 생성 결과는 다음과 같다. 아래 이미지로 보면 타이틀 부분에 Configure testing이 생긴 걸 알 수 있다. 그리고 나서 DB_NAME, DB_USERNAME, DB_PASSWORD를 입력해보자. 이번에는 \u0026lsquo;deploy\u0026rsquo;를 입력하여 \u0026lsquo;deploy\u0026rsquo;란 이름의 environment를 생성해보자.\n생성된 environment 목록은 다음과 같다. 이 목록을 확인하기 위해서는 side bar의 Environments tab을 입력하면 확인할 수 있다. Security tab의 Actions으로 가서 Repository secrets에 있는 모든 secret을 삭제한다.\nworkflow에 입력하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 name: Demo on: push: branches: - main - dev env: DB_NAME: ${{secrets.DB_NAME}} jobs: test: # 추가하기 environment: testing # env: DB_USERNAME: ${{secrets.DB_USERNAME}} DB_PASSWORD: ${{secrets.DB_PASSWORD}} runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 - name: Cache dependencies uses: actions/cache@v3 with: path: ~/.npm key: deps-node-modules-${{ hashFiles(\u0026#39;**/package-lock.json\u0026#39;) }} - name: Install dependencies run: npm ci - name: Check DB information run: | echo \u0026#34;DB_NAME: ${{ env.DB_NAME }}\u0026#34; echo \u0026#34;DB_USERNAME: $DB_USERNAME\u0026#34; echo \u0026#34;DB_PASSWORD: $DB_PASSWORD\u0026#34; 특정 브랜치에 한해서 workflow 실행되기 \u0026lsquo;Selected branches\u0026rsquo;를 선택한 다음에 testing job을 실행할 branch를 입력한다.\n위 이미지에 따르면 main을 선택했다. 그러면 dev branch를 새로 파서 여기에 push를 해보자. 아래 이미지에 나온 것처럼 배포에 실패했다.\nReference [udemy lecture] Github Actions - The Complete Guide Manage workflow runs - skip workflow runs github actions - context Skipping workflow runs github actions events github actions cache github actions - Default environment variables ","permalink":"http://jeha00.github.io/post/ci_cd/github_action/lecture_02/","summary":"첫 번째, Activity type, filters가 뭔지 학습한다. 두 번째 Job artifacts, outputs 를 비교해보고 github actions caching을 어떻게 하면 적용할 수 있는지 알아본다. 세 번째, github action에서 환경 변수와 secrets 값을 어떻게 설정하는지 알아본다.","title":"CI/CD를 위한 github action study: Activity type, filters, caching, environment variables and secrets"},{"categories":"CI/CD","content":"0. Introduction 프로젝트를 진행하면서 새로 작성된 또는 수정된 코드를 repository에 push하면 자동적으로 테스트를 실행하고, 통과되면 합쳐지고 아니면 에러를 발생시키는 workflow를 적용하고 싶어서 예전부터 공부하고 싶었던 github action에 대해 study를 시작한다.\n국내에서는 github action에 대한 강의나 서적을 찾지 못하여 멘토링을 찾았지만 시간 대비 너무 비싸서 포기했다. 그래서 udemy를 찾던 중 저렴한 가격에 좋은 퀄리티 강의를 찾게 되어 이 강의를 중심으로 학습을 진행한다.\n해당 강좌에서 사용되는 소스 코드를 사용하는 부분들은 빼고 블로그에 정리한다.\n해당 소스 코드를 사용하는 부분이 있다면 그 부분이 없어도 해당 블로그만 봐도 익힐 수 있도록 정리해놓는다.\n이미 알고 있는 개념들도 있지만, 놓치고 있는 부분을 확인하고자 정리해본다.\n🔆 첨부된 링크는 구글에 github actions {keyword} 로 입력하면 제일 첫 번째로 나온다.\n1. What is Git, Github and Github Action? 1.1 What is Git? 무료로 사용할 수 있는 관리 시스템 도구로서, 소스 코드의 변화들을 관리하는 역할을 한다.\n구체적으로 정리하자면 다음 3가지로 정리할 수 있다.\nGit의 3가지 역할 create a snpshot (commit) branch를 사용하여 다른 코드와 작업이 가능하고, 여러 브랜치와 commit들 사이로 이동할 수 있다. (checkout, switch) 1.2 What is Github? store \u0026amp; manage git repositories\ngit 으로 관리되고 있는 repositories들의 cloud 저장소이자, 저장된 code들에 대해 여러 서비스를 제공하는 회사다.\nGithub의 3가지 역할 cloud git repository storage(push \u0026amp; pull) code 관리 \u0026amp; 개발하는데 협력하는 도구 (Issues, PR 등등) github Action을 통한 CI / CD 1.3 What is Github Actions? github에 의해서 제공되는 workflow 자동화 서비스로, repository와 관련하여 자동화된 프로세스들과 action들을 의미한다.\n하지만 이 서비스에서 가장 중요한 부분은 CI / CD 다. 이 용어는 아래 용어의 약어를 의미한다.\nCI: Continuous Integration CD: continuous Delivery CI는 코드 변화을 기존에 존재한 코드와 합쳐져서 build 되고, 테스트를 거치고, 최종적으로 합쳐지는 단계를 말한다.\nCD는 CI 를 거치고 나서, 새로운 앱과 패키지 버전들이 자동적으로 배포되는 걸 말한다.\n예를 들어 코드를 수정하면 자동적으로 새로운 웹 사이트 버전을 자동적으로 업로드하고 publish 하기를 원할 것이다. 이것이 CI/CD다.\n그러면 가장 중요한 부분이 CI/CD라고 했으니 그 외의 부분들에 대해 언급하자면 workflow나 프로세스의 종류만을 자동화하는 것뿐만 아니라, repository 및 코드 관리도 수행한다.\ncode reviews, issue management 2.Github Actions - Basic Building Blocks \u0026amp; Components 그러면 본격적으로 github action에 대해 학습해보자.\n학습 목표는 다음과 같다.\ngithub action에서 핵심 요소들을 이해하기 Workflows, Jobs \u0026amp; Steps 로 작업하기 예시 workflow를 직접 구성해보기 2.1 key elements: Workflows, Jobs, Steps Github Action에서는 실행\n위 3가지는 Code repository와 관련 있다.\nworkflow는 몇 개가 되든 추가할 수 있다. 하나의 workflow는 한 개 이상의 Job을 포함한다. 하나의 job은 한 개 이상의 Step을 포함한다. Step은 실질적인 것들을 의미하는데, code 를 다운 받거나, dependency를 설치하거나, 테스트를 진행하는 등의 단계들을 의미한다. Workflows\nGithub repository에 부착된다 한 개 이상의 Job을 가진다 Events를 기반으로 시작된다. .github/workflows Jobs\n하나의 Job마다 하나의 Runner를 정의한다. Runner는 runs-on으로 지정한다. 그래서 job마다 runs-on을 입력해야 한다. 즉 job마다 자신만의 virtual machine을 가져서 다른 machine과 job으로부터 완전히 격리시켜야 한다는 의미다. 1개 이상의 Steps를 포함한다. 병렬적으로 또는 동기적으로 실행된다. 실행 조건을 부여할 수 있다. Steps\n하나의 Action 또는 하나의 shell script를 실행한다. Action은 workflow의 가장 작은 실행 단위 커스텀 또는 third party action을 사용할 수 있다. steps는 순서대로 실행된다. 실행 조건을 부여할 수 있다. 정책\npublic repository에 대해서는 Github Action은 무료다. 하지만 private이면 매달 특정 사용량까지만 무료다. 보다 구체적인 사용 요금 정책은 여기를 확인한다. 만약 repository tab에서 Actions 를 확인하지 못한다면 여기를 클릭하여 설명을 확인하자. 2.2 Practice 1 해당 실습은 gh-firsts-action이라는 public repository를 생성하여 이 repository에서 진행했다.\n그러면 첫 workflow를 생성해보자. 첫 예제인 만큼 Actions tab에 들어가서 간단한 worflow인 Simple workflow 를 선택해서 사용해보자. 해당 workflow의 configure를 선택하자.\nrunners에 대한 상세 설명 여기를 확인하자.\nworkflow yml 파일을 작성해보자. 위에부터 아래 순으로 하나 하나 설명해보겠다.\nname, on, jobs, runs-on, steps, name, run은 github action에 내장된 keyword다. name: workflow의 이름을 말한다. 아래 예시의 이름은 First workflow다. on: 아래 workflow를 실행시킨 이벤트를 정의한다. workflow_dispatch는 Actions tap에서 수동적으로 직접 실행시키는 걸 말한다. jobs: job들을 정의한다. 첫 번째 job의 이름은 first-job 으로 명명한다. \u0026lsquo;firstjob\u0026rsquo;으로 해도 되고, job의 이름을 짓는 건 자유롭다. runs-on: 해당 job이 실행될 환경을 말한다. 구체적인 환경 확인은 위에 언급된 runners에 대한 설명을 본다. job마다 자신만의 runner를 가지고 있다. 즉 job마다 runs-on을 입력해야 한다. 이 말은 job마다 자신만의 virtual machine을 가져서 다른 machine과 job으로부터 완전히 격리시켜야 한다는 의미다. steps: 이제 여러 step들을 정의한다. 여기부터는 - 를 붙어서 key - value 형식으로 작성한다. 위에 Workflows, Jobs, Steps의 설명에 언급된 것처럼 step은 하나의 shell script를 실행하는데, 아래 step은 총 2개의 script를 실행하도록 정의했다. 1 2 3 4 5 6 7 8 9 10 name: First workflow on: workflow_dispatch jobs: first-job: runs-on: ubuntu-latest steps: - name: Print greeting run: echo \u0026#34;Hello World!\u0026#34; - name: Print Goodbye run: echo \u0026#34;Done - bye!\u0026#34; 위 스크립트는 여러 step을 통해 shell commands를 실행했다. 하지만 다음과 같이 pipe symbol(|)을 사용하여 하나의 step에서도 실행할 수 있다.\n1 2 3 4 ... run: | echo \u0026#34;First output\u0026#34; echo \u0026#34;Second output\u0026#34; 그러면 이를 다 작성했으면 오른쪽 상단에 Commit Changes...를 클릭하여 아래 이미지에 보이듯이 팝업창의 Commit changes 를 클릭하여 작성한 workflow를 생성하자.\n그러면 Actions tab을 클릭하면 다음 이미지처럼 화면이 보일 것이고, 오른쪽 위에 Run workflow를 클릭하면 실행할 브랜치와 수동으로 실행시킬 수 있다.\n직접 실행하는 workflow_dispatch로 실행할 경우, workflow의 name이 위 이미지처럼 title로 뜬다. 2.3 workflow를 실행시키는 event의 종류들 다음 실습을 실행하기에 앞서서 workflow를 실행시키는 여러 events들에 대해 알아보자.\ngithub action에서 내장된 event 들 중 많은 것들은 repository와 관련있다.\nrepository와 관련된 events push: pushing a commit pull_request: pull request action (opened, closed,..) create: branch 나 tag 생성 시 fork: repository가 fork 될 때 issues: 하나의 issue가 열리고, 삭제될 때 등등 issue_comment: Issue나 PR에 comment가 달릴 때 discussion: Discussion action과 관련하여 생성되고, 삭제되고, 수정되거나 등등 기타 등등 repository와 관련 없는 events workflow_dispatch: 수동적으로 workflow를 진행시키는 것 repository_dispatch: REST API 요청으로 workflow를 진행시키는 것 schedule: workflow를 특정 시간에 실행시키는 것 workflow_call: 다른 work flow에 의해서 호출될 경우 Github workflow의 이용 가능한 모든 event들을 알고 싶다면 여기 를 클릭하자.\n2.4 What are Actions? command는 작성자에 의해 정의되는 shell command로 대체로 단순한다.\n하지만 Action은 빈번하게 반복되는 일을 수행하는 애플리케이션으로 대체로 복잡하다. custom Action을 만들 수 있고, 또는 공식적인 Action을 사용할 수 있다.\n그래서 코드를 내려받는 Action 중에 actions/checkout이 존재한다. Github 팀에 의해서 만들어지고 유지 관리되고 있는 repository다.\n위 action외에도 github action market에 들어가면 여러 action을 확인할 수 있다.\n2.5 Practice 2 그러면 다음 실습으로 보다 실제 프로젝트에 가깝게 하기 위해서 local에서 workflow를 작성하여 진행해볼려고 한다.\n실습 1에서 만든 repository와는 상관 없이 진행한다. 두 번째로 진행할 실습은 참고 강의에서는 reactJS로 진행했다. reactJS를, js를 만질 줄 몰라도 상관없다. 이 글은 frontend를 학습하기 위한 글이 아닌, github action을 학습하기 위한 글이기 때문이다. 소제목이 무엇을 의미하는지, 또는 소제목 대로 진행하기 위해서는 어떻게 yml을 작성하면 되는지 를 이해하면 된다. 단지 실습을 통해서 여러 내용을 학습하기 위한 것일 뿐이다.\n이번 실습을 하기 전에 workflow를 진행시키는 event 들에 대해 알아보자.\n1 2 3 4 5 6 7 name: Test Project on: push jobs: test: runs-on: ubuntu-latest steps: - name: Get code run과 uses의 차이 그러면 다시 yml 작성으로 돌아가보자.\nname을 작성했으니 그 다음으로 runs를 작성하면 될까?\n그렇지 않다.\nruns은 Action이 아닌 command를 실행할 때 사용하는 내장된 키워드다.\nAction을 실행하기 위해서는 uses를 사용해야 한다. 그 다음으로 해당 Action의 식별자를 입력한다.\n1 2 3 4 5 6 7 8 name: Test Project on: push jobs: test: runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 actions/checkout은 github action market에 들어가서 checkout을 검색하여 들어가면 다음 이미지와 같이 Usage에서 - uses: actions/checkout@v3를 확인할 수 있다. Actions를 입력할 때 버전도 함께 입력하자. 업데이트 되면서 현재 사용하고 있는 Action이 조금 달라질 수도 있기 때문이다.\nwith 몇 몇 Action의 경우에는 추가적인 세팅을 요구하기도 한다. 그럴 때는 with keyword를 하단에 입력하여 사용한다. uses keyword를 사용한 후 입력한다.\n1 2 3 4 5 6 7 8 9 10 name: Test Project on: push jobs: test: runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 with: ... 그렇다면 추가로 입력해야하는 설정들의 key 값은 무엇이 있는지 어떻게 알 수 있을까?\n바로 위에 첨부한 이미지를 보면 uses keyword 밑에 with keyword가 있는 걸 알 수 있다. 이 설정들은 그대로 사용한다면 수정하지 않아도 되지만, custom 하여 사용한다면 수정해야할 수도 있다.\nactions/checkout@v3에는 특별하게 요구되는 옵션이 없으므로 with는 사용하지 않는다.\n이미 설치된 소프트웨어 확인 python 기반 프레임워크를 사용한다면 python을, js라면 Node.js 가 설치해야 한다. runs-on에 있는 작성한 소프트웨어에 미리 설치된 소프트웨어로 뭐가 있는지 확인해서 없으면 python 또는 node.js를 설치해야 한다. 이를 확인하기 위해서 pre-installed software에 있는 os 목록들 중 해당되는 os를 클릭하여 확인한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 name: Test Project on: push jobs: test: runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 - name: Install NodeJS uses: actions/setup-node # or - name: Install Python uses: actions/setup-python 직접 programming language 설치하기 하지만 만약 직접 설치를 해야한다면 다음과 같이 설치 step을 추가한다.\nstep을 추가할 때는 actions/setup-node 를 검색하여 나온 actions/setup-node 또는 actions/setup-python 을 검색하여 나온 actions/setup-python 에 들어가면 작성 안내를 확인할 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 name: Test Project on: push jobs: test: runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 # Python - name: Install Python uses: actions/setup-python@v4 with: python-version: \u0026#39;3.10\u0026#39; # or NodeJS - name: Install NodeJS uses: actions/setup-node@v3 with: node-version: 18 Dependency 설치하기 그 다음으로 dependency를 설치해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 name: Test Project on: push jobs: test: runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 # Python - name: Install Python uses: actions/setup-python@v4 with: python-version: \u0026#39;3.10\u0026#39; # dependency - name: Install dependencies run: pip install -r requirements.txt # poetry도 사용 가능하다. # or NodeJS - name: Install NodeJS uses: actions/setup-node@v3 with: node-version: 18 # dependency - name: Install dependencies run: npm ci test 실행하기 다음으로 test를 실행하는 step을 작성해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 name: Test Project on: push jobs: test: runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 # Python - name: Install Python uses: actions/setup-python@v4 with: python-version: \u0026#39;3.10\u0026#39; - name: Install dependencies run: pip install -r requirements.txt # tests - name: Run tests run: pytest # 해당 글 작성자는 pytest를 통해 test를 하기 때문에 pytest를 작성했다. # or NodeJS - name: Install NodeJS uses: actions/setup-node@v3 with: node-version: 18 - name: Install dependencies run: npm ci # tests - name: Run tests run: npm test 여기까지 작성했으면 remote repository에 push를 하자.\n❗️ udemy 강좌에서는 원격을 등록할 때 Personal access tokens 을 사용하는 방식으로 했으나 나는 그 방식을 사용하지 않았다. 만약 그 방식으로 remote origin을 등록했다면 github의 settings에 들어가서 New personal access token 항목에 들어가 Select scopes에서 workflow를 클릭한 후 토큰을 생성해야 local에서 작성한 workflow를 원격에 push할 수 있다.\nworkflow 확인하기 push가 완료된 후, github repository의 Actions tab에 들어가서 확인하면 생성했던 workflow가 이미 실행 중인 걸 확인할 수 있다. 왜냐하면 새로 생성된 workflow의 on keyword에 대한 value가 push 이기 때문이다.\n강의의 소스 코드 예제가 js이기 때문에 Node.js 중심으로 작성된 workflow다. 실행 결과는 다음과 같다.\n그러면 테스트 코드 일부를 수정한 후, 다시 원격에 push 해서 fail를 발생시켜보자. 실행 결과는 다음과 같다.\n실패한 step을 클릭하면 어느 부분으로 실패했는지까지 알 수 있다.\n여러 개의 job 추가하기: 병렬적으로 실행하기 이번에는 test 란 job에 추가로 deploy 라는 job을 추가해보자. job을 추가하는 것이기 때문에, test와 동일한 level로 띄어쓰기를 해야 한다.\n예제에서는 실제 hosting provider를 가지고 있지 않기 때문에 단지 echo 하는 걸로 대신하겠다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 name: Deploy Project # Test Project에서 다음과 같이 수정 on: push jobs: test: runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 # Python - name: Install Python uses: actions/setup-python@v4 with: python-version: \u0026#39;3.10\u0026#39; - name: Install dependencies run: pip install -r requirements.txt - name: Run tests run: pytest deploy: # 또 다른 job 추가하기 runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 - name: Install Python uses: actions/setup-python@v4 with: python-version: \u0026#39;3.10\u0026#39; - name: Install dependencies run: pip install -r requirements.txt - name: Deploy run: echo \u0026#34;Deploying...\u0026#34; # or NodeJS - name: Install NodeJS uses: actions/setup-node@v3 with: node-version: 18 - name: Install dependencies run: npm ci - name: Run tests run: npm test deploy: # 또 다른 job 추가하기 runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 - name: Install NodeJS uses: actions/setup-node@v3 with: node-version: 18 - name: Install dependencies run: npm ci - name: Build project run: npm run build - name: Deploy run: echo \u0026#34;Deploying...\u0026#34; 동일한 level로 아래와 같이 작성한 두 job들은 순차적으로 실행되는 게 아닌 아래 이미지처럼 병렬적으로 실행된다.\n완료되면 아래 이미지와 같이 Total duration으로 전체 걸린 시간을 알 수 있다.\n🔆 github action에 뜨는 workflow 소제목 직접 실행하는 workflow_dispatch로 실행할 경우, workflow의 name이 위 이미지처럼 title로 뜬다. 하지만 push 같은 자동적으로 실행되도록 하는 event의 경우 commit message가 title로 뜬다.\nadd new job이 commit message로 작성한 것 병렬이 아닌 순차적으로 workflow 실행하기 job 식별자를 입력한 후에 needs라는 내장 키워드를 입력하여, 선 작업을 지정한다. 선 작업으로 진행된 job이 끝나야 needs가 작성된 job이 실행될 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 name: Deploy Project on: push jobs: test: runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 ... deploy: needs: test # 선작업 지정하여 순차적으로 실행 runs-on: ubuntu-latest steps: - name: Get code uses: actions/checkout@v3 ... 아래 이미지에서 확인할 수 있듯이 Actions tap을 들어가보면 jobs의 위치가 바뀐 걸 알 수 있다.\n하지만 만약 test job이 fail되면 아래 이미지처럼 deploy는 실행되지 않는다.\n하나의 event가 아닌 여러 events를 trigger로 사용하기: 대괄호로 사용하기 이전 코드에서 작성된 event는 다음과 같이 하나다.\n1 2 3 4 5 6 7 name: Deploy Project on: push # 하나의 event jobs: test: ... deploy: ... 그러면 여러 event를 정의해보자. 여러 events를 정의하기 위해서는 대괄호를 사용해야 한다.\n1 2 3 4 5 6 7 name: Deploy Project on: [push, workflow_dispatch] jobs: test: ... deploy: ... 아래 이미지는 Multiple events로 수정하여 push하고, 수동적으로 workflow를 main branch에서 실행한 것이다.\nevent에 workflow_dispatch가 있기 때문에 동시에 workflow를 실행할 수 있다.\nExpressions and Github context 위 yml처럼 command를 실행할 수도 있지만 환경변수를 필요로 하는 command를 실행할 필요가 있을 수 있다.\n3번째 workflow output.yml 를 생성해보자.\n1 2 3 4 5 6 7 8 name: Output information on: workflow_dispatch jobs: info: runs-on: ubuntu-latest steps: - name: Output github context run: echo \u0026#34;${{ toJSON(github) }}\u0026#34; 위 workflow를 보면 ${{ }} 을 확인할 수 있다. 이 문법으로 작성된 text는 github에 신호를 보낸다.\nGithub에 의해서 이용가능하도록 만들어진 metadata에 접근할 것이다.\ngithub는 내장된 key 값이다. 그리고 Github의 내장된 함수인 toJson으로 이 값을 감쌀 것이다.\n내장된 context key값은 Github Actions context 를 확인하면 알 수 있다. 그리고 github actions의 내장된 function expression은 Github Actions expressions를 보면 알 수 있다.\ngithub key는 위 문서에 따르면 진행 중인 workflow에 대한 정보를 의미한다고 한다. toJSON은 위 문서에 따르면 JSON 형태로 바꿔준다.\n새로 생성한 workflow를 수동적으로 실행한 후, 출력물을 확인하면 github context object로부터 가져온 데이터를 확인할 수 있다. 아래 이미지를 확인하므로써 Practice 2를 마친다.\n3. Summary 그러면 Github actions의 core component인 workflow, job, step을 다시 짚어보자.\nCore components workflow 안에는 한 개 이상의 Job들이 존재하고, Job 안에는 한 개 이상의 step이 존재한다.\nworkflows: define Events + Jobs event란 workflow를 실행시키는 trigger다. 하나 이상의 event와 Job을 정의하는 component Jobs: define Runner + Steps runner와 step을 정의하는 component job들은 병렬로 또는 순차적으로 실행 가능하다. Steps: Do the actual works 실제 작업을 수행하는 component 여기서 work는 Github action에서 내장되어 정의된 작업 또는 직접 정의한 work가 해당된다. 실제로 실행되는 actions Events / Triggers Events의 종류에는 매우 다양한데, 크게 분류하자면 repository와의 관련 유무로 나눌 수 있다.\nworkflow 정의하기 .github/workflows/\u0026lt;file\u0026gt;.yml 인 경로로, 파일 형식으로 작성하여 정의한다.\n이 때 작성 장소는 local과 github 모두에서 작성 가능하다.\n그리고 Github Actions syntax를 반드시 따라야 한다.\nRunners runner는 job 들을 실행하는 서버들을 의미한다. 이 runners는 OS에 따라서 다르게 사전에 정의된 runner들이 존재한다. 하지만 custom runner도 정의내릴 수 있다. Reference [udemy lecture] Github Actions - The Complete Guide github actions billing policy github settings for repository github actions - runners github actions - runners: pre-installed software github actions - events that trigger workflows github actions market actions/setup-python actions/setup-node Github Actions context Github Actions expressions ","permalink":"http://jeha00.github.io/post/ci_cd/github_action/lecture_01/","summary":"github actions의 core components인 workflow, jobs, steps에 대해 알아보고 실습을 진행하면서 github action의 내장 keyword도 알아본다.","title":"CI/CD를 위한 github action study basic"},{"categories":"Network","content":"네트워크 학습 내용 순서 [TIL]Web Application Basic study: OSI 7 layer outline [TIL] Network OSI 7 layer: 1계층 [TIL] Network OSI 7 layer: 2계층 이번 장에서는 네트워크(Network) 계층인 3계층에 대해 알아보자.\n1. IP(Internet Protocol) 네트워크 계층 개요 네트워크 계층은 한 네트워크와 다른 네트워크 간 통신하기 위해 IP를 결정하는 계층 으로, 사용하는 \u0026lsquo;주요 프로토콜\u0026rsquo;은 IP(Internet Protocol) 를 사용한다. \u0026lsquo;주요 네트워크 기기\u0026rsquo;는 라우터 이며, \u0026lsquo;주요 데이터 단위\u0026rsquo; 는 packet 이다.\n네트워크 계층의 특징은 아래 4가지로 요약할 수 있다.\n비신뢰성 데이터가 송신지까지 도달하는 걸 보장하지 않는다. 그래서 인터넷 계층의 윗 계층인 4계층 전송 계층에서 이를 갖춘다. 그래서 데이터 순서가 바뀔 수도 있고, 서로 다른 경로를 통해 전송될 수 있다.\n비연결형 4계층 전송 계층과는 달리 연결설정 과정 없이 데이터를 전송한다.\n주소 지정 IP 주소를 제공하여 각 기기 장치가 식별될 수 있도록 하는 역할을 한다. MAC 주소는 컴퓨터의 물리적인 식별자라면 IP 주소는 인터넷 연결 간 논리적인 식별을 하는데 사용된다.\n경로 결정 이 IP 주소를 통해 라우팅의 경로 설정도 가능하다.\n2. IP 주소 IP 주소란? 그리고 IP 주소의 사용 목적 각 기기들을 식별하기 위한 논리적인 주소를 말한다. 네트워크에 연결되어 있는 기기(호스트나 라우터)들은 자신의 고유한 주소를 갖고 있어야 데이터를 주고 받을 수 있다. 이를 위해서 인터넷 프로토콜은 논리적인 주소인 IP 주소를 제공하여 데이터를 서로 송수신할 수 있게 한다.\n사설 네트워크(Private Network)와 공용 네트워크(Public Network) 사설 네트워크는 사설 IP를 사용하고, 공용 네트워크는 공인(공용) IP를 사용하며 ISP(Internet Service Provider) 인터넷 서비스 제공업체로부터 공인 IP를 할당받는다.\n인터넷에 접속하기 위해서는 반드시 공인 IP 주소가 필요하다. 그래서 사설 네트워크에서 인터넷에 접속하기 위해서는 공인 IP 주소를 거쳐야 한다.\nLG 유플럿, KT와 같은 인터넷 서비스 제공업체가 라우터에 공인 IP 주소를 부여한다.\n가정 내의 기기들과 사내 컴퓨터들은 사설 IP 주소가 할당되어 있다.\n다음 범위를 보면 알 수 있듯이 사설 IP와 공인 IP 네트워크 대역은 겹치지 않는다.\n[사설 IP 네트워크 대역]\n클래스 IP 주소 범위 A 10.0.0.0 ~ 10.255.255.255 B 172.16.0.0 ~ 172.31.255.255 C 192.168.0.0 ~ 192.168.255.255 [공인 IP 네트워크 대역]\n클래스 IP 주소 범위 A 0.0.0.0 ~ 9.255.255.255 A 11.0.0.0 ~ 126.255.255.255 B 128.0.0.0 ~ 172.15.255.255 B 172.32.0.0. ~ 191.255.255.255 C 192.0.0.0 ~ 192.167.255.255 C 192.169.0.0 ~ 223.255.255.255 IPv6 버전은 IPv4를 대체하기 위해 등장 IPv4 에서 4는 . 으로 나눠진 부분이 4군데여서 그렇다는 게 아닌 IP 를 표시하는 게 4세대 버전이라는 의미다. IPv6는 6세대 버전이라는 의미.\nIPv4: Internet Protocol version 4 IPv6: Internet Protocol version 6 IPv4 IPv6 주소 형식 192.168.10.1 FE80:CD00:0000:0CDE:1257:0000:211E:729C 주소 표현 10진수 16진수 크기 32bit(4 bytes) 128bit(16 bytes) 최대 표현 개수 약 43억개 범위: 0.0.0.0 ~ 255.255.255.255 무한대에 가깝다. 서비스 품질 제한적 품질 확장된 품질 보안 기능 IPSec 별도 설치 기본 제공 크기\nIPv4 기준으로 각각 8bit씩 총 4 부분 * 8bit = 32bit를 이룬다. IPv6 기준으로 각각 8bit씩 총 8 부분 * 16bit = 128bit를 이룬다. 8bit를 1 옥텟(octet)이라 부른다.\nNetwork ID와 Host ID 범위에 따라 Network ID와 Host ID로 구분할 수 있다.\n네트워크 ID: 전체 중 작은 네트워크를 식별하는 ID이자 호스트의 집합 대표 주소\n호스트 ID: 호스트를 식별\nIP 주소 클래스 (IPv4 기준) 클래스 IPv4 (2진수) IPv4 (10진수) 네트워크 ID 호스트 ID 비고 A 00000001. 00000000. 00000000. 00000000 0.0.0.0 ~ 127.255.255.255 8 bit 24 bit B 10000000. 00000000. 00000000. 00000000 128 .0.0.0 ~ 191.255.255.255 16 bit 16 bit C 11000000. 00000000. 00000000. 00000000 192 .0.0.0 ~ 223.255.255.255 24bit 8 bit D 11100000. 00000000. 00000000. 00000000 224.0.0.0 ~ 239.255.255.255 멀티캐스트용 E 11110000. 00000000. 00000000. 00000000 240.0.0.0 ~ 239.255.255.255 특수용도 예약주소 docker IP는 B 클래스에 해당된다. MAC 주소와 비교 MAC 주소: 48 bit, 16진수 IP 주소 (IPv4): 32 bit, 2진수 실제로는 2진수로 되어 있고, 사람이 보기 편하게 10진수로 되어 있다. A, B class의 문제점과 해결책 A 클래스와 B 클래스는 하나의 IP 주소로 많은 호스트를 가질 수 있다. 그런데 한 기관에서 이렇게 많은 호스트를 가지게 되는 경우는 없기 때문에, IP 주소가 낭비되는 문제가 발생된다. 또한, 이렇게 많은 컴퓨터가 패킷을 보내면 네트워크가 혼잡해진다. 이러한 문제점을 해결하는 방법이 이어서 학습할 내용인 \u0026ldquo;서브넷팅\u0026rdquo; 이다.\nIP 주소 확인하기: ifconfig IP 주소를 확인하는 명령어\nterminal에 ifconfig를 입력해보고, 뜨는 것을 분석해보자.\n이것이 네트워크의 전부다.\nlo0: loop back을 의미하는데, 자기 자신에게 보내는 데이터를 처리하기 위한 가상 인터페이스 장치 이름\ninet 127.0.0.1: localhost로 자신의 컴퓨터를 의미한다. netmask 0xff000000: 255.0.0.0 /8 11111111 00000000 000000000 00000000 en0: ethernet을 의미한다\ninet6 fe80::1872:9ed:4de7:e8c: IPv6 주소 inet 172.30.1.1: IPv4 주소로 내부 IP broadcast 172.30.1.255: broadcast address netmask 0xffffff00: 255.255.255.192 /26 11111111 11111111 1111111 11000000 3. Subnetting(서브넷팅) Subnetting, Subnet(서브넷), Subnet mask(서브넷 마스크) 란? 서브넷팅(subnetting) 이란 IP 주소를 클래스로 구분하는 방법으로, 네트워크를 작은 네트워크로 분할하여 너무 많은 IP 주소들이 낭비되는 문제를 해결하기 위한 기술이다. 이 분할된 네트워크를 Subnet(서브넷) 이라고 부른다. 서브넷들의 IP에서 어디까지가 네트워크 ID이고 호스트 ID인지 식별하기가 어려운데, 이를 돕는 게 바로 Subnet mask(서브넷 마스크) 이다. 네트워크 ID와 호스트 ID를 식별하기 위해서, 네트워크 ID에 해당되는 부분을 모두 1로, 호스트 ID에 해당하는 부분을 모두 0으로 표기하는 형식을 말한다.\n클래스별 서브넷 마스크 그래서 서브넷 마스크를 클래스 별로 표시하자면 다음과 같다.\n클래스 IPv4 (2진수) IPv4 (10진수) 프리픽스 표기법 A 255.0.0.0 11111111 00000000 00000000 00000000 /8 B 255.255.0.0 11111111 11111111 00000000 00000000 /16 c 255.255.255.0 11111111 11111111 11111111 00000000 /24 🔆 프리픽스 표기법: 서브넷 마스크를 슬래시 비트 수로 나타낸 것으로, 네트워크 ID 부분을 나타낸다.\n그래서 255.255.255.240인 경우, 8bit 3개에 4bit를 더해서 /28 로 표기한다.\n4. IP packet 과 header 역캡슐화의 관점에서 packet이란? 네트워크 계층보다 더아래에 있는 데이터 링크 계층에서는 데이터 단위를 \u0026lsquo;프레임(frame)\u0026lsquo;을 사용한다. 이 프레임에서 역캡슐화를 통해 이더넷 헤더와 트레일러를 제거한 것이 네트워크 계층에서의 프로토콜 데이터 단위인 \u0026lsquo;패킷(packet)\u0026lsquo;이 된다.\n캡슐화의 관점에서 packet이란? 또 네트워크 계층보다 위 계층의 데이터 단위인 TCP 세그먼트에서 캡슐화해서 IP 헤더를 붙인 것도 \u0026lsquo;패킷(packet)\u0026lsquo;이다.\nIP packet header에는 어떤 정보가 담겨져 있는가? (IPv4 기준) 데이터를 전달하기 위한 정보들이 포함되어 있다. 이 정보들을 사용하여 네트워크 계층의 장비인 라우터가 라우팅 동작을 하는데 핵심적인 역할을 수행한다.\n5. Router 가정 내에의 네트워크(LAN)에서 인터넷 네트워크(WAN)로 접속하기 위해서는 라우터가 필요하다. 그 이유는 이 라우터에는 ISP(ex: KT, SK telecom, LG U+)를 통해서 공인 IP를 부여받은 라우터를 거쳐야하기 때문이다.\n5.1 Router의 역할 라우터는 위 내용을 보다 일반화해서 표현하자면 \u0026lsquo;한\u0026rsquo; 네트워크에서 \u0026lsquo;다른\u0026rsquo; 네트워크로 데이터를 보내는 역할 을 한다.\n그러면 네트워크 계층보다 하위 계층인 데이터 링크 계층의 장비인 스위치부터 다시 생각해보자.\n스위치에 연결된 장비들은 같은 네트워크 범위에 있다. 그런데 네트워크를 통해 데이터를 보낼 때 반드시 동일한 네트워크 범위 내로만 보내는 게 아니다. 다른 네트워크에 있는 곳으로도 데이터를 보내야 한다. 이 때 이 네트워크 계층을 지나야하고, 이 계층에서의 장비가 \u0026lsquo;라우터\u0026rsquo;다. 이 라우터를 지나면 바로 다른 네트워크 로 갈 수 있지만, 때로는 목적지 네트워크에 도달하기 위해 해당 네트워크와 보다 가까운 \u0026lsquo;다른 라우터\u0026rsquo;를 판단 하기도 한다.\n아래 이미지를 통해 보다 자세히 알아보자.\nNetwork 1과 Network 3 사이에는 Network 2가 존재한다. Router 1은 network 1 뿐만 아니라 network 2에도 연결이 되어 있다. 복수의 인터페이스를 제공하며 이에 맞는 물리적 배선과 IP 주소가 설정되어 있다. 그래서 라우터에는 각 네트워크마다 연결되어 있어서 여러 IP 주소를 가진다.\n5.2 Routing 과 Routing table 그렇다면 라우터는 다른 네트워크로 가는 경로를 어떻게 아는 것일까? 이에 대한 답은 바로 \u0026lsquo;라우팅 테이블\u0026rsquo; 에 있다. 위 이미지 양 끝단에 Router 1과 Router 2에 대한 라우팅 테이블이 존재한다.\n라우팅 테이블에 대해 간략히 설명하기에 앞서 \u0026lsquo;라우팅\u0026rsquo; 이란 단어에 대해 알아보자.\n라우팅 이란 패킷을 목적지 IP까지 최적의 경로로 전송할 수 있도록 이 경로를 찾는 동작을 말한다. 이 라우팅을 하기 위해서는 경로에 대한 정보를 라우터가 가지고 있어야 가능하다. 그 정보가 등록되고 관리되는 테이블이 라우팅 테이블 이다. 라우팅 하기 위해 라우팅 테이블을 이용한다.\n5.3 라우터에서 MAC 주소와 IP 주소 MAC 주소는 우리가 사용하는 desktop, labtop 뿐만 아니라 스위치와 라우터도 포함하여 각 장치마다 부여된 고유의 물리적인 주소다. MAC 주소는 랜카드에 탑재되어 있고, 랜카드(LAN card 또는 Network Interface Card, NIC)는 각 기기마다 존재하기 때문이다.\n다른 네트워크에 전달하기 위해서는 여러 기기들을 전송 도중에 거쳐야하기 때문에 라우터를 거치면 도착지 MAC 주소와 출발지 MAC 주소를 바꿔가며 전송하게 된다. 즉 프레임 데이터의 관점에서 보자면 이더넷헤더와 FCS(트레일러)가 교체된다는 의미다. 다음으로 전송해야할 MAC 주소를 알아내기 위해서 \u0026lsquo;ARP\u0026rsquo; 라는 다른 프로토콜을 사용한다.\n하지만, IP 헤더의 경우 NAT 주소 변환 시를 제외하고는 도착지 IP와 출발지 IP 주소는 변하지 않고, TTL과 헤더 체크섬이 변경된다.\n5.4 라우터 간의 통신 🔆 그렇다면 라우터 간 통신은 어떻게 하는 걸까?\n출처: 네트워크 전반적인 과정에 대해 문의드립니다. 위 출처에 따르자면 한 라우터에 다른 라우터로 이동할 때 라우터마다 내부적으로 물리 계층 - 데이터 링크 계층 - 네트워크 계층 까지의 캡슐화와 역캡슐화가 계속 이뤄진다고 이해하면 된다.\n라우터에서 데이터를 받으면 역캡슐화 작업을, 데이터를 보낼 때는 캡슐화 작업을 거친 후 다른 라우터에게 보내진다. 이는 라우터뿐만 아니라 스위치도 마찬가지다.\n스위치도 스위치 끼리 물리 계층 - 데이터 링크 계층 까지 캡슐화와 역캡슐화가 계속 이뤄진다고 이해하면 된다.\n6. Routing Protocols 6.1 개요 라우팅 과정에서 사용되는 프로토콜들에 대해 알아보자. 라우팅 프로토콜은 라우팅 정보를 교환하기 위한 프로토콜이다.\n라우팅 방식에는 \u0026lsquo;정적\u0026rsquo; 과 \u0026lsquo;동적\u0026rsquo; 라우팅으로 나눠진다. 전자는 \u0026lsquo;관리자가 직접 관리\u0026rsquo;하는 방식으로 수동으로 해야하므로 비효율적이다. 후자는 라우팅 테이블의 정보를 주기적으로 받아 갱신하는 방식이다.\n이번 소단원에서 알아볼 라우팅 프로토콜들은 이 동적 라우팅에 사용되는 프로토콜이다.\n동적 라우팅 프로토콜은 AS(Autonomous System)을 기준으로 어떤 역할을 하느냐에 따라서 내부 라우팅 프로토콜과 외부 라우팅 프로토콜로 분류할 수 있다.\nAS(Autonomous System) 란 하나의 회사나 조직에서 관리하는 라우터들의 집합으로, 이 AS들로 네트워크가 구성되어 체계적으로 네트워크를 관리할 수 있다.\n여러 AS들 간에 라우팅을 수행하는 외부 게이트웨이 라우팅 프로토콜을 \u0026lsquo;EGP(Exterior Gateway routing Protocol)\u0026rsquo; 이라고 하며, 하나의 AS 내부에서 라우팅을 수행하는 내부 게이트웨이 라우팅 프로토콜을 \u0026lsquo;IGP(Interior Gateway routing Protocol)\u0026rsquo; 라 한다.\nEGP의 종류\nBGP IGP의 종류\nRIP(Routing Information Protocol) OSPF(Open Shortes Path First) 그러면 IGP에 대해 알아보자.\n6.2 IGP IGP: RIP(Routing Information Protocol) RIP는 목적지로 도착하기까지 홉 수 정보를 저장하고 인접 라우터와 주기적으로 정보를 공유하는 방법 이다. 여기서 홉 수(Hope Count) 이란? 목적지로 도착하기까지 거쳐야 하는 링크 또는 라우터의 수를 말한다.\n일반적으로 30초 마다 라우팅 테이블을 갱신하며, 120초 동안 정보를 받지 못하면 경로 단절로 판단된다. 단절된 경우 무한 으로 표시하거나, 홉 수 16으로 표시하기도 한다.\n사용 포트로는 UDP 520번 포트를 사용한다.\n그러면 RIP를 사용하는 라우팅 테이블을 아래 그림에서 확인해보자. 아래 그림을 보면 30초마다 갱신되는 정보를 확인할 수 있다. 이렇게 주기적으로 인접 라우터와 정보를 공유하는 방법 이 RIP이다.\nRouter A의 홉 수 계산을 다음 아래와 같이 할 수 있다. 나머지 Router B와 C도 동일한 방식으로 계산된다.\n[Router A]\nRouter A에서 Network 1 또는 2를 가기 위해서는 다른 Router를 거칠 필요가 없으므로 홉 수 0 Router A에서 Network 3을 가기 위해서는 Router B를 거쳐야 하므로 홉 수 1 Router A에서 Network 4를 가기 위해서는 Router B, C를 거쳐야 하므로 홉 수 2 이러한 RIP 방식에는 느린 수렴(Slow Convergence) 문제가 존재한다. 예를 들어서 네트워크와 라우터 간 연결이 끊어졌을 경우, 해당 라우터의 라우팅 테이블에 적힌 홉 수는 무한대로 수정된다. 그러면 주변 라우터들에게도 이 상황 정보가 빠르게 전달되야 하는데, 느리게 전달되어 모든 라우터가 변경 사항을 적용하는데 오랜 시간이 걸린다.\n이 문제점을 해결하기 위해서 3가지 방식 을 사용한다. 첫 번째는 홉 수를 16으로 수정 하여 홉 수가 15를 넘으면 바로 16으로 수정하여 상황 정보를 받지 않아도 바로 수정하는 방식으로 적용 시간을 단축할 수 있다. 두 번째는 Split - Horizon 방식으로 전달하는 정보를 구분하여 전송하는 방식으로 단절 상황에 관한 정보만 전달하고, 다른 라우터에게서 받은 라우팅 정보를 다시 상대방에게 전달하지 않는 방법을 말한다. 세 번째는 Triggered Update 방식이다. 이는 갱신되는 시간 간격 30초와 상관없이 단절되는 상황이 발생하면 바로 전달하는 방식이다.\nIGP: OSPF (Open Shortest Path First) OSPF는 가장 많이 사용하는 IGP(내부 게이트웨이 프로토콜)의 한 종류로, 링크 상태 알고리즘 및 광고 기법으로 사용한다. 가장 짧은 경로 계산은 Dijkstra(다이제스트로) 알고리즘으로 최적의 경로를 계산한다.\n그리고 OSPF는 라우팅을 효과적으로 수행하기 위해서 네트워크를 영역 단위로 나누어 관리하는데, AS 내에 여러 개의 영역으로 나눈 다음 내부의 라우터들끼리 각 영역에서 라우팅 정보를 교환하는 계층적 구조 를 가진다.\n6.3 NAT(Network Address port Translation) IP 주소는 이용하는 범위에 따라서 공인과 사설로 나눌 수 있다. 공인은 인터넷을 시용할 때 반드시 필요한 것이고, 사설은 가정 내 네트워크 또는 사내 네트워크 처럼 사설로 사용하는 네트워크다.\n사설 네트워크에 속한 장비로 사설 네트워크 내의 통신을 할 때는 필요 없다. 하지만, 사설 IP 주소에서 인터넷 같은 \u0026lsquo;공인 IP 주소\u0026rsquo;에 접속하려고 할 때 사설 네트워크 그대로 인터넷을 사용할 수 없기 때문에 NAT 가 필요하다.\n그러면 이 \u0026lsquo;NAT\u0026rsquo;에 대해 알아보자. 이 NAT를 통해서 인터넷 접속을 위해 사설 IP 주소를 공인 IP로 변환이 필요하고, 이 작업을 위해서 NAT 프로토콜을 사용한다.\nIP 패킷에는 출발지 IP 주소와 도착지 IP 주소가 있는지를 기억하자. 집에서 브라우저를 통해 데이터를 보내고자할 때, 이 패킷은 웹 서버로 보내고자 하기 때문에 출발지 IP 주소는 사설 주소이고 도착지 IP 주소는 공인 주소가 된다. 이 주소 설정으로는 웹 서버까지 요청 전송이 문제 없이 가능하지만, 응답이 제대로 도착하지 않는다. 왜냐하면 사설 IP 주소의 범위와 공인 IP 주소의 범위가 다르기 때문이다.\n이 문제를 해결하기 위해 NAT를 사용해보자.\n사설에서 패킷을 보낼 경우, 출발지 IP 주소는 사설 주소이고 도착지 IP 주소는 공인 주소다. 웹 서버에 도착하기에 앞서서 라우터의 NAT 테이블을 통해 출발지 사설 IP 주소를 공인 IP 주소로 바꾼 후, 웹서버에게 전달한다. 그리고 변환한 주소의 정보를 NAT 테이블에 보존한다. 그 후, 웹 서버가 응답을 보낼 때 패킷이 라우터에 도착하면 NAT 테이블을 바탕으로 목적지 IP 주소를 공인에서 저장했던 사설로 바꾼다. 그러면 정확하게 사설 IP로 데이터가 도착한다.\n6.3 ARP(Address Resolution Protocol) 알아낸 내용 앞서 학습한 내용을 통해 우리는 2가지를 알았다.\n첫 번째, MAC 주소는 각 장치마다 부여된 고유의 물리적인 주소이기 때문에 전송 도중에 거쳐야할 기기들을 지나면서 데이터의 이더넷 헤더와 FCS가 교체되면서 목적지 MAC 주소와 출발지 MAC 주소가 바뀔 수 있다.\n두 번째, 도착지 IP 주소와 출발지 IP 주소는 그대로다 (단, NAT 주소 변환은 예외)\nARP란? 그런데, 첫 번째 사실에서 MAC 주소가 바뀌는 이유는 네트워크를 지나는 데이터들은 한 네트워크 내에서 뿐만 아니라 여러 개의 네트워크를 지나는 경우가 많기 때문이다. 이렇게 여러 개의 네트워크를 지나기 위해서는 라우터가 다음 라우터로 데이터를 전송하기 위해서 물리적인 주소인 IP 주소뿐 아니라 물리적인 주소인 MAC 주소도 알아야 한다. 그러나 보내는 측의 입장에서는 목적지 IP 주소는 알 수 있더라도 \u0026lsquo;목적지 MAC 주소\u0026rsquo;는 알 수 없다. 그러면 이 문제에 대한 해결책은 무엇일까?\n해결책이 바로 IP 목적지 IP 주소를 통해 목적지 MAC 주소를 알아내고자 하는 방법 인 ARP 다.\n패킷 -\u0026gt; ARP로 대응시켜 캡슐화 -\u0026gt; 프레임\n패킷의 IP 헤더: 목적지 IP 주소, 출발지 IP 주소 프레임의 이더넷 헤더: 목적지 MAC 주소, 출발지 MAC 주소 ARP의 주소 해석 이렇게 ARP로 목적지 IP 주소를 통해 목적지 MAC 주소를 알 수 있는데, ARP의 \u0026lsquo;주소 해석\u0026rsquo; 을 사용해서 알 수 있다. IP 주소와 MAC 주소를 대응시키는 것을 \u0026lsquo;주소 해석\u0026rsquo; 이라고 한다.\n다음으로 이 주소 해석에 대해 알아보자.\nARP 요청을 통해 목적지 IP 주소에 대응하는 MAC 주소를 질의한다. 이 때 ARP는 \u0026lsquo;브로드캐스트 방식\u0026rsquo; 으로 전송한다. 브로드캐스트 방식으로 전송하기에 다수의 호스트에 요청하며 이 때 브로드캐스트 주소는 48 비트가 모두 1이기에 \u0026lsquo;FF:FF:FF:FF:FF\u0026rsquo; 다.\n여러 호스트에서 이 요청을 받고, 질의를 받는 IP 주소를 가진 호스트 즉 목적지 IP 주소와 동일한 주소를 가진 호스트가 ARP 응답으로 MAC 주소를 알려준다. 응답은 \u0026lsquo;유니캐스트 방식\u0026rsquo; 으로 전송한다.\n해당 IP 주소와 MAC 주소의 대응 정보를 ARP 캐시에 저장한다.\nARP 캐시는 획득한 목적지 정보를 20분 동안 저장한다. 저장 후 또 다시 MAC 주소 요청이 들어오면 ARP 캐시에 저장된 정보를 사용한다. 6.4 ICMP ICMP란? ICMP가 나온 배경을 이해하기 위해서 IP의 특징을 다시 한 번 짚어보자.\n비신뢰성: 신뢰성 있는 전송은 \u0026lsquo;전송 계층\u0026rsquo;에서 이뤄진다 비연결형 주소 지정: IP 주소 경로 설정: 라우팅 TCP를 사용하는 4계층은 데이터가 중간에 유실될 경우를 고려한 전송 서비스를 제공하지만, 3계층은 데이터 전송 후 제대로 도착했는지 확인하지 못한다. 그래서 3계층의 이러한 문제점을 해결하기 위해 \u0026lsquo;ICMP\u0026rsquo; 가 개발되었다. 이 프로토콜은 목적지 IP로의 데이터 전송 여부를 확인할 수 있게 해주는 프로토콜 을 수행한다. 그래서 \u0026lsquo;2가지 기능\u0026rsquo;을 가지고 있다.\n보내는 측에게 네트워크 내에서 일어나는 에러 상황을 통보하거나 네트워크 상태를 진단하는 기능을 제공한다.\n에러 보고 (Reporting) 기능 질의 (Query) 기능 ICMP 헤더 ICMP는 프로토콜이지만 IP 헤더에 의해 캡슐화되는 게 특징이다.\nIP 헤더 + ICMP 헤더 + 데이터 이 ICMP 헤더에는 타입, 코드, 체크섬, ICMP 데이터가 포함되어 있다.\n타입: ICMP 메시지 유형으로 Reporting 인지, Query 인지 코드: 타입 값의 내용 체크섬: 에러 검사 역할 데이터: 타입과 코드에 따라서 달라진다. Type 설명 용도 0 Echo Reply 질의 3 Destination Unreachable 에러 4 Source Quench 에러 5 Redirect 에러 8 Echo Request 질의 11 Time Exceeded 에러 0번, 3번, 8번을 자주 확인할 수 있다. ICMP 사용 상황 예시 네트워크 망이 다음과 같이 구성되어 있다고 하자.\nPC A - Router 1 - Router 2 - PC B PC A에서 PC B에게 데이터를 전송하는 도중 패킷이 Router 2에서 유실되거나 폐기되었다고 하자.\n그러면 라우터는 ICMP 메시지를 통해서 IP 패킷이 도중 유실된 이유를 원래 출발지인 PC A에게 통지한다.\nICMP 메시지 목적지: PC A 출발지: Router 2 이를 통해서 ICMP는 목적지 IP로의 데이터 전송 과정 중에 에러 상황을 출발지로 통보하는 기능을 수행한다.\nICMP 메시지 이 ICMP 메시지를 보고 싶다면 \u0026lsquo;ping\u0026rsquo; 명령어를 사용해보면 된다.\nPing(Packet INternet Groper)의 약자로, 네트워크 상태를 점검 및 진단하는 명령어\n나중에 서버를 구출할 때, 그 서버에 ping을 날려보면 데이터를 보내고 받을 수 있는지 확인할 수 있다.\n터미널 실행 후, ping google.co.kr를 입력해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026gt; ping google.co.kr PING google.co.kr (172.217.26.227): 56 data bytes 64 bytes from 172.217.26.227: icmp_seq=0 ttl=114 time=45.149 ms 64 bytes from 172.217.26.227: icmp_seq=1 ttl=114 time=36.573 ms 64 bytes from 172.217.26.227: icmp_seq=2 ttl=114 time=44.751 ms 64 bytes from 172.217.26.227: icmp_seq=3 ttl=114 time=44.796 ms 64 bytes from 172.217.26.227: icmp_seq=4 ttl=114 time=40.381 ms 64 bytes from 172.217.26.227: icmp_seq=5 ttl=114 time=45.104 ms 64 bytes from 172.217.26.227: icmp_seq=6 ttl=114 time=37.562 ms 64 bytes from 172.217.26.227: icmp_seq=7 ttl=114 time=36.680 ms ^C --- google.co.kr ping statistics --- 8 packets transmitted, 8 packets received, 0.0% packet loss round-trip min/avg/max/stddev = 36.573/41.375/45.149/3.740 ms 총 8개의 packet을 보내고, 받았다는 걸 알 수 있다. 이렇게 Ping을 보내어 해당 서버와 통신 유무를 확인할 수 있다. 이 때 보내지는게 ICMP 에코 요청 응답 메시지다. 이 메시지를 통해서 다음 요소들을 확인할 수 있다.\n원격지 호스트 라우터 동작 여부 원격 호스트까지 왕복 시간 중간 손실되는 메시지 크기 등등 Reference 나노디그리 러닝스푼즈: Python \u0026amp; Django backend course 네트워크, 그림으로 이해해자 네트워크 기초(4) - OSI 7계층 - 3계층: 네트워크 계층 ","permalink":"http://jeha00.github.io/post/network/osi_7_layer/3_layer/","summary":"OSI 7 layer에서 한 네트워크에서 다른 네트워크와 통신하기 위한 IP 주소를 결정하는 3계층에 대해 더 알아보자.","title":"[TIL]OSI 7 layer: 3계층 네트워크 계층"},{"categories":"Network","content":"네트워크 학습 내용 순서 [TIL]Web Application Basic study: OSI 7 layer outline [TIL] Network OSI 7 layer: 1계층 이번 장에서는 데이터 링크(Data link) 계층인 2계층에 대해 알아보자.\n1. 데이터 링크 계층(2계층) 개요 네트워크 장치 간 데이터를 전송하는 기능과 절차를 제공하는 으로, 물리적 주소 설정, 흐름제어, 에러제어 등을 수행한다.\n이 계층에서 \u0026lsquo;주요 네트워크 기기\u0026rsquo;는 스위치 이고, \u0026lsquo;주요 프로토콜\u0026rsquo;은 이더넷, CSMA/CD 다. \u0026lsquo;주요 데이터 단위\u0026rsquo;는 Frame 이다.\nFrame의 구성: 이더넷 헤더 + IP 헤더 + TCP 헤더 + 응용 헤더 + User data + 트레일러 2. 주요 프로토콜 첫 번째: 이더넷 데이터를 전송하는 프로토콜, 네트워크를 구성하는 기술 방식\n대부분의 LAN은 이더넷 방식 ISO에서 국제 표준으로 지정 초기 네트워크 규격은 버스형이어서 CSMA/CD 기술이 사용되었다. 하지만 점차 데이터의 양이 매우 많아지면서 고속 네트워크 망이 필요하여 아래 기술이 현재 사용 중이다. Gigabit Ethernet 데이터의 전송속도가 1Gbps로 향상 기존의 이더넷과 호환 스타넷(성형) 네트워크 토폴로지 이용 이더넷 규격(참고) 이더넷 규격 전송 속도 전송 매체 기타 10BASE5 10Mbps 동축 케이블 초기 이더넷의 규격 10BASE2 10Mbps 동축 케이블 초기 이더넷의 규격 10BASE-T 10Mbps UTP 케이블 100BASE-FX 100Mbps 광섬유 케이블 1000BASE-SX 1000Mbps 광섬유 케이블 1000BASE-LX 1000Mbps 광섬유 케이블 10GBASE-T 10Gbps UTP 케이블 SX: Short wavelength / LX: Long \u0026hellip; SX와 LX는 전송 거리의 차이: 550m / 5Km 3. 주요 데이터 단위: 프레임 3.1 이더넷 헤더와 트레일러 이더넷 헤더 이더넷 헤더에는 다음 정보가 포함되어 있다.\n목적지 MAC 주소 + 출발지 MAC 주소 + 타입 타입: 상위 계층의 프로토콜 종류를 구분하는 역할 (IPv4, IPv6..) 이더넷 트레일러 이더넷 트레일러에는 오류 발생 체큐 용도로 사용되어 FCS(Frame Check Sequence) 라 불린다. 이 프레임을 주고 받으면서 MAC 주소를 얻는다.\n3.2 이더넷 프레임 프레임(Frame)이란? 이더넷 헤더와 트레일러가 붙으면서 캡슐화된 데이터를 프레임 이라 한다.\n캡슐화와 역캡슐화 시 프레임 변화 캡슐화 시 이더넷 헤더와 트레일러를 부착하지만, 역캡슐화 시 이더넷 헤더와 트레일러를 제거하면서 전송한 데이터를 받는다.\n이더넷 프레임의 크기 이더넷 프레임의 크기는 64 ~ 1518 byte로, 이 이더넷헤더 + packet + 트레일러 3가지를 포함한 크기다.\n각 부분의 크기는 다음과 같다.\n이더넷 헤더: 14 Byte 목적지 MAC 주소 (6 Byte) + 출발지 MAC 주소 (6 Byte) + 타입 (2 Byte) packet: 46 ~ 1500 Byte 트레일러: 4 Byte 3.3 주요 식별자: MAC 주소 MAC 주소란? 이더넷에서 특정 인터페이스를 식별하기 위한 48bit의 물리적인 주소다. 컴퓨터가 제조될 때 새겨지는 전 세계에서 유일한 번호로서, 장치의 실제 주소를 식별하기 때문에, MAC 주소 = 물리 주소 = 하드웨어 주소 로 생각하면 된다.\n물리 주소, 하드웨어 주소라고도 불린다. 사용 용도 허브 또는 스위치에 2대 이상의 컴퓨터가 연결되어 있을 때, 스위치는 어느 포트에는 어느 MAC 주소로 이어지는지에 대한 정보가 담겨 있는 MAC 주소 테이블 을 사용하여 무슨 컴퓨터에 데이터를 전달할지를 결정한다.\n스위치가 동작하는 과정에서 MAC 주소가 MAC 주소 테이블에 저장된다.\n표기: 16진수로 총 48bit\nex) 11-AA-11-AA-11-AA, 11:AA:11:AA:11:AA, 11AA. 11AA. 11AA 앞 24bit: 랜 카드 제조사 번호 뒤 24bit: 제조사가 붙인 일련 번호 MAC 주소와 IP 주소의 차이 MAC(Media Access control) IP(Internet Protocol) 개념 미디어 접속 제어 주소 인터넷 프로토콜 주소 목적 장치의 실제 주소 식별 (물리적 주소) 인터넷에서의 기기 간 연결을 식별(논리적 주소) 주소 표기와 크기 16진수 표기, 48비트 IPv4: 10진수, 32비트 // IPv6: 16진수 128비트 공급자 NIC 카드 제조업체에서 지정 네트워크 관리자 또는 ISP (Internet Service Provider) 4. 주요 네트워크 기기: 스위치 스위치란? 스위치에 연결된 장치들끼리 이더넷을 이용한 \u0026lsquo;하나의 네트워크\u0026rsquo;를 구성하는 기기로, 기존 허브에서 MAC 주소 테이블을 활용한 스위칭 기능을 추가해서 Point to Point 접속이 가능해져 속도 저하를 개선했다.\n더미 허브와 외관상 차이 거의 없다.\n스위치는 연결된 장치의 물리적인 주소인 MAC 주소를 구분해서 해당 주소가 있는 장치로 데이터를 보내주는 장비 다.\nMAC 주소 테이블 원리 더비 허브의 문제점을 극복한 방법은 \u0026lsquo;MAC 주소 테이블\u0026rsquo;이다. 각 port 별 연결된 장치의 Mac 주소를 이 테이블에 이미 저장해놓기 때문에 연결된 모든 포트에 데이터를 전달할 필요 없이 해당되는 Mac 주소에 연결된 포트로만 데이터를 보내면 된다.\n스위치 동작 플러딩(flooding): MAC 주소 테이블에 frame header에 있는 목적지 MAC 주소 정보가 없을 경우, 전송 받은 포트를 제외한 다른 모든 포트로 데이터를 보내는 동작 필터링(filtering): 데이터의 도착지 MAC 주소와 MAC 주소 테이블의 MAC 주소와 비교한 후, 일치하지 않을 경우 전송하지 않는 동작 포워딩(forwarding): 일치할 경우 전송하는 동작 5. 반이중 통신, 전이중 통신 통신 종류 반이중 통신 전이중 통신 정의 데이터의 송수신을 \u0026lsquo;번갈아가며\u0026rsquo; 하는 방식 데이터의 송수신을 \u0026lsquo;동시에\u0026rsquo; 하는 방식 이더넷 사용 시기 초기 현재 그래서 반이중 통신은 데이터 송수신이 동시에 불가능하다. 6. 주요 프로토콜 두 번째: CSMA/CD CSMA/CD 란 Carrier Sense Multiple Access/Collision Detection 의 약어다.\n이 개념이 등장한 배경은 네트워크 망 형태가 버스형처럼 되어 있어서 여러 대의 기기가 동시에 데이터를 전송하면 충돌이 일어난다. 이를 해결하고자 나온 것이 CSMA/CD 다.\nCS(Carrier Sense)는 \u0026lsquo;반송파 감지\u0026rsquo;, MA(Multiple Access)는 \u0026lsquo;다중 접속\u0026rsquo;, CD(Collision Detection)는 \u0026lsquo;충돌 탐지\u0026rsquo; 를 의미하는데 이를 해석하자면 처음에는 CS의 의미대로 케이블이 현재 사용 중인지 감지하여, MA의 의미대로 다른 곳에서 사용 중인지 통신 회선이 비어있는지를 확인한다. 만약 케이블에 트래픽이 없으면 충돌 없이 데이터는 성공적으로 전송된다.\n하지만, 다른 컴퓨터에서도 데이터를 보내서 CD의 의미대로 충돌이 감지된다면 그 즉시 데이터의 전송을 중지하고 각 컴퓨터에서는 랜덤 시간이 설정되어 기다린 후 데이터를 전송한다. 컴퓨터 A, B에서 각각 서로 충돌되는 방향으로 데이터를 보내어 충돌이 감지된다면 A는 10초를, B는 20초를 기다린 후 데이터를 재송신한다.\nCSMA/CD 알고리즘 7. 랜카드(NIC: Network Interface Card) NIC가 동작하는 계층 NIC 카드 는 랜카드 라고도 하는데, NIC 제조 업체에서 MAC 주소를 지정하고 이 주소를 랜카드에 기입한다.\n그렇다면 NIC는 1계층인가 2계층인가? NIC는 이 두 계층 모두에서 동작할 수 있다.\n랜카드 자체는 1계층에서 작동하는데, 이를 더 상세히 풀어서 설명하자면 물리 계층으로부터 받은 디지털 정보를 전기 신호로 변화하는 역할을 수행하는게 랜카드다.\n하지만 랜카드 드라이버를 설치하여 이 드라이버를 통해서 2계층인 데이터 링크 계층에서도 동작한다. 왜냐하면 위에서 언급한 대로 랜카드에는 MAC 주소가 기입되어 있고 이 MAC 주소를 2계층에서 사용하기 때문이다.\n그래서 \u0026lsquo;속하였다\u0026rsquo; 라고 생각하기보다는 \u0026lsquo;이 계층들에서 동작할 수 있다\u0026rsquo; 라고 생각하는 게 정확하다.\n이를 운영체제와의 관계 관점에서 보자면 다음과 같다.\n응용 프로그램 \u0026lt;-\u0026gt; 운영체제의 네트워크 스택 \u0026lt;-\u0026gt; 랜카드 드라이버 Reference 나노디그리 러닝스푼즈: Python \u0026amp; Django backend course 네트워크, 그림으로 이해해자 ","permalink":"http://jeha00.github.io/post/network/osi_7_layer/2_layer/","summary":"OSI 7 layer에서 \u0026lsquo;네트워크 기기\u0026rsquo; 간의 데이터 전송과 물리 주소를 결정하는 계층인 2계층에 대해 더 알아보자.","title":"[TIL]OSI 7 layer: 2계층 데이터 링크 계층"},{"categories":"Network","content":"네트워크 학습 내용 순서 [TIL]Web Application Basic study: OSI 7 layer outline 이번 장에서는 1계층인 물리 계층(physical layer)에 대해 알아보자.\n0. 물리 계층(1계층) 개요 OSI 7 layer에서 제일 하위에 있는 계층으로, 데이터 링크로부터 받은 데이터를 케이블 같은 전송 매체로 전송하기 위해서 \u0026lsquo;전기 신호\u0026rsquo;로 변환하는 역할 을 한다. 그래서 전송 매체와 관련이 깊다.\n이 계층에서 \u0026lsquo;주요 네트워크 기기\u0026rsquo;는 각 장치들을 중계하고 신호를 증폭하기 위해서 사용되는 리피터 와 허브 다. 주요 데이터 단위는 비트(bit) 다.\n1. 네트워크 전송 매체: 케이블 위에서 언급한 것처럼 변환된 전기 신호를 전달해주기 위해서는 \u0026lsquo;전송 매체\u0026rsquo;가 필요하다. 전송매체의 종류에는 유선 케이블과 무선 케이블로 크게 나눠진다.\n1.1 유선 케이블: 3가지 UTP 케이블(일반적으로 불리는 LAN cable) 우리가 흔히 랜선이라 부르는 케이블이다. 이 케이블을 분해해서 보면 선이 꼬아져 있는데 이는 노이즈를 억제하기 위해서다. UTP 케이블의 종류는 2가지로 나눠진다.\nUTP 케이블의 종류: 다이렉트 케이블, 크로스 케이블 양 각 끝의 RT 커넥터에 연결된 선의 위치가 동일하면 다이렉트 케이블, 크로스되어 다르면 크로스 케이블이다. UTP 케이블 규격도 별도로 존재한다. 동축 케이블, 광섬유 케이블 위 두 케이블에 대한 상세 설명은 생략한다.\n1.2 무선 케이블 유선 케이블처럼 선이 꼬이지 않지만, 속도가 불안정하며 보안상 위험하고, 전파에 영향을 많이 받는다.\n전체 구조 무선 LAN 액세스 포인트(ex: 공유기) + 무선 LAN 클라이언트(ex: 공유기에 연결한 노트북들)\n연결 방식: 2가지 인프라스트럭처 방식: 유선 이더넷에 연결된 공유기를 중심으로 기기들이 연결된 상태\n애드혹 방식: 무선 클라이언트끼리 직접 통신하는 방식 ex) 닌텐도 근거리 통신\n2. 주요 네트워크 기기: 리피터와 허브 2.1 리피터(중계 역할) 통신 기기가 서로 멀리 있을 때 거리에 반비례해서 신호가 약해지는데, 이를 증폭하여 다시 신호를 복원하고 거리를 더 연장시키는 기기다. 하지만 요즘 네트워크 장비는 리피터의 기능을 기본적으로 내장되어 나오기 때문에 리피터가 별도로 필요하지 않다.\n2.2 허브 여러 컴퓨터들을 서로 중계해주는 역할을 하는 네트워크 장비로서, 리피터의 증폭 역할이 내장되어 있다. 허브의 종류로는 더미 허브 와 스위칭 허브 로 2가지가 있고, 전자는 이 1계층에서 후자는 2계층에서 사용된다.\n2.2.1 더미허브(1계층의 주요 장비(중계 역할만 담당)) 1계층에는 지정된 header가 없어서 허브의 포트들에 연결된 모든 컴퓨터에게 데이터를 전송하기 때문에(broadcast 방식), 네트워크의 전체 대역폭(bandwidth)을 허브에 연결된 컴퓨터들끼리 분할해서 사용하는 방식이다.\n예를 들어 대역폭이 100Mbps 라고할 때, 이 허브에 연결된 컴퓨터가 4대라면 각 컴퓨터의 대역폭은 25Mbps씩 나눠서 속도를 지원한다. 그래서 연결된 장치가 많아지면 속도가 저하되기 때문에 작은 환경에서만 사용하는 방식이다.\n더미 허브의 문제점 이 더미 허브에 노트북 pc1, pc2, pc3, pc4가 연결되어 있다고 해보자. pc1이 pc2에게만 데이터를 전송하고 싶어도 더미 허브는 포트에 연결된 모든 클라이언트에게 데이터를 전송하기 때문이다. 즉, 특정 대상으로 전송하는 능력이 없다. 2.2.2 스위칭 허브(스위치): 2계층의 주요 장비 대역폭을 나눠 사용하여 속도 저하가 되는 더미 허브의 문제점을 개선한 허브로, 데이터를 전송하는 기능만 있는 더미 허브와 달리 각종 관리 기능이 추가되어 있다.\n이 스위칭 허브에 대한 상세 설명은 2계층 내용 정리에서 다룬다. 1계층에서의 허브는 \u0026lsquo;더미 허브\u0026rsquo;를 의미한다 허브의 종류에는 위와 같이 2가지가 존재하지만 1계층에서의 주요 네트워크 기기로 언급되는 \u0026lsquo;허브\u0026rsquo;는 실제로 \u0026lsquo;더미 허브\u0026rsquo;를 의미한다.\n계층 보편적 통칭 또 다른 표현 2계층 스위치 스위칭 허브 1계층 허브 더미 허브 3. 네트워크 토폴로지 from: 위키피디아 성형 중앙 집중식 형태 일대일 장단점 장점: 고속의 대규모 네트워크 단점: 중앙 시스템 고장 시 전체 네트워크 중단 버스형 구조가 가장 간단 장단점 장점: 구조가 간단하여 설치가 쉽고 비용이 저렴 단점: 어느 한 곳에 장애가 발생 시, 전체 네트워크에 영향 링형 고리 모양으로 둥글게 연결\n장단점\n장점: 케이블 비용 저렴, 네트워크 전송 시 충돌이 없다. 단점: 어느 한 곳에 장애가 발생할 시 전체 네트워크가 중단, 재구성이나 변경이 어렵다 망형 공중 전화망과 공중 데이터 통신망에 적합\n장단점\n장점: 한 곳에 장애가 발생하여도 다른 회선을 사용하면 되서 신뢰성이 높음 단점: 설치 비용이 높고, 유지보수가 힘들다. 또한, 어느 한 곳에 장애가 발생하면 발생 위치를 추적하기 어렵다 4. 더미 허브와 LAN 카드의 관계 \u0026lsquo;LAN 카드 \u0026lsquo; 는 들어온 디지털 신호를 전기 신호로 바꿔주는 역할을 수행한다.\nLAN 카드에 의해서 바뀐 전기 신호를 \u0026lsquo;더미 허브 \u0026lsquo; 가 감지하여, 이 전기 신호를 더미 허브에 연결된 모든 포트 로 연결 매체를 통해 전송하는 역할을 한다.\n그리고, 이 전기 신호를 받는 대상의 컴퓨터에서는 이 들어온 전기 신호를 이 컴퓨터의 LAN 카드에 의해서 디지털 데이터로 다시 변환 한다.\n즉 다음과 같은 순서로 진행된다.\nPC A의 랜카드 -\u0026gt; 전송 매체 -\u0026gt; 더미 허브의 포트 -\u0026gt; 더미 허브 -\u0026gt; 더미 허브의 각 모든 포트 -\u0026gt; 전송 매체 -\u0026gt; PC B의 랜카드 (여기서 전기 신호는 디지털 데이터로 변환)\n➕ 추가 내용\nLAN 카드는 우리가 흔히 사용하는 데스크탑과 랩탑에만 있는 장치가 아니다. 네트워크와 연결된 스위치, 라우터에도 존재한다. 그리고 위에서 언급된 것처럼 LAN 카드에는 MAC 주소도 포함되어 있기 때문에, 스위치와 라우터도 MAC 주소를 가지고 있다.\nReference 나노디그리 러닝스푼즈: Python \u0026amp; Django backend course 네트워크, 그림으로 이해해자 ","permalink":"http://jeha00.github.io/post/network/osi_7_layer/1_layer/","summary":"OSI 7 layer에서 데이터를 전기 신호로 변환하여 전송매체로 보내는 1계층에 대해 더 깊이 알아보자.","title":"[TIL]OSI 7 layer: 1계층 물리 계층"},{"categories":["Python"],"content":"0. Introduction Poetry와 Pyenv의 자주 사용하는 명령어를 정리해둔다.\nPoetry를 사용하는 이유 dependency를 group 별로 나눠서 관리할 수 있다. dependency 간 충돌을 관리 해주고, 설치 시 기본적으로 최신 버전으로 설치해준다. package 관리 뿐만 아니라 가상환경까지 설치 가능 하다. import 시 절대 경로 로 사용할 수 있다. ❗️이를 위해서 만든 app 안에 설치하는 게 아닌 밖에 설치해야 한다. Pyenv를 사용하는 이유 virtualenv \u0026lt;가상환경 이름\u0026gt; --python=\u0026lt;python version 명\u0026gt; 으로 생성하는 방식의 경우, 가상환경을 버전과 관련하여 정리하지 않는다. 하지만, pyenv의 경우에는 버전별로 설치한 후, 이 버전 안에서 여러 가상환경을 만들기 때문에 같은 python 버전을 공유하는 여러 가상환경이 있으면 패키지를 공유할 수 있다.\nPoetry로 생성한 가상환경을 사용하지 않는 이유 위에 Pyenv를 사용하는 이유와 동일하다. Poetry로 생성한 가상환경은 일반 가상환경이랑 관리 방식이 동일하다. 버전별로 관리하는 게 아닌, poetry가 생성한 가상환경을 기준으로 디펜던시를 설치하기 때문에, 동일한 파이썬 버전이어도 가상환경이 다르면 아래처럼 파이썬 패키지가 중복 설치되는 문제점이 존재한다.\n- Poetry로 생성한 가상환경 1 (Python 3.10.8 사용) - bin/ - lib/ - Poetry로 생성한 가상환경 2 (Python 3.10.8 사용) - bin/ - lib/ 1. Poetry 명령어 정리 poetry 공식문서는 여기를 클릭한다.\nPoetry 설치 및 삭제하기\n설치하기: curl -sSL https://install.python-poetry.org | python3 - 삭제하기: curl -sSL https://install.python-poetry.org | python3 - --uninstall pyproject.tomal 생성하기: poetry init\npoetry에 dependency 추가하기 : poetry add {dependency name to install}\ndependency를 group 별로 추가하기:poetry add --group {group name} {dependency to install}\npoetry에 dependency 제거하기: poetry remove {dependency name}\npoetry의 pyproject.toml에 있는 dependencies 설치하기: poetry install\n현재 프로젝트에 있는 pyproject.toml을 읽어서, 해당 dependencies 를 설치하는 명령어로, 실행하면 poetry.lock 이 생긴다. poetry.lock과 pyproject.toml이 일치하지 않는 문제가 생기면 lock을 삭제한 후, 다시 poetry install을 실행하자. Poetry가 바라보고 있는 가상환경 정보 확인하기: poetry env info\n위 명령어는 pyproject.toml이 존재하는 directory에서 실행한다. Poetry 버전 확인: poetry --version\n2. Pyenv 명령어 정리 pyenv 공식문서는 여기를 클릭한다.\n실행 명령어: pyenv shell {python version installed} 설치된 버전들 확인: pyenv versions 설치할 수 있는 파이썬 버전들 확인: pyenv install --list 파이썬 특정 버전 설치하기: pyenv install {python version to install} 가상환경 생성하기: pyenv virtualenv {python_version to install} {virtualenv_name to install} 가상환경 지정하기(활성화하기): pyenv shell {virtual_name installed} 가상환경 삭제하기: pyenv uninstall {virtualenv installed} 3. Poetry와 Pyenv 사용 순서 pyenv 가상환경을 생성 pyenv 가상환경 활성화하기 프로젝트 내부로 이동 후, poetry init 실행 poetry env info 로 system과 가상환경 모두 pyenv를 바라보는지 확인 poetry에 dependency 추가하기 dependency를 모두 추가하면 poetry install 실행: 개인 프로젝트는 파이썬 공식 프로젝트가 아니기 때문에 반드시 해야한다. main.py가 있는 위치로 이동 후, 프로젝트 실행 ❗️ poetry 설치 후 프로젝트 directory 경로가 절대경로로 인식되지 않는다면 가상환경이 제대로 실행되고 있지 않거나, poetry가 설치가 잘 안된 것이므로 재확인한다. 이런 경우 poetry install를 잊지 않는다.\n❗️ poetry env info 를 실행하여 Virtualenv 와 System 모두 pyenv를 바라보고 있는지 확인한다.\n4. Poetry 설치 시 프로젝트 directory 구조 pyproject.toml에서 name의 값이 project root directory가 기본적으로 들어가지는데 이를 기준으로 절대경로가 형성된다.\n그리고 Dockerfile 실행 시 pyproject.toml과 동일한 레벨에 해당 name을 가지고 있는 directory 와 README.md 가 poetry 설치가 가능하여 container 화가 가능하다.\n1 2 3 4 5 6 7 8 # directory 구조 - \u0026lt;생성한 project name\u0026gt; ㄴ config ㄴ \u0026lt;app 또는 domain name\u0026gt; ㄴ pyproject.toml ㄴ poetry.lock ㄴ README.md Reference 파이썬 의존성 관리자 Poetry 사용기 poetry 가상환경 pyenv 가상환경 ","permalink":"http://jeha00.github.io/post/python/others/3_poetry_pyenv/","summary":"Poetry와 Pyenv의 자주 사용되는 명령어를 정리한다.","title":"Poetry 와 Pyenv의 자주 사용하는 명령어 정리"},{"categories":"architecture","content":"1. What is DDD and its advantages? 이번 프로젝트의 구조를 DDD로 잡아가기로 결정되어 이에 대한 기본적인 내용을 정리해본다.\n1.1 DDD란? DDD(Domain-Driven Development)는 2003년 에릭 에반스가 Domain-Driven Design이라는 책을 처음 출간하면서 소개한 개발 방법론으로, \u0026ldquo;훌륭한 소프트웨어를 개발하고 싶다면 서비스 도메인에 귀를 기울여라\u0026quot;라는 슬로건으로부터 시작되었고, 현재는 서비스 개발에 가장 큰 주류를 이루고 있는 개발 방법론이다.\n1. 도메인 레벨과 코드 레벨의 용어와 구조를 일치시키는 것 용어 일치: domain model과 software entity의 이름을 일치시키기 구조 일치: domain logic에 code logic을 일치시키기 2. 코드를 계층별로 분리하고 추상화 수준을 구별하는 것 4개의 계층으로 분리하여 추상화 수준을 구별한다.\nPresentation layer Application layer Domain layer Infrastructure layer 각 layer가 무슨 역할을 하고, 무엇을 의미하는지는 다음 챕터에서 알아본다.\n1.2 DDD의 장점 첫 번째, 소통이 편리하다 도메인 전문가(기획자)와 개발자 간의 소통을 도와준다. 개발자들도 다른 사람의 코드를 이해하기가 쉬워진다. 두 번째, 유지보수가 편리하다 의존성을 제어하기 때문에 유지보수가 편리하다\nLoose Coupling (느슨한 결합)과 High Cohesion(높은 응집)\ndomain 간에는 Loose Coupling domain 내에서는 High Cohesion 이를 위해서 class로 만들어 추상화한다.\n2. Layers of DDD DDD의 layer는 각 도메인 당 Presentation, Application, Infrastructure, Domain layer로 총 4개로 구성된다.\n그러면 각 레이어가 무슨 역할을 하는 지 정리해보겠다.\n2.1 Each layer of DDD Presentation Layer request를 받아서 response를 하는 layer로 코드 레벨에서는 \u0026ldquo;controller\u0026quot;가 이에 해당된다.\n위 요약문처럼 request를 받아서 response를 하는 레이어지만, 이를 보다 자세히 말하자면 다음 3가지만을 드러내야한다.\nAPI url 설정 request model, response model 상세 비지니스 로직 수행을 하기 위한 service를 하위 layer인 Application layer에서 호출하여 실행 Application Layer 비지니스 로직을 정의하는 layer로 코드 레벨에서는 \u0026ldquo;service\u0026quot;가 이에 해당된다.\n이 레이어에서는 비지니스 로직을 정의한다.\nDomain Layer domain model과 비즈니스 룰을 정의하는 layer로, 코드 레벨에서는 \u0026ldquo;model\u0026quot;이 이에 해당된다.\nmodel entity를 정의하고, model structure와 state를 관리한다.\nInfrastructure Layer 실제 구체적인 처리를 담당하는 곳으로, 주로 외부와의 통신을 담당한다.\n코드 레벨에서는 \u0026ldquo;repository\u0026quot;가 이에 해당된다.\n예를 들어 RDBMS, NoSQL 그리고 email 발송을 위해 Email client와 접촉하는 부분이 이 레이어가 된다.\n해당 앱 외 부분들은 외부에 해당된다.\n각 layer의 code level에서의 명칭 정리 각 레이어와 각 레이어가 코드 레벨에서 구현된 명칭은 다음과 같다.\nDDD Layer code level name Presentation controller Application service Domain model Infrastructure repository 2.2 Dependency between layers 각 layer는 다음과 같이 의존성을 띈다.\nPresentation Layer → Application Layer → Infrastructure Layer + Domain Layer\nPresentation Layer는 바로 밑에 Application Layer를 의지하고, Application Layer는 Infrastructure와 Domain Layer를 의지한다.\n이를 코드 수준으로 표현하자면 다음과 같다.\ncontroller -\u0026gt; service -\u0026gt; repository 순서로 의존성을 가진다.\ncontroller는 service 만 호출한다. service 는 repository 만 호출한다. 이를 도메인 간으로 생각하면 다음과 같다.\n여러 도메인이 결합된 문제를 해결할 때는 의존성이 어떻게 띄게 될까?\nA domain의 controller 에서 B domain의 service 를 호출하여 여러 도메인이 결합된 문제를 해결한다. A domain의 service 에서 B domain의 repository 를 호출하여 여러 도메인이 결합된 문제를 해결한다. A domain 의 repository 는 B domain의 repository 를 의지하지 않는다. A domain 의 service 는 B domain의 service 를 의지하지 않는다. 위 2가지의 이유는 다음과 같다.\ncircular import error를 방지하기 위함이다. domain 간 coupling이 많이 생기기 때문인데, 이를 보다 구체적으로 말하자면 각 layer마다 가지고 있는 역할들이 존재하는데 이 역할들이 명확해지지 않아진다. 그러면 DDD 아키텍처가 시간이 지날수록 유지하기 힘든 시스템 구조가 된다고 한다. 2.3 그리고 class를 사용하여 추상화한다 어째서 class를 사용하는가?\n결합도에 따른 코드 관리 클래스는 기본적으로 강하게 결합된 요소는 모아두고, 약결합된 요소를 분리하거나 의존성 주입(dependency injection) 이라는 형태를 통해 가져다가 사용한다. 이러한 결합도에 따른 코드 분리는 \u0026ldquo;무엇이 무엇과 연결되어 있는가\u0026rdquo; 를 신경쓰는지 않도록 하여 \u0026lsquo;인지 비용\u0026rsquo;을 줄일 수 있다.\n상태 관리 클래스는 함수와 달리 상태(state)를 속성으로 관리한다. 특정 상태를 여러 함수에서 사용해야 한다면 함수에서는 다른 함수를 부를 때마다 그 값을 반환해야하지만, 클래스는 해당 정보를 선언하면 클래스 내의 메서드에서는 자유롭게 가져와서 사용하거나 다른 메서드를 호출하면 된다.\n코드 재사용 도메인 간에 특정 layer에 중복된 형태의 로직이 발견된다면 해당 중복 코드를 상위 클래스로 만들어 분리할 수 있다.\n","permalink":"http://jeha00.github.io/post/architecture/what_is_ddd/","summary":"DDD란 무엇이고, layer 간 의존성은 어떻게 띄고 있고, 어떻게 구성하는지에 대해 정리해본다. 또한 이를 class를 사용하여 추상화하는 이유도 정리해본다.","title":"DDD basic concept"},{"categories":"DB","content":"0. Introduction 원티드 백엔드 챌린지 2월: MySQL \u0026lsquo;잘\u0026rsquo; 사용하기 를 듣고 정리한 포스팅입니다.\n해당 챌린지의 목표는 주니어 개발자 및 개발 준비생을 대상으로 하기 때문에, MySQL의 특징을 이해하여 효율적으로 사용하고, MySQL 기본 개념들을 학습하여 기술 면접에 대비하는 게 목적입니다.\n그래서 운영체제의 cache 운용도가 높은 storage engine을 최적화할 때 어떻게 해야하는가 또는 쿼리 효율 개선 같은 내용은 다루지 않습니다.\n해당 포스팅의 주제와 키워드 이번 포스팅의 주제는 [Big Tech가 MySQL을 선택하는 이유] 입니다.\nKeyword: Transaction, Database Lock, Isolation Level\nMySQL installation Mac에서 MySQL 설치는 해당 문서 How to Install MySQL 8 on macOS Using Homebrew를 참고하자.\nMySQL 로그인 root 모드: mysql -u root -p 1. MySQL을 사용하는 BigTech와 이유 MySQL을 사용하는 BigTech Uber, Airbnb, Pinterest, Netflix, Twitter, Amazon, Udemy, Slack\nMySQL을 사용하는 이유 transaction을 요구할 때 에러없이 넣고 싶으면 RDBMS를 사용\n오픈 소스\n2. MySQL storage engine 데이터 읽기/쓰기를 담당하며, 어떤 스토리지 엔진을 사용하느냐에 따라서 MySQL에 데이터를 읽고 쓰는 방법이 다름\n2.1 Engine의 종류 MySQL 엔진은 크게 SQL 엔진과 Storage 엔진으로 나눠진다.\nSQL engine의 역할 query parsing\nORM 사용 시 이 기능을 통해서 SQL 문법으로 바꿔주는 역할 query optimizing\n쿼리를 실행하면 \u0026lsquo;실행계획\u0026rsquo;이라는 걸 가지고서 DB가 최적화를 스스로 고민 후 실행한다. 그러면 storage engine이 실행된 SQL을 바탕으로 데이터를 가져온다. query 실행\n더 상세한 Engine 종류는 MySQL 설치 및 실행 후 SHOW ENGINES을 입력하면 된다.\n2.2 중요한 Storage engines 위 이미지에 있는 ENGINE을 지금 단계에서는 다 알기보다는 아래 3가지만 알고 있자.\nMyISAM MEMORY InnoDB (제일 중요) 요즘은 innoDB가 default create table을 할 때 별도로 지정해주지 않는다면 default engine이 사용 ❗️ MEMORY ENGINE의 경우, memory에 저장되어 cache로 사용되는데 이 ENGINE을 사용하기보다는 redis를 사용해보자. (이런 게 있다 정도로만 알고 있자.)\nInnoDB의 장점 버퍼링\nread는 foreground thread를, write는 background thread를 사용한다. 그래서 thread pool에 한계가 있어서 모아서 진행해서 효율을 높이는 기능 Foreign key\ntransaction\nInnoDB만 transaction을 지원한다. InnoDB 때문에 MySQL에서도 postgreSQL처럼 transaction이 가능하다. 3. 🔆 Transaction 사용자의 작업셋을 \u0026lsquo;모두 완벽하게 처리\u0026rsquo; 하거나 \u0026lsquo;처리하지 못하면 원상태로 복구\u0026rsquo; 하여 작업의 완전성을 보장하는 하나의 논리적인 작업 단위\n그러면 MySQL InnoDB가 지원하는 transaction에 대해 눈으로 직접 확인해보자.\n🔆 서버 개발자들은 직접 db에 접근하지 않고 흔히들 ORM을 사용한다. 각 프레임워크에서는 각 ORM별로 트랜젝션을 지원하는 쿼리가 존재하기 때문에 사용해봐야 한다.\n3.1 트랜잭션의 특징 ACID Atomicity(원자성) 한 트랜잭션의 연산들이 모두 성공하거나, 반대로 전부 실패되는 성질\nA 계좌에서 B 계좌로 돈 500만원을 입금한다고 하자. A 계좌의 현재 잔액은 1000만원, B 계좌의 현재 잔액은 0원이다.\n첫 번째, A 계좌의 잔액 1000만원을 500만원으로 수정한다. 두 번째, B 계좌에 잔액 0원을 500만원으로 수정한다. 성공적으로 수행된다면 A, B 각 계좌에는 500만원이 남는다.\n하지만 일부만 적용된다면 예를 들어 만약 첫 번째 과정만 수행되고, 두 번째 과정이 실패된다면 A 계좌의 500만원은 세상에서 사라지는 돈이 된다. 그러므로 한 가지라도 실패한다면 모든 작업이 실패로 돌아가야 한다. 이것이 원자성이다.\nConsistency(일관성) 허용된 방식으로만 데이터를 수정해야 한다.\n데이터베이스의 모든 데이터는 여러 가지 조건, 규칙에 따라 유효해야 한다.\n예를 들어 A한테 500만원이 있고, B는 0원을 가지고 있다. A는 B에게 최대 500만원을 송금할 수 있다. 하지만, B는 어떤 돈도 송금할 수 없다. 0원이기 떄문이다. 만약 돈을 송금할 수 있다면 해당 데이터는 유효하지 않다.\nIsolation(고립) 트랜잭션 수행 시 서로 끼어들지 못한다.\n복수의 병렬 트랜잭션은 서로 격리되어 마치 순차적으로 실행되는 것처럼 작동되어야 하고, 여러 사용자가 같은 데이터에 접근할 수 있어야 한다.\n하지만 순차적으로 접근이 가능하다면 성능이 떨어진다.\nDurability(지속성) 성공적으로 수행된 트랜잭션은 영원히 반영되어야 한다.\n3.2 트랜젝션을 지원하는 스토리지 엔진(InnoDB)와 트랜젝션을 지원하지 않는 스토리지 엔진(MyISAM) 비교 1) Engine이 다른 table 생성하기 엔진 설정이 각각 InnoDB고 MyISAM인 table을 생성해보자.\nSHOW databases 를 사용하여 databases 목록을 확인하고, 사용할 database를 use \u0026lt;database name\u0026gt;을 사용하여 database를 바꾼다.\nENGINE이 MyISAM인 DB\nCREATE TABLE myisam (id INT NOT NULL, PRIMARY KEY(id)) ENGINE=MyISAM; ENGINE이 InnoDB인 DB\nCREATE TABLE innodb (id INT NOT NULL, PRIMARY KEY(id)); default이므로 따로 ENGINE을 입력하지 않아도 된다. 생성된 table 보기: SHOW CREATE TABLE \u0026lt;생성된 table 이름\u0026gt;\n2) 정수 5 data 추가하기 desc \u0026lt;table name\u0026gt;;으로 구조를 출력할 수 있다.\nmyisam에 데이터를 추가한다.\nINSERT INTO myisam (id) VALUES (5); SELECT * FROM myisam 으로 table 데이터를 확인한다. innodb table에 데이터를 추가한다.\nINSERT INTO innodb (id) VALUES (5); SELECT * FROM innodb 으로 table 데이터를 확인한다. 3) 정수 1부터 5까지 data 추가해보기 myisam에 추가: INSERT INTO myisam (id) VALUES (1), (2), (3), (4), (5); 실행 결과: Duplicate entry '5' for key 'myisam.PRIMARY' innodb에 추가: INSERT INTO innodb (id) VALUES (1), (2), (3), (4), (5); 실행 결과: Duplicate entry '5' for key 'innodb.PRIMARY' 4) 실행 결과 확인해보기 myisam 확인해보기: SELECT * FROM myisam\nid 1 2 3 4 5 innodb 확인해보기: SELECT * FROM innodb\nid 5 🔆 innodb는 트랜젝션을 지원하기 때문에 한 가지 작업이라도 에러가 발생되어 처리되지 못하자 원상태 그대로를 유지한다. 이것이 바로 Transaction 이다.\n3.3 어떻게 가능한 걸까? \u0026lsquo;Buffer pool\u0026rsquo; 과 \u0026lsquo;Undo log\u0026rsquo; 를 사용한다.\nBuffer pool: 일괄적으로 모아서 처리하는 공간 Undo log: error가 발생되면 되돌리기 위해 데이터를 임시로 저장하는 공간 테이블의 데이터를 변경하는 작업을 하기 전에 다음 작업들이 일어난다.\n위에서 정수 1부터 5까지를 추가하는 명령어를 실행했었다.\ndisk에는 id가 5인 값이 저장되어 있는 상태였다. 명령어를 실행하면 Buffer pool에 먼저 id가 1부터 5인 값이 생성된다. Undo log에는 1)번 상태를 기억해두고 있다. 2)번에서 buffer pool에서 생성한 데이터를 하나씩 disk에 추가한다. 4)번 과정에서 error가 발생되면 3)번에서 기억해둔 데이터를 disk로 가져와 복귀시킨다. 3.4 Transaction - states transaction에도 상태(state)가 존재한다.\n3.2 어떻게 가능한 걸까? 에서의 각 과정은 다음과 같이 진행된다.\nActive state -\u0026gt; Partially commited state -\u0026gt; Failed state -\u0026gt; Aborted state -\u0026gt; Terminated state 만약 성공적으로 흘러가면 다음과 같이 진행된다.\nActive state -\u0026gt; Partially committed state -\u0026gt; Commited state -\u0026gt; Terminated state 4. Database Lock 하나의 데이터를 동시에 여러 명이 조작할 수 없도록 데이터를 잠궈서 동시성을 보장하는 기능\n[Lock의 종류: MySQL engine lock vs InnoDB lock]\nSQL 엔진이 제공하는 lock: global lock, table lock, named lock, meta-data lock MySQL의 InnoDB가 제공하는 lock: record lock, Auto increment Lock 등등 위 Lock의 종류들은 다 MySQL이 알아서 Lock을 걸고 풀기 때문에 잘 사용되지 않는다.\nDEAD LOCK 한 곳에서만 자원에 접근이 가능하고, 다른 곳들로부터 자원에 접근하는 걸 막은 걸 \u0026lsquo;DEAD LOCK\u0026rsquo;이라 한다.\n만약 이 상황에 계속해서 지속되면 좋지 못한 상황이기 때문에 innoDB에서는 이 같은 Lock을 따로 관리리하는 table이 존재한다.\n4.1 글로벌 락(Global lock) 범위가 가장 넓은 lock으로서, 서버 전체에 영향을 미치기 때문에 A 서버에서 global lock을 걸면 B 서버에까지 적용된다.\n잘 사용되지 않는다.\nGlobal lock 걸기: FLUSH TABLES WITH READ LOCK;\nGlobal lock을 해제하기: Global lock을 걸은 서버에서 MySQL과의 연결이 끊겨야 해제\nSELECT를 제외한 모든 쿼리들이 대기상태로 남기 때문에, 쿼리를 입력해도 진행이 되지 않는다.\n서버 전체에 영향을 미치기 때문에 작업 대상이나 테이블이 다르더라도 동일하게 영향 받는다.\ntable이 myisam 상태에서 global lock을 걸면 innoDB에 있는 서버도 락이 걸린다. 4.2 Table Lock 특정 테이블에 대한 lock으로서 read lock과 write lock으로 나눠진다.\nread lock: READ 작업만 가능하도록 잠그는 기능\nLOCK TABLES innodb READ; write lock: WRITE 작업만 가능하도록 잠그는 기능\nLOCK TABLES innodb WRITE; lock을 걸지 않으면 DB를 read 또는 write하기 직전에 data가 바뀔 수 있기 때문이다.\n해당 명령어를 사용할 일은 거의 없다. 그 이유는 특별한 상황이 아니라면 다른 작업에 영향을 미치기 때문이다.\n테이블에 데이터를 변경하는 쿼리를 실행하면 자동으로 lock이 발생한다.\n데이터 추가, 변경 시 lock 설정 데이터 변경 commit 시 lock release InnoDB의 경우에는 DML 쿼리에서는 lock이 작동하지 않과 DDL의 경우에만 영향을 미침 스토리지 엔진의 구조 차이라는 정도만 알아두자. READ LOCK test 한 터미널에서 READ LOCK test 해보기\nREAD LOCK 걸기: LOCK TABLES innodb READ; UPDATE 작업 실행: INSERT INTO innodb (id) VALUES (34); 실행 결과: ERROR 1099 (HY000): Table 'innodb' was locked with a READ lock and can't be updated READ LOCK 풀기: UNLOCK TABLES; UPDATE 작업 실행 완료 두 터미널(A, B)에서 READ LOCK test 해보기\nA terminal에서 innodb에 대해 READ LOCK을 걸어보자. B termianl에서 UPDATE 작업 실행: INSERT INTO innodb (id) values (98); 결과: 쿼리문이 진행되지 않는다. A terminal에서 READ LOCK을 풀어보자: UNLOCK TABLES; 대기되고 있던 UPDATE SQL이 바로 진행된다. WRITE LOCK test 두 터미널(A, B)에서 READ LOCK test 해보기 Temianl A: LOCK TABLES innodb WRITE; 실행 Terminal B: SELECT * FROM innodb; 를 입력하면 실행되지 않고 LOCK에 걸린다. Terminal A: UNLOCK TABLES; 실행 Terminal B: 2)번에 명령어 바로 실행 4.3 Named Lock GET_LOCK()이라는 명령어로 임의의 문자열에 대해 잠금을 설정하는 Lock COMMIT 후 SELECT RELEASE_LOCK(문자열)을 입력하여 Lock이 해제된다. 자주 안사용한다. 여러 클라이언트가 상호 동기화를 처리해야할 때 사용할 수 있다. 많은 레코드에 대해 복잡한 요건으로 변경하는 트랜잭션에 유용하다. ❗️ MySQL에서는 autocommit이란 전역 변수가 참으로 되어 있어서 COMMIT 이 자동적으로 된다. 이를 확인하기 위해서는 SET GLOBAL VARIABLES LIKE 'autocommi';를 입력하면 확인할 수 있고, AUTO COMMIT을 끄고 싶으면 SET GLOBAL autocommit=0;을 입력한다.\nLock test A, B termianl에서 test 진행\nTerminal A: SELECT GET_LOCK('wanted', 30); 30분 동안 wanted 라는 문자열에 대해 사용하는 걸 잠금한다.\n결과: True\nGET_LOCK(\u0026lsquo;wanted\u0026rsquo;, 30) 1 SELECT IS_FREE_LOCK('wanted');: 를 실행하여 LOCK이 자유로운지 확인하면 다음과 같은 결과가 뜬다. 0은 False를 의미하므로 Lock 걸려있다는 상태를 말한다.\n| IS_FREE_LOCK('wanted') | | ---- | |0 | Terminal B: SELECT GET_LOCK('wanted', 20); 이미 A terminal에서 잠궜기 때문에 위 명령어는 잠겨져 대기하게 된다. Terminal A: SELECT RELEASE_LOCK('wanted');를 실행하면 Lock이 풀리면서 2)번 명령이 실행될 수 있다. 4.4 메타데이터 락 데이터베이스 객체(table, column)의 이름이나 구조를 변경하는 경우에 사용되는 락\n테이블 락처럼 별도의 명령어를 사용할 수는 없고, 테이블을 변경하는 등의 작업을 할 때 자동으로 가져왔다가 release한다.\n이는 다른 락과 달리 명령어가 없어서 직접 보여줄 수 없으니 이런 게 존재하는 것만 알고 있자.\n4.5 레코드 락 입력한 쿼리에 해당되는 record / row를 가져오는 동안 이 record / row에 lock을 거는 것 EXPLAIN SELECT * FROM innodb;: 해당 쿼리를 설명하는 테이블을 가져온다. id select_type table partitions type possible_keys key key_len ref rows filtered Extra 1 SIMPLE innodb NULL index NULL PRIMARY 4 NULL 2 100.00 Using index 여기서 rows column에서 2라고 나와있는데, 위 쿼리로 데이터를 가져오는 동안 2개의 row에 record lock을 거는 것\n만약 이게 8만개라면? 8만개의 row가 record lock에 걸린 것이므로 효율적이지 않다. 그래서 \u0026lsquo;인덱스\u0026rsquo;를 잘 설계해야 한다.\n4.6 Auto Increment Lock PRIMARY KEY의 중복 방지를 위해 table 생성 시 입력하는 auto increment에 거는 lock을 말한다.\nrow 추가 시 id 값이 자동적으로 증가하는 설정인 AUTO_INCREMENT에 대해 lock을 거는 것이다.\n만약 row가 1개 밖에 없는 상황에서 여러 클라이언트가 데이터를 추가할 때, id = 2인 row가 여러 개가 생성될 수 있다. 그래서 innoDB가 동시에 데이터를 못 넣어 중복을 방지하고자 사용하는 게 auto increment lock이다.\n매우 빨라서 체감하기 어렵다.\n5. Isolation Level(격리수준) 여러 트랜잭션이 동시에 처리될 때 특정 트랜잭션이 다른 트랜잭션에서 변경하거나 조회하는 데이터를 볼 수 있게 허용할지 말지 결정한다.\n🔆 격리 수준의 종류에는 무엇이 있고, 각 격리 수준은 무엇이며 장단점은 뭔지, 그래서 무엇을 사용하면 좋은지에 대해서만 먼저 알고 있자.\n격리 수준의 종류: 각 격리 수준마다 단점이 존재하는데 이 모든 걸 다 해결하는 방법은 default engine인 innoDB를 사용하는 것 read uncommitted read committed repeatable read: 나머지는 이런 게 있다는 정도로만 알고, 이를 자세히 알자. serializable ❗️ 격리 기본 수준 값을 변경 시, 트랜잭션이 진행 중이라 바꿀 수 없다는 Error가 발생했다면 COMMIT을 사용하라.\n❗️ autocommit = 1 이어도 start transcation으로 트랜잭션을 명시적으로 시작해주면 commit 명령어를 입력해야 DB에 적용이 된다. ❗️ mysql에서 나갔다가 다시 들어오면 autocommit은 다시 1로 세팅된다.\n격리수준 별 발생할 수 있는 문제점 dirty read 한 트랜젝션에서 커밋 전 \u0026lsquo;데이터를 업데이트한 시점\u0026rsquo;을 기준으로 다른 트랜젝션에서 조회되는 데이터가 달라진다. 즉, 나의 transaction이 아닌데도 COMMIT 전 데이터가 읽혀서 데이터 정합성이 준수되지 않는 현상(reads are not consistent)이다. 데이터가 업데이트된 트랜잭션이 rollback되어도 다른 트랜잭션에서 이 데이터를 읽고 진행했기 때문에, 취소된 데이터가 남아 있어서 에러가 발생할 수 있다.\nnon-repeatable read 트랜잭션이 완료되지 않고 커밋된 데이터를 다른 트랜잭션에서 읽을 수 있어서 한 트랜잭션 내에서 동일한 쿼리를 2번 이상 보냈을 때 해당 조회 결과가 달라서 데이터 정합성이 준수되지 않는 현상을 말한다. 이 또한 dirty read와 유사하게 부분적으로 커밋된 트랜잭션이 rollback되어도 다른 트랜잭션에서 이 데이터를 읽고 진행했기 때문에, 취소된 데이터가 남아 있어서 에러가 발생할 수 있다.\n만약 핀테크라면 금액이 달라지는 문제이기 때문에 심각하다. phantom read non-repeatable read는 한 row에 관한 것이고 phantom read는 여러 row 조회에 관한 것만 다르고 나머지는 동일하다.\n5.1 Read uncommitted COMMIT 되지 않은 데이터를 읽을 수 있는 격리 수준으로, 한 트랜잭션에서 다른 트랜잭션의 커밋되지 않은 데이터를 읽을 수 있기 때문에 이런 데이터는 변경될 수 있어서 \u0026lsquo;dirty read\u0026rsquo;라는 문제가 발생된다.\n실습 autocommit을 off 시킨다: SET GLOBAL autocommit=0; 결과 확인: SHOW GLOBAL VARIABLES LIKE 'autocommit'; 실제 작업할 때는 건드리지 않는다. 기본 isolation level 값을 A, B terminal에서 모두 변경: SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED; A, B terminal에서 모두 트랜젝션 시작: START TRANSACTION; 변경된 isolation level을 mysql 8.0 부터는 확인할 수 없다. TABLE 새로 생성: CREATE TABLE auto (id INT NOT_NULL AUTO_INCREMENT, name VAR(4), PRIMARY_KEY(id)); A, B terminal에서 모두 트랜젝션 시작: START TRANSACTION A terminal에서 데이터 추가: INSERT INTO auto (name) VALUES ('jeha'); 현재 나의 transaction이므로 추가된 데이터가 보인다. B terminal에서 확인하기: SELECT * FROM auto; 다른 transaction인데 commit되지 않은 추가된 데이터가 보인다. ROLLBACK을 진행하여 TRANSACTION 취소: ROLLBACK; A terminal: SELECT * FROM auto; -\u0026gt; commit을 실행하여 TRANSACTION을 마무리: COMMIT; 취소된 데이터를 확인할 수 없다. A terminal에 트랜젝션 과정 중에 데이터를 추가한 6번을 기준으로, B terminal에서 진행되는 트랜젝션 과정에서 조회되는 데이터가 달라진다.\n한 트랜젝션 과정에서 데이터의 정합성이 보장되지 못하는 문제점이 발생된다. 또한 이로 인해서 여러 문제점이 발생될 것이다.\n5.2 Read committed COMMIT된 것만 읽을 수 있는 격리 수준으로 트랜젝션이 완료된 데이터만 다른 트랜잭션에서 조회 가능하다. dirty read는 발생하지 않고 non-repeatable read와 phantom read가 발생할 수 있다.\nPostgreSQL의 기본값이다.\n커밋되기 전에는 undo log에 있는 곳의 데이터를 읽어오므로 추가한 값이 없고, 커밋 후에 불러오면 추가한 값이 존재한다.\nundo log: 뭔가 잘못되면 돌려야돼서 임시로 저장하는 공간 데이터 업데이트 sql을 입력하면 이 sql을 table에 적용하기 전에 undo log에 현 상태를 임시 저장한 후 sql을 적용한다. 그 후 커밋이 안되어있으면 데이터를 가져올 때 undo log에 있는 데이터를 조회한다. 실습 autocommit을 off 시킨다: SET GLOBAL autocommit=0; 결과 확인: SHOW GLOBAL VARIABLES LIKE 'autocommit'; 실제 작업할 때는 건드리지 않는다. 기본 isolation level 값을 A, B terminal에서 모두 변경: SET TRANSACTION ISOLATION LEVEL READ COMMITTED; 변경된 isolation level을 mysql 8.0 부터는 확인할 수 없다. A, B terminal에서 모두 트랜젝션 시작: START TRANSACTION; 데이터 추가 전 데이터 조회 in A, B terminal: SELECT * FROM auto; A terminal에서 데이터 변경 후 확인: UPDATE auto SET name='kim' WHERE name='lee' -\u0026gt; SELECT * FROM auto; 데이터 변경이 진행된 동일한 트랜젝션이므로 확인할 수 있다. B terminal에서 데이터 조회: SELECT * FROM auto; 변경 전 데이터로 조회된다. A terminal에서 commit 실행: COMMIT; B terminal에서 데이터 조회: SELECT * FROM auto; 변경 후 데이터로 조회된다. B terminal에서 commit 실행: COMMIT; READ UNCOMMITED와의 차이점을 확인했고, 문제점도 확인했다.\n7)번 단계를 기준으로 B terminal에서 transaction이 진행 중인데 조회되는 데이터가 달라졌다. 이 부분이 transaction 진행 중에 데이터의 정합성이 보장되어야하는데 그러지 못하는 문제점이다.\n5.3 🔆 Repeatable read 커밋 완료된 데이터에 대해서만 조회할 수 있으며 반복해서 행을 조회하더라도 똑같은 행을 보장하는 수준이다. 하나의 트랜잭션이 수정한 행을 다른 트랜잭션이 수정할 수 없도록 막아주지만 새로운 행을 추가하는 것은 막지 않는다. 그래서 똑같은 범위 쿼리를 실행해도 이후에 추가된 행이 발견될 수 있다. 그래서 \u0026lsquo;phantom read\u0026rsquo;가 발생할 수 있다. 그리고 InnoDB의 기본 Isolation level 값이다.\n반복적으로 읽을 수 있다. 또한 undo 영역에 백업된 이전 데이터를 이용해서 동일 트랜잭션에서는 같은 내용을 보여줄 수 있도록 한다.\nundo record에는 lock을 걸 수 없어서 같은 트랜잭션에서 조회 가능 귀신 같이 row가 추가되어 이를 phantom 이라 한다. ❗️ non repeatable read와 헷갈릴 수 있다. 하지만 repeatable read는 한 행에 대한 것이고 phantom read는 전체 데이터에 관한 현상을 말한다.\nphantom read에 대한 해결책 InnoDB에서는 undo log를 transaction-id을 기준으로 버전관리를 하여, 해당 transaction-id가 끝날 때까지 보관하기 때문에 phantom read가 문제가 되지 않는다.\n그래서 innoDB를 default engine으로 계속해서 사용한다.\n실습 autocommit을 off 시킨다: SET GLOBAL autocommit=0; 결과 확인: SHOW GLOBAL VARIABLES LIKE 'autocommit'; 실제 작업할 때는 건드리지 않는다. 기본 isolation level 값을 A, B terminal에서 모두 변경: SET TRANSACTION ISOLATION LEVEL REPEATABLE READ; 변경된 isolation level을 mysql 8.0 부터는 확인할 수 없다. A, B terminal에서 모두 트랜젝션 시작: START TRANSACTION; 데이터 추가 전 데이터 조회 in A, B terminal: SELECT * FROM auto; A terminal에서 데이터 변경: UPDATE auto SET name='lee' WHERE name='kim'; B terminal에서 데이터 조회: 4번과 동일한 데이터가 조회된다. read uncommited라면 5번을 기준으로 B terminal에서 조회되는 데이터가 달라지만, 그렇지 않았다. A terminal에서 commit: COMMIT; B terminal에서 데이터 조회: 4번과 동일한 데이터가 조회된다. read commited라면 7번을 기준으로 B terminal에서 조회되는 데이터가 달라지만, 그렇지 않았다. B terminal에서 트랜젝션 종료 후 데이터 조회: ROLLBACK; -\u0026gt; SELECT * FROM auto; 5번에서 추가된 데이터를 확인할 수 있다. 한 TRANSACTION 동안 조회되는 데이터가 정합성을 준수하는 걸 확인했다.\n5.4 Serializable 위에 여러 read의 문제점을 해결하는 방법으로, 하나의 transaction에서 접근한 record에 lock을 걸어 다른 transaction이 동일한 데이터에 접근할 경우 이를 막아 transaction 간의 완전한 격리를 이루는 기능\n문제점 read도 lock을 획득해야만 가능하다. 이 전 isolation level에서는 read에 lock을 걸면 write만 할 수 없고, write에 lock을 걸면 read만 할 수 없었다. 하지만, read에 lock을 걸면 write나 update, delete 등을 실행할 수 없다. 그래서 시간이 많이 걸려 효율적이지 않아 사용하지 않는다. 해결책: default인 innodb 사용하기 InnoDB에서 repeatable read를 사용하면 serializable은 불필요하다.\n6. 알아두면 좋은 명령어 SHOW CREATE TABLE {table name} 테이블이 어떻게 생성되었는지를 보여준다.\nORM으로 생성하면 실제 SQL에서 테이블을 어떻게 생성하는지 알기 어렵기 때문에 도움된다.\n특히 회사에 갔을 때 기존에 생성된 테이블들이 어떤식으로 만들어졌는지 궁금하다면?!? 매우 유용하다.\nORM으로 테이블을 생성했을 때 본인의 의도와 다르다면 추가 학습이 필요하다.\ncharset 어떤 character(문자열)의 데이터를 저장할지\ncollate 저장된 데이터를 어떤식으로 비교, 정렬 할지\n간단한 테이블에서는 문제가 되지 않는다 Reference 원티드 백엔드 챌린지 2월: MySQL \u0026lsquo;잘\u0026rsquo; 사용하기 Difference between non-repeatable read vs dirty read MySQL의 트랜잭션 격리 수준 ","permalink":"http://jeha00.github.io/post/db/wanted/lecture_02/","summary":"MySQL storage engine들의 종류들과 default engine인 InnoDB /  Transaction이란 무엇인지 / Database Lock의 종류에는 어떤 것들이 있고, 왜 필요한지 / Isolation level에 대해 알아본다.","title":"MySQL storage engine의 종류들, Transaction, Database Lock, Isolation Level"},{"categories":"DB","content":"0. Introduction 원티드 백엔드 챌린지 2월: MySQL \u0026lsquo;잘\u0026rsquo; 사용하기 를 듣고 제 언어로 정리한 포스팅입니다.\n해당 챌린지의 목표는 주니어 개발자 및 개발 준비생을 대상으로 하기 때문에, MySQL의 특징을 이해하여 효율적으로 사용하고, MySQL 기본 개념들을 학습하여 기술 면접에 대비하는 게 목적입니다.\n그래서 운영체제의 cache 운용도가 높은 storage engine을 최적화할 때 어떻게 해야하는가 또는 쿼리 효율 개선 같은 내용은 다루지 않습니다.\n해당 포스팅의 주제와 키워드 이번 포스팅의 주제는 [다양한 데이터베이스의 특징과 장단점] 입니다.\nKeyword: 데이터 베이스의 원칙, CAP Theorem, RDBMS, NoSQL\n기본 용어: Read / write / query / record \u0026amp; row\nrecord는 DB에 저장된 data를 의미 1. 데이터베이스의 원칙 무결성, 안전성, 확장성\n아래 3가지를 고려하여 DB를 정해야 한다.\n1.1 무결성(data integrity) 데이터가 전송, 저장, 처리되는 과정에서 변경되거나 손상되지 않아야한다는 원칙 -\u0026gt; 정확성, 일관성, 유효성을 유지\nintegrity 단어의 의미 integrity 단어는 말, 행동, 생각이 일치하여 일관되고, 이 생각을 기반으로 행동과 말이 온전한 상태라는 의미를 가진다.\n그렇다면 DB에서의 integrity란? 데이터는 일관되어야 하고, 완전해야 하고, 손상되지 않고 정확해야 한다는 의미다.\n그래서 데이터의 정확성, 일관성, 유효성 을 유지한다.\n어떤 개발자가 동일한 데이터를 요청하면 동일한 값을 가진 데이터가 보내져야 한다.\n1.2 안전성(data reliability) 데이터를 보호해야한다는 원칙\ndb를 복제하든지, stand-by db를 대기해둔다든지, 인증/인가되지 않은 사용자로부터 데이터를 보호 하는 걸 말한다.\n1.3 확장성(scalability) 데이터 양이나 사용자가 늘어날 때 대비하기 위해 확장되는 성질\nMySQL, Redis는 확장성이 좋지 않다.\n2. 다양한 데이터베이스 종류: RDBMS vs NoSQL - DB의 종류: RDBMS(MySQL, PostgreSQL..), NoSQL(redis, MongoDB)\n- 서비스에 적합한 DB 선택법: CAP Theorem\n2.1 RDBMS Ex: MySQL, Oracle, PostgreSQL\u0026hellip;\n데이터를 row와 column으로 이뤄진 table의 형태 로 저장되기 때문에 데이터 무결성이 보장 된다. 그래서 만약 schema가 자주 변경되거나 column이 자주 변경되는 데이터는 RDBMS가 적합하지 않다.\n그리고, 이 저장된 table로부터 SQL(Structured Query Language) 를 사용해서 데이터를 쉽게 읽어오거나 조작한다.\nscale out이 아닌 scale up이 가능한 이유:\n여러 db를 서버에 나눠서 저장해도 table name이 중복될 수 없기 때문에 scale up을 해야 한다. 하지만 이 특성으로 인해 분산 저장을 하지 않기 때문에 데이터 일관성이 잘 유지된다. 2.2 NoSQL Ex: key-value, graph, document\n데이터가 저장되는 형태인 key-value, graph, document 에 따라 NoSQL 여러 종류로 나눠진다.\n데이터가 저장되는 형태는 더 많지만 위 3가지가 대부분이므로 더 알아보지 않는다.\n2.2.1 key-value key-value 쌍으로 데이터가 저장된다. 여기서 Key는 unique identifier로 사용되기 때문에 key는 중복되지 않는다. 그래서 추가하면 기존에 있던 key는 날라간다. ex) redis, DynamoDB [Redis]\ncache로 사용: 자주 사용되는 쿼리 명령어를 캐쉬에 저장하여 바로 사용 docker나 쿠버네티스 상에 올릴 때 많이 사용 celery와도 많이 사용하여 message broker로서 pub/subscribe 에 보내진다. ❗️한계: 위 3가지 DB 원칙 중 확장성의 관점에서는 redis는 in-memory 기반으로 최대 RAM 크기까지만 확장이 가능하기 때문이다.( not scalable ) [DynamoDB in AWS] 최근에 많이 사용되고 있다. redis와 달리 key가 partiton key(primary) 와 sort key(secondary, optional)로 나눠진다. partition key는 scale out으로 DB가 나눠졌을 때 값이 존재하는 위치를 나타낸다. 장점: scalable → HA(High Availability), serverless 2.2.2 graph 데이터가 graph 형태로 저장되기 때문에, SNS 등 관계가 복잡한 상황에서 자주 사용된다.\nex) instagram, linkedin\n각 user를 node로 생각하고, node 간의 관계는 edge를 사용해서 나타낸다. 종류: Neo4j, OrientDB 등 2.2.3 document 데이터가 document 형태로 저장되서 구조가 자유롭다. ex) JSON 또는 XML 형태\nMongoDB를 통해서 설명해보겠다.\nMySQL과 비교하자면 Collections이 table이고, Documents가 table의 row라고 생각하면 된다.\n스키마를 만들 수 있지만, 형태가 스키마에서 떨어져도 자유롭게 저장할 수 있다. 그래서 이 DB는 블로그 같은 곳에 사용될 수 있다. DB 별로 데이터를 조작할 수 있는 언어가 따로 있다. 종류: MongoDB, CassandraDB, Couchbase 등이 해당 3. DB를 나누는 또 다른 기준: row oriented db vs column oriented db DB를 나누는 또 다른 기준이 row-oriented 와 column-oriented가 있다.\nrow 와 column oriendtd에 따른 DB 종류 row-oriented DB: MySQL, PostgreSQL, hbase column-oriented DB: CassandraDB, hbase, Bigquery big query: 구글에서 만든 DB 엔진 row와 column oriented에 따른 read, insert 성능 차이 row oriented db column oriented db read 느림 빠름 insert 빠름 느림 가정 데이터가 아래 table처럼 저장되어 있다고 가정하자.\nName City Age James Seoul 29 Kang London 33 Mac London 27 3.1 Row oriented DB column으로 스키마가 정해져서 row가 원하는 데이터인 DB\n그러면 Row oriented DB에 대해 알아보자.\n3.1.1 disk에 저장되는 형태 row oriented DB의 저장 형태는 대략적으로 다음과 같다.\ntable의 각 row들이 disk에 저장될 때 한 줄로 저장된다.\n| James | Seoul | 29 | Kang | London | 33 | Mac | London | 27 |\ndisk의 block에는 다음과 같이 각 row 들로 저장된다.\n🔆 sector, block의 차이\nblock 1\nName City Age James Seoul 29 block 2\nName City Age Kang London 33 block 3\nName City Age Mac London 27 3.1.2 추가 row oriented db에서의 데이터 추가는 문제가 되지 않는다.\n만약 row가 한 줄 추가된다면 table은 다음과 같이 한 줄 추가된다.\nName City Age James Seoul 29 Kang London 33 Mac London 27 Paul Chicago 22 disk에는 다음과 같이 동일한 row의 맨 끝에 추가된다. 추가된 데이터는 bold 표시를 했다.\n| James | Seoul | 29 | Kang | London | 33 | Mac | London | 27 | Paul | Chicago | 22 |\n그래서 row oriented db에서의 데이터 추가는 간단하여 문제가 되지 않는다.\n3.1.3 조회 조회하려는 속성 값에 대해 연속적으로 저장되지 않기 때문에 문제가 된다.\n나이 관련된 데이터를 조회하고 싶을 때 row로 저장되기 때문에 나이 관련 데이터가 연속적이지 않아 조회하는 데 시간이 걸린다.\n| James | Seoul | 29 | Kang | London | 33 | Mac | London | 27 |Paul | Chicago | 22 |\n그래서 id가 auto increment여도 순서가 보장되지 않기 때문에 이를 위해서 row 기반 DB에서는 별도의 index 테이블을 사용한다.\n🔆 즉, row oriented db에서의 최적화란 read를 어떻게 빠르게 할 것인가를 의미한다.\n3.1.4 삭제 후 추가 데이터 삭제하여 생긴 빈 자리에 그대로 추가되기 때문에 데이터 순서가 보장되지 않는다. 그래서 DB에서는 \u0026lsquo;인덱스\u0026rsquo;라는 걸 생성하여 관리한다.\n현재 table이 다음과 같다고 가정하자.\nName City Age James Seoul 29 Kang London 33 Mac London 27 Paul Chicago 22 disk에는 다음과 같이 같이 한 줄로 이어서 저장되어 있다.\n| James | Seoul | 29 | Kang | London | 33 | Mac | London | 27 | Paul | Chicago | 22 | 이런 상황에서 | Mac | London | 27 | 데이터가 삭제된다면 디스크에서는 어떻게 될까?\n| James | Seoul | 29 | Kang | London | 33 | | | ___ | Paul | Chicago | 22 | 위와 같이 빈 자리가 생긴다.\n그 다음 다른 데이터 | Mike | Shanghai | 43 | 이 추가되면 디스크에는 어떻게 저장되는 것일까?\n뒤에 있는 | Paul | Chicago | 22 | 이 댕겨지면서 뒤에 저장될까? 아니면 빈 자리에 데이터가 그대로 추가될까?\n바로 후자다.\n그래서 row oriented db 는 db에 저장되는 순서를 보장하지 않는다. 이 특성으로 인해서 ORDER BY 로 정렬할 때, id의 경우 DB에서 별도로 인덱스라는 걸 생성하여 관리한다고 한다.\n❗️추가할 때, 빈 자리로 데이터를 shift하면 순서가 맞혀지지 않을까? 이럴 경우, shift하는데 시간이 많이 걸리기 때문에 빈 자리에 바로 추가하는 게 낫다.\n3.2 Column oriented DB row으로 스키마가 정해져서 column이 원하는 데이터인 DB\n3.2.1 disk에 저장되는 형태 그리고, disk에는 다음과 같이 저장된다.\nblock 1\nName James Kang Mac block 2\nCity Seoul London London block 3\nAge 29 33 27 3.2.2 추가 row 기반 db처럼 끝에 추가되는 게 아닌 \u0026lsquo;데이터 사이에 추가 \u0026rsquo; 되는 거라 오래 걸린다.\n추가 되기 전 디스크에 저장된 형태는 다음과 같다.\n| James | Kang| Mac | Seoul | London | London | 29 | 33 | 27 | 데이터가 추가되면 아래와 같은 순서로 데이터가 저장된다. 추가된 데이터는 bold 처리했다.\n| James | Kang| Mac | Paul | Seoul | London | London | Chicago | 29 | 33 | 27 | 22 | 저장된 데이터의 순서를 보면 row oriented db와 달리 어떻게 저장되는지 이해할 수 있다.\n3.2.3 조회 만약 내가 Age를 기준으로 데이터를 찾는다고 하면 row oriented db와 달리 조회하는 게 쉽다. 왜냐하면 아래와 같이 한 가지 column에 대해 한 디스크 위치에 저장되어 있기 때문이다.\nbold 처리된 게 나이 관련 데이터다.\n| James | Kang| Mac |Paul | Seoul | London | London |Chicago | 29 | 33| 27 | 22 | 그래서 bigquery가 데이터 조회에서 MySQL보다 빠른 이유가 바로 이 때문이다.\n4. 서비스에 적합한 데이터베이스 선택법 4.1 CAP Theorem consistency(일관성) 데이터베이스가 서버가 여러 개인 분산 데이터베이스 상에서 모든 node들이 데이터베이스 안에 같은 값을 가지고 있어야 하는 성질 (같은 정보를 공유하고 있어야하는 성질) 어떤 노드에게 요청을 보내도 상관없이 같은 데이터를 보여준다. 하지만 request를 보내면 동기화를 위해서 해당 request가 delay 될 수 있다. 그래서 일관성의 목표는 데이터의 동기화가 충분히 빨라서 사용 상 문제가 없도록 하는 것이다. 금융 쪽에서는 이 일관성이 중요하다. 송금 데이터가 데이터베이스 노드당 동기화되지 않으면 송금 안된 줄 알고 계속 보낸다. 실생활에서 예시: 통신사 상담원에게 전화하여 집 주소를 변경하고 전화를 끊은 뒤 집 주소 중 일부가 잘못 전달된 걸 알고, 다시 전화하여 다른 상담원이 받을 지라도 변경된 내용을 정확히 알고 있는 상황 availability(가용성) 데이터베이스에 보내는 모든 request는 response를 반드시 받아야 하는 성질로, 시스템이 중단되는 일 없이 언제든지 사용 가능한 상태여야 한다. 작업이 실패하더라도 사용자는 응답을 받을 수 있어야 한다. consistency는 동기화 때문에 response가 바로 안온다. 하지만 해당 response가 가장 최근 데이터라는 것을 보장받을 수 없다. 데이터가 일관되지 않아도 언제든지 접근할 수 있다. 접근하는 node에 따라 값이 다르다 E-commerce에서 중요 실생활에서 예시: 24시간 가능한 통신사 고객센터 partition-tolerance(분할 허용성) DB node 간 소통이 불가능 하더라도 서비스는 정상적으로 작동하는 성질 데이터량이 매우 많을 때 중요 인스타그램 같은 SNS에서 중요 실생활에서 예시: 통신사 고객센터에 전화하여 문의를 하니 고객센터에서는 현재 본사와 통신할 수 없다고 한다. 하지만 고객센터는 정상적으로 운영된다. 4.2 위 3가지를 다 가질 수 없는 이유 서버가 s1과 s2로 나눠져 있는 상황이라고 하자.\npartition-tolerance가 없으면?? consistency, availability 함께 지원된다.\n이 s1과 s2 사이에서 소통할 수가 없어서 데이터를 분산 저장할 수 없다. 그러면 한 서버로만 흘러가서 write / read를 수행하기 때문에 request를 보내면 바로 response를 받을 수 있고, 항상 동일한 데이터를 얻을 수 있다. partition-tolerance가 있으면? consistency와 availability는 함께 지원되지 않는다.\n서버가 끊겨도 계속해서 소통할 수 있다면?\ndb가 consistency하다면 db에 요청을 보냈을 때, s1과 s2의 각 서버가 동기화 작업을 하느라 response가 느려지고, 사용자는 계속 기다려야 한다.\n쿠팡에서 탄산수를 주문했는데 바로 response가 오지 않는다. 왜냐하면 다른 서버에도 저장을 해야하기 때문이다. 하지만 db가 consistency하지 않고, 데이터가 availability 하다면 write/read request를 했을 때 바로 response가 온다. 대신에 write한 데이터가 모든 서버에 동기화되지 않기 때문에, 어느 서버로 흘러가냐에 따라서 내가 요청한 write data가 안올 수 있다.\n4.3 예시 RDBMS RDBMS: Netflix (ex: MySQL)\n영상에 대한 정보를 저장하는 방식 데이터 분산은 잘 안되서 내가 write한 걸 잘 읽어올 수 있다. NoSQL NoSQL: 인스타그램\n인스타그램은 availability를 굉장히 중요하게 생각한다.\n즉, 데이터가 write된 게 매우 중요하게 여겨서, 해당 사용자가 속한 노드에서 이 데이터가 저장되었는지가 중요하다. 왜냐하면 글이나 메세지는 작성된 게 남겨져야하기 때문이다. 그리고 consistency를 중요하게 여기지 않는다.\n즉, 저장된 데이터가 다른 노드들에 복제되었는지는 그리 중요하지 않아서, 동기화를 바로 하지 않고 나중에 할 시간이 별도로 있다. Cassandra DB 블로그↗️\n그래서 각 도메인과 데이터 종류에 따라서 DB 선택을 잘 해야 한다.\n5. RDBMS와 NoSQL 비교 RDBMS NoSQL Data modeling 특징 1 스키마에 맞춰서 관리하기 때문에 데이터 정합성 보장 자유롭게 데이터를 관리할 수 있다. 어느 data가 해당 관계를 맺고 있는 데이터가 자주 변경되는 경우 해당 데이터 구조를 정확히 알 수 없고, 데이터가 변경/확장 되는 경우 해당 Scalability Scale up Scale out Query Language SQL(Structured Query Language) 문법이 조금 다름 Consistency Strong eventual consistency flexibility Not really very flexible 위 데이터 종류에 맞춰서 분리 적용한다.\n사용자 정보의 경우 스키마가 변하지 않기 때문에 RDBMS를 사용한다. RDBMS는 scale out이 어려운 이유 RDBMS는 위에서 언급한 대로 스키마에 맞춰서 데이터가 저장되기 때문에 중복이 어렵다. 이는 다르게 말하자면 테이블 간에 column을 통한 관계 형성이라는 제약 조건을 통해서 이뤄지고 있다. (그래서 데이터 모델링이 RDBMS에서는 중요하다.)\n그래서 이런 제약조건을 모두 만족하면서 분류하여 나눠서 확장을 해야하므로 Nosql보다 더 어렵다. nosql은 각 객체를 분류하는 기준이 강하지 않기 때문이다. 즉 중복을 줄이기 위한 \u0026ldquo;관계\u0026rdquo; 로 인해서 확장하기가 어렵다.\n🔆 Scale up VS. Scale out scale out의 단점: 데이터가 중복될 수 있다. Reference 원티드 백엔드 챌린지 2월: MySQL \u0026lsquo;잘\u0026rsquo; 사용하기 Understanding NoSQL Databases by the CAP Theorem What is MongoDB – Working and Features How row oriented and column oriented db works? A Beginner’s Guide to CAP Theorem for Data Engineering CAP 이론 소개 - 데이터베이스 초보자용 ","permalink":"http://jeha00.github.io/post/db/wanted/lecture_01/","summary":"데이터베이스의 3가지 원칙 / 데이터베이스의 종류 RDBMS와 NoSQL의 비교 / 또 다른 분류 기준인 row oriented db와 column oriented db의 차이 / DB 선정 시 고려할 CAP Theorem 에 대해 알아본다.","title":"DB 원칙과 종류 비교(RDBMS vs NoSQL, Row vs Column oriented) 그리고 CAP Theorem"},{"categories":"Book Study","content":"0. Introduction 아래 book study는 알 스웨이가트가 지었고, 박재호님이 번역하신 클린 코드, 이제는 파이썬이다. 를 읽고 진행한 book study 입니다. 영문 원본으로 온라인 공개된 자료가 있어서 영문으로 학습합니다.\n기존에 읽었던 Clean Code는 자바 코드로 되어 있어서, 먼저 파이썬 클린 코드를 학습 후 시작할려고 합니다.\n이번 book study를 진행하면서 code에 대한 철학이 생기고, code를 바라보는 눈이 깊어지고, 넓어지기를 바랍니다.\n각 chapter를 읽고 내용 정리하는 식으로 진행합니다.\n이번에 학습하는 chapter의 주제는 \u0026lsquo;Chapter 08: Common Python Gotchas - 파이썬에서 빠지기 쉬운 함정들\u0026rsquo; 입니다.\n1. 루프문 진행 중에는 리스트에서 아이템을 추가/삭제하지 말자 루프문 진행 중에는 리스트를 수정하지 말고, 새로운 리스트를 생성하자.\nlist에 \u0026lsquo;sock\u0026rsquo;이라는 문자열이 발견될 때마다 이와 일치하는 \u0026lsquo;sock\u0026rsquo;을 삽입하여 해당 \u0026lsquo;sock\u0026rsquo;의 갯수를 짝수로 만드는 코드다.\n아이템 추가 1 2 3 4 5 6 7 8 9 10 11 12 clothes = [\u0026#39;skirt\u0026#39;, \u0026#39;red sock\u0026#39;] for clothing in clothes: # 리스트를 반복 if \u0026#39;sock\u0026#39; in clothing: # \u0026#39;sock\u0026#39; 문자열 찾기 clothes.append(clothing) # 일치하는 \u0026#39;sock\u0026#39; 짝을 추가 print(\u0026#39;Added a sock:\u0026#39;, clothing) # 사용자에게 알림 Added a sock: red sock Added a sock: red sock Added a sock: red sock ... Added a sock: red sock ... clothing에 추가된 아이템이 다음 반복에서 참조된다. 아래 이미지와 같이 \u0026lsquo;red sock\u0026rsquo;이 추가된다. 컴퓨터의 메모리가 부족해지거나 사용자가 중단해야 멈춘다.\n이 코드에서 알려주는 교훈은 list를 반복하는 동안 이 리스트에 새 아이템을 추가하면 안된다는 점이다. 의도치 않게 계속 반복되기 때문이다.\n그래서 위 코드를 아래와 같이 변경하는 걸 권장한다.\n\u0026rsquo;newClothes\u0026rsquo; 같은 새 리스트를 생성하여 사용한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 clothes = [\u0026#39;skirt\u0026#39;, \u0026#39;red sock\u0026#39;, \u0026#39;blue sock\u0026#39;] newClothes = [] for clothing in clothes: if \u0026#39;sock\u0026#39; in clothing: print(\u0026#39;Appending:\u0026#39;, clothing) newClothes.append(clothing) print(newClothes) clothes.extend(newClothes) Append: red sock Append: blue sock [\u0026#39;red sock\u0026#39;, \u0026#39;blue sock\u0026#39;] \u0026gt;\u0026gt; clothes.extend(newClothes) [\u0026#39;skirt\u0026#39;, \u0026#39;red sock\u0026#39;, \u0026#39;blue sock\u0026#39;, \u0026#39;red sock\u0026#39;, \u0026#39;blue sock\u0026#39;] 아이템 삭제 for 루프문을 실행하는 과정에서 아이템을 \u0026lsquo;추가\u0026rsquo;하면 안되듯 \u0026lsquo;삭제\u0026rsquo;해서도 안된다. 삭제를 하여 index가 수정되면 이 과정에서 원소를 조사하지 않고 지나치기 때문이다.\n아래 코드를 보면 \u0026lsquo;mello\u0026rsquo;는 삭제되었지만 \u0026lsquo;yello\u0026rsquo;는 삭제되지 않았다. 위 설명대로 \u0026lsquo;mello\u0026rsquo;가 삭제된 순간 index가 댕겨지면서 index [2]까지 확인했기 때문에, 삭제된 후 [3]을 확인하게 된 것이다.\n1 2 3 4 5 6 greetings = [\u0026#39;hello\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;mello\u0026#39;, \u0026#39;yello\u0026#39;, \u0026#39;hello\u0026#39;] for i, word in enumerate(greetings): if word != \u0026#39;hello\u0026#39;: del greetings[i] print(greetings) # [\u0026#39;hello\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;yello\u0026#39;, \u0026#39;hello\u0026#39;] 그렇다면 어떻게 코드를 작성하는게 좋을까?\n삭제할 아이템을 제외한 모든 아이템을 복사하는 새 리스트를 만든 다음, 원래 리스트를 교체하자.\n1 2 3 4 5 6 7 8 greetings = [\u0026#39;hello\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;mello\u0026#39;, \u0026#39;yello\u0026#39;, \u0026#39;hello\u0026#39;] newGreetings = [] for word in greetings: if word == \u0026#39;hello\u0026#39;: newGreetings.append(word) greetings = newGreetings print(greetings) # [\u0026#39;hello\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;hello\u0026#39;] 다음으로 이를 list comprehension으로 작성해보자. 훨씬 더 간결하고, 리스트를 변경할 때 발생하는 함정을 피할 수 있다.\n1 2 greetings = [\u0026#39;hello\u0026#39;, \u0026#39;hello\u0026#39;, \u0026#39;mello\u0026#39;, \u0026#39;yello\u0026#39;, \u0026#39;hello\u0026#39;] newGreetings = [word for word in greetings if word == \u0026#39;hello\u0026#39;] 참조, 메모리 사용, sys.getsizeof() method 원본 대신 새로운 리스트를 생성하면 메모리 낭비로 보일 수 있다. 하지만, 변수가 실제 값 대신에 \u0026lsquo;값에 대한 참조\u0026rsquo;를 포함하는 것처럼 리스트도 값에 대한 참조를 포함한다.\nnewGreetings.append(word) 행은 word 변수에 있는 문자열을 복사하는 게 아니라, 문자열의 참조를 복사하기 때문에 훨씬 적은 메모리를 차지한다. sys.getsizeof()를 통해 확인해보자.\n1 2 3 4 5 6 7 8 9 10 \u0026gt;\u0026gt; import sys \u0026gt;\u0026gt; sys.getsizeof(\u0026#39;cat\u0026#39;) 52 # 52바이트 \u0026gt;\u0026gt; sys.getsizeof(\u0026#39;a much longer string than just \u0026#34;cat\u0026#34;\u0026#39;) 85 # 85바이트 \u0026gt;\u0026gt; sys.getsizeof([\u0026#39;cat\u0026#39;]) 64 # 64바이트 \u0026gt;\u0026gt; sys.getsizeof([\u0026#39;a much longer string than just \u0026#34;cat\u0026#34;\u0026#39;]) 64 # 64바이트 list에 담겨진 문자열을 크기와 상관없이 64바이트를 차지한다. 왜냐하면 실제 문자열을 포함하는 게 아닌, 문자열을 참조할 뿐이다.\n🔆 참조는 참조된 데이터의 크기에 관계없이 크기가 동일하다.\n그러므로 원래 리스트를 반복하면서 해당 리스트를 수정하지 않고 새로운 리스트를 생성한다고 해서 메모리를 낭비한다고 생각해서는 안된다.\n리스트를 수정하는 코드가 언뜻 동작하듯이 보여도, 에러 발견과 수정에 오랜 시간이 걸리는 미묘한 버그의 원인이 될 수 있다. 차라리 컴퓨터 메모리를 낭비하는 편이 낫고, 프로그래머의 시간을 허비하는 것은 훨씬 고비용이다.\n아이템 변경은 가능하다. 루프문에서 리스트를 실행할 때, 아이템을 추가하거나 제거하지 않아야 하지만 리스트의 내용은 수정해도 좋다.\n1 2 3 4 5 6 \u0026gt;\u0026gt; numbers = [\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;5\u0026#39;] \u0026gt;\u0026gt; for i, number in enumerate(numbers): \u0026gt;\u0026gt; numbers[i] = int(number) \u0026gt;\u0026gt; numbers [1, 2, 3, 4, 5] 안전하게 아이템을 삭제, 추가하는 또 다른 방법: 거꾸로 반복하기 아이템을 삭제하거나 추가하기 위한 또 다른 방법은 리스트를 끝에서부터 앞으로 거꾸로 반복하기 다.\n예를 들어 다음 코드를 보면 리스트에서 루프 반복문이 실행되는 동안 삭제되어 IndexError가 발생된다\n1 2 3 4 5 someInts = [1, 7, 4, 5] for i in range(len(someInts)): if someInts[i] % 2 == 0: del someInts[i] # IndexError: list index out of range 이번에는 거꾸로 반복해보자.\n1 2 3 4 5 6 someInts = [1, 7, 4, 5] for i in range(len(someInts)-1, -1, -1): if someInts[i] % 2 == 0: del someInts[i] someInts # [1, 7, 5] 위 코드가 잘 동작하는 이유는 for 루프 내에서 반복되면서 인덱스의 변화가 없기 때문이다.\n삭제뿐만 아니라 추가도 잘 동작이 되지만, 살짝만 바꿔도 버그가 등장하므로 제대로 하기 까다롭다.\n그렇기 때문에 ❗️ 원본 리스트 수정보다는 신규 리스트 생성이 훨씬 더 간단하다.\n🔆 그래서 파이썬의 핵심 개발자 레이먼드 헤팅어는 이렇게 말한다.\nQuestion: 루프문을 돌면서 리스트를 수정하는 가장 좋은 방법은?\nAnswer: 없다. 생각도 하지 마라.\n2. copy.copy()나 copy.deepcopy() 없이 가변 값을 복사하지 말자 변수는 객체를 포함하는 상자라기보다는 객체를 참조하는 레이블 또는 이름 태그 로 생각하자.\n변수 할당 시 파이썬에서 할당문은 절대로 객체를 복사하는 게 아닌, 객체에 대한 참조를 복사할 뿐이다.\n1 2 3 4 5 6 7 8 spam = [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;eel\u0026#39;] cheese = spam spam # [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;eel\u0026#39;] cheese # [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;eel\u0026#39;] spam[2] = \u0026#39;MOOSE\u0026#39; spam # [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;MOOSE\u0026#39;] cheese # [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;MOOSE\u0026#39;] id(cheese), id(spam)# 235696337288 분명히 spam만 수정했지만, cheese까지 수정된 걸 확인할 수 있다.\n이렇게 된 이유는 할당문은 객체를 복사하지 않고, 객체에 대한 참조만 복사하기 때문이다.\n리스트 객체를 중복으로 만들지 않는다.\n인자로 전달 시 이는 할당뿐만 아니라, 함수 호출에 인자로 전달된 객체에도 동일한 원리가 전달된다.\n1 2 3 4 5 6 def printIdOfParam(theList): print(id(theList)) eggs = [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;eel\u0026#39;] print(id(eggs)) # 2356893256136 printIdOfParam(eggs) # 2356893256136 ❗️ 만약 파이썬이 참조가 아닌 전체 리스트를 복사했다고 생각해보자.\neggs에는 단 3개가 아닌 10억 개의 아이템이 들어있는 상황에서 인자로 넘기면 이거에 대한 리스트를 전부 복사해야 한다.\n따라서 간단한 함수를 호출하는데 메모리는 매우 많이 잡아먹는다. 그래서 파이썬 할당이 참조만 복사하고 객체는 절대 복사하지 않는 이유다.\n해결책 이런 함정에서 벗어나는 방법은 copy.copy() 메소드로 단순히 참조가 아닌 복사본을 만드는 것이다.\n1 2 3 4 import copy bacon = [2, 4 ,8, 16] ham = copy.copy(bacon) id(bacon) == id(ham) # False 그러나 변수가 객체를 포함하는 상자가 아닌 객체에 대한 레이블이나 이름표와 같듯이, 중첩 리스트의 경우에는 리스트 안에 객체를 참조하는 레이블이나 이름표가 포함된다. 그래서 중첩 리스트의 경우에는 copy.copy()를 할지라도 내부 리스트에 대해서는 참조만 복사한다.\n1 2 3 4 5 6 7 8 9 10 import copy bacon = [[1, 2], [3, 4]] ham = copy.copy(bacon) bacon.append(\u0026#39;APPENDED\u0026#39;) bacon # [[1, 2], [3, 4], \u0026#39;APPENDED\u0026#39;] ham # [[1, 2], [3, 4]] bacon[0][0] = \u0026#39;CHANGED\u0026#39; bacon # [[\u0026#39;CHANGED\u0026#39;, 2], [3, 4], \u0026#39;APPENDED\u0026#39;] ham # [[\u0026#39;CHANGED\u0026#39;, 2], [3, 4]] id(bacon[0]) == id(ham[0]) # False 위 코드의 결과 copy.copy()를 사용했음에도 불구하고 두 변수에 모두 반영되었다.\n이런 경우, copy.deepcopy() 를 사용하면 리스트 객체 내의 모든 리스트 객체를 복사할 수 있다.\ncopy.deepcopy를 권장 객체를 복사할 때 2가지 방법이 있음을 알았다. 이 중에서 copy.deepcopy()를 권장한다. 왜냐하면 미묘한 버그까지 예방할 수 있기 때문이다. copy.copy()에 비해서 약간 느리지만 눈치채기 어려운 정도라고 한다.\n3. 기본 인수에 가변 객체는 사용하지 말자 파이썬에선 정의된 함수에서 파라미터에 대한 기본 인수(default argument)를 설정할 수 있다. 개발자가 파라미터를 명시적으로 사용하지 않으면 기본 인수를 사용해서 함수가 실행된다. 예를 들어서 'cat dog'.split()는 'cat dog'.split(None)를 호출하는 경우와 동일하다.\n그러면 다음으로 기본 인수로 가변 객체를 사용한 경우를 보자.\n1 2 3 4 5 6 7 def addIngredient(ingredient, sandwich=[\u0026#39;bread\u0026#39;, \u0026#39;bread\u0026#39;]): sandwich.insert(1, ingredient) return sandwich mySandwich = addIngredient(\u0026#39;avocado\u0026#39;) mySandwich # [\u0026#39;bread\u0026#39;, \u0026#39;avocado\u0026#39;, \u0026#39;bread\u0026#39;] 위와 같이 작성할 수 있다. 하지만, 기본 인자로 가변 객체를 사용할 경우 다음 코드와 같은 문제점이 발생할 수 있다. 위 코드에 이어서 작성 후 실행했다.\n1 2 anotherSandwich = addIngredient(\u0026#39;lettuce\u0026#39;) anotherSandwich # [\u0026#39;bread\u0026#39;, \u0026#39;lettuce\u0026#39;, \u0026#39;avocado\u0026#39;, \u0026#39;bread\u0026#39;] anotherSandwich를 선언한 건 처음인데, 어째서 avocado가 있는 것일까?\naddIngredient()가 호출될 때마다 이 기본 인자 리스트를 재사용하기 때문에 이처럼 예상치 못한 동작으로 이어진다.\n함수 def문은 매번 함수를 호출할 때마다 실행되는 게 아니라 한 번만 실행되기 때문에, 오직 ['bread', 'bread'] 하나만 생성된다.\n1 2 3 mySandwich = [\u0026#39;bread\u0026#39;, \u0026#39;cheese\u0026#39;, \u0026#39;bread\u0026#39;] mySandwich = addIngredient(\u0026#39;butter\u0026#39;, mySandwich) mySandwich # [\u0026#39;bread\u0026#39;, \u0026#39;butter\u0026#39;, \u0026#39;cheese\u0026#39;, \u0026#39;bread\u0026#39;] 해결책 그래서 리스트 또는 딕셔너리 같은 가변 객체를 기본 인수로 사용해야하는 경우, 파이썬다운 해법은 기본 인수를 None으로 설정하는 것이다. 그리고, 이를 확인하고 함수가 호출될 때마다 새로운 리스트나 딕셔너리를 제공하는 코드를 작성한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 def addIngredient(ingredient, sandwich=None): if sandwich is None: sandwich = [\u0026#39;bread\u0026#39;, \u0026#39;bread\u0026#39;] sandwich.insert(1, ingredient) return sandwich firstSandwich = addIngredient(\u0026#39;cranberries\u0026#39;) firstSandwich # [\u0026#39;bread\u0026#39;, \u0026#39;cranberries\u0026#39;, \u0026#39;bread\u0026#39;] secondSandwich = addIngredient(\u0026#39;lettuce\u0026#39;) secondSandwich # [\u0026#39;bread\u0026#39;, \u0026#39;lettuce\u0026#39;, \u0026#39;bread\u0026#39;] id(firstSandwich) == id(secondSandwich) # False 🔆 가변 데이터 타입에는 리스트, 딕셔너리, 집합, 클래스 문으로 만들어진 객체가 포함된다. 이러한 유형의 객체를 def 문에 기본 인수로 넣어서는 안된다.\n4. 문자열을 문자열 연결로 생성하지 말자 파이썬에서 문자열은 immutable이다. 문자열을 수정하는 것처럼 보이는 코드도 실제로는 새로운 문자열 객체를 생성한다.\n새로운 문자열 객체를 생성하면 예전 문자열 객체를 버리는데 수 많은 문자열 연결로 문자열을 만들면 프로그램이 느려질 수 있다.\n아래 코드의 경우 매우 심각한 메모리 낭비를 초래한다.\n1 2 3 4 5 final_string = \u0026#39;\u0026#39; for _ in range(100000): final_string += \u0026#39;spam\u0026#39; final_string # spam spam spam spam spam ..... --생략-- 위 코드는 맨 마지막 문자열만 필요하고 나머지는 불필요하다.\n그래서 위 코드를 보다 파이썬다운 방법으로 작성한다면 다음과 같다.\n1 2 3 4 5 6 final_string = [] for _ in range(100000): final_string.append(\u0026#39;spam \u0026#39;) final_string = \u0026#39;\u0026#39;.join(finalString) final_string 이전 코드와 똑같이 십만 개의 문자열 객체를 생성하지만, join을 호출할 때 한 번만 문자열 연결을 수행한다.\n시간을 측정한 결과 첫 번째 경우보다 세 번째 경우가 3배 빠른 걸 확인했다.\n파이썬은 여러 가지 동작 세부 사항에 대한 고민거리로부터 개발자를 해방시켜준다. 이를 통해 프로그래머는 소프트웨어를 빨리 작성할 수 있다.\n프로그래머의 시간은 CPU의 시간보다 더 가치 있다.\n하지만, 연결을 통한 문자열 생성과 같은 실수를 피하기 위해 불변의 문자열과 가변 리스트의 차이 등 세세한 부분가지 이해하는 편이 좋은 경우도 있다.\n5. sort()가 알파벳 순으로 정렬하리라 기대하지 말자 아스키라 읽히는 \u0026lsquo;ASCII\u0026rsquo;는 정보 교환을 위한 미국 표준 코드를 의미하는데, 숫자코드와 텍스트 문자 사이의 대표적인 인코딩 방식이다.\nsort()는 알파벳 정렬이 아닌 아스키 정렬을 사용한다. 그래서 대문자가 소문자보다 훨씬 앞에 온다. 대문자 A는 코드 포인트 65, 소문자 a는 코드 포인트 97, 대문자 Z는 코드 포인트 90이다.\n문자의 코드 포인트를 알고 싶으면 ord()를 사용한다. 또한, 코드 포인트의 문자열을 알고 싶으면 chr()를 사용한다.\n1 2 ord(\u0026#39;a\u0026#39;) # 97 chr(97) # \u0026#39;a\u0026#39; 알파벳 정렬을 하고 싶다면 다음과 같이 sort method에 key 값을 사용해보자. 리스트는 값이 lower() 문자열 메소드에서 호출된 것처럼 정렬된다.\n1 2 3 letters = [\u0026#39;z\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;Z\u0026#39;] letters.sort(key=str.lower) letters # [\u0026#39;A\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;Z\u0026#39;] 파이썬 sort()는 병합정렬과 삽입 정렬을 혼합한 알고리즘으로서 팀 피터스에 의해서 만들어졌다.\n6. 부동소수가 완벽히 정확할 거라고 가정하지 말자 문제점 컴퓨터는 0과 1만 저장할 수 있다. 이는 소수점이 존재하는 실수도 마찬가지다. 그래서 실제 실수 계산할 때 다음과 같이 사람의 생각과 다른 결과가 나온다.\n1 2 0.1 + 0.1 + 0.1 # 0.30000000000000004 0.3 == (0.1 + 0.1 + 0.1) # False 이러한 결과가 나온 게 컴퓨터가 부동소수를 다루는 방식에 의해 야기되는 반올림 에러(rounding error) 의 결과다. 이는 파이썬만의 문제가 아니라, CPU의 부동소수점 회로에 직접 구현된 하드웨어 표준 때문이다.\n해결방식 이 부동소수점 계산은 은행이나 원자로 같은 실시간성이 강하고, 사람 생명이나 금전적인 피해를 일으킬 가능성이 있는 업무의 경우에는 매우 중요하다. 위 같은 업무처럼 정확성이 요구된다면 어떻게 이를 해결할 수 있을까?\n파이썬의 내장 모듈이 decimal을 사용하자. docs python - decimal 에 잘 정리되어 있다.\n속도는 느리지만 Decimal 객체는 부동소수 값을 정확하게 대체한다.\ndecimal.Decimal('0.1')을 사용하면 정확한 숫자 0.1을 나타내는 객체가 생성된다.\n하지만 0.1을 문자열이 아니라 정수로 입력하면 다음과 같다.\n1 2 3 import decimal decimal.Decimal(0.1) # Decimal(\u0026#39;0.1000000000000000055511151231257827021181583404541015625\u0026#39;) decimal.Decimal(\u0026#39;0.1\u0026#39;) # Decimal(\u0026#39;0.1\u0026#39;) 하지만, 위 코드에서 본 것처럼 정수로 입력하면 Decimal 객체의 정밀도는 무한하지 않다.\n예측 가능하고 안정적인 수준의 정밀도를 지원할 뿐이다.\n만약 소수점 자리수를 원하는 자리수로 제한하고 싶다면?\n1 2 3 4 5 6 import decimal decimal.getcontext().prec # 28 decimal.Decimal(1) / 3 # Decimal(\u0026#39;0.3333333333333333333333333333\u0026#39;) decimal.getcontext().prec = 2 decimal.Decimal(1) / 3 # Decimal(\u0026#39;0.33\u0026#39;) decimal.getcontext().prec에 원하는 자리수를 할당하여 출력한다.\n7. 부등 연산자 !=를 연달아 쓰지 말자 (18 \u0026lt; age) and (age \u0026lt; 35) 를 연달아 작성하면 18 \u0026lt; age \u0026lt; 35 다. six = 6; halfDozen = 6을 연달아 작성하면 six = halfDozen = 6 이다. 이처럼 파이썬은 연달아 작성할 수 있다.\n하지만, 이러지 말아야하는 게 있는데, 바로 \u0026lsquo;부등 연산자 !=\u0026rsquo; 다. 아래 코드를 보자.\n1 2 3 4 a = \u0026#39;cat\u0026#39; b = \u0026#39;dog\u0026#39; c = \u0026#39;moose\u0026#39; a != b != c # True 위 코드는 연달아 비교된 걸로 생각이 들 것이다. 하지만 사실은 (a != b)와 (b != c)만 적용된 것이다.\n그래서 다음과 같이 작성해도 동일한 결과가 나온다.\n1 2 3 4 a = \u0026#39;cat\u0026#39; b = \u0026#39;dog\u0026#39; c = \u0026#39;cat\u0026#39; a != b != c # True 오해의 소지가 있기 때문에 부등 연산자를 연달아 사용하지 말자.\n8. 단일 아이템 튜플에서는 쉼표를 잊지 말자 단일 아이템 튜플에서는 쉼표를 반드시 입력해야 튜플로 인식된다.\n1 2 3 4 5 type((1)) # int type((1,)) # tuple type((\u0026#39;cat\u0026#39;)) # str type((\u0026#39;cat\u0026#39;,)) # tuple Reference 클린 코드, 이제는 파이썬이다. ","permalink":"http://jeha00.github.io/post/bookstudy/pythoncleancode/chapter08_commonpythongotchas/","summary":"파이썬 코드를 작성하면서 빠지기 쉬운 함정들과 이에 대한 해결책을 파이썬스러운 코드를 통해 해결해본다.","title":"클린 코드, 이제는 파이썬이다: 파이썬에서 빠지기 쉬운 함정들(Common Python Gotchas)"},{"categories":"Book Study","content":"0. Introduction 아래 book study는 알 스웨이가트가 지었고, 박재호님이 번역하신 클린 코드, 이제는 파이썬이다. 를 읽고 진행한 book study 입니다. 영문 원본으로 온라인 공개된 자료가 있어서 영문으로 학습합니다.\n기존에 읽었던 Clean Code는 자바 코드로 되어 있어서, 먼저 파이썬 클린 코드를 학습 후 시작할려고 합니다.\n이번 book study를 진행하면서 code에 대한 철학이 생기고, code를 바라보는 눈이 깊어지고, 넓어지기를 바랍니다.\n각 chapter를 읽고 내용 정리하는 식으로 진행합니다.\n이번에 학습하는 chapter의 주제는 \u0026lsquo;Chapter 07: Programming Jargon - 파이썬 세상의 프로그래밍 언어\u0026rsquo; 입니다.\n파이썬 용어집: https://docs.python.org/3/glossary.html 참고하기\n파이썬 객체 설명: https://docs.python.org/3/reference/datemodel.html 참고하기\n본격적으로 시작하기 전에 \u0026lsquo;전문 용어\u0026rsquo;에 대해서 생각을 잠시 해보자. 이 \u0026lsquo;전문 용어\u0026rsquo;를 풀어서 설명할 수 있다. 하지만, 그러기 시작하면 문장이 길어져서 일하기가 어려워진다. 그래서 약어를 선호하게 되고, 전문 용어를 선호하게 된다.\n그래서 이번 장에서는 파이썬에서 사용되는 프로그래밍 언어의 전문 용어의 의미를 짚어본다. 그 이유는 소프트웨어 개발의 용어와 파이썬 세상의 프로그래밍 용어가 미묘하게 의미 차이가 있기 때문이다. 그래서 이번 장에서는 파이썬과 관련된 용어만 다룬다.\n1. 각종 용어 정의 각종 용어에 대한 공식 문서 정의는 이 링크를 참고한다.\n프로그래밍 언어로서 파이썬 vs 인터프리터로서 파이썬 \u0026lsquo;파이썬이 프로그램을 실행한다\u0026rsquo; 또는 \u0026lsquo;파이썬이 예외를 발생시킨다\u0026rsquo; 에서 파이썬은 .py 파일의 코드를 읽고 수행하는 실제 소프트웨어인 파이썬 인터프리터를 의미한다.\n그리고, 파이썬 인터프리터는 파이썬 소프트웨어 재단이 관리하며 www.python.org 에서 다운받을 수 있는 C파이썬(CPython)을 의미한다. 이 인터프리터를 구현체(implementation) 라고 한다.\n구현체의 종류에는 C 프로그래밍 언어로 된 C파이썬, java로 작성된 Jython, 프로그램 실행됨에 따라 컴파일하며 파이썬으로 작성된 PyPy가 있다.\n가비지 컬렉션 프로그래밍 언어는 수동적으로 메모리 할당과 할당 해제 과정을 사람이 직접 지시를 내려야 했다. 그래서 사람이 이를 잊으면 메모리 누수 같은 많은 버그를 일으켰다.\n하지만, 이제는 가비지 컬렉션(garbage collection) 이 존재하기 때문에, 메모리 할당과 해제를 해야하는 시점을 추적하여 프로그래머의 부담을 덜어주는 자동화된 메모리 관리 기법 을 말한다.\n1 2 3 4 5 def someFunction(): print(\u0026#39;someFunction() called\u0026#39;) spam = [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;moose\u0026#39;] someFunction() 위 함수를 호출하는 순간 spam 이라는 변수가 메모리에 올라가고, 호출이 반환되면 로컬 변수를 해제해서 다른 데이터가 해당 메모리를 사용 가능하도록 한다.\n리터럴 리터럴 이란? 사람이 직접 손으로 작성한 \u0026lsquo;고정 값\u0026rsquo;을 나타내는 소스 코드 텍스트에 나타나는 값 이라고 생각하면 된다. 파이썬 소스 코드에는 내장 데이터 형식만 리터럴 값을 가질 수 있으므로, 변수 age는 리터럴 값이 아니다. 42와 \u0026lsquo;Zophie\u0026rsquo;는 literal이다.\n1 age = 42 + len(\u0026#39;Zophie\u0026#39;) 키워드 모든 프로그래밍 언어에는 언어만의 고유의 키워드를 가진다. 이를 예약어라고 부른다. 이 키워드들은 변수명으로 사용해서는 안된다.\n🔆 객체, 값, 인스턴스, 아이디 객체 는 데이터를 표현하는 것인데, 여기서 데이터란 복잡한 데이터 구조 전부를 포함하여 의미한다.\n모든 객체에는 값(value), 아이디(identity), 데이터 타입(data type) 이 존재한다.\n아래의 spam 은 변수지만, ['cat', 'dog', 'moose'] 라는 값을 가진 리스트 객체가 포함된 변수라고 말할 수 있다.\n1 2 3 4 5 6 7 8 spam = [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;moose\u0026#39;] id(spam) # 33805656 spam.append(\u0026#39;snake\u0026#39;) id(spam) # 33805656 spam = [x for x in range(1, 4)] id(spam) # 33838544 새로운 값을 spam에 지정하니 id 값이 바뀌었다.\nspam이라는 식별자들은 동일한 객체를 참조할 수 있기 때문에, 아이디와는 전혀 다르다.\n그러면 동일한 객체를 참조하는 두 식별자의 id값은 어떨까?\n1 2 3 4 5 spam = {\u0026#39;name\u0026#39;: \u0026#39;Zophie\u0026#39;} id(spam) # 33861824 eggs = spam id (eggs) # 33861824 동일한 딕셔너리 객체를 참조하기 때문에 id는 동일하다.\n이런 상황에서 spam이 참조한 객체의 값을 변경하면?\n1 2 3 spam[\u0026#39;name\u0026#39;] = \u0026#39;Al\u0026#39; spam # {\u0026#39;name\u0026#39;: \u0026#39;Al\u0026#39;} eggs # {\u0026#39;name\u0026#39;: \u0026#39;Al\u0026#39;} spam만 변경되었는데, eggs도 변경되었다. 그 이유는 두 식별자가 동일한 객체를 참고하기 때문이다.\n변수는 값의 보관소(container)가 아니라 엄밀히 말하면 값의 참조다. 변수를 설명할 때, 상자로 흔히들 설명하는데 이보다는 아래 이미지처럼 레이블로 생각해보자. 여러 변수가 하나의 객체를 가리킬 수 있으므로 그 객체는 여러 변수에 저장될 수 있다.\n그래서 항상 할당 연산자(assignment operator)는 객체가 아닌 참조를 복사한다는 사실을 이해하지 못한채, 객체의 복사본을 만든다고 생각하여 버그를 유발할 수 있다.\n1 2 3 4 5 6 7 8 spam = {\u0026#39;name\u0026#39;: \u0026#39;Zophie\u0026#39;} eggs = spam spam is eggs # True spam == eggs # True bacon = {\u0026#39;name\u0026#39;: \u0026#39;Zophie\u0026#39;} spam == bacon # True spam is bacon # False 동일한 값을 spam과 bacon이 가졌다고 해도, 엄연히 다른 객체다. 그래서 맨 마지막에 False가 뜬 것이다.\nbacon과 spam이 동일한 id를 가지기 원한다면 다음과 같이 작성한다.\n1 bacon = spam 아이템 list나 dictionary 처럼 컨테이너 객체 안에 있는 객체를 파이썬에서는 아이템(item) 또는 원소(element)라고 부른다. ['dog', 'cat', 'moose'] 내의 문자열은 객체지만 아이템, 원소라고도 부른다.\n가변 데이터 타입, 불변 데이터 타입 파이썬의 모든 객체는 값, 데이터 타입, 아이디를 가지며 이 중에서 값만 변경할 수 있다. 값을 변경할 수 있으면 mutable 객체이며, 변경할 수 없으면 immutable 객체다.\n가변 데이터 타입 불변 데이터 타입 리스트(list) 정수(Integer) 딕셔너리(Dictionary) 부동소수점(Floating-point number) 집합(set) 부울(Boolean) 바이트 배열 문자열(string) 배열(Array) 고정집합(Frozen set) 튜플(tuple) 바이트(Byte) String 아래 두 문자열 객체는 서로 다르므로 각기 다른 id를 가진다.\n1 2 3 4 5 spam = \u0026#39;hello\u0026#39; id(spam) # 140350166163120 spam = \u0026#39;goodbye\u0026#39; id(spam) # 140349607257072 기존 문자열에 새로운 문자열을 더하는 연산도 다른 id 값을 가지게 된다.\nList 하지만, 가변 객체를 가리키는 변수 안의 값은 in-place 방식으로 수정될 수 있다.\n1 2 3 4 5 6 spam = [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;] id(spam) # 140349608412032 spam.append(\u0026#39;moose\u0026#39;) spam # [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;moose\u0026#39;] id(spam) # 140349608412032 이 리스트도 id 값이 바뀌는 경우가 있다. 바로 + 연산자를 사용해 리스트를 연결하는 경우다. 하지만 이 또한 .extend() method를 사용하면 id값이 변경되는 것 없이 값만 수정된다.\n1 2 3 4 5 6 7 8 9 # + 연산자 spam = spam + [\u0026#39;rat\u0026#39;] spam id(spam) # 140349608476352 # extend 메서드 사용 spam.extend([\u0026#39;rat\u0026#39;]) spam id(spam) # 140349608476352 extend method로 list를 추가하면 id값이 바뀔 것 같지만, 그렇지 않았다.\n+ 연산을 하면서 id 값이 변경되지 않기 위해서는 += 연산자를 사용하면 된다.\nTuple 1 2 3 4 5 6 7 8 9 10 11 eggs = (\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, [2, 4, 6]) id(eggs) # 140349884290368 id(eggs[2]) # 140349875845504 eggs[2] += [8, 10] --------------------------------------------------------------------------- TypeError Traceback (most recent call last) Input In [76], in \u0026lt;cell line: 1\u0026gt;() ----\u0026gt; 1 eggs[2] += [8, 10] TypeError: \u0026#39;tuple\u0026#39; object does not support item assignment 하지만 tuple의 내부 list는 가변이기 때문에 수정할 수 있다.\n1 2 3 eggs[2] += [8, 10] eggs[2].append(8) id(eggs[2]) # 140349875845504 인덱스, 키, 해시 list list의 원소에 접근하기 위해서는 인덱싱을 해야하는데 이 때 **대괄호([])**를 사용한다.\n인덱스는 0 기반 인덱스 를 사용한다.\ndictionary, tuple dictionary에서 인덱싱은 key 값을 사용한다. 그래서 해시 가능한 객체가 될 수 있다.\n객체의 해시는 객체의 수명 주기 동안 절대로 변하지 않으며, 객체의 값이 같다면 해시도 반드시 같아야 한다. 이 값을 기준으로 해시를 반환하기 때문이다. 그래서 객체의 id는 달라도, 값이 같으면 해시는 같다.\n해시가 가능한 대상은 immutable data type(ex: string, integer, tuple \u0026hellip;)만 가능하다. 그래서 딕셔너리에서는 해시 가능한 아이템만 키로 사용할 수 있고, 해시 불가능한 리스트가 포함된 튜플은 키로 사용할 수 없다.\n1 2 3 4 5 6 7 8 hash(\u0026#39;hello\u0026#39;) 8683495156774441600 hash(3.14) 322818021289917443 hash([1,2,3]) TypeError: unhashable type: \u0026#39;list\u0026#39; 컨테이너, 시퀀스, 매핑 파이썬에서 컨테이너, 시퀀스, 매핑, 집합 타임은 무엇일까?\n컨테이너: 여러 종류의 객체를 포함할 수 있는, 즉 어떤 데이터 타입이든 포함할 수 있는 객체 ex)list, dictionary, tuple..\n시퀀스: 순서가 있어서 정수 인덱스를 통해 원소에 접근이 가능한 컨테이너 데이터 타입의 객체 ex) list, tuple..\n매핑: 인덱스 대신 키를 사용하는 컨테이너 데이터 타입의 객체 ex) dictionary\n매핑은 3.6버전부터는 정렬되었지만, 그 이전에는 정렬되지 않았다. 매핑이 정렬되었다는 건 딕셔너리의 키-값 쌍의 삽입 순서가 유지된다는 것이다. 하지만 그렇다고 인덱스를 통해 원소에 접근할 수 있는 건 아니다. 파이썬에서 매핑 유형은 매우 다양하다: OrderedDict, ChainMap, Counter, UserDict 등등 이중밑줄 메소드, 매직 메소드 위 메소드들은 파이썬에서 이름의 앞 뒤에 2개의 밑줄(_)이 붙는 특수한 메소드를 말한다.\n주로 연산자 오버로드에 사용된다.\nDunder는 Double UNDERscore의 줄임말이다.\n가장 익숙한 dunder method인 __init__은 객체를 초기화한다.\n17장에서 자세히 설명한다.\n모듈, 패키지 모듈은 다른 파이썬 프로그램이 해당 모듈의 코드를 사용할 수 있게 해주는 기능을 말한다.\n파이썬과 함께 설치되는 모듈들을 총칭하여 파이썬 표준 라이브러리라고 한다.\n패키지는 __init__.py라는 이름의 파일 담겨진 폴더 안에 있는 모듈들의 집합을 말한다.\n호출가능 객체, 일급 객체 호출 가능 객체 호출가능 연산자(callable operator)를 구현하는 모든 객체는 호출가능 객체다.\n호출가능 연산자란 ()를 말한다.\n일급 객체 파이썬에서 함수는 일급 객체(first-class object)이므로, 변수에 저장되고 함수 호출에서 인수로 전달되고, 함수 호출 결과로 반환되는 등 객체로 할 수 있는 모든 기능을 할 수 있다.\n1 2 3 4 5 6 7 def spam(): print(\u0026#39;Spam! Spam! Spam! Spam!\u0026#39;) spam() # Spam! Spam! Spam! Spam! eggs = spam eggs() # Spam! Spam! Spam! Spam! 이 방식은 주로 함수 이름을 변경할 때 사용된다. 상당 수의 기존 코드가 예전 이름을 쓰고 있으며, 옛 이름을 변경하기 힘들 경우 별칭을 활용한다.\n그 외에 일급 함수를 사용하는 이유 는 함수를 다른 함수에 인자로 넘기기 위함 이다.\n아래 코드를 보자.\n1 2 3 4 5 6 7 8 def callTwice(func): func() func() callTwice(spam) Spam! Spam! Spam! Spam! Spam! Spam! Spam! Spam! 2. 흔히 혼동되어 사용되는 용어 문(statement) vs 표현식(expression) expression은 값들과 연산자들로 구성된 명령어로, 변수이거나 값을 가지거나 함수 호출로 값을 반환하는 것들을 말한다.\n1 2 3 2 + 2 len(myName) \u0026gt; 4 myName.isupper() 하지만 statement는 값으로 도출되지 않는 모든 명령으로, 다른 함수에 인수로 전달될 수 있고, 변수에 할당할 수 있다.\nif 문, for 문, return 문 등의 표현식이 포함된다.\n블록 vs 절 vs 바디 블록(block) 은 들여쓰기로 시작하여 해당 들여쓰기 수준이 이전 들여쓰기 수준으로 돌아오면 종료된다.\nfor 문, if 문에 따라나오는 코드를 해당 문(statement)의 블록 이라고 한다.\n공식 문서에서는 모듈, 함수, 클래스 같이 한 단위로 실행하는 파이썬 코드 조각을 지칭하는데는 블록을 사용한다.\n한 편으로는 파이썬 공식 문서에서는 블록보다는 \u0026lsquo;절(clause)\u0026rsquo; 이라는 용어를 선호한다.\n아래 코드를 보면 if 문은 clause header(절 헤더) 이고, 그 아래 오는 부분은 clause suite 또는 바디(body) 라고 한다.\n1 2 3 if name == \u0026#39;Zophie\u0026#39;: print(\u0026#39;Hello, kitty!\u0026#39;) print(\u0026#39;Do you want a treat?\u0026#39;) 변수 vs 속성 변수: 객체를 가리키는 이름\n속성: 점(.) 다음에 나오는 모든 이름이기 때문에 객체(점/마침표 앞에 위치하는 이름)와 연관된다.\n1 2 3 4 import datetime spam = datetime.datetime.now() spam.year spam.month 위 코드에서 spam은 datetime을 포함하는 변수다.\nyear, month는 해당 객체의 속성이다.\n함수 vs 메서드 method는 클래스와 연관된 일종의 function이다.\n1 2 3 4 5 6 len(\u0026#39;Hello\u0026#39;) \u0026#39;Hello\u0026#39;.uppper() import math math.sqrt(25) 위 예제에서 len()은 함수이고, upper()는 문자열 메소드다. 이 문자열 메소드는 객체의 속성으로 간주되기도 한다.\n마침표/점이 있다고 해서 반드시 메소드라고 생각해서는 안된다.\n반복가능 객체 vs 반복자 for 문에서 사용되기 위해서는 iterable object (반복가능한 객체)여야 한다.\n반복 가능한 객체로는 range, list, tuple, string 같은 유형이 포함된다.\nfor 루프문에는 iter() 과 next() 를 호출한다.\n반복 가능 객체는 파이썬에 내장된 iter()에 전달되며, 이 함수는 iterable object를 iterator object(반복자 객체)로 반환한다. 그후, next()에 전달되어 객체에 포함된 다음 원소를 반환한다.\n1 2 3 4 5 6 7 8 iterableObj = range(3) # range(0, 3) iterableObj = iter(iterableObj) # \u0026lt;range_iterator at 0x7fc9b1db24b0\u0026gt; listObj = [1, 2, 3] listObj = iter(listObj) # \u0026lt;list_iterator at 0x7fc9b1ddf580\u0026gt; print(next(listObj)) # 1 print(next(listObj)) # 2 print(next(listObj)) # 3 print(next(listObj)) # StopIteration: iter()은 __iter__을, next()는 __next__를 호출하기 때문에, 클래스 문에서 나만의 데이터 타입을 만들 때 이 던더 메소드들을 사용해서 특별한 메소드를 구현할 수 있다.\n구문 에러 vs 런타임 에러 vs 의미 에러 구문 에러 지정된 프로그래밍 언어의 유효한 명령어에 대한 규칙에서 벗어나 잘못된 문법이나 단어들이 입력되었을 경우, 발생되는 에러\n런타임 에러 실행 중인 프로그램이 존재하지 않는 파일을 열려고 하거나, 숫자를 0으로 나누는 것과 같은 몇 가지 작업을 수행하지 못 하는 경우에 발생한다.\n의미 에러(semantic error) 에러 메세지를 발생하거나, 충돌을 일으키지 않지만 컴퓨터가 프로그래머의 의도한 방식으로 코드를 수행하지 않은 걸 말한다.\n파라미터 vs 인수 parameter(파라미터) 는 def 문에서 괄호 사이의 변수 이름들을 말한다.\nargument(인수) 는 함수 호출에서 전달된 값으로 파라미터에 지정된다.\n1 2 def greeting(name, species): print(name + \u0026#39;is a\u0026#39; + species) 타입 강제변환 vs 타입 캐스팅 데이터 타입이 \u0026lsquo;명시적으로\u0026rsquo; 변환되는 걸 객체를 casting 한다고 할 수 있다.\n하지만, \u0026lsquo;묵시적으로\u0026rsquo; 데이터 타입이 변환되는 거를 타입 강제변환(type coercion) 이라고 한다.\n1 2 3 4 5 # type casting int(\u0026#39;42\u0026#39;) # 42 # type coercion 2 + 3.0 # 5.0 프로퍼티(property) vs 속성(attribute) 속성은 객체와 연관된 이름이라는 걸 변수 vs 속성 편에서 알았다.\n파이썬에서 property는 훨씬 더 깔끔한 구문으로 getter와 setter를 사용할 수 있는데, 이 getter와 setter란 속성에 값을 직접 대입하는 것 대신, 프로그램은 해당 속성에 대한 setter method를 사용하여 올바른 값만 할당하도록 한다. 그리고, getter method를 사용하여 속성의 값을 읽는다.\n바이트 코드 vs 기계어 코드 소스 코드 \u0026ndash; (컴파일) \u0026ndash;\u0026gt; 기계어 코드: CPU의 명령어 집합\n이 기계어 코드로 컴파일된 프로그램을 바이너리(binary) 라고 한다.\n소스 코드를 기계어 코드로 바꾸는 방법에는 다른 방법이 있는데, 소스 코드를 기계어 코드로 만드는 대신 바이트 코드(bytecode)를 만들면 된다. 이 바이트 코드는 CPU가 직접 수행하는 게 아니라, 소프트웨어 인터프리터 프로그램이 수행한다.\n파이썬 바이트코드는 실제 CPU가 수행하는 명령어가 아닌 파이썬 내부에서 자체적으로 해석해서 수행하는 명령어로 구성되어 있다. .py 소스 파일이 인터프리터로 넘어갈 때 생성되는 .pyc 파일에 저장된다. C로 작성된 C파이썬 인터프리터는 파이썬 소스 코드를 파이썬 바이트코드로 컴파일한 다음 해당 바이트 코드를 수행할 수 있다.\n파이썬 인터프리터는 파이썬 소스 코드를 파이썬 바이트 코드로 컴파일한 다음, 해당 바이트 코드를 수행할 수 있다.\n스크립트 vs 프로그램, 스크립트 언어 vs 프로그래밍 언어 스크립트와 프로그램을 구별하는 방법 중 하나는 바로 코드 실행 방식이다.\n스크립트 언어로 작성된 스크립트는 소스 코드로부터 직접 해석되지만, 프로그래밍 언어로 작성된 프로그램은 바이너리로 컴파일 된다.\n파이썬 프로그램이 실행될 때, 바이트 코드로 컴파일하는 단계가 있어도 컴파일 언어로 바라보지 않는다.\n왜냐하면 언어는 컴파일이나 해석 관점이 아닌, 컴파일러나 인터프리터 구현체 관점으로 바라봐야하기 때문이다.\n라이브러리 vs 프레임워크 vs SDK vs 엔진 vs API 라이브러리 제 3자가 만든 코드 모음의 총칭\n프레임워크 제어 역전(inversion of control)로 동작하는 코드의 모음이다. 프레임워크의 요구에 따라 호출될 함수를 코드로 만든다.\nSDK(Software Development Kit) 특정 운영체제나 플랫폼에서 동작하는 애플리케이션 작성을 돕는 코드 라이브러리, 문서화, 도구가 모두 포함된다.\n엔진(engine) 개발자의 소프트웨어가 외부에서 제어할 수 있는 독립적으로 동작하는 대규모 시스템\nReference 클린 코드, 이제는 파이썬이다. ","permalink":"http://jeha00.github.io/post/bookstudy/pythoncleancode/chapter07_programjargon/","summary":"파이썬 세상의 프로그래밍 용어에 대해 알아본다.","title":"클린 코드, 이제는 파이썬이다: Program Jargon"},{"categories":"Book Study","content":"0. Introduction 아래 book study는 알 스웨이가트가 지었고, 박재호님이 번역하신 클린 코드, 이제는 파이썬이다. 를 읽고 진행한 book study 입니다. 영문 원본으로 온라인 공개된 자료가 있어서 영문으로 학습합니다.\n기존에 읽었던 Clean Code는 자바 코드로 되어 있어서, 먼저 파이썬 클린 코드를 학습 후 시작할려고 합니다.\n이번 book study를 진행하면서 code에 대한 철학이 생기고, code를 바라보는 눈이 깊어지고, 넓어지기를 바랍니다.\n각 chapter를 읽고 내용 정리하는 식으로 진행합니다.\n이번에 학습하는 chapter의 주제는 \u0026lsquo;Chapter 06: Pythonic Code\u0026rsquo; 입니다.\n1. 흔히 잘못 사용되는 구문 1.1 range() 보다는 enumerate()를 사용하자. 아래의 i는 index를 의미한다.\n1 2 3 4 # Not pythonic code animals = [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;moose\u0026#39;] for i in range(len(animals)): print(i, animals[i]) 위 코드를 파이썬스러운 코드로 바꿔보자.\n1 2 3 4 # Pythonic code animals = [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;moose\u0026#39;] for i, animal in enumerate(animals): print(i, animal) 보다 코드가 훨씬 깔끔해졌다.\nrange(len())은 구식 규약이므로 enumerate를 사용하자.\n만약 animal만 원한다면 range(len())을 사용하기보다는 다음과 같이 작성하자.\n1 2 for animal in animals: print(animal) 훨씬 깔끔하고, 직관적이다.\n1.2 open() 과 close()보다는 with문을 사용하자. open()과 close()를 통해서 파일 객체에 접근하기보다는 with 문을 사용하자.\nopen() 함수는 파일을 읽거나 쓰는 메소드가 포함된 파일 객체를 반환한다.\n그리고, close() 함수로 파일을 닫아 다른 프로그램에서 읽고 쓸 수 있게 한다.\n그러면 파이썬답지 않은 코드를 보자.\n1 2 3 fileObj = open(\u0026#39;spam.txt\u0026#39;, \u0026#39;w\u0026#39;) fileObj.write(\u0026#39;Hello, world!\u0026#39;) fileObj.close() 이를 pythonic code로 작성해보자.\n1 2 with open(\u0026#39;spam.txt\u0026#39;, \u0026#39;w\u0026#39;) as fileObj: fileObj.write(\u0026#39;Hello, world!\u0026#39;) close()에 대한 명시적인 호출이 없어도, 실행 흐름이 블록을 벗어나면 with 선언문은 close 호출을 자동적으로 실행한다.\n1.3 == 대신 is를 써서 None과 비교하자. == (equality operator)는 두 객체의 value를 비교하는 반면, is (identity operator)는 두 객체의 id를 비교한다. 값이 동일해도 id값은 다를 수 있다.\n어떤 파이썬 프로그램에서도 None 객체는 하나밖에 없다. 그래서 변수가 None으로 설정되어 있다면 is None 비교는 항상 참이다. 그래서 None과 비교할 때는 == 가 아닌 is를 사용해야 한다.\nNone 값을 비교할 때 ==를 사용하고 싶으면 다음과 같이 오버라이딩을 해야 한다.\n1 2 3 4 5 6 7 8 class Practice: def __eq__(self, other): if other is None: return True spam = Practice() print(spam == None) # True 하지만, 대체로 == None 보다는 is None을 사용한다는 걸 기억하자.\nTrue와 False는 is 연산자가 아닌 == 를 사용하여 판단한다. id보다는 그 값 자체의 판단에서 사용되기 때문이다. 이 때 if \u0026lt;변수\u0026gt; == True: 또는 if \u0026lt;변수\u0026gt; == False: 보다는 if \u0026lt;변수\u0026gt;: 또는 if not \u0026lt;변수\u0026gt;: 처럼 연산자와 boolean 값을 생략하는게 파이썬에서 일반적인 사용 방식이다.\n2. 문자열 포매팅 2.1 문자열에 백슬래시가 많은 경우에는 원시 문자열을 사용하자. 원시 무자열이란 \u0026lsquo;r\u0026rsquo; 접두사가 붙은 문자열 리터럴을 말한다.\n1 2 3 4 5 6 # Not pythonic code print(\u0026#39;The file is in C:\\\\Users\\\\Al\\\\Desktop\\\\Info\\\\Archive\\\\Spam\u0026#39;) # Pythonic code print(r\u0026#39;The file is in C:\\Users\\Al\\Desktop\\Info\\Archive\\Spam\u0026#39;) 2.2 f-string을 사용한 문자열 formatting 처음에는 print('Hello,' + name) 처럼 연산자와 문자열, 변수를 조합하여 출력하는 방식이었다가\n%s 를 사용하는 방식에서 .format() 을 사용하는 방식으로 발전했다.\n하지만, 이는 가독성이 좋지 않다.\n그래서 파이썬 3.6에서 f-string 방식을 도입했다.\n문자열 내부에 변수 이름과 표현식을 인라인으로 넣을 수 있기 때문에 코드의 가독성이 개선된다.\n3. 리스트의 얕은 사본 만들기 얕은 사본을 만드는 방식에 다음과 같이 작성할 수 있다.\n1 2 3 4 spam = [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;rat\u0026#39;, \u0026#39;eel\u0026#39;] eggs = spam[:] id(spam) == id(eggs) # False 슬라이스를 사용해서 새로운 객체를 생성할 수 있다.\n하지만 이는 파이썬스럽지 않다.\n파이썬스럽게 작성한다면 다음과 같다.\n1 2 3 import copy spam = [\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;rat\u0026#39;, \u0026#39;eel\u0026#39;] eggs = copy.copy(spam) 같은 값의 다른 객체를 생성하고 싶으면 copy module을 사용해보자.\n4. 파이썬다운 딕셔너리 사용법 4.1 dictionary에서 get()과 setdefault()를 사용하자. get() 존재하지 않은 딕셔너리 키에 접근하고자하여 KeyError가 발생해서 다음과 같이 파이썬스럽지 않은 코드를 작성하기도 한다.\n1 2 3 4 5 6 # Not pythonic code numberOfPets = {\u0026#39;dogs\u0026#39;: 2} if \u0026#39;cats\u0026#39; in numberOfPets: print(\u0026#39;I have\u0026#39;, numberOfPets[\u0026#39;cats\u0026#39;], \u0026#39;cats\u0026#39;) else: print(\u0026#39;I have 0 cats\u0026#39;) 위 코드보다는 파이썬스럽게 작성한다면 다음과 같이 작성한다.\n1 2 3 # Pythonic code numberOfPets = {\u0026#39;dogs\u0026#39;: 2} print(f\u0026#39;I have {numberOfPets.get(\u0026#39;cats\u0026#39;, 0)}, cats\u0026#39;) setdefault() 만약 해당 키가 없어서 기본값을 설정한다면?\n1 2 3 4 5 6 7 8 9 10 11 12 # Not Pythonic code numberOfPets = {\u0026#39;dog\u0026#39;: 2} if \u0026#39;cats\u0026#39; not in numberOfPets: numberOfPets[\u0026#39;cats\u0026#39;] = 0 numberOfPets[\u0026#39;cats\u0026#39;] += 10 numberOfPets[\u0026#39;cats\u0026#39;] # Pythonic code numberOfPets = {\u0026#39;dogs\u0026#39;: 2} numberOfPets.setdefault(\u0026#39;cats\u0026#39;, 0) numberOfPets[\u0026#39;cats\u0026#39;] += 10 4.2 기본값으로 collections.defaultdict를 사용하자. 그리고 기본값을 위해 계속해서 setdefault()를 사용하기보다는 defaultdict를 사용하는 걸 추천한다.\n다음 코드는 int를 넘겼을 때, int의 최소값이 기본값으로 자동적으로 들어가는 코드다.\n1 2 3 4 5 6 7 import collections # int scores = collections.defaultdict(int) scores[\u0026#39;Al\u0026#39;] scores[\u0026#39;Zophie\u0026#39;] scores # defaultdict(int, {\u0026#39;Al\u0026#39;: 1, \u0026#39;Zophie\u0026#39;: 0}) 아래 코드는 list를 넘겼을 때, 키값만 입력하면 빈 리스트가 자동적으로 값으로 들어가는 코드다.\n1 2 3 # list scores = collections.default(list) scores # defaultdict(list, {\u0026#39;Al\u0026#39;: [], \u0026#39;Zophie\u0026#39;: []}) 4.3 switch 문 대신에 dictionary를 사용하자. if-elif 조건문을 dictionary로 대체하자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # if-elif case if season == \u0026#39;Winter\u0026#39;: holiday = \u0026#39;New year\\\u0026#39;s Day\u0026#39; elif season == \u0026#39;Spring\u0026#39;: holiday = \u0026#39;May Day\u0026#39;: elif season == \u0026#39;Summer\u0026#39;: holiday = \u0026#39;Juneteenth\u0026#39;: elif season == \u0026#39;Fall\u0026#39;: holiday = \u0026#39;Halloween\u0026#39;: else: holiday = \u0026#39;Personal day off\u0026#39; # dictionary case holiday = {\u0026#39;Winter\u0026#39; : \u0026#39;New Year\\\u0026#39;s Day\u0026#39;, \u0026#39;Spring\u0026#39;: \u0026#39;Man day\u0026#39;, \u0026#39;Summer\u0026#39;: \u0026#39;Juneteenth\u0026#39;, \u0026#39;Fall\u0026#39;: \u0026#39;Halloween\u0026#39;, }.get(season, \u0026#39;Personal day off\u0026#39;) season의 할당값에 따라서 다른 걸 반환하고, 만약 season에 할당된 값이 없다면 기본값을 반환한다.\nif-elif case 보다 코드가 훨씬 짧아진 걸 알 수 있다. 하지만 가독성은 떨어진다.\n5. 조건식: 파이썬의 보기 흉한 3항 연산자 밀도가 높은 한 줄이지만 읽을 때는 이해가 안될 정도로 답답함을 주는 코드가 3항 연산자다. 그런데 왜 이것을 사용하는 걸까?\n많은 개발자들이 파이썬이 3항 연산자를 갖지를 원해서, 보기 흉할지라도 파이썬의 가치관과 벗어날지라도 사용하기를 선택된 사례다. 대다수의 개발자들은 3항 연산자가 익숙하기 때문이다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 3항 연산자를 사용하지 않은 경우 condition = True if condition: message = \u0026#39;Access granted\u0026#39; else: message = \u0026#39;Access denied\u0026#39; message # \u0026#39;Access granted\u0026#39; # 3항 연산자를 사용하는 경우 condition = False valueIfTrue = \u0026#39;Access granted\u0026#39; valueIfFalse = \u0026#39;Access denied\u0026#39; message = valueIfTrue if condition else valueIfFalse message # Access denied 6. 변수값 작업 6.1 체이닝 할당(Chaining Assignment)과 비교 연산자(Comparison Operators) 특정 변수가 원하는 범위 안에 있는지 확인하기 위해서 다음과 같이 작성할 때가 있다.\n1 2 # Unpythonic code if 42 \u0026lt; spam and spam \u0026lt; 99: 하지만, 파이썬에서는 chaining Comparison Operators (체이닝 비교 연산자)를 사용하기 때문에 다음과 같이 작성하는 게 보다 파이썬다운 코드다.\n1 2 # Pythonic code if 42 \u0026lt; spam \u0026lt; 99: 또한, 체이닝을 사용해서 동일한 값을 여러 변수들에게 한 번에 할당할 수도 있고, 같은지 유무를 확인할 수 있다.\n1 2 3 4 5 # Pythonic code spam = eggs = bacon = \u0026#39;string\u0026#39; print(spam, eggs, bacon) spam == eggs == bacon == \u0026#39;string\u0026#39; 하지만, 체이닝을 연달아 사용했을 때, 발생할 수 있는 버그도 존재한다. 이는 8장에서 알아본다.\n6.2 변수가 여러 값 중 하나인지 여부를 확인하자. 위 경우와 반대로 변수가 여러 값 중 하나인지는 어떻게 확인할 수 있을까?\n1 2 3 4 5 6 # Not pythonic code spam == \u0026#39;cat\u0026#39; or spam == \u0026#39;dog\u0026#39; or spam == \u0026#39;moose\u0026#39; # Pythonic code spam = \u0026#39;cat\u0026#39; spam in (\u0026#39;cat\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;moose\u0026#39;) 파이썬스럽지 않은 코드보다 파이썬답게 작성한 코드가 실행속도가 보다 더 빠르다는 걸 timeit module을 통해서 확인할 수 있다.\nReference 클린 코드, 이제는 파이썬이다. ","permalink":"http://jeha00.github.io/post/bookstudy/pythoncleancode/chapter06_writingpythoniccode/","summary":"파이썬을 파이썬스럽게 쓰지 못하는 부분들에 대해 알아보고, 이를 어떻게 파이썬스럽게 작성할지 알아본다.","title":"클린 코드, 이제는 파이썬이다: Write pythonic code"},{"categories":"Book Study","content":"0. Introduction 아래 book study는 알 스웨이가트가 지었고, 박재호님이 번역하신 클린 코드, 이제는 파이썬이다. 를 읽고 진행한 book study 입니다. 영문 원본으로 온라인 공개된 자료가 있어서 영문으로 학습합니다.\n기존에 읽었던 Clean Code는 자바 코드로 되어 있어서, 먼저 파이썬 클린 코드를 학습 후 시작할려고 합니다.\n이번 book study를 진행하면서 code에 대한 철학이 생기고, code를 바라보는 눈이 깊어지고, 넓어지기를 바랍니다.\n각 chapter를 읽고 내용 정리하는 식으로 진행합니다.\n이번에 학습하는 chapter의 주제는 \u0026lsquo;Chapter 05: Finding Code Smells\u0026rsquo; 입니다.\ncode smell: 1) 복사 붙여넣기한 코드 중복되는 코드 부분이 많아지고 길어질수록, 중복 제거를 더 해야합니다.\n저자는 프로그램에 3 ~ 4개의 사본이 있다면 코드 중복 제거를 고려하기 시작한다고 한다.\n중복 코드는 한 부분을 수정하면 다른 복사 붙여넣기한 코드도 수정해야한다.\n복사 붙여넣기한 모든 코드 부분을 다 수정하면 좋겠지만, 한 부분만 수정하고 나머지 수정하는 걸 잊을 수도 있고, 한 부분만 놓쳐서 error를 발생할 수 있다.\n그래서 더욱 함수로 만들어야 한다.\n아래는 중복 코드가 많은 잘못된 예시다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Bad case print(\u0026#39;Good morning!\u0026#39;) print(\u0026#39;How are you feeling?\u0026#39;) feeling = input() print(\u0026#39;I am happy to hear that you are feeling\u0026#39; + feeling) print(\u0026#39;Good afternoon!\u0026#39;) print(\u0026#39;How are you feeling?\u0026#39;) feeling = input() print(\u0026#39;I am happy to hear that you are feeling\u0026#39; + feeling) print(\u0026#39;Good evening!\u0026#39;) print(\u0026#39;How are you feeling?\u0026#39;) feeling = input() print(\u0026#39;I am happy to hear that you are feeling\u0026#39; + feeling) 해결책: 함수화 아래는 위 잘못된 케이스를 개선한 예시다.\n1 2 3 4 5 6 7 8 9 10 11 12 # Good case def ask_feeling(): print(\u0026#39;How are you feeling?\u0026#39;) feeling = input() print(\u0026#39;I am happy to hear that you are feeling\u0026#39; + feeling) print(\u0026#39;Good morning!\u0026#39;) ask_feeling() print(\u0026#39;Good afternoon!\u0026#39;) ask_feeling() print(\u0026#39;Good evening!\u0026#39;) ask_feeling() 다시 위 코드를 개선해보자.\n1 2 3 for time_of_day in [\u0026#39;morning\u0026#39;, \u0026#39;afternoon\u0026#39;, \u0026#39;evening\u0026#39;] print(f\u0026#39;Good {time_of_day} !\u0026#39;) ask_feeling() 이처럼 코드를 더 적은 수로, 목적이 확실하게, 유지보수성이 좋게 바꿀 수 있다.\ncode smell: 2) 의도가 드러나지 않은 값들 코드를 보면 뜬끔없이 숫자(magic number)나, 문자열이 나타나질 때가 있다.\n의도, 목적이 명확하게 드러나지 않는 부분 또한 code smell이 나는 부분이다.\n해결책: 숫자를 상수로 사용하기 숫자를 숫자로 그대로 사용하면 몇 달 후, 작성자가 다시 볼 때나 다른 사람이 볼 때 이 숫자의 의미를 알 수 없다.\n1 2 # Bad case expiration = time.time() + 604800 그래서 이를 옆에 주석을 달아서 다음과 같이 작성할 수 있지만, 이보다는 상수 변수로 사용하는 게 더 좋은 방식이다.\n1 2 3 4 5 6 7 8 9 10 # Bad case expiration = time.time() + 604800 # Expire in one week # Good case SECONDS_PER_MINUTE = 60 SECONDS_PER_HOUR = 60 * SECONDS_PER_MINUTE SECONDS_PER_DAY = 24 * SECONDS_PER_HOUR SECONDS_PER_WEEK = 7 * SECONDS_PER_DAY expiration = time.time() + SECONDS_PER_WEEK 이 방식으로 작성했을 때, 또 다른 장점을 예시를 들어 언급해보겠다.\n이렇게 동일한 값이어도 다른 상수로 구분했을 경우, NUM_CARDS_IN_DECK 를 수정해도 NUM_WEEKS_IN_YEAR 에 영향을 주지 않는다.\n1 2 3 4 5 6 # Good case NUM_CARDS_IN_DECK = 52 NUM_WEEKS_IN_YEAR = 52 print(\u0026#39;This deck contains\u0026#39;, NUM_CARDS_IN_DECK, \u0026#39;cards.\u0026#39;) print(\u0026#39;The 2-year contract lasts for\u0026#39;, 2 * NUM_WEEKS_IN_YEAR, \u0026#39;weeks.\u0026#39;) 해결책: 문자열을 상수로 사용하기 문자열로 입력을 하면 이 문자열이 무슨 목적과 의도를 가지는지 모른다. 그렇다고 변수로 입력하면 undefind 가 뜬다.\n아래 코드를 예를 들어 설명해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 NORTH = \u0026#39;north\u0026#39; SOUTH = \u0026#39;south\u0026#39; EAST = \u0026#39;east\u0026#39; WEST = \u0026#39;west\u0026#39; while True: print(\u0026#39;태양광 패널 방향을 정해라.\u0026#39;) direction = input().lower() if direction in (NORTH, SOUTH, EAST, WEST): break print(f\u0026#39;태양광 패널의 방향은 {direction} 이다.\u0026#39;) # Bad case 1 if direction == \u0026#39;nrth\u0026#39;: print(\u0026#39;북쪽을 바라보는 것은 효율적이지 않다.\u0026#39;) # Bad case 2 if direction == NRTH: print(\u0026#39;북쪽을 바라보는 것은 효율적이지 않다.\u0026#39;) 아래처럼 direction == 'nrth' 로 입력하면 'nrth' 가 무엇을 의미하는지 모르고, NRTH로 입력하면 undefined가 뜬다.\ncode smell: 3) 죽은 코드 죽은 코드란? 코드를 일시적으로 주석 처리하는 방식이 테스트 과정에서 흔히 사용된다.\n그런데, 주석 처리된 코드가 그대로 남아있으면, 왜 주석처리되었는지 모르는 상태가 된다.\n또한, 항상 false 조건인 if block이나, 절대 호출되지 않는 함수 등\n작성한 의미가 없는 코드 를 모두 죽은 코드 라고 한다.\n1 2 3 4 5 6 7 8 9 import random def coinFlip(): if random.randint(0, 1): return \u0026#39;Heads!\u0026#39; else: return \u0026#39;Tails!\u0026#39; return \u0026#39;The coin landed on its edge!\u0026#39; print(coinFlip) 위 실행에서 맨 마지막 줄인 return 'The coin landed on its edge!'은 실행되지 않는 코드다. 이것이 바로 죽은 코드다.\n죽은 코드의 예외: stub stub 이란 함수가 아직 호출될 준비가 되지 않은 것을 보여주는 코드 다.\n다음과 같이 함수가 실행될 때 error가 발생하지 않도록 아무 작업도 수행하지 않는 pass문이나, raise NotImplemnetedError 로 stub을 걸 수 있다.\n1 2 3 4 5 def example_function(): pass def example_function(): raise NotImplementedError code smell: 4) 숫자 접미사가 붙은 변수 숫자 접미사가 붙은 변수를 사용하지 말고, 그 변수가 3개 이상일 경우 collection을 사용하자\n이 부분은 이전에 학습한 Chapter 04의 naming에도 해당된다.\n숫자 접미사가 붙은 변수란 password1, password2, pet1Name, pet2Name, pet3Name 처럼 접미사로 숫자가 붙은 것 뿐만 아니라 숫자로 구분된 변수를 의미한다.\n이렇게 작성하면 변수들 간의 차이점을 알 수 없다.\n그래서 변수마다 고유한 이름을 작성하자.\n좌표계 개념을 변수에 도입하고 싶으면 x1, x2, y1, y2가 아니라 start_x, end_x, start_y, end_y 로 작성하자.\n숫자 접미사가 3개 이상인 경우 각 데이터를 독립적인 변수에 담는 것이 아닌 list, set, dictionary 같은 collection으로 저장 하자.\n1 2 3 4 5 6 7 8 # Bad case pet1Name = \u0026#39;one\u0026#39; pet2Name = \u0026#39;two\u0026#39; pet3Name = \u0026#39;three\u0026#39; # Good case petNames = [\u0026#39;one\u0026#39;, \u0026#39;two\u0026#39;, \u0026#39;three\u0026#39;] petNames = {\u0026#39;one\u0026#39;, \u0026#39;two\u0026#39;, \u0026#39;three\u0026#39;} 예외: 숫자가 고유 이름의 일부일 경우 enableIPv6 인 경우, IPv6는 고유 이름으로 상관없다.\ncode smell: 5) 그냥 함수나 모듈이어야하는 클래스 일회성 함수를 만들 때는 클래스 메서드를 만들지 말자.\n일회성 함수를 만들 때는 클래스를 사용하지 않는다.\n그리고, 함수를 그룹화할 때는 클래스가 아닌 모듈을 사용한다.\n클래스로 잘못만든 함수의 예시를 보자.\n1 2 3 4 5 6 7 8 9 10 import random class Dice: def __init__(self, sides=6): self.sides = sides def roll(self): return random.randint(1, self.sides) a = Dice() print(a.roll()) 이 클래스는 사실 아래 함수와 같다.\n1 print(random.randint(1, 6)) 클래스 작성에 대한 객체지향 설계 원칙은 Chapter 15 ~ 17을 참고하자.\ncode smell: 6) 중첩된 list comprehension 중첩 list를 만들 때는 \u0026lsquo;가독성\u0026rsquo;을 위해서 list comprehension 하나에 for 루프문을 사용하여 만들자\n여러 종류의 comprehension 파이썬에는 list comprehension 외에도 set comprehension, dictionary comprehension이 존재한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # list comprehension 사용 x span = [] for number in range(100): if number % 5 != 0: span.append(str(number)) # list comprehension 사용 o span = [str(number) for number in range(100) if number % 5 != 0] # set comprehension span = {str(number) for number in range(100) if number % 5 != 0} # dictionary comprehension span = {str(number): number for number in range(100) if number % 5 !=0} list comprehension을 사용하여 중첩 리스트 만들기 또한 중첩 리스트를 list comprehension으로 생성할 수 있다.\n1 2 3 # nested list comprehension nested_int_list = [[0, 1, 2, 3], [4], [5, 6], [7, 8, 9]] nested_str_list = [[str(i) for i in sublist] for sublist in nested_int_list] 중첩 리스트 생성 시, 가독성 향상시키는 방법 하지만 이 코드는 가독성이 좋지 않기 때문에, 중첩 리스트를 생성할 때는 for 루프문을 하나 이상 사용해서 기존의 리스트 컴프리헨션을 확장하는 게 낫다.\n1 2 3 4 5 6 7 8 nested_int_list = [[0, 1, 2, 3], [4], [5, 6], [7, 8, 9]] nested_str_list = [] for sublist in nested_int_list: nested_str_list.append([str(i) for i in sublist]) # 결과 \u0026gt;\u0026gt;\u0026gt; nested_str_list [[\u0026#39;0\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;], [\u0026#39;4\u0026#39;], [\u0026#39;5\u0026#39;, \u0026#39;6\u0026#39;], [\u0026#39;7\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;9\u0026#39;]] code smell: 7) 빈 예외 처리 블록과 부실한 에러 메시지 해당 코드를 사용하는 사용자가 조치를 어떻게 취하라는 에러 메시지를 가진 예외 처리 블록을 만들자. 프로그램에서 발생할 수 있는 모든 예외를 처리하지 않으면 프로그램 개발은 완료된 것이 아니다.\n빈 예외처리 블록 예외 처리 블록(except)이 없으면 파이썬 프로그램은 즉시 멈추면서 충돌을 일으켜서 저장되지 않은 작업이 손실되거나, 파일이 반만 완료된 상태로 남아 있을 수 있다.\n그래서 개발자들은 이 부분을 비어있지 않도록 만들기 위해서 다음과 같이 작성하는 경우가 있다.\n1 2 3 4 5 try: num = input(\u0026#39;Enter a number: \u0026#39;) num = int(num) except ValueError: pass 이는 except 블록이 존재하지만 사실상 예외 처리를 하지 않는 것이다. 이렇게 프로그램이 넘어가면 에러를 처리하기보다는 감춰 버려서 더 심각한 버그가 만들어질 수 있다.\n부실한 에러 메세지 그래서 다음과 같이 수정해보자.\n1 2 3 4 5 try: num = input(\u0026#39;Enter a number: \u0026#39;) num = int(num) except ValueError: print(\u0026#39;An incorrect value was passed to int()\u0026#39;) 구체적인 문제 상황을 알 수 있지만, 사용자가 어떻게 할 수 있는 게 아니다. 이보다는 사용자가 여기서 무엇을 어떻게 해야할지를 설명하는 게 더 성숙한 코드라고 생각한다.\n그래서 print('You have to input a number') 로 하는 게 더 낫다고 판단된다.\nDebug debug 시에 많은 사람들이 디버깅 정보를 출려갛기 위해 print() 호출을 사용한다.\n쉬운 방법이지만, 장기적으로 버그를 진단하기 위해서는 debugger와 log에 의존하는 게 더 빠르다.\ncode smell에 관한 잘못된 통념 code smell(코드 악취)인 줄 알았지만, 사실 아닌 것들에 대해 정리해본다.\n함수 마지막에는 return 문이 하나만 있여야 한다? 하나의 입구, 하나의 출구라는 아이디어는 어셈블리어 언어와 포트란 언어로 프로그래밍하던 시절에 나온 조언을 잘못 해석한데에서 비롯된다.\n함수나 메소드마다 return 문을 하나씩만 유지하려면, 여러 개의 if-else 문으로 작성되어 분기처리하기 때문에 return 문이 둘 이상 있어도 괜찮다.\n함수에는 try 문이 둘 이상 있으면 안된다? 함수와 메서드는 한 가지일만 해야하는 건 맞지만, 예외 처리도 별도의 함수에서 발생해야 한다는 의미는 아니다.\n별도의 함수에서 발생해야한다는 사람들은 아래 코드를 다음과 같이 수정해야 한다고 말한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # before import os def deleteWithConfirmation(filename): try: if (input(\u0026#39;Delete\u0026#39; + filename + \u0026#39;, are you sure ? Y/N\u0026#39;) == \u0026#39;Y\u0026#39;): os.unlink(filename) except FileNotFoundError: print(\u0026#39;That file already did not exist.\u0026#39;) # after import os def handleErrorForDeleteWithConfirmation(filename): try: _deleteWithConfirmation(filename) except FileNotFoundError: print(\u0026#39;That file already did not exist.\u0026#39;) def _deleteWithConfirmation(filename): if input(\u0026#39;Delete\u0026#39; + filename + \u0026#39;, are you sure ? Y/N\u0026#39;) == \u0026#39;Y\u0026#39;\u0026#34; os.unlink(filename) 위와 같이 함수로 \u0026lsquo;한 가지 일\u0026rsquo;에 집중하여 나눴지만, 오히려 복잡하다.\n이 \u0026lsquo;일\u0026rsquo;을 어떻게 정의해야할지 생각해보자.\n플래그 인수는 나쁘다? 플래그 인수 란 함수 또는 메소드 호출의 boolean 인수를 말한다.\n이 플래그 인수는 다음과 같이 사용된다.\n1 2 3 4 5 def someFunction(flagArgument): if flagArgument: # 특정 코드 실행 else: # 완전히 다른 특정 코드 실행 이 값이 True냐 false이냐에 따라서 다르게 작동한다.\n이 인수를 사용하는 예가 sorted() 다. reverse 키워드 인자에 boolean 값을 전달해서 정렬 순서를 정할 수 있다.\n그런데 왜 플래그 인수를 code smell로 여길까?\n이 값에 따라 실행되는 내용이 달라서 2개의 함수를 만들어야 한다는 통념 때문이다.\n오히려 2개의 함수로 나누면 더 복잡해진다.\n전역 변수는 나쁘다? 함수와 메서드가 전역 변수를 사용한다면 변수가 잊혀지는 격리 기능을 일부 잃어버린다.\n이 격리 기능으로 올바르게 작동될 수도 있다.\n하지만, 이 전역 변수를 많이 사용하면 인수가 많아져서 복잡도가 높아지듯이 복잡해지고, 버그 발생 가능성도 높아진다.\n이 전역 변수를 사용하는 함수에서 에러가 발생됬을 경우 프로그램 전체에서 다 찾아봐야하기 때문에 전역 변수 사용을 권장하지 않는다.\n하지만 이 책에서 말하고 싶은 건 \u0026lsquo;모든\u0026rsquo; 전역 변수는 나쁜 아니라는 사실이다.\n주석은 불필요하다? 이런 주장이 나온 이유는 나쁜 주석이 달린 코드는 주석이 전혀 없는 것보다 더 나쁘기 때문이다.\n하지만, 주석을 간결하고 효과적으로 작성한다면 훨씬 도움이 된다.\n실제 프로그램에서는 주석이 너무 많거나 잘못된 주석이 문제라기보다는 주석이 아예 없거나 부족한 경우가 대부분이다.\n주석을 효과적으로 작성하는 방법은 Chapter 10에서 학습한다.\nReference 클린 코드, 이제는 파이썬이다. ","permalink":"http://jeha00.github.io/post/bookstudy/pythoncleancode/chapter05_findingcodesmell/","summary":"code smell(코드 악취)이 나는 부분들에는 무엇이 있고, 이를 어떻게 해결해야하는지에 대해 알아본다.","title":"클린 코드, 이제는 파이썬이다: Find code smell"},{"categories":"Project: Devket","content":"0. Introduction 이 repository는 현재 러닝스푼즈 나노디그리 - django backend 부트캠프에서 팀 프로젝트를 진행하면서 다음과 같은 내용들에 대해 정리하고자 만들었습니다.\n팀 정책을 이것으로 정한 이유 개발하면서 부딪힌 문제들에 대한 원인, 해결방안, 해결과정, 그리고 그 이유들 1. S3 CORS issue web application에서 S3 RDS에 있는 js 파일을 가져올 때 CORS(Cross Origin Resource Sharing) issue가 발생했다.\n위 이미지에 따르면 2가지 사실을 알 수 있다.\nCORS 정책에 의해 스크립트에 접근하는 게 막혔다는 것 \u0026lsquo;Access-Control-Allow-Origin\u0026rsquo; header가 http request header에 존재하지 않는다는 것 해결책은 이 header를 추가하는 것이라는 걸 알 수 있다.\n그렇다면 CORS란 무엇이고, 이 header는 어떻게 추가할 수 있는 것일까?\n2. CORS CORS 란? \u0026lsquo;Cross-Origin Resource Sharing\u0026rsquo; 으로 \u0026lsquo;교차 출처 리소스 공유 정책\u0026rsquo; 으로 직역할 수 있다. 여기서 교차 출처란 \u0026lsquo;서로 다른 출처\u0026rsquo;를 의미한다.\n그렇다면 origin의 기준 그리고, 서로 다른 지 판단하는 기준은 무엇일까?\nOrigin이란? origin = protocol + host + port number\n사용자가 사이트에 접속하는 방법은 URL 창에 URL 문자열을 입력하여 접근한다.\nURL 구성은 URL 분석 을 보면 \u0026lsquo;프로토콜\u0026rsquo; - \u0026lsquo;호스트명\u0026rsquo; - \u0026lsquo;Port 번호\u0026rsquo; - \u0026lsquo;path\u0026rsquo; - \u0026lsquo;query parameter\u0026rsquo;로 구성된다.\n여기서 origin은 \u0026lsquo;Protocol + Host + Port\u0026rsquo; 까지 합친 URL을 의미한다.\njavascript에서 location.origin이 바로 이 origin을 의미하기 때문에, 쉽게 알아낼 수 있다.\nCross-origin 그렇다면 cross origin이란 이 Protocol + Host + Port 가 합쳐진 것이 서로 다른 출처임을 이해할 수 있다. 즉, 이 3가지 중 하나라도 다르면 출처가 다르다.\nSame-origin 반대로 same origin은 이 3가지 모두가 동일한 출처라는 걸 의미한다.\n이외의 CORS의 기본 개념들 위 개념들 이외에 same-origin-policy, cross-origin-policy 등등 CORS에 관한 모든 내용이라고 할 정도로 내용이 좋은 블로그 악명 높은 CORS 개념 \u0026amp; 해결법 - 정리 끝판왕를 찾았기 때문에, 이 글에 추가하지 않는다.\n3. Solution 서버에서 Access-Control-Allow-Origin 헤더에 허용할 출처를 기재해서 클라이언트에 응답하면 되는데, 기재하는 방식은 알아보니 매우 다양했다.\nnginx, django, AWS 모두 다 가능했다.\n그중에서 AWS 방식을 선택했다.\n그 이유는 django의 경우 별도의 패키지를 설치해야 하기 때문이다. nginx는 nginx에서 설정을 해도 django나 AWS에서 그 설정이 제대로 되지 않으면 계속해서 뜨는 걸 이 블로그 Django, Nginx CORS 설정에서 확인했기 때문이다.\nAWS S3 \u0026gt; 권한 \u0026gt; CORS 편집 aws - CORS configuration을 참고하여 작성했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [ { \u0026#34;AllowedHeaders\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;AllowedMethods\u0026#34;: [ \u0026#34;GET\u0026#34;, \u0026#34;HEAD\u0026#34; ], \u0026#34;AllowedOrigins\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;ExposeHeaders\u0026#34;: [ \u0026#34;x-amz-server-side-encryption\u0026#34;, \u0026#34;x-amz-request-id\u0026#34;, \u0026#34;x-amz-id-2\u0026#34; ], \u0026#34;MaxAgeSeconds\u0026#34;: 3000 } ] 위 내용을 추가하니 CORS error가 뜨지 않는다.\n위 값들에 대한 설명은 위 aws 문서를 참고한다.\nReference 악명 높은 CORS 개념 \u0026amp; 해결법 - 정리 끝판왕 Django, Nginx CORS 설정 Using cross-origin resource sharing (CORS) aws - CORS configuration ","permalink":"http://jeha00.github.io/post/project/devket/deployment/02_deployment_cors/","summary":"배포 후 발생한 S3 CORS issue에 대해 알아본다. 이 과정에서 CORS란 무엇이고 이를 헤결하기 위해서 어떤 header를 어떻게 추가하는지 알아본다.","title":"Project: deployment issue - S3 CORS"},{"categories":"Project: Devket","content":"0. Introduction 이 repository는 현재 러닝스푼즈 나노디그리 - django backend 부트캠프에서 팀 프로젝트를 진행하면서 다음과 같은 내용들에 대해 정리하고자 만들었습니다.\n팀 정책을 이것으로 정한 이유 개발하면서 부딪힌 문제들에 대한 원인, 해결방안, 해결과정, 그리고 그 이유들 배포 작업 시작 1차적으로 구현한 기능을 마치고, Docker 내용을 복습한 후 배포 작업을 시작했다. 배포 작업 순서, 에러, 해결방안, 그리고 여러 이유들에 대해 정리해본다.\n배포 관련 이전 학습 내용들 배포에 관련해서 배운 내용은 다음과 같다.\ndjango live 강의에서는 docker를 사용하지 않고, AWS EC2 서버에서 nginx, uwsgi와 django app을 연결 후, AWS RDS, IAM, S3와 연결하여 배포했다. Docker 강의에서는 AWS EC2 서버에서 Docker container만을 사용하여 nginx, gunicorn, django app, postgreSQL image들을 사용하여 배포했다. 위 내용을 바탕으로 구성한 배포 구조 그래서 이번 프로젝트 배포에서는 django live 강의 마지막에 학습한 배포와 docker 강의에서 학습한 docker를 활용한 배포 내용을 정리한 것을 보고 합하여 진행해본다.\nAWS EC2 서버에 docker-compose를 사용하여 nginx, django의 각 custom image를 만든다. django app에는 AWS RDS(postgreSQL), IAM, S3 연결 세팅을 해놓은 후 build 실행한다. uWSGI와 gunicorn 중 후자를 택한 이유 uWSGI 와 gunicorn 중 gunicorn을 선택했다.\n지난 강의 때 들었던 내용을 정리한 WSGI의 종류를 참고하면 gnicorn은 입문자가 사용하기에 편리하고, 성능을 내는 데에는 uWSGI가 좋다고 판단했다.\n하지만, 이외의 여러 블로그 의견들을 취합했고 많은 공통된 의견들을 발견했다.\n한 예로 python개발자 uWSGI를 버리고 gunicorn으로 갈아타다.을 근거로 전달하자면 uWSGI는 다른 WSGI에 비해서 무거워 자원 소모가 큰 문제점이 있다.\n하지만, gunicorn은 가볍고 큰 프로젝트가 아닌 경우 uWSGI보다 빠른 성능을 낸다는 장점이 있다.\n현재 프로젝트는 규모가 크지 않아서 uWSGI보다는 gunicorn을 사용하는 것이 적절하다고 판단했다.\nroot 계정으로 하지 않기 root 계정으로 배포를 하게 되면 일반 user는 로그인하지 못하기 때문이다.\n1. git clone 및 file directory 구조 git clone 하여 가져오기 ~/development/devket directory를 생성하여 git clone으로 가져온다.\n이에 따라 requirements.txt를 docker compose를 실행하기 위해서 위치를 바꾼다. Devket 안이 아니라 Dockerfile과 동일한 레벨로 옮긴다.\nfile directory 익숙하지 않아서 먼저 구조를 잡기 위해 파일들을 생성했다.\n아래 파일 구조를 출력하기 위해 sudo apt-get install tree을 설치한 후, tree ./을 입력한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # ~/deployment ./ ├── devket │ ├── Devket │ │ ├── config │ │ ├── manage.py │ │ ├── pocket │ │ ├── static │ │ │ ├── css │ │ │ └── js │ │ └── templates │ ├── Dockerfile │ └── requirements.txt ├── docker-compose.yml └── nginx ├── Dockerfile └── default.conf 2. Dockerfile 생성 2.1 django app(devket) Dockerfile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 FROM python:3.10.8 WORKDIR /usr/src/app COPY . . RUN python -m pip install --upgrade pip \\ \u0026amp;\u0026amp; pip install -r requirements.txt \\ \u0026amp;\u0026amp; pip install boto3 \\ \u0026amp;\u0026amp; pip install django-storages \\ \u0026amp;\u0026amp; pip install gunicorn # git WORKDIR ./Devket RUN python manage.py collectstatic --noinput CMD sh -c \u0026#34;python manage.py makemigrations \\ \u0026amp;\u0026amp; python manage.py migrate \\ \u0026amp;\u0026amp; python manage.py runserver 0:8000\u0026#34; CMD gunicorn config.wsgi:application --bind 0:8000 EXPOSE 8000 boto3를 사용하는 이유: 파이썬 언어를 사용하여 EC2, S3 같은 AWS 서비스를 구성하고 관리하려면 boto3를 사용해야 한다. django-storages를 설치하는 이유: 장고 프로젝트가 특정 storage를 사용하기 위해서 설치한다. docs.docker - CMD 위 문서에 따르면 기본 명령어 형식으로 CMD는 여러 개를 입력할 수 없다. 그래서 shell에 입력하듯이 하는 방식으로 CMD를 입력했다. ❗️ EOFError python manage.py collecstatic은 input 값을 기본적으로 필요로 하는 명령어다.\n오랫동안 입력값이 없으면 EOFError가 발생한다. 그래서 옵션으로 --noinput을 하면 input 값을 기다렸다가 yes로 자동적으로 입력되어 진행된다.\nDockerfile이 진행되는 동안 입력값을 받지 못하고, 처음 image build 시 collectstatic을 반드시 실행해야하기 때문에 이 옵션을 사용했다.\n출처: Where to run collectstatic when deploying django app\u0026hellip;using Docker 2.2 django app Dockerfile version 입력 위 Dockerfile에서 다음 명령어를 삭제 또는 수정하기로 했다.\n1 2 3 \u0026amp;\u0026amp; pip install boto3 \\ \u0026amp;\u0026amp; pip install django-storages \\ \u0026amp;\u0026amp; pip install gunicorn 왜냐하면 정확한 버전이 적혀있지 않아서 설치할 때 최신 버전을 설치하게 되는데, 이런 방식으로 설치하는 건 지금은 문제가 없을 수 있다.\n하지만, 그 당시 최신 버전에서 작동되었던 코드들이 업데이트 되면서 작동되지 않을 수 있기 때문이다.\n그래서 삭제 후, requirements.txt에 버전 명과 함께 구체적으로 입력한다.\n1 2 3 4 5 ... boto3==1.26.27 django-storages==1.13.1 gunicorn==20.1.0 ... 또는 위 명령어를 삭제하지 않고, 아래와 같이 정확한 버전 명을 입력하는 것도 또 하나의 방법이다.\n1 2 3 \u0026amp;\u0026amp; pip install boto3==1.26.27 \\ \u0026amp;\u0026amp; pip install django-storages==1.13.1 \\ \u0026amp;\u0026amp; pip install gunicorn==20.1.0 2.3 nginx Dockerfile 1 2 3 4 FROM nginx RUN rm /etc/nginx/conf.d/default.conf COPY default.conf /etc/nginx/conf.d CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] 3. nginx의 default.conf 80 port로 트래픽을 받아서 web application에 전달한다.\nproxy_pass에서 devket은\n1 2 3 4 5 6 7 8 server { listen 80; server_name localhost; location /{ proxy_pass http://devket:8000; } } 4. docker-compose.yml 생성 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 version: \u0026#34;3\u0026#34; services: devket: build: ./devket container_name: devket restart: always expose: - \u0026#34;8000\u0026#34; devket-nginx: build: ./nginx container_name: devket-nginx restart: always ports: - \u0026#34;80:80\u0026#34; depends_on: - devket ❗️ 502 Bad Gateway docker logs \u0026lt;container id\u0026gt; 로 nginx와 django app을 확인해보자.\ndjango error 1 python: can\u0026#39;t open file \u0026#39;/usr/src/app/devket/Devket/manage.py\u0026#39;: [Errno 2] No such file or directory nginx error 1 nginx: [emerg] host not found in upstream \u0026#34;devket\u0026#34; in /etc/nginx/conf.d/default.conf:6 위 두 에러 모두 django Dockerfile의 WORKDIR을 수정하여 해결했다.\n5. RDS 생성 및 연결 RDS 생성 시 설정 세팅은 RDS 연결하기를 참고하여 진행했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # config/settings.py DATABASES = { \u0026#34;default\u0026#34;: { \u0026#34;ENGINE\u0026#34;: \u0026#34;django.db.backends.postgresql_psycopg2\u0026#34;, # 아래는 예시일 뿐, 리스트말고 문자열로 입력한다. “HOST\u0026#34;: [RDS 엔드포인트], \u0026#34;NAME\u0026#34;: [DB 이름], \u0026#34;PORT\u0026#34;: \u0026#34;5432\u0026#34;, \u0026#34;USER\u0026#34;: [마스터 사용자 이름], \u0026#34;PASSWORD\u0026#34;: [비밀번호], } } RDS endpoint 는 연결 \u0026amp; 보안에서 확인 가능 DB 이름, 마스터 사용자 이름은 구성에서 확인 가능 🔆 super user가 생성가능하면 DB 연결이 된 것이다.\n❗️ RDS 생성할 때 DB 이름의 기본값 RDS 생성 시, 추가사항 탭 클릭하여 DB 이름을 설정하지 않았다면 기본값으로 \u0026lsquo;postgres\u0026rsquo;가 입력된다.\nDB를 하나만 사용하고 있는 상황에서는 반드시 DB 이름을 입력할 필요는 없다고 판단되나, 프로젝트의 첫 배포 과정으로서 DB에 이름을 부여하고 싶어 입력했다.\n6. S3 연결하기 S3에 연결하기 전에 이전에 학습해던 3가지 방식을 다 사용하면서 왜 S3를 사용하는지 되새겨본다.\n6.1 첫 번째 방법: ’location /static/’ 추가 문제점: admin에 적용되는 css를 확인할 수 없다.\n1 2 3 4 5 6 # 경로: nginx의 default.conf # 추가할 파일 내용 location /static/ { alias /devket/static/; } 6.2 두 번째 방법: collectstatic - 장점: 첫 번째 방법에 대한 문제점 해결\n- 문제점: 프로젝트 내부에 정적 파일들을 모아놓기 때문에, 서버 부하를 피할 수 없다.\npython manage.py collectstatic 명령어를 사용하여 모든 static 파일들을 public directory 안에 모으기 위해서 location 설정을 바꾼다.\nsettings.py 설정 변경\n1 2 3 4 5 6 7 8 9 # 경로: cofig/settings.py # 추가할 파일 내용 # STATIC STATIC_URL = \u0026#34;/static/\u0026#34; STATICFILES_DIRS = [BASE_DIR / \u0026#34;static\u0026#34;] # 위에 두 줄은 이미 입력되어 있기 때문에, 밑에 한 줄만 입력한다. STATIC_ROOT = os.path.join(BASE_DIR, \u0026#34;public\u0026#34;) python manage.py collectstatic 실행: public 폴더 생김\n먼저 docker compose up -d --build를 실행하여 변경사항이 반영된 container를 실행한다. django 명령어를 입력할 때는 해당 image에 접속하여 입력하면 된다. nginx/default.conf 설정 변경\n1 2 3 4 5 6 # 경로: nginx의 default.conf # 추가할 파일 내용 location /static/ { alias /devket/public/; } 6.3 세 번째 방법: S3에 연결하기 admin에 적용되는 css도 확인할 수 있으면서, 내부가 아닌 외부 AWS S3에 모아놓은 정적 파일들을 올려서 서버 부하를 분산시키기 때문에 이 방식을 최종적으로 선택한다.\n6.3.1 AWS S3 bucket 생성하기 bucket 명: devket 객체 소유권: ACL 활성화 + 객체 소유권: 객체 라이터 퍼블릭 액세스 차단 설정 6.3.2 AWS IAM을 사용하는 이유 IAM 역할을 사용하면 일반적으로 조직의 AWS 리소스에 대한 액세스 권한이 없는 사용자나 서비스에 액세스 권한을 위임할 수 있습니다. \u0026hellip; 그러면 애플리케이션이 이러한 자격 증명을 사용해 Amazon S3 버킷 또는 Amazon DynamoDB 데이터 등의 리소스에 액세스할 수 있습니다.\n출처: AWS - manage-roles\nAWS S3 bucket을 데이터 저장소로 사용한다면 IAM을 사용해서 액세스 권한을 위임받아야한다는 내용이므로, 반드시 IAM을 사용해야 한다.\n6.3.3 AWS IAM에서 다운 받은 key를 settings.py에 반영하기 이 링크를 따라서 생성한다.\n하지만, config/settings.py 에 추가되는 설정은 아래 코드를 사용한다. 기존에는 KEY가 오픈되었지만, get_secret()을 사용하여 드러나지 않도록 했다.\nsecret.json 에도 추가하도록 한다.\n1 2 3 4 5 6 7 8 AWS_ACCESS_KEY_ID = get_secret(\u0026#34;AWS_ACCESS_KEY_ID\u0026#34;) AWS_SECRET_ACCESS_KEY = get_secret(\u0026#34;AWS_SECRET_ACCESS_KEY\u0026#34;) AWS_REGION = \u0026#34;ap-northeast-2\u0026#34; AWS_STORAGE_BUCKET_NAME = \u0026#34;devket\u0026#34; AWS_S3_CUSTOM_DOMAIN = f\u0026#34;{AWS_STORAGE_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com\u0026#34; AWS_DEFAULT_ACL = \u0026#34;public-read\u0026#34; DEFAULT_FILE_STORAGE = \u0026#34;config.storages.S3DefaultStorage\u0026#34; STATICFILES_STORAGE = \u0026#34;config.storages.S3StaticStorage\u0026#34; 6.3.4 config/storages.py 추가하기 1 2 3 4 5 6 7 from storages.backends.s3boto3 import S3Boto3Storage class S3DefaultStorage(S3Boto3Storage): location = \u0026#34;media\u0026#34; class S3StaticStorage(S3Boto3Storage): location = \u0026#34;static\u0026#34; 6.3.5 현재 과정에서 file directory 구조 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # ~/deployment ./ ├── devket │ ├── Dockerfile │ ├── Devket │ │ ├── config │ │ │ ├── __init__.py │ │ │ ├── asgi.py │ │ │ ├── settings.py │ │ │ ├── storages.py │ │ │ ├── urls.py │ │ │ └── wsgi.py │ │ ├── manage.py │ │ ├── pocket │ │ ├── static │ │ │ ├── css │ │ │ ├── images │ │ │ └── js │ │ └── templates │ └── requirements.txt ├── docker-compose.yml └── nginx ├── Dockerfile └── default.conf 6.3.6 static file들을 S3로 옮기기:`python manage.py collectstatic ❗️python manage.py collectstatic 시 발생된 Error\n첫 번째 Error : botocore.errorfactory.NoSuchBucket: An error occurred (NoSuchBucket) when calling the PutObject operation: The specified bucket does not exist\n지정한 bucket이 존재하지 않는다는 의미다. S3의 bucket name이 storages.py의 BUCKET_NAME과 동일한지 비교한다. 두 번째 Error : botocore.exceptions.ClientError: An error occurred (AccessControlListNotSupported) when calling the PutObject operation: The bucket does not allow ACLs\nbucket 인식문제는 해결되었지만, 이 문제가 새롭게 발생했다. bucket 생성 시, 아래 설정대로 했는지 확인해보자. 6.3.7 nginx의 location url로 경로 바꾸기 이 단계까지 수행하면 css file들이 AWS S3 bucket으로 연결되지 않은 걸 확인할 수 있다. 그래서 nginx의 default.conf 설정을 수정해야한다. 생성한 bucket에 들어가서 새로고침을 하면 static/이 생긴 걸 확인할 수 있다. 이를 선택하면 URL 복사가 활성화되는데, 이 버튼으로 복사해서 alias 옆 경로를 붙여넣는다. 1 2 3 location /static/ { alias https://devket.s3.ap-northeast-2.amazonaws.com/static/; } ❗️Error: Django amazon S3 SuspiciousOperation 위 nginx의 location url 경로를 수정해도 이와 같은 error가 발생했다.\ndjango S3 연결 SuspiciousOperation을 검색하니 아래와 같은 문서가 떴다.\n읽어보면 해결 방법은 총 3가지다.\n첫 번째 방법은 storages.py 의 class 내용을 수정하는 방식 두 번째 방법은 static tag 뒤에 파일 경로의 시작 부분 /를 삭제하는 방식 세 번째 방법은 img의 src에 static template tag를 사용하는 방식 기존에 알고 있던 django template tag를 사용하는 방식이 보다 django 를 잘 활용하는 개발 방식이라 판단하여 세 번째 방식을 선택했다. 그래서 img src에도 django template tag를 적용했다.\n그 전에는 이를 적용하지 않았던 이유는 django static template tag를 head tag 안에 import 시에만 사용하고, body 안에는 사용한다는 생각을 못 했기 때문이다.\n위 방식을 알아낸 것은 아래 문서를 통해서 인지했다.\n출처: Django amazon s3 SuspiciousOperation\nS3 CORS issue S3 CORS issue는 해당 링크 Project: deployment issue - S3 CORS를 참고한다.\n7. Django image size 줄이기: slim docker image ls로 확인한 결과 django image의 size는 다음과 같다.\n1 2 REPOSITORY TAG IMAGE ID CREATED SIZE deployment-devket latest 059f304f1f5d 11 minutes ago 1.09GB 1GB를 넘기 때문에 이를 줄이고자 python 버전을 slim으로 다운받아서 비교해본다.\n현재 django Dockerfile에서 FROM python:3.10.8으로 python 설치를 시작하지만, FROM python:3.10.8-slim으로 수정했다.\ndocker compose build를 실행한 결과, 설치 실패가 떴다.\n에러 내용은 다음과 같다.\n1 2 3 4 5 6 7 Error: pg_config executable not found. pg_config is required to build psycopg2 from source. Please add the directory containing pg_config to the $PATH or specify the full executable path with the option: python setup.py build_ext --pg-config /path/to/pg_config build ... or with the pg_config option in \u0026#39;setup.cfg\u0026#39; stackoverflow - pg_config executable not found에 모든 답변을 따라서 시도했지만 계속해서 같은 오류가 떴다. 그래서 pip install psycopg2-binary=2.9.5을 설치하기로 한다.\npsycopg2 와 psycopg2-binary의 차이는 다음 글을 참고했다.\n먼저 공식문서 psycopg2 vs psycopg2-binary와 what is the different about psycopg2 and psycopg2-binary python package 를 참고했다. docker image ls로 확인해보면 다음과 같은 크기로 줄어들었다.\n1 2 REPOSITORY TAG IMAGE ID CREATED SIZE deployment-devket latest 2c0746fca459 2 minutes ago 308MB 동일한 기능을 낸다면 가벼운 것과 상대적으로 무거운 것 중 가벼운 것으로 가는 방향이 cost가 덜 나가기 때문에 size를 줄이는 방향을 선택했다.\nReference WSGI의 종류 python개발자 uWSGI를 버리고 gunicorn으로 갈아타다. boto3를 사용하는 이유 django-storages를 설치하는 이유 docs.docker - CMD Where to run collectstatic when deploying django app\u0026hellip;using Docker RDS 연결하기 staticfiles 연결 3가지 방식 AWS IAM에서 다운 받은 key를 settings.py에 반영하기 Django amazon s3 SuspiciousOperation AWS - manage-roles stackoverflow - pg_config executable not found psycopg2 vs psycopg2-binary what is the different about psycopg2 and psycopg2-binary python package ","permalink":"http://jeha00.github.io/post/project/devket/deployment/01_deployment/","summary":"docker compose를 사용하여 nginx, gunicorn, AWS S3, AWS RDS와 연결된 django application을 배포한다. 이때, AWS S3에 접근하기 위해서 AWS IAM을 사용한다. static files에 연결하는 방식으로 3가지를 사용했다.","title":"Project: Docker를 사용하여 django app 배포하기"},{"categories":"Docker","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 장철원 강사님의 docker 강의를 학습한 내용입니다.\n인스턴스는 우분투를 사용한다.\n1. PostgreSQL 컨테이너로 배포하기 DB 관리 db를 컨테이너에 띄어서 관리하는가, 아니면 쌩 서버에 관리하는가 는 호불호가 갈린다.\n왜냐하면 컨테이너의 기본이 지워져도 상관없다는 전제이기 때문에, db는 지워지면 안되기 때문에 컨테이너에 사용되지 않는다.\n컨테이너 내부 접속하기 컨테이너 내부로 들어가기: docker exec -it \u0026lt;Container ID\u0026gt; /bin/bash\n그래서 이 내부에서 명령어를 잘못 입력하면 컨테이너에서 나갔다가 Kill하면 된다. superuser로 로그인하기: psql -U postgres 를 의미한다.\n\\dt: 테이블 조회\npostgresql 종료 명령어: \\q\nDockerfile이란? 도커 이미지에 대한 정보를 기술한 템플릿 패키지, 명령어, 환경 변수 설정등을 기록 도커 파일을 통해 postgreSQL container 띄우기 PostgreSQL에 대한 Dockerfile을 담을 directory를 생성한다.\n해당 경로에 vim Dockerfile를 실행하여 FROM postgres를 입력한다.\n2. 도커 볼륨(docker volume) 도커 볼륨이란? 도커 컨테이너에 있는 데이터를 보관하기 위해서 사용하는 툴\n도커 볼륨을 사용하는 방식에는 2가지 방식이 있다.\nEC2 서버 내부의 file system 경로에 연결하는 것 volume에 연결하는 것 위 방식들을 사용하면 file system과 계속해서 연결되어 있기 때문에, DB가 꺼져도 file system까지 다 저장되어 있어서 데이터를 보존할 수 있다.\n도커에서는 볼륨을 생성하여 사용하기를 추천한다.\n2.1 로컬 경로로 연결 이 방식의 문제점 : 필요한 경로라 생각하여 사용자가 무심코 경로를 삭제할 수 있다. 연결할 호스트 경로 확인 docker run -e POSTGRES_PASSWORD=mysecretpassword -v ~/test:/test:rw -d postgres\n-v: volume을 의미\nlocal 상의 ~/work/test와 container 상의 ~/work/test를 연결\nrw: read와 write 권한을 주겠다는 걸 의미\n-d: background으로 작동한다는 걸 의미\ncontainer ls로 확인 후, 접속하기 docker container ls docker exec -it \u0026lt;container id\u0026gt; /bin/bash 접속하면 /test가 있는 걸 확인할 수 있다. 그러면 /test 경로로 이동한다(cd test). ls로 확인하면 postgresql에 접속하기 전과 동일하다는 걸 알 수 있다. 접속한 container에서 생성 후, docker host에서도 확인하기 mkdir inside 후, exit하여 나온다.\n동일한 경로로 이동하여 ls로 확인하면 inside directory가 있는 걸 알 수 있다.\n생성한 directory를 docker host에서 삭제한 후, container에 접속하여 확인하면 똑같이 삭제된 걸 확인할 수 있다.\n2.2 도커 볼륨으로 연결하기 생성 후, 내용 확인하기 첫 번째, 명령어 docker volume create \u0026lt;볼륨명\u0026gt;을 사용하여 볼륨을 ec2 내에서 생성한다.\n생성 후, 볼륨 목록을 확인하고 싶으면 docker volume ls를 입력한다.\n생성한 볼륨에 대한 정보를 확인하고 싶으면 docker volume inspect \u0026lt;생성한 볼륨명\u0026gt;을 입력한다.\n확인된 정보들에서 Mountpoint는 생성한 볼륨의 경로를 의미한다. docker host의 경로와 연결하기 docker run -e POSTGRES_PASSWORD=mysecretpassword -v myvolume:/var/lib/postgresql/data -d postgres\nmyvolume을 postgresql의 데이터 경로와 연결한다.\n❗️/var/lib/postgresql/data 는 내가 임의로 정하는 게 아닌 RDBMS마다 정해져있으므로 다른 것을 사용한다면 추가로 확인해야한다.\npostgresql 데이터 생성, 컨테이너 삭제 후 실행하여 데이터 확인하기 container 접속: docker exec -it \u0026lt;postgresql에 해당되는 container id\u0026gt; postgresql 접속: psql -U postgres 사용자 추가: CREATE USER jeha PASSWORD '1234' SUPERUSER; \\du: 모든 사용자 보여주기 \\q: 나오기 container 중단: docker container stop \u0026lt;container id\u0026gt; container 삭제: docker container rm \u0026lt;container id\u0026gt; 다시 postgresql 실행하여 접속한다. \\du로 등록된 사용자가 아직 존재하는지 확인 후, exit 3. Docker로 django 배포하기 3.1 Django image pull 받고 확인하기 django image pull 받기: docker pull django django pull 한 image 확인: docker image ls 3.2 장고 컨테이너 가동 배포시스템 구조 이해하기 서버 포트와 컨테이너 포트 연결하기\n트래픽은 바로 들어오는 게 아닌, 서버를 거쳐서 컨테이너로 들어온다. 총 2단계가 필요하다.\n우리가 브라우저의 url 창에 도메인을 입력하고 나서 입력하는 포트 번호는 컨테이너의 포트 번호가 아니라 \u0026lsquo;서버의 포트 번호\u0026rsquo;를 말한다.\nPort 번호\n내가 사용하는 프레임워크는 django 이므로, port 번호는 8000을 사용하기로 한다. HTTP port는 80으로 정해져있다. www.naver.com 을 입력하는 것은 www.naver.com/:80 을 입력하는 것과 동일하다. 그래서 80 port를 지난 후, 8000 port로 오도록 연결해야 한다. 이를 설계하지 않으면 컨테이너를 띄어도 외부에서 접속할 수 없다.\n장고 컨테이너 가동하기 docker run -d -p 80:8000 django bash -c \u0026ldquo;pip install django \u0026amp;\u0026amp; django-admin startproject \u0026amp;\u0026amp; cd \u0026amp;\u0026amp; python manage.py runserver 0.0.0.0:8000\u0026rdquo;\n-d: 도커 컨테이너의 백그라운드 실행\n-p 80:8000: 컨테이너 포트 설정 - 호스트 포트: 컨테이너 포트\n두 포트를 연결하겠다는 의미 bash: 컨테이너 실행 후, bash 실행\nbash에 \u0026quot;\u0026quot; 안 내용을 실행한다. bash를 사용해서 장고 프로젝트를 생성한다. \u0026amp;\u0026amp;: 연결지어 순차적으로 실행한다.\npython manage.py runserver 0.0.0.0:8000 에서 위에 -p 옵션으로 입력할 포트번호와 일치시켜야 한다.\n만약 해당 포트가 이미 사용 중이라고 한다면 ps -ef | grep 8000을 입력해서 8000번에 무엇이 사용되는지 알 수 있다.\n🔆 참고사항 만약 docker container ls를 입력했는데 아무것도 안뜨면 자세히 확인하기 위해서 docker container ls -a 를 입력하면 STATUS를 통해 확인하면 Exited를 확인할 수 있다. 그러면 아래 명령어를 사용하여 로그를 확인해보면 에러 원인을 보다 자세히 알 수 있으므로 활용하자.\n로그 확인: docker logs \u0026lt;container ID\u0026gt; ❗️Error starting userland proxy Error starting userland proxy: listen tcp4 0.0.0.0:80: bind: address already in use.\nsudo netstat -nlptu | grep 80을 입력해보자. 만약 command not found가 뜬다면 apt-get install net-tools를 입력하여 설치 후, 다시 실행해보자.\n그러면 80 port를 누가 사용 중인지 확인할 수 있다.\n만약 그 포트를 사용하는게 nginx, apache라면 sudo systemctl stop nginx 또는 sudo systemctl stop apache 을 입력하여 중단하자.\n그후 다시 장고 컨테이너 가동하기 위한 명령어 docker run -d -p 80:8000 ...을 입력한다.\nnginx, apache가 아니라면서 sudo kill -9 \u0026lt;PID\u0026gt; 를 입력한다.\n3.3 docker container 정지 및 재가동 정지: docker container stop \u0026lt;container ID\u0026gt;\n재가동\ndocker container ls -a로 정지했었던 container id를 확인 멈춰있는 도커를 재시작한다는 의미이므로, docker start \u0026lt;container id\u0026gt;를 입력 4. 서버에 장고 코드 배포하기 4.1 AWS 외부 접속을 위한 포트 설정 해당 EC2의 인바운드 규칙 편집에 사용자 지정 TCP로 \u0026lsquo;8000\u0026rsquo;을 추가한다. 4.2 장고 프로젝트 생성 및 가동 root 계정으로 이동: sudo -i\nwork로 이동\npyenv는 아래 링크를 따라서 진행하여 설치 및 활성화한다.\npyenv를 통한 파이썬(python) 가상환경 구축 가상환경 실행: pyenv activate \u0026lt;가상환경명\u0026gt;\npyenv 말고, ec2에 설치된 게 있으면 그것으로 하면 된다. 프로젝트 명칭: django-admin startproject \u0026lt;프로젝트 명\u0026gt;\n4.3 장고 설정파일 수정 및 접속 확인 settings.py 에서 ALLOWED_HOSTS 를 ['*']로 수정한다. 이것의 의미는 모든 외부 접속을 허용한다는 의미다.\n수정할 때에만 vim을 사용하고, 그냥 볼 때는 cat를 사용한다.\npython manage.py runserver 0:8000 를 입력해야 ec2 ip 주소를 사용해서 \u0026lt;IP v4\u0026gt;:8000 로 접속할 수 있다.\n❗️ 발생한 Error _ModuleNotFoundError: No module named \u0026lsquo;_sqlite3\u0026rsquo; _\nsqlite3는 파이썬 설치 시, 포함되는데 위와 같은 에러는 파이썬 설치가 제대로 안된 것이기 때문에,\npyenv install \u0026lt;python version\u0026gt;을 입력하여 설치를 다시 한다.\n5. 직접 짠 코드 container로 배포하기 5.1 디렉토리 정리, tree 설치하여 파일 구조 확인하기 sudo apt-get install tree\n위 명령어 실행 후, tree ./로 원하는 경로의 directiory 구조를 tree로 확인한다.\n5.2 requirements.txt 파일 생성 이 파일 추가하는 이유는 나만의 도커 이미지를 만들기 위해 django 4.1.1 layer를 쌓기 위해서다.\n왜냐하면 도커는 여러 Layer가 쌓여진 것이기 때문이다.\nvim requirements.txt를 실행하여 생성한다.\ndjango==4.1.1를 추가한다. 5.3 Dockerfile 생성하기 Dockerfile 생성하기 위 장고 과정에서 직접 하나하나 설치하고 실행한 건 도커 개념을 이해하기 위해서다.\nrequirements.txt만 실행하면 바로 설치된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 FROM python:3.10.4 WORKDIR /usr/src/app COPY . . RUN python -m pip install -upgrade pip RUN pip install -r requirements.txt WORKDIR ./practice CMD python manage.py runserver 0:8000 EXPOSE 8000 이 때 생성해야하는 Dockerfile 이름은 다음과 같다.\nDockerfile 주의사항: 첫 글자가 대문자이고, 확장자가 존재하지 않는다. FROM: 기본 layer를 무엇으로 할 것인가?\npython:3.10.4: 기본 Layer를 이것으로 한다. 첫 번째 WOKDIR: root부터 시작하는 container 내부 경로를 의미한다.\nCOPY . .: 모든 것을 컨테이너 안으로 가져오겠다는 의미다.\nRUN: 오른쪽에 입력한 명령어를 실행하겠다.\n두 번째 WORKDIR: 위에 RUN 명령어를 실행 후, 오른쪽에 입력한 경로로 이동한다.\nEXPOSE: 컨테이너에 포트 몇 번을 열지를 알려주는 것\nDockerfile 의 file level Dockerfile과 requirements.txt는 동일한 파일 level에 있어야 한다.\n5.4 image build 하기 docker build . -t \u0026lt;만들 image 이름\u0026gt;\nDockerfile이 있는 위치에서 실행한다.\n.은 위 명령어를 실행하는 경로 안에 있는 모든 걸 의미한다.\n-t: 태그를 의미\ndocker image ls를 입력하면 목록에 위에 입력한 image 이름으로 존재하는 걸 확인할 수 있다.\n❗️ 컨테이너는 운영체제가 아니기 때문에, root User 관련 경고는 문제가 아니다. ❗️ 만약 image를 빌드 후, Dockerfile을 수정하면 다시 image를 만들어야 한다.\n빌드한 이미지 실행하여 컨테이너 가동 docker run -d -p 80:8000 \u0026lt;만든 image 이름\u0026gt;\n위 명령어 실행 후, docker container ls를 입력하면 가동되고 있는 container를 확인할 수 있다.\n❗️ 위 명령어로 container id가 떴음에도 불구하고, docker container ls -a로 해당 container id의 status가 exited 이면 docker logs \u0026lt;container id\u0026gt;로 원인을 파악한다.\n6. docker로 nginx 배포하기 django만으로는 traffic을 받을 수 없기 때문에, nginx를 설치해야한다.\n6.1 nginx 디렉토리 생성 mkdir nginxtest 생성\n6.2 Dockerfile 생성 위에 생성한 디렉토리로 이동 후, vim Dockerfile로 생성하여 아래 내용을 입력한다. ❗️ 입력 시, 홀따옴표가 아닌 쌍따옴표를 사용한다.\n1 2 FROM nginx CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] daemon off의 의미 nginx를 foreground로 돌리기 위함 container가 background로 실행되므로, nginx를 foreground로 돌리지 않으면 nginx가 exited된다. file level 6.3 image build 및 확인 image build Dockerfile이 있는 경로에서 아래 명령어를 실행한다.\ndocker build . -t nginx-test\nimage 확인 docker image ls를 실행하여 목록을 확인한다. 이 때 경로는 상관없다.\n6.4 nginx container 가동 container 가동 docker run -d nginx-test\n목록 확인 docker container ls\n7. Docker compose로 장고와 nginx 함께 배포하기 위 이미지처럼 컨테이너 두 개를 연결하려고 한다.\n서버 외부에서 80포트로 들어오면 nginx로 이동하면 django-test 8000 port로 이동되도록 한다. nginx: 서버 와 django: 웹 서버를 연결하기 위해서 gunicorn을 사용해볼 예정이다.\n이를 위해서 docker compose를 사용해보자.\n7.1 Docker compose 개념 \u0026amp; 설치 Docker compose concept django과 nginx를 연결하는데, 많은 컨테이너를 하나 하나 직접 연결하는 건 매우 시간이 많이 걸린다.\n도커 파일은 \u0026lsquo;하나의 컨테이너\u0026rsquo; 를 관리하기 위한 파일이다.\n하지만, 도커 컴포즈는 \u0026lsquo;여러 개의 컨테이너\u0026rsquo;를 관리하는 도커 애플리케이션이다.\n도커 컴포즈를 사용하기 위해서는 docker-compose.yml이라는 YAML 파일을 사용한다.\nYAML YAML은 마크업 언어가 아니다.\n기존 JSON의 불편함을 해소하기 위해 만들어진 언어\n주로 설정 파일(configuration file)에 사용\n확장자: *.yml\n7.2 Docker compose installation docs.docker.com - install the plugin manually를 보고 아래 명령어를 순차적으로 입력한다.\n1 2 3 4 5 6 7 mkdir -p ~/.docker/cli-plugins curl -SL https://github.com/docker/compose/releases/download/v2.14.0/docker-compose-linux-x86_64 -o ~/.docker/cli-plugins/docker-compose chmod +x ~/.docker/cli-plugins/docker-compose docker compose version ❗️ Error docker: \u0026lsquo;compose\u0026rsquo; is not a docker command\ncurl -o 뒤에 경로와 mkdir의 경로가 일치한지 확인하기\n7.3 directory 정리 다음과 같이 경로를 수정한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ./ ├── django │ ├── Devket │ │ ├── config │ │ │ ├── __init__.py │ │ │ ├── __pycache__ │ │ │ │ ├── __init__.cpython-310.pyc │ │ │ │ ├── settings.cpython-310.pyc │ │ │ │ ├── urls.cpython-310.pyc │ │ │ │ └── wsgi.cpython-310.pyc │ │ │ ├── asgi.py │ │ │ ├── settings.py │ │ │ ├── urls.py │ │ │ ├── wsgi.py │ │ │ └── ~ │ │ ├── db.sqlite3 │ │ └── manage.py │ ├── Dockerfile │ └── requirements.txt └── nginx └── Dockerfile 7.4 Dockerfile 수정 django directory 안에 있는 dockerfile 수정 첫 번째 CMD 뒤에 다른 CMD를 추가한다.\nCMD gunicorn config.wsgi:application --bind 0.0.0.0:8000\nnginx directory 안에 있는 dockerfile 수정 다음과 같이 수정한다.\n1 2 3 4 FROM nginx RUN rm /etc/nginx/conf.d/default.conf COPY default.conf /etc/nginx/conf.d CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] 기존 컨테이너에 있던 default.conf를 삭제하고, 새로운 default.conf를 기존에 있던 경로에 만들겠다는 의미다. 7.5 nginx에 default.conf 추가 1 2 3 4 5 6 7 8 server { listen 80; server_name localhost; location /{ proxy_pass http://\u0026lt;nginx에 연결할 service name\u0026gt;:8000; } } listen 80 : 서버로부터 들어오는 것을 80 port로 받겠다는 의미 proxy_pass: 80 port로 들어온 것을 8000 port로 돌리겠다는 의미 7.6 docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # docker-compose.yml이 있는 경로: ~/test version: \u0026#34;3\u0026#34; services: \u0026lt;첫 번째 service name\u0026gt;: build: ./\u0026lt;django Dockerfile이 있는 directory name\u0026gt; container_name: \u0026lt;생성될 image name\u0026gt; restart: always expose: - \u0026#34;8000\u0026#34; \u0026lt;두 번째 service name\u0026gt;: build: ./\u0026lt;nginx Dockerfile이 있는 directory\u0026gt; container_name: \u0026lt;생성될 image name\u0026gt; restart: always ports: - \u0026#34;80:80\u0026#34; depends_on: - \u0026lt;첫 번째 service name\u0026gt; version: version에 따라 참고하는 규격이 달라진다. About versions and upgrading services 밑에 바로 오는 것은 여러 서비스 명칭들을 의미 expose: container 상에 몇 번 포트를 열지 지정 ports: 서버에서 들어와 바로 받기 때문에 입력해야 한다. depends_on: service 간 관계성을 지정하는 키워드로서, 실행 순서를 정하는 키워드로 depends_on에 있는 service를 실행한 후, 해당 service를 실행 생성될 image name은 현재 test 경로에서 실행되었기 때 문에, test-\u0026lt;생성될 image name\u0026gt;으로 image가 생성된다. 7.7 docker compose 실행 및 내리기 docker compose 명령어는 docker-compose.yml 파일이 있는 경로 및 그 아래 경로 어디서든 실행할 수 있다.\ndocker compose 실행하기: docker compose up -d --build docker compose 내리기: docker compose down 8. 도커로 장고, nginx, PostgreSQL 함께 배포하기 전체적인 서버 구성은 다음과 같다.\n그리고, 컨테이너의 관점에서 바라보면 전체적인 구성은 다음과 같다.\ngunicorn을 선택한 이유 gunicorn을 사용한 이유는 현재 과정에서는 빠른 속도가 불필요하기 때문이다. 빠른 속도와 빠른 성능이 필요하면 wsgi를 쓴다.\n8.1 file directory 구조 django, nginx, psql이 docker-compose.yml과 동일한 file level이어야 한다.\n그리고 django, nginx, psql에는 각 해당되는 Dockerfile이 존재해야한다.\ndjango에는 requirements.txt가, nginx에는 default.conf가 추가로 존재해야 한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ./ ├── django │ ├── Devket │ │ ├── config │ │ │ ├── __init__.py │ │ │ ├── __pycache__ │ │ │ │ ├── __init__.cpython-310.pyc │ │ │ │ ├── settings.cpython-310.pyc │ │ │ │ ├── urls.cpython-310.pyc │ │ │ │ └── wsgi.cpython-310.pyc │ │ │ ├── asgi.py │ │ │ ├── settings.py │ │ │ ├── urls.py │ │ │ ├── wsgi.py │ │ │ └── ~ │ │ ├── db.sqlite3 │ │ └── manage.py │ ├── Dockerfile │ └── requirements.txt ├── docker-compose.yml ├── nginx │ ├── Dockerfile │ └── default.conf └── psql └── Dockerfile 8.2 docker-compose.yml 수정하기 DB 추가에 따른 docker-compose.yml은 다음 내용이 추가된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 version: \u0026#34;3\u0026#34; services: ... psql: build: ./psql container_name: psql restart: always volumes: - myvolume:var/lib/postgresql/data environment: - POSTGRES_USER=postgres - POSTGRES_PASSWORD=postgres - POSTGRES_DB=postgres volumes: myvolume: psql-test에는 db이기 때문에 volume이 추가된 걸 알 수 있다. ❗️ 만약 용량 부족 error가 뜰 경우 docker system prune --volumes 명령어를 상용해보자.\n8.3 django settings.py의 DB 설정 변경하기 django application의 settings.py의 DATEBASES 환경 변수를 수정한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # before DATABASES = { \u0026#39;default\u0026#39;: { \u0026#39;ENGINE\u0026#39;: \u0026#39;django.db.backends.sqlite3\u0026#39;, \u0026#39;NAME\u0026#39;: BASE_DIR / \u0026#39;db.sqlite3\u0026#39;, } } # after DATABASES = { \u0026#39;default\u0026#39;: { \u0026#39;ENGINE\u0026#39;: \u0026#39;django.db.backends.postgresql\u0026#39;, \u0026#39;NAME\u0026#39;: \u0026#39;postgres\u0026#39;, \u0026#39;USER\u0026#39;: \u0026#39;postgres\u0026#39;, \u0026#39;PASSWORD\u0026#39;: \u0026#39;postgres\u0026#39;, \u0026#39;HOST\u0026#39;: \u0026#39;db-test\u0026#39;, \u0026#39;PORT\u0026#39;: 5432, } } 8.4 requirements 변경 후, compose 실행하기 requirements.txt에 psycopg2를 추가 compose 실행: docker compose up -d --build ❗️ Error 01 invalid mount config for type \u0026ldquo;volume\u0026rdquo;: invalid mount path: \u0026lsquo;var/lib/postgresql/data\u0026rsquo; mount path must be absolute\n\u0026lsquo;var/lib/postgresql/data\u0026rsquo; 앞에 /가 없어서 생긴 문제다.\n❗️ Error 02 strconv.Atoi: parsing \u0026ldquo;\u0026rdquo;: invalid syntax\ndocker-compose.yml 또는 Dockerfile에 입력 형식이 잘못되었다는 의미다.\n❗️ 용량 부족으로 인한 Error image가 과도하게 많아서 에러가 발생할 경우, sudo docker system prune을 실행한다.\nReference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/docker/04_deployment-by-docker/","summary":"docker만을 사용하여 django를 배포한 후, Dockerfile을 nginx와 djang application 에 대해 각각 만들어서 docker compose로 여러 컨테이너를 연결하여 배포하는 것을 학습해본다.","title":"Docker-compose로 nginx, django, postgreSQL을 연결하고 배포하기"},{"categories":"Project: Devket","content":"0. Introduction 이 repository는 현재 러닝스푼즈 나노디그리 - django backend 부트캠프에서 팀 프로젝트를 진행하면서 다음과 같은 내용들에 대해 정리하고자 만들었습니다.\n팀 정책을 이것으로 정한 이유 개발하면서 부딪힌 문제들에 대한 원인, 해결방안, 해결과정, 그리고 그 이유들 이번 포스팅에서는 payment 결제 1차 기능을 개발하는 과정에서의 고려사항들과 개발 이슈들에 대해 정리해보겠습니다.\npayment 결제 1차 기능은 내부적으로 정한 상황들에 대해서 결제 자체가 가능하도록 개발하는 것에 목적을 두었습니다. 이후에는 환불 기능과 정기결제 기능을 추가하여 \u0026lsquo;구독\u0026rsquo; 개념을 도입할 예정입니다. 1. Payment model에 대한 고려사항 내가 구상하는 결제 모델은 배달, 장바구니, 할인 같은 모델과 연관이 되어 있지 않는 순수한 결제 자체의 정보만 담는 모델임을 고려하여 구성했다.\n이번 경험을 통해서 결제 api를 가져와 연동할 때에는 입력된 기본값의 타입들이 외부 api에서는 무엇인지 확인하고 나서 모델 설계를 들어가야한다는 걸 알게 되었다.\n1.1 User ForignKey 결제를 할 때는 로그인이 된 후 진행되는 user story로 구성했기 때문에, User model을 foreignKey로 진행한다.\n1.2 merchant_id 필요 이유 merchant_id 는 \u0026lsquo;주문 번호\u0026rsquo;를 의미한다. 이를 생성한 이유는 다음과 같다.\n주문마다 독립적이고, 결제 정보를 보안의 관점에서 안전히 지킬 수 있기 위해서다. 아임포트를 사용할 때, 결제 금액을 위변하여 결제 진행 자체를 막기 위해 아임포트에 독립된 주문 번호를 전달해야하기 때문이다. merchant_id 암호화 위에 언급된 대로 독립적이고, 안전해야하기 때문에 \u0026lsquo;암호화\u0026rsquo; 하여 생성하기로 결정했다.\n암호화는 class PaymentManager(models.Manager)에서 선언한 메서드인 create_new 과정에서 user 정보를 받아 진행된다.\n1) 기존 모듈 vs 외부 모듈 설치\n\u0026lsquo;암호화\u0026rsquo; 하는 방법에는 기존 라이브러리를 사용하는 방식과 써드 파트를 설치하는 방식이 있지만, 추가 설치하여 무게를 늘리고 싶지 않기 때문에 기존에 존재하는 모듈인 hashlib를 사용하기로 결정했다. 만약 무게가 늘어나면 EC2에 배포 시에 비용이 더 들기 때문이고, 다른 요인들에 영향을 주지 않는다면 비용이 적은 걸 추구하는 게 엔지니어로서 맞다고 생각했다.\n고려 대상 모듈: crytography 2) sha1 vs sha256\n기존 모듈로 고려한 대상은 hashlib를 선택했으며 이 안에서도 sha-1과 sha-256을 고민했다. sha-2에서 sha-256을 선택한 이유는 일반적으로 이 해쉬 알고리즘을 사용한다고 확인했기 때문이다. 일반적으로 사용하는 만큼 안전성과 접근성 등등 여러모로 이유가 있을거라 판단했기 때문이다. 그러면 결국 sha-1을 선택한 이유는 이 두 가지를 사용하여 해시값을 생성해보니 sha-1이 더 짧았기 때문이다. 현재 프로젝트 규모가 크지 않기 때문에 그리 긴 해시값은 필요없다고 판단했기 때문이다.\n❗️ 하지만 프로젝트 발표 후, 프로젝트 진행한 거를 회고하면서 다시 sha-1과 sha-2를 알아보면서 sha-1에 해독 가능성이 제시됭 이를 중단하여, 크롬 브라우저에서는 2019년부터는 SHA-1 인증서를 사용하는 사이트는 접속 못하도록 차단했다고 들어 프로젝트가 다시 착수할 때는 sha-256으로 바꿀 계획이다.\nsha: Secure Hash Algorithm의 약어 참고 문서 hashlib - 보안 해시와 메시지 요약 namu.wiki - SHA 3) 암호화의 대상 구체화하기\n이 다음으로는 사용자 id 외에 구체적으로 무엇을 암호화할지를 고민하기 시작했다.\n사용자 id만 하기에는 안전하지 못하다는 생각이 들어, 지속적으로 변하여 그 값이 이전과 독립적인 게 무엇이 있을까 고민했다. 그건 바로 \u0026lsquo;시간\u0026rsquo; 이었다. 그리고, 사용자 한 명이 결제를 여러 번 시도할 때 시간을 지속적으로 흐르기 때문에 사용자 id(user.id)와 시간을 가지고 만든다면 계속해서 독립적인 주문 번호를 생성할 수 있을거라 판단했다.\n4) digest vs hexdigest\ndigest에 대해 먼저 알아보자.\n원본 데이터가 해시함수를 통과하여 암호화된 데이터를 \u0026lsquo;다이제스트(digest)\u0026lsquo;라고 한다.\nhashlib.sha1()을 사용하는 코드들을 참고하니 digest와 hexdigest가 많이 언급되어 공식문서를 찾아보니 무엇보다 큰 차이는 digest는 해싱한 바이트 문자열을 반환하고, hexdigest는 바이트 문자열을 16진수로 변환한 문자열을 반환한다. hashlib.sha1(\u0026lt;문자열\u0026gt;.encode()).digest() 또는 .hexdigest()로 비교해보면 된다.\n출력 결과 16진수로 되어있는 hexdigest가 더 짧은 문자열을 가지기 때문에 DB에 저장되는 용량이 더 적어질거라 판단하여 digest를 선택했다.\n5) 해시하기 위한 encoding\n파이썬에서의 문자열은 기본적으로 유니코드이므로, 해시하기 위해서는 바이트 형태가 필요하다. 그래서 해시 전에 반드시 인코딩되어야 하므로 .encode('utf-8')를 사용한다.\n❗️encode의 기본값은 'utf-8'이므로 별도로 입력할 필요는 없다. 프로젝트가 다시 착수될 때 수정할 사항 중 하나다.\n6) merchant_id의 자릿수\nmerchant_id의 자릿수를 설계할 때 아임포트 API에 string(40)을 확인하지 못하고 다음과 같이 과하게 설계했다.\n1 merchant_id = models.CharField(verbose_name=\u0026#39;주문번호\u0026#39; , max_length=120, unique=True) 그후 merchant_id를 암호화하여 자릿수를 생성할 때, 40을 20으로 착각했고, 현재 결제 건은 많지 않으니 \u0026lsquo;10\u0026rsquo;에 맞춰서 진행하기로 결정했다.\n그후, 프로젝트 발표를 마치고 코드를 보면서 회고하는 과정에서 max_length와 암호화 후, 자릿수를 인덱싱하는 과정에서 설계 상 맞지 않는 걸 확인했고, 이 부분 또한 프로젝트가 다시 착수되면 수정 사항으로 확인되었다.\n🔆 max_length는 DB의 VARCHAR 사이즈를 나타내는데, VARCHAR는 mysql에서 버전 4에서는 bytes 였다가 버전 5에서 글자수로 바뀌었다.\na max_length argument which specifies the size of the VARCHAR database field used to store the data. 출처: Field options 7) 두 번 암호화하기\n암호화를 할 때, user의 id와 시간만 합쳐서 암호화를 한 번 하는 것보다 부분적으로 인덱싱하여 가져와서 합친 후, 암호화를 한 번 더 실행하기로 했다. 그 이유는 구글링하여 해시에 대해 알아보다가 여러 번 해시함수를 거쳐서 다이제스트를 생성하는 방식을 보안적으로 사용한다는 글을 확인했기 때문이다.\n1 2 3 user_hash = hashlib.sha1(str(user.id).encode(\u0026#39;utf-8\u0026#39;)).hexdigest()[:5] time_hash = hashlib.sha1(str(int(time.time())).encode(\u0026#39;utf-8\u0026#39;)).hexdigest()[-5:] merchant_id = hashlib.sha1((user_hash + time_hash).encode(\u0026#39;utf-8\u0026#39;)).hexdigest()[:10] 1.3 payment_id 아임포트에 merchant_id와 amount를 전달하고, 결제 이후에 아임포트 내에서 merchant_id를 기준으로 결제내역을 확인할 때 imp_id를 받는다. 이 imp_id와 merchant_id로 정상 거래인지 아닌지를 판단한다.\n이 아임포트에서 전달한 imp_id가 DB에 payment_id로 저장됩니다. 즉 \u0026lsquo;결제 번호\u0026rsquo;를 의미한다. 이 결제 번호는 결제 오류로 아임포트에서 받지 못할 수도 있어 다음과 같이 blank=True로 설정한다.\n1.4 amount amount는 \u0026lsquo;결제 금액\u0026rsquo;을 의미한다. 이 결제는 테스트 결제이기 때문에, 테스트 결제를 위한 최소 결제 금액을 알고 있는 것이 중요했다. 최소 결제 금액은 최소,최대 결제금액이 얼만지 궁금해요!에서 KG 이니시스를 확인하면 \u0026lsquo;신용카드\u0026rsquo;는 100원이라는 걸 알 수 있다. 그래서 다음과 같이 default 값으로 100을 입력해야 한다.\n1 amount = models.PositiveIntegerField(verbose_name=\u0026#39;결제 금액\u0026#39;, default=100) 만약 이 100원보다 낮은 금액으로 merchant_id와 amount를 아임포트에 전달할 경우, 아임포트에서는 받아들여지지 않아서 다음과 같은 에러가 발생된다.\n발생된 error: 거래건이 존재하지 않습니다. 그렇기 때문에 결제 외부 API를 사용한다면 반드시 테스트를 위한 최소 결제 금액을 확인해야 한다.\n1.5 type type은 결제 방식을 의미한다. 아임포트에서는 결제 수단을 \u0026lsquo;method\u0026rsquo;라 했지만 이는 다른 의미로 받아들여질 확률이 크다고 판단되어 type이란 명칭을 선택했다.\n또한, 프로젝트의 클론 대상이 되는 사이트에서는 카드 결제만을 고려했기 때문에, 이번 프로젝트 또한 카드 결제만을 고려했다.\ntype의 choices 속성 값에 해당되는 PAYMENT_TYPE_CHOICES가 처음에는 IntegerField에 입력되기 위해서 다음과 같이 before case로 적혔지만, 이런 경우 type 정보를 아임포트에 전달하면 못 받아들였기 때문에 아임포트와의 호환을 위해서 after case로 수정했다.\n1 2 3 4 5 # before case PAYMENT_TYPE_CHOICES = [(1, \u0026#39;신용카드\u0026#39;)] # after case PAYMENT_TYPE_CHOICES = [(\u0026#39;card\u0026#39;, \u0026#39;신용카드\u0026#39;)] ❗️ type이란 명칭은 파이썬의 내장 함수 type()에 사용되는 예약어이기 때문에 수정사항에 해당된다.\n1.6 status \u0026lsquo;결제 상태\u0026rsquo;를 말한다. 결제 객체를 생성 후 중간 중간 과정을 저장하는 게 중요하기 때문이다. 이 저장된 값에 따라서 결제가 어떻게 중단되었고, 어디서 중단되었는지 알 수 있기 때문이다. 또한, 결제가 정확하게 이뤄졌는지 판단할 수 있다.\n처음에는 이 또한 IntegerField를 사용하여 choices를 다음과 같이 만들었다.\n1 2 3 4 5 6 7 8 9 10 11 12 # status choices IS_DONE = 2 IS_AWAITING = 1 IS_CANCELLED = 0 STATUS_CHOICES =[ {IS_DONE, \u0026#39;결제완료\u0026#39;}, {IS_AWAITING, \u0026#39;결제대기\u0026#39;}, {IS_CANCELLED, \u0026#39;결제취소\u0026#39;} ] status = models.IntegerField(choices=STATUS_CHOICES, default=IS_AWAITING, verbose_name=\u0026#39;결제상태\u0026#39;) 하지만 이럴 경우, 아임포트와 연동하는 과정에서 혼란스러웠기 때문에 아임포트에서 전달하는 상태 값을 최대한 그대로 사용하는 게 낫다는 판단을 하여 CharField를 사용했다.\n1 2 3 4 5 6 7 8 9 STATUS_CHOICES =[ {\u0026#39;await\u0026#39;, \u0026#39;결제대기\u0026#39;}, {\u0026#39;paid\u0026#39;, \u0026#39;결제성공\u0026#39;}, {\u0026#39;failed\u0026#39;, \u0026#39;결제실패\u0026#39;}, {\u0026#39;cancelled\u0026#39;, \u0026#39;결제취소\u0026#39;} ] status = models.CharField(verbose_name=\u0026#39;결제상태\u0026#39;, default=\u0026#39;await\u0026#39;, choices=STATUS_CHOICES, max_length=10) max_length는 cancelled 를 고려하여 10으로 설정했다.\n2. Iamport.py 작성 시 고려사항 iamport.py 는 아임포트 github에서 제공하는 함수를 그대로 가져온 게 아니라, 이를 참고로 나만의 방식으로 작성했다.\nIMP_KEY와 IMP_SECRET IMP_KEY와 IMP_SECRET 값을 가리키는 인스턴스 변수들을 생성자에 포함시켜서 해당 클래스를 가져와서 변수를 인스턴스화할 때, 별도의 KEY와 SECRET 값을 받지 않도록 설계했다.\n아임포트 api url을 클래스 변수로 만들기 아임포트 api url에서 protocol + host 부분은 클래스 변수로 만들어서 복잡한 url을 보다 가독성 좋고 알아보기 쉽게 만들었다.\n아임포트 응답 성공일 때, \u0026lsquo;code\u0026rsquo;의 값 아임포트에서 응답을 보낼 때 \u0026lsquo;code\u0026rsquo;라는 key의 대응되는 값이 0이므로 단지 0으로 두기보다는 response_success라는 변수가 가리키도록 하여 가독성 부분도 고려했다.\nrequest module 아임포트에 url에 데이터를 전달할 때는 request module을 사용했다.\n❗️ 위 부분이 반복되기 때문에 프로젝트를 다시 착수할 때 별도의 메서드로 함수화할 예정이다.\nstatus code status code 부분은 400번대가 존재하는데 아임포트 api 문서에서 실패 시 반환하는 status code를 그대로 가져왔기 때문이다.\n3. models.Manager 작성 시 고려사항 models.Manager를 사용한 이유 models.Manager를 사용한 이유는 로직을 view에서 처리하면 너무 길어지기 때문에, 이보다는 해당 Manager model에서 만든 쿼리 메서드를 만들어서 사용하는 게 관리의 관점에서 낫다고 판단했기 때문이다.\nmodels.Manager 관련 django docs Manager name 공식문서를 참고하여 Manager의 이름은 \u0026lt;이 모델 매니저를 사용할 모델명\u0026gt;Manager로 작명한다. 그리고 이 Manager를 사용할 모델에 objects에 할당한다.\n1 2 3 4 class Payments(models.Model): ... objects = PaymentsManager() ... 4. DB에 저장되는 결제 정보 시간대 설정 결제 시간을 저장하기 위해서 DateTimeField를 사용했다.\n저장된 결제 시간을 보니 실제 결제 시간과 DB에 저장된 시간이 다른 issue가 발생했다.\nDjango docs - TIME_ZONE를 보면 settings.py에 TIME_ZONE이 정의되어 있지않으면, default 값으로 America/Chicago 로 설정되는 걸 알 수 있다.\n그래서 다음 두 가지 설정을 추가해본다.\n1 2 3 4 # settings.py TIME_ZONE = \u0026#39;Asia/Seoul USE_TZ = False USE_TZ 가 True이면 default 값으로 time zone이 인식된다. 그래서 이 부분을 False로 변경한다.\n그리고, TIME_ZONE에 무슨 값을 세팅할지 알지 못해서 구글링을 통해 확인했다. 나중에 위 문서를 보니 list of time zones에 목록들이 나와있는 걸 확인했다.\n5. post_save.connect() post_save.connect를 택한 이유와 역할 이유 post_save.connect()를 사용한 이유는 2가지다.\n첫 번째: Payment 모델 객체에 관한 것이기 때문에, models.py 에서 처리하길 원했다. 두 번째: Payment 모델 save()가 실행되면 자동적으로 payment_validation을 체크하여 아임포트와 로컬 DB에 존재하는지 자동적으로 체크하길 원했다. 1 2 3 from django.db.models.signals import post_save ... post_save.connect(payment_validation, sender=Payment) 역할 docs Django - Signals를 참고하면 post_save는 model 객체에 대해 save() method가 실행된 후, method가 실행되도록 신호를 보낸다.\nPayment model이 저장되면 위 코드를 사용하여 payment_validation 함수를 실행한다. 만약 payment_id가 존재할 경우, 아임포트 내에서 찾은 결제 내역이 실제 모델에도 존재하는지를 확인한다. 한 곳이라도 없으면 \u0026lsquo;비정상 거래\u0026rsquo; 임을 알리는 역할을 수행한다.\npost_save.connect의 내부 원리 post_save.connect 실행 전체 순서 post_save.connect(receiver, sender)를 통해서 sender와 receiver를 Signal.connect()에 전달하여 sender와 receiver가 실행이 순차적으로 되도록 연결시키는 단계 model.save()가 실행되어 Signal.send(sender)가 실행 Signal.send(sender)에서 Signal._live_receiver(sender)가 호출된다. 그 결과 sender에 연결된 receiver들을 반환하고, 각 receiver들을 실행시킨다. ModelSignal class and partial class model 객체인 sender 그리고, receiver를 받아서 partial class를 통해 Signal.connect에 전달하기\nmodel.save()가 실행되기 전에 receiver와 sender를 미리 연결하기 위해서 Signal.connect에 전달하는 단계다.\n그러면 그후, model.save()가 실행되어 sender가 실행될 때, receiver가 실행된다.\npost_save는 다음과 같이 ModelSignal class의 인스턴스다. 그래서 이 인스턴스에 접근하여 인스턴스 메서드인 connect가 실행된다. connect에서 받은 인자들을 _lazy_method에 전달한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # signals.py class ModelSignal(Signal): ... def _lazy_method(self, method, apps, receiver, sender, **kwargs): ... partial_method = partial(method, receiver, **kwargs) if isinstance(sender, str): ... else: return partial_method(sender) def connect(self, receiver, sender=None, weak=True, dispatch_uid=None, apps=None): self._lazy_method( super().connect, apps, receiver, sender, weak=weak, dispatch_uid=dispatch_uid, ) ... ... post_save = ModelSignal(use_caching=True) 받은 인자는 아래 코드대로 self를 사용하여 같은 클래스의 메서드를 호출하여 전달된다. 아래에서 super()는 Signal 상위 클래스를 말한다.\n1 self._lazy_method(method=super().connect, apps=None, receiver=payment_validation, sender=Payment, ...) 그러면 partial_method 인스턴스 객체를 만든다. 이 때 partial class 내부의 __new__ method가 실행되서 다음과 같이 func과 args 속성이 각각 method와 receiver를 가리킨다.\n1 2 3 partial_method = partial(method=super().connect, receiver=payment_validation) partial_method.func = super().connect partial_method.args = payment_validation 그 다음으로 _lazy_method method는 객체가 문자열 유무에 따라 분기가 되는데, Payment의 type()은 str이 아니고, \u0026lt;class 'django.db.models.base.ModelBase'\u0026gt; 이므로, partial_method(sender=Payment)를 실행한다.\npartial_method(sender=Payment) 실행되면 \u0026lsquo;partial class\u0026rsquo;의 __call__ method가 호출된다.\n1 2 3 def __call__(self, /, *args, **keywords): keywords = {**self.keywords, **keywords} return self.func(*self.args, *args, **keywords) 위의 각 매개변수는 다음을 의미한다.\nself.func: super().connect -\u0026gt; Signal.connect *self.args: payment_validation *args: Payment Signal.connect 전달받은 sender와 receiver를 매핑하는 단계\n그러면 self.func(*self.args, *args, **keywords)가 어떻게 실행되는지 알아보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 self.lock = threading.Lock() self.sender_receivers_cache = weakref.WeakKeyDictionary() if use_caching else {} self._dead_receivers = False def connect(self, receiver, sender=None, weak=True, dispatch_uid=None): if dispatch_uid: lookup_key = (dispatch_uid, _make_id(sender)) else: lookup_key = (_make_id(receiver), _make_id(sender)) if weak: ... weakref.finalize(receiver, self._remove_receiver) with self.lock: self._clear_dead_receivers() if not any(r_key == lookup_key for r_key, _ in self.receivers): self.receivers.append((lookup_key, receiver)) self.sender_receivers_cache.clear() [weakref.finalize()]\nSignal class는 weak라는 변수로 약한 참조와 강한 참조를 구분한다. weak가 True이면 약한 참조를 의미하여, weakref.finalize() class를 통해 receiver가 garbage collector에 의해서 수거될 때 실행할 콜백함수를 등록한다. 여기서 콜백함수는 self._remove_receiver다.\n[dead_receivers] 만약 receiver가 실행 및 완료되면 self._remove_receiver가 실행되어 self._dead_receivers = True 값으로 변경되어 self.receivers에 dead_receiver가 존재하는 걸 알린다.\n이 dead_receiver는 self.lock이 유지되는 동안 _clear_dead_receivers에 의해서\n플래그 변수인 self._dead_receivers를 존재하지 않는다는 의미로 False로 바꾼 후, dead_receivers를 self.receivers에서 제외시킨다. [sender_receivers_cache] dead_receivers 를 clear 후, sender_receivers_cache도 clear 한다.\nconnect() -\u0026gt; send() -\u0026gt; _live_receivers() model.save() 후, Signal.send(sender)를 통해 sender와 연결된 receiver들을 실행\nmodel인 sender가 model.save() 되면 send(self, sender)에 의해서 signal을 receiver한테 보내는 과정이 실행된다.\n이 send(self, sender) 안에서 _live_receivers(self, sender)를 호출한다.\n이 _live_receivers()의 역할은 self.sender_receivers_cache에 sender에 대응되는 receiver를 .get(sender)를 사용하여 가져와 send()에 보내준다. 그러면 이 send()에서 sender에 대응되는 receiver를 실행시킨다.\n1 2 3 4 sender: \u0026lt;class \u0026#39;pocket.models.Payment\u0026#39;\u0026gt; # send()의 반환값: [(receiver, response)] [(\u0026lt;function payment_validation at 0x10547d510\u0026gt;, None)] 참고 문서: docs Django - signals: sending signals\n🔆 참고: 약한 참조 vs 강한 참조 약한 참조(Weak reference): 참조수(reference count)를 증가시키지 않는 reference 객체\n강한 참조(Strong reference): 참조수(reference count)를 증가시키는 reference 객체\nGarbage collector는 reference count가 0인 경우, 해당 reference 객체를 삭제하고 사용하지 않는 메모리라고 판단하여 해당 메모리를 반환한다.\n그렇다면 약한 참조는 언제든지 GC에 의해서 언제든지 제거될 수 있다. 강한 참조는 reference count가 0이 되거나 메모리에서 해제될 때 제거된다. Reference count 확인하기\nreference count는 sys.getrefcount(value)를 사용하면 value의 참조 수를 알 수 있다. Reference hashlib - 보안 해시와 메시지 요약 namu.wiki - SHA Field options 최소,최대 결제금액이 얼만지 궁금해요! models.Manager 관련 django docs list of time zones docs Django - Signals ","permalink":"http://jeha00.github.io/post/project/devket/django/02_payment_issues/","summary":"Payment 1차 기능을 개발하는 과정에서의 고려사항들과 개발 이슈들에 대해 정리해본다.","title":"Project: Payment 개발 과정에서의 고려사항들과 개발 이슈들"},{"categories":"Project: Devket","content":"0. Introduction 이 repository는 현재 러닝스푼즈 나노디그리 - django backend 부트캠프에서 팀 프로젝트를 진행하면서 다음과 같은 내용들에 대해 정리하고자 만들었습니다.\n팀 정책을 이것으로 정한 이유 개발하면서 부딪힌 문제들에 대한 원인, 해결방안, 해결과정, 그리고 그 이유들 이번 포스팅에서는 제가 맡은 결제 기능의 전체적인 프로세스와 아임포트를 사용하면서 이 과정이 어떻게 변하는 지에 대해 설명하겠습니다.\n1. 기존 결제 과정 결제의 기본 진행 과정: 인증 -\u0026gt; 결제 순서로 진행\n하지만, 한국에서는 이 인증 부분에서 차이가 있다. 한국에서 카드 결제 과정은 다음과 같다. 왜냐하면 한국에서는 카드 정보(카드 번호 / 유효기간 / cvc )를 일부 가맹점 또는 PG 사를 제외하고는 저장할 수 없기 때문이다. 카드 정보는 오로지 카드사에서만 저장 가능하다.\n카드사 서버가 구매자 브라우저로부터 직접 카드 정보를 전달받아 인증처리하는 게 다른 나라와 가장 큰 차이이다.\n이 카드 인증된 결과를 바탕으로 결제 프로세스가 진행된다. 결제 프로세스는 3번부터 8번까지의 과정을 말한다.\n출처: 아임포트 공식문서 - webhook\nPG 사에서 저장할 수 없도록 만든 방법 출처: 아임포트 공식문서 - webhook\n그래서 결제를 진행할 때 PG 사의 결제 모달 창이 뜬 후, 카드사를 클릭하면 또 다른 모달 창이 뜬다.\n이것이 PG 사에서 카드 정보를 저장하지 못하도록 하기 위함이다.\n그래서 PG 결제 모듈 창을 띄우고 나서 결제 과정의 첫 시작인 \u0026lsquo;인증\u0026rsquo; 과정이 시작될 수 있다.\n2. Iamport 선택 이유와 장점 Iamport 사용 시 결제 과정 출처: 아임포트 공식문서 - webhook\n아임 포트를 선택한 이유 PG 사와의 복잡한 연동 과정 해소 직접 api로 만들어야하는 많은 부분을 아임포트가 대신 해주기 때문에, 짧은 기간 안에 결제 기능을 추가하기 좋은 라이브러리로서, 경험이 없는 학습자가 사용하기에 보다 퀄리티에 집중할 수 있다.\n직접 PG 서버와 통신해야 했던 가맹점 서버의 역할을 대신한다. PG 서버와 직접 통신하기 위해서 PG가 지원하는 제한적인 개발환경을 사용해야하고, PG 모듈을 설치하는 등 절차가 복잡했지만, 아임포트를 사용하면서 간결하고 REST API를 통해 쉽게 결제를 연동할 수 있다.\n위 이미지의 1, 2, 5, 7번 과정만 신경쓰면 된다. 카드정보가 잘못되었다면 카드사 모듈 창에서 입력 시, 인증 오류가 날 것이다. 결제 정보가 잘못되었다던가, 카드 한드가 초과되었다던가, 사용자 변심으로 결제가 취소했다면 결제 단계에서 에러가 난다.\n결제 기능 확장성 토스에서도 결제 API를 제공한다. 하지만, 나중에 \u0026lsquo;구독\u0026rsquo;이란 정기 결제를 도입할 상황에서 아임포트는 정기 결제 기능을 제공하고 토스에서는 그렇지 않기 때문에, 추후 결제 기능 확장성을 고려할 때 아임포트를 선택했다.\n편리한 복수 PG 사용 연동되는 PG 선택도 iamport admin에서 로그인하여 테스트 버전으로 자유롭게 선택할 수 있다.\n잘 정리된 api 문서 아임포트 api 문서 를 보면 아임포트 API가 체계적으로 정리되어 있다.\n적절한 api url에 필요한 정보만 보내면 결제 정보를 조회할 수 있다.\n3. 아임포트 Javascript SDK를 사용한 결제 흐름 아임포트 결제 연동 서비스를 사용하기 위해서는 아임포트 Javascript SDK(Software Development Kit)를 사용해야 한다. 이 SDK를 통해서 내가 생성한 주문번호와 금액을 아임포트에 전달하고, 아임포트는 결제 번호를 나에게 전달한다.\n그래서 이 SDK를 통해 결제 각 단계에서의 데이터 처리를 js function을 통해서 해당 api로 데이터를 전달하기 위해서 fetch를 사용했다. 그리고, 이 view에서 model에 접근하여 고유 주문 번호, 결제 상태, 결제 금액 등의 정보를 저장한다. model에 접근할 때는 ModelManager를 사용하여 해당 Model 객체만의 ORM을 만들었다.\n3.1 결제 프로세스 과정 순서 해당 프로젝트에서 설계한 결제 프로세스의 전체 흐름은 다음 이미지와 같다.\n1), 2) 결제 버튼 클릭 및 call-payment.js 실행 아래 이미지의 \u0026lsquo;이 옵션 선택\u0026rsquo; 태그를 클릭하여 call-payment.js를 실행한다.\n❗️ 원래 사이트에서는 월간 멤버쉽과 연간 멤버쉽 둘 다 존재했다. 하지만, 월간 멤버쉽만 고려한 이유는 1차로 결제 자체 기능만 구현한 후, 그 다음으로 월간 멤버쉽만을 추가로 구현할 계획이기 때문이다.\ncall-payment.js의 전체 소스 코드를 보고 싶다면 이 링크를 클릭한다.\n위 이미지의 버튼은 .order이라는 클래스 명을 가지고 있기 때문에 이를 통해서 DOM을 인식하여 event를 건다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 import {getElement ,setFetchData} from \u0026#39;./common.js\u0026#39;; window.onload = function () { const IMP = window.IMP; IMP.init(\u0026#39;imp62676076\u0026#39;); const paymentButton = getElement(\u0026#39;.order\u0026#39;) paymentButton.addEventListener(\u0026#39;click\u0026#39;, async (e) =\u0026gt; { const type = \u0026#39;card\u0026#39;; let buyer_name, buyer_email, merchant_id, amount, payment_info; payment_info = await passPaymentInfo(e, type); [buyer_name, buyer_email, merchant_id, amount] = payment_info if (merchant_id !== \u0026#39;\u0026#39; \u0026amp;\u0026amp; merchant_id !== undefined) { ... } return false; }) }; 3) 가맹점 식별코드로 IMP 객체 초기화 \u0026lsquo;call-payment.js\u0026rsquo;가 실행되면서 제일 먼저 하는 건 \u0026lsquo;가맹점 식별코드\u0026rsquo;로 인한 초기화 작업이다. \u0026lsquo;가맹점 식별코드\u0026rsquo;는 아임포트를 가입할 때 IMP_KEY와, IMP_SECRET 그리고 가맹점 식별코드인 MERCHANT_ID가 제공된다. 이 MERCHANT_ID를 입력해야 한다. IMP_KEY와 IMP_SECRET은 아임포트에 접근하기 위한 토큰을 받기 위해서 필요하다.\n4) passPaymentInfo 함수 실행 IMP.request_pay()에 전달하기 위한 merchant_id(고유 주문 번호), buyer_name, buyer_email을 backend에서 받아내는 함수\n이벤트가 발생 시, call-payment.js에서 가장 먼저 실행되는 함수다. 그 이유는 아임포트 api에 전달할 merchant_id (고유 주문 번호)를 생성하고, amount(결제 금액)와 함께 전달하기 위해서다.\nargument(or parameter)로 받은 type은 결제 방식을 말한다. 현재 개발 단계에서는 카드 결제만 고려하고 있기 때문에 const type = 'card'로 정해져있다.\n[4-1, 4-2] 과정 merchant_id를 생성하기 위해서 정해놓은 /api/payment/checkout 으로 fetch를 사용하여 data를 보낸다. 그러면 urls.py 에 의해서 이 api url과 mapping된 django view class로 request를 보낸다. 이 api url과 연결된 class는 PaymentPassView 다. [4-5] 과정 PaymentPassView에서 보낸 response에서 json형태로 데이터를 뽑아낸다. .works는 아임포트 api에서 응답 결과를 알려주는 key 값이다. 아임포트에서 응답이 성공했으면 \u0026quot;works\u0026quot;: True로, 실패하면 False로 값이 온다. 그래서 works가 True이면 view class에서 원하는 값을 받은 것이기 때문에, 이 경우 unpacking을 사용하고자 배열의 형태로 결과값을 반환했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // IMP.request_pay를 호출하기 위한 merchant_id 반환 async function passPaymentInfo(e, type) { e.preventDefault(); let merchant_id = \u0026#39;\u0026#39; let amount = 0 let buyer_name = \u0026#39;\u0026#39; let buyer_email = \u0026#39;\u0026#39; const data = setFetchData(\u0026#39;POST\u0026#39;, { amount: amount, type: type }) const response = await fetch(`/api/payment/checkout`, data) const result = await response.json() if (result.works) { buyer_name = result.buyer_name buyer_email = result.buyer_email merchant_id = result.merchant_id amount = result.amount return [buyer_name, buyer_email, merchant_id, amount] } else if (response.status === 401) { alert(\u0026#39;로그인 해주세요.\u0026#39;) } else { alert(\u0026#39;문제가 발생했습니다. 다시 시도해주세요.\u0026#39;) }}; 그러면 PaymentPassView class에서 어떻게 merchant_id를 생성하여 반환하는지 알아보자.\n로그인 후, 결제를 시도하면 다음 ORM으로 user과 email를 조회한다.\n1 2 3 user = User.objects.get(id=kwards[\u0026#39;user_id\u0026#39;]) buyer_email = Email.objects.get(user=user).email # Email model에서 email은 회원가입 시 사용한 이메일을 말한다. 그 후, 이 객체 정보를 사용하여 merchant_id를 생성한다.\n1 2 3 4 5 merchant_id = Payment.objects.create_new( user=user, amount=amount, type=payment_type, ) [4-3 ~ 4-5 과정] (4-3) class PaymentManager\nPayment만의 orm을 사용하기 위해 만든 PaymentManager를 통해서 merchant_id를 생성한다. (4-4) import.py \u0026amp; Payment object 생성\n그후, 이 merchant_id와 amount를 아임포트에 전달한다. PaymentManager의 클래스 변수로 선언한 imp를 사용하여 prepare_payments method를 통해 생성한 merchant_id를 amount와 함께 아임포트에 전달한다. 이 때 전달하는 아임포트 api url은 {아임포트 기본 api url}/payments/prepare 이다. 그 다음에 payment 객체를 새롭게 생성한다. 1 2 3 4 5 6 7 8 9 10 11 class PaymentManager(models.Manager): imp = Iamport() def create_new(self, user, amount, type): ... # 아임포트에 전달 PaymentManager.imp.prepare_payments(merchant_id, amount) # 새로운 payment 객체 생성 new_payment = self.model(user=user, merchant_id=merchant_id, amount=int(amount), type=type) (4-5) class PaymentPassView\nPaymentManager의 create_new에서 반환한 merchant_id와 함께 필요한 정보들을 call-payments.js의 passPaymentInfo function에 response를 보낸다. 5) IMP.request_pay()에 결제 정보 전달 이전 단계에서 보낸 amount, merchant_id, pay_method, buyer_name, buyer_email와 함께 어느 pg사를 호출할 것인지 pg key 값에 value로 입력해야 한다. 이는 아임포트 공식문서를 참고한다.\npg사로는 KG 이니시스를 선택했는데, 그 이유로는 웹표준으로서 브라우저 제약 없이 결제가 가능하기 때문이다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 if (merchant_id !== \u0026#39;\u0026#39; \u0026amp;\u0026amp; merchant_id !== undefined) { IMP.request_pay({ pg: \u0026#39;html5_inicis\u0026#39;, // KG 이니시스 merchant_uid: merchant_id, name: \u0026#39;Devket Premium 서비스\u0026#39;, pay_method: \u0026#39;card\u0026#39;, amount: amount, buyer_name : buyer_name, buyer_email : buyer_email }, // 결제창 오픈 function (response) { if (response.success) { ... } else { ... } }); } 6) PG사의 결제창 오픈 및 카드사 선택하여 결제 진행 다음과 같은 KG 이니시스의 결제창이 떠서 결제가 진행된다.\n7), 8) 결제 성공: storeImpIdInDB 함수 실행 -\u0026gt; redirect 결제가 성공하여 아임포트에서 받은 imp_uid를, 생성했던 payment 객체에 imp_id로서 결제 상태를 저장하고, User 객체의 결제 상태를 변경하는 함수\n(7-1) urls.py\nfetch를 사용하여 \u0026lsquo;/api/payment/validation\u0026rsquo; api url에 data를 보내면 urls.py에서 이 api url에 mapping된 PaymentImpStoreView로 request가 가도록 한다. (7-2, 7-3, 7-4, 7-5) class PaymentImpStoreView\nrequest로부터 imp_id, amount, merchant_id, status를 가져와 이에 해당하는 payment 정보와 User 정보를 조회한다. 1 2 3 4 class PaymentImpStoreView: ... user = User.objects.get(id=kwards[\u0026#39;user_id\u0026#39;]) payment = Payment.objects.get(user, merchant_id, amount) 조회 후, payment 객체에 imp_id, status 정보를 저장한다. user 객체에는 기존에 미결제 상태인 것을 \u0026lsquo;결제\u0026rsquo; 상태로 변경한다. 1 2 3 4 5 user.payment_status = User.PAYMENT_ON user.save() payment_data = {\u0026#39;payment_id\u0026#39;: imp_id, \u0026#39;status\u0026#39;: payment_status} self.check_validation(payment, data=payment_data) ... 그리고, 변경 결과에 따라서 works의 값이 변경되고, 이를 storeImpIdInDB에 전달한다. (7-5 ~ 7-7) 결제 검증하기: payment_validation \u0026amp; get_transaction\npost_save에 의해서 Payment 객체가 저장되면 결제가 유효한지 검증하는 payment_validation function이 실행된다. 1 post_save.connect(payment_validation, sender=Payment) payment_validation 내부에는 PaymentManager로 정의한 get_transaction 메서드가 있어서, 이를 통해서 iamport 내에 결제 내역이 있는지 확인하여 아임포트에도 존재하고, db에도 다 존재하는지를 확인합니다. 다 존재해야 결제가 올바르게 된 것입니다. [8] 과정- redirect : PG 결제 창에서 결제가 완료되면 다른 화면으로 리다이렉트합니다.\n9) 결제 실패: makeStatusFailure 함수 실행 사용자가 결제 정보를 다 입력하고, 완료버튼만 누르면 되는 상황에서 \u0026lsquo;사용자 변심\u0026rsquo;으로 결제를 취소할 경우 결제 상태를 반영하는 함수\n(9-1) urls.py\nfetch를 사용하여 \u0026lsquo;/api/payment/failure\u0026rsquo; api url에 data를 보내면 urls.py에서 이 api url에 mapping된 PaymentFailedView로 request가 간다. (9-2 ~ 9-5) class PaymentFailedView\nrequest로부터 imp_id 와 merchant_id를 가져와 아래아 같이 객체 조회 및 수정에 사용한다. Payment 객체 조회 및 수정 1 2 3 4 5 6 7 8 9 imp_id = request.data[\u0026#39;imp_id\u0026#39;] merchant_id = request.data[\u0026#39;merchant_id\u0026#39;] # Payment 객체 조회 payment = Payment.objects.get(merchant_id= merchant_id) # Payment 객체 정보 수정 payment_data = {\u0026#39;payment_id\u0026#39;: \u0026#39;imp_id\u0026#39;, \u0026#39;status\u0026#39;: \u0026#39;failed\u0026#39;} serializer = PaymentSerializer(payment, data=payment_data, partial=True) 처리 결과에 따라서 \u0026quot;works\u0026quot;의 값을 True, False로 바꿔서 Response를 보낸다. 10) 결제 실패 안내문 9)의 경우처럼 사용자 변심으로 결제 실패한 경우와 그 외의 실패했을 때 다음과 같이 alert를 사용하여 안내한다.\n1 2 3 4 5 6 7 8 9 else { if (response.imp_uid) { // 결제한 유저의 이름과 이메일 확인 후, 사용자 변심으로 결제 창을 닫아 결제 취소되는 로직 makeStatusFailure(e, response.merchant_uid, response.imp_uid); } let msg = \u0026#39;결제에 실패하였습니다. \\n\u0026#39;; msg += \u0026#39;에러내용: \u0026#39; + response.error_msg; alert(msg) } 3.2 결제 프로세스에서 고려한 발생할 수 있는 상황들 결제 기능에서 중요하고 어려운 것은 다음 3가지라고 생각한다.\n내부 정책에 따라서 무엇보다 여러 상황에 대해서 고려해보고 이에 대해 어떻게 코드를 짰는지 배달을 하는 e-commerce처럼 장바구니, 배달, 쿠폰 할인 같은 여러 모델들이 엮어져야 복잡해지는 상황 대규모 트래픽 상황에서 많은 사용자들이 동시에 결제 요청들이 들어올 때 이를 얼마나 빠르고 정확하게 처리하는지 하지만, 현재 프로젝트는 단지 구독 같은 개념이고, e-commerce처럼 복잡하지 않다. 또한, 트래픽이 거의 없는 상황이다. 그래서 내가 최대한 고려할 것은 첫 번째 경우라고 생각한다.\n이런 상황에서 최대한 내가 생각해낼 수 있는 결제 상황들에 대해 정리해보려고 한다.\n고려한 결제 상황 merchant_id imp_id status x x failed (1) o x await (2) o x failed (3) o o failed (4) o o paid (5) 로그인 전 =\u0026gt;\n로그인 전 결제를 시도할려고 한다면 alert()를 사용하여 결제 후 시도하라는 안내문이 뜬다. 로그인 후 =\u0026gt;\n(1) 새로운 객체를 생성하는데 실패하여, PG 결제 창이 뜨지 못한 경우 merchant id와 imp id는 존재하지 않고, 결제 상태는 failed (2) PG 결제 창을 띄웠지만 카드사를 선택하지 않고, 사용자 변심으로 취소했을 경우 =\u0026gt; 결제 실패 merchant id는 존재하지만, imp id는 존재하지 않고, 결제 상태는 await (2) 카드 정보 입력 실패 =\u0026gt; 결제 실패 카드 정보 불일치, 한도 초과, 잔액 부족 등의 사유로 결제가 중단 merchant id는 존재하지만, imp id는 존재하지 않고, 결제 상태는 await (3) 주문 번호가 이미 존재할 경우 =\u0026gt; 결제 실패 주문 번호는 시간에 따라 다른 주문 번호를 생성하도록 했기 때문에, 이미 존재하는 주문 번호가 들어왔다는 건 에러가 발생한 상황을 의미 merchant id는 존재하지만, imp id는 존재하지 않고, 결제 상태는 failed 카드 정보 입력 완료 =\u0026gt; (4) \u0026lsquo;취소\u0026rsquo; 버튼 클릭 =\u0026gt; 사용자 변심으로 인한 결제 실패 merchant id, imp id는 존재하지만 결제 상태는 failed (5) \u0026lsquo;완료\u0026rsquo; 버튼 클릭 =\u0026gt; 결제 성공 merchant id, imp id는 다 존재하면서 결제 상태는 paid 위의 상황들은 1차 결제 기능 구현 시 고려한 상황이다. 계속해서 환불과 정기 결제를 추가하려고 한다.\n그렇다면 환불 시에는 사용 기간에 따른 환불 정책을 어떻게 세울 것인지, 정기 결제를 도입한다면 결제 기간 몇 일 전에 알림을 주는 것이 사용자 편의성에 좋을텐데 이를 기술적으로 어떻게 구현할지가 고려사항으로 올라온다.\n1차적인 결제 과정에서의 고려사항은 Project: Payment 개발 과정에서의 고려사항들과 개발 이슈들 문서를 참고하도록 한다.\nReference 한국 전자결제 서비스 흐름 Django에서 아임포트를 통해 결제 구현하기 - (1) 아임포트 세팅 및 결제 구조 iamport admin 아임포트 api 문서 ","permalink":"http://jeha00.github.io/post/project/devket/django/01_payment_overall_flow/","summary":"기존 결제 과정과 iamport를 사용 시 변한 결제 과정을 정리하고, iamport 사용 시 얻는 장점들에 대해 정리해본다. 마지막으로 프로젝트에서 아임포트 javascript SDK를 사용한 결제 흐름을 정리해본다.","title":"Project: Iamport를 선택한 이유, 사용 시 결제 과정과 장점, 그리고 아임포트 javascript SDK를 사용한 결제 흐름"},{"categories":"Docker","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 장철원 강사님의 docker 강의를 학습한 내용입니다.\n다른 터미널에서 실행 중인 컨테이너에 접속하거나, 종료시키기 또는 host와 container 간 파일을 전송하는 명령어에 대해 알아본다.\n먼저 ec2 접속하기 위해 ssh \u0026lt;root 계정 이름\u0026gt;@\u0026lt;IPv4\u0026gt;를 입력하여 시작합니다.\n5. 컨테이너 네트워크: 2개 이상의 터미널 그렇다면 docker host 안에 container가 있는 그림을 생각하자.\n5.1 (터미널 1)container 내부에서 bash shell 실행 docker host에서 만든 container 내부에서 bash shell을 실행한다는 의미다. container는 하나의 서버이기 때문이다.\n아래 명령어 입력 시, 바로 bash shell에 접속한다. docker run -it \u0026lt;image name\u0026gt; i: interactive t: 터미널을 통해 대화형 조작이 가능하게 한다. 5.2 (터미널 2)새로운 터미널을 열고 컨테이너 리스트 확인 터미널 2는 docker host로 접속된 상태\n컨테이너의 리스트를 확인하기\ndocker container ps 5.3 서로 다른 터미널에 접속 및 종료 시키기 현재 터미널 상황: Docker host가 동작 중인 터미널 1, 2에서 터미널 1만 container 실행 중\n터미널 1은 docker run -it \u0026lt;image name\u0026gt;으로 컨테이너 실행 중인 상황\n터미널 2에서 터미널 1에 실행 중인 컨테이너 접속하기: docker exec -it \u0026lt;container id\u0026gt; bash\n여기서 container id란 터미널 1에서 실행 중인 컨테이너다. 터미널 2에서 docker container ls 명령어로 실행 중인 컨테이너 id를 확인 후, 이를 입력하여 접속한다. 두 터미널을 비교해보면 동일한 container id를 나타내는 걸 알 수 있다. 터미널 2에서 터미널 1에 실행 중인 컨테이너 접속 후, 나갈 때: exit\n터미널 2에서 터미널 1에 실행 중인 컨테이너 종료 시키기\ndocker stop \u0026lt;container id\u0026gt; 6. 컨테이너와 docker host 간 파일 전송 2개의 터미널 A, B를 띄어서 실행한다.\n터미널 A에 임의의 경로 C에 파일 하나를 생성한다.\n생성한 파일을 D라고 하자.\n6.1 Docker host -\u0026gt; container로 파일 전송 terminal A에서 terminal B의 container로 파일 전송 터미널 A: cd \u0026lt;경로 C\u0026gt; 로 이동하여 ls 로 D가 있는지 확인하자.\n터미널 B: docker run -it ubuntu bash\n터미널 A: docker container ls 로 터미널 B에서 실행시킨 컨테이너 ID를 확인하여 실제로 실행되었는지 확인\n터미널 A: docker cp \u0026lt;파일 D의 경로\u0026gt; \u0026lt;B에서 실행한 컨테이너 ID\u0026gt;:\u0026lt;복사할 경로\u0026gt;\nex) 파일 D의 경로: ./while_loop.py 컨테이너 ID: 26fcb671e9ef 복사할 경로: /home docker cp ./while_loop.py 26fcb671e9ef:/home 터미널 B: 위에 복사할 경로에 입력한 경로로 이동해서 ls로 확인\n그러면 위 터미널 B에서 복사한 파일을 확인할 수 있다.\n6.2 container -\u0026gt; Docker host로 파일 전송 위에 host에서 container로 파일 전송하는 것과 동일하다.\n터미널 A: docker cp \u0026lt;B에서 실행한 컨테이너 ID\u0026gt;:\u0026lt;복사할 경로\u0026gt; \u0026lt;파일 D의 경로\u0026gt; docker cp 26fcb671e9ef:/home ./while_loop.py Reference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/docker/00_docker-commands-02/","summary":"2개의 터미널을 띄어넣고, 다른 터미널에서 실행 중인 컨테이너에 접속하거나, 종료시키기. 그리고, host와 container 간에 파일을 전송하는 명령어에 대해 알아본다.","title":"Docker command list 02"},{"categories":"Docker","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 장철원 강사님의 docker 강의를 학습한 내용입니다.\n도커 설치 명령어, docker image를 가져와서 container로 실행하는 명령어에 대해 알아봅니다.\n먼저 ec2 접속하기 위해 ssh \u0026lt;root 계정 이름\u0026gt;@\u0026lt;IPv4\u0026gt;를 입력하여 시작합니다.\n1. Docker Installation ec2에 로그인하기\nsudo apt update: sudo 명령어 사용하여 apt 업데이트하기\ndocker 설치 확인 docker를 지금 단계에서 입력하면 Command 'docker' not found 를 확인할 수 있다.\ndocker 설치하기: sudo apt install docker.io\ndocker 설치 확인: docker를 입력했을 때, 여러 옵션들이 뜨면 성공\ndocker version 확인: docker --version\ndocker 명령어를 유저 모드에서도 사용할 수 있게 변경\nsudo usermod -aG docker \u0026lt;사용자이름\u0026gt; exec $SHELL 쉘 재가동 ❗️ root 계정이 아닌 사용자 추가하여 사용하기\n2. Docker image 설치, 실행, 목록 확인 설치 및 실행 docker run hello-world를 실행하여 docker image를 확인해본다.\n1 2 3 Unable to find image \u0026#39;hello-world:latest\u0026#39; locally latest: Pulling from library/hello-world ... 처음이라면 unable to find image 'hello-world:latest' locally 가 뜰 것이다. 이 의미는 로컬에 hello-world docker image가 없다는 걸 말한다.\n그러면 자동적으로 pull을 하여 registry 에서 image를 가져온다.\n아래 registry에서 hello-world image를 확인할 수 있다. https://hub.docker.com/_/hello-world 그래서 그 다음 줄에 로컬에 없으니 pull한다는 의미.\ndocker image 목록 확인 docker image ls 3. docker container 목록 확인, 정지하기 container 목록 확인하기 작동 중인 컨테이너 확인: docker container ls\n모든 컨테이너 확인: docker container ls -a\nstatus에서 Extied는 종료되었다는 의미\n직접 경로 이동하여 확인하기\n도커 실행 후, cd /run/docker 로 이동 ls를 입력하여 확인하면 실행 중인 container id 확인가능 container 정지하기 docker container stop \u0026lt;container ID\u0026gt; 🔆 참고: runtime-runc directory에 \u0026lsquo;moby\u0026rsquo;는 도커의 옛날 프로젝트 명이다.\n4. Docker pull docker pull docker pull \u0026lt;댕겨올 image\u0026gt; Ex) docker pull ubuntu pull된 docker image 저장 경로 cd /var/docker/image/overlay2/imagedb/content/sha256 pull 받은 image를 container로 실행 먼저 루트 계정으로 로그인: sudo -i\ndocker image ls 로 해당 image id를 확인한다. 그 후, docker run \u0026lt;image id\u0026gt;를 입력하여 실행한다.\n동일한 종류의 만들어놓은 image가 많을 경우 id를 사용하는 걸 권장\ncontainer 목록 확인 실행 확인: docker container ls -a Reference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/docker/00_docker-commands-01/","summary":"ec2를 활용한 server에 docker를 설치하고, docker image 파일 설치 및 실행 명령어부터 docker의 여러 명렁어를 정리해본다.","title":"Docker command list 01"},{"categories":"Docker","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 장철원 강사님의 docker 강의를 학습한 내용입니다.\n이번 챕터는 docker 기본 image를 바탕으로 자신만의 image를 만드는 과정을 학습하겠습니다.\n또한, 다른 터미널에서 만든 image를 확인할 수 있다는 걸 알기 위해서 터미널 2개를 띄어 진행합니다.\nDocker image 변경 후 저장 기본 Layer를 기반으로 여러 layer를 쌓아나가는 것\n예를 들어서 파이썬이라는 image는 우분투라는 image를 받아서 그 위에 파이썬을 깔아서 만든 image다.\n이처럼 여러 layer를 깔아서 만든 게 image다.\n자신만의 docker image를 만들어보자.\n현재 상황 terminal 2개 A, B를 실행 중인 상황\nterminal B에만 container 실행 중\nterminal A 기존 ubuntu image 실행하기\ndocker run -it ubuntu bash 그러면 원하는 기능이 ubuntu에 있는지 명령어를 입력하여 확인해보자.\n예를 들어서 ifconfig를 실행해본다. ifconfig: 네트워크 IP 정보 보는 명령어 그 결과: bash: ifconfig: command not found 기본 ubuntu에는 이게 설치되어 있지 않기 때문이다.\n그래서 별도의 layer를 쌓아야 한다.\n아래 명령어를 통해서 설치해보자.\napt-get update \u0026amp;\u0026amp; apt-get install net-tools ifconfig를 입력하면 inet \u0026lt;ip 주소\u0026gt;를 확인할 수 있다.\nterminal B docker container ls\nterminal A에 올린 container를 확인할 수 있다. docker commit \u0026lt;container id\u0026gt; \u0026lt;만들려는 image의 이름: 임의 지정\u0026gt;:\u0026lt;tag 번호: 임의 지정\u0026gt;\nex) docker commit \u0026lt;container id\u0026gt; my-ubuntu:0.1\n0.1은 태그 번호라서 자신의 마음대로 입력하면 된다.\n기본 우분투 위에 지금 net-tools 라는 걸 설치하여 한 layer를 쌓았다. 이를 저장하기 위해서는 위 명령어를 사용한다.\n만든 image 실행 일반 image 실행과 동일하다.\ndocker run -it \u0026lt;image name:image tag\u0026gt; 🔆 docker build는 내 local 상에 있는 걸 저장할 때 사용하고, 위 명령어는 이미 떠 있는 컨테이너를 이미지로 뜨는 것이다.\nReference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/docker/03_make-custom-image/","summary":"docker run -it 으로 docker의 기본 image를 실행한 후, 이를 바탕으로 apt-get install로 여러 layer를 쌓는다. 마지막으로 docker commit으로 나만의 image를 만든다.","title":"기본 image 활용하여 나만의 custom image 만들기"},{"categories":"Docker","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 장철원 강사님의 docker 강의를 학습한 내용입니다.\ndocker의 기본 개념에 대해 학습해보겠습니다.\n1. Docker란? container(컨테이너) 라고 부르는 패키지 형태 OS-level 가상화 기술을 사용한 PaaS(Platform as a service) 제품 컨테이너를 관리하는 소프트웨어를 도커 엔진(Docker Engine) 이라 한다. 2. laaS, PaaS, SaaS의 개념 On premises 사용자가 전부 다 관리해야하는 서비스 다나와에서 서버를 하나 사서, 처음부터 끝까지 사용자가 다 하는 것 IaaS (Infrastructure as a Service) 인프라를 서비스로 제공한다는 의미로서, Networking부터 가상화까지만 업체에서 제공하고, 나머지만 사용자가 관리하는 서비스 Ex) AWS, Google Cloud, Microsoft Azure HW 고장을 신경쓰지 않는다. PaaS (Platform as a Service) applications과 data 제외한 모든 부분을 업체에서 제공하는 서비스 Ex) Docker, github, Kubernetes 배포할 수 있는 플랫폼을 제공하는 서비스 SaaS (Software as a Service) 전부 다 업체가 관리하는 서비스 소프트웨어만 사용자가 신경쓴다. ex) Gmail, Google Docs, Office 365 그렇다면 개인 프로젝트들은 IaaS, PaaS, SaaS 중 무엇일까? 정답: SaaS 사용자가 아닌 제공자의 관점에서 위 이미지 기준으로 어느 단계까지 제공하는 지가 분류 기준이다. IaaS X: EC2를 사용할 뿐, EC2를 제공하지 않는다. PaaS X: Docker를 사용할 뿐, Docker service를 제공하지 않는다. 3. 가상화, 가상화의 종류 그리고 docker 가상화(virtualization)이란? 물리적 자원(H/W)을 논리적 자원으로 변환해서 사용하는 것\n예를 들어 하드 디스크 하나지만, C 드라이브와 D 드라이브로 쪼개서 사용하는 것이 가상화의 개념이다.\n가상화의 종류 첫 번째 : 호스트 가상화(Host virtualization)\n두 번째 : 하이퍼 바이저 가상화(Hypervisor virtualization)\n세 번째 : OS level 가상화, 컨테이너 가상화\n출처: https://transferhwang.tistory.com/31\n첫 번째, Host virtualization(호스트 가상화) Host OS(기존에 깔려 있는 OS) 위에 Guest OS(설치할려는 OS)를 얹어서 사용하는 방식\nlayer 구성\nHW \u0026gt; Host OS(ex: Window) \u0026gt; Hypervisor (ex: VMware) \u0026gt; 가상 서버 #1, #2\u0026hellip;#N 가상서버는 다음과 같이 밑에서부터 구성된다.\n가상 서버 #1: guest OS(ex: linux) \u0026gt; Bins/libs \u0026gt; application A 가상 서버 #2: guest OS \u0026gt; Bins/libs \u0026gt; application B 장점: Host OS가 무엇이든지 상관없이 제약이 없다.\n단점: OS 위에 OS를 얹기 때문에 무거워서 느리다.\n두 번째, Hypervisor virtualization(하이퍼바이저 가상화) Host OS 없이 하드웨어 위에 바로 하이퍼바이저 설치\nlayer 구성\nHW \u0026gt; Hypervisor \u0026gt; 가상 서버 #1, #2, .., #N 가상 서버: guest OS \u0026gt; Bins/libs \u0026gt; application A 장점: Host OS가 존재하지 않으므로 가벼움\n단점: 머신 전체를 관리하기 위한 또 다른 PC 필요\n그래서 많이 사용하지 않는다.\n세 번째, Container virtualization(컨테이너 가상화): Docker Host OS 위에 컨테이너 관리 프로그램 설치\nlayer 구성\nHW \u0026gt; Host OS \u0026gt; Docker \u0026gt; Container #1, #2, \u0026hellip; , # N Container #1: Bins/libs \u0026gt; Application A application만 관리\n장점: 가볍고 빠르다.\n컨테이너가 없이 사용할 경우 문제점\nOS 위에 바로 장고를 설치하여 app을 배포한다면 OS에 따라서 달라지는 문제가 생긴다. 컨테이너 없이 배포를 한다면 계속해서 서비스를 유지해야 하기 때문에 다른 걸 하기 어렵다. 하나의 서버에 여러 서비스를 돌리면 위험한 이유\n서로 다른 서비스에게 반드시 영향을 줄 수 밖에 없다. 이 서비스를 삭제한다고 해도 흔적이 남기 때문이다. 하지만 도커를 사용해서 다음 것들이 가능해졌다.\n1번 컨테이너에 문제가 생겼으면 해당 컨테이너를 끄기만 하면 된다.(격리 isolation) 다른 container에 있는 것에 영향을 줄 수 없다. 옛날에는 하나의 EC2 마다 하나의 서비스를 배포했지만, 지금은 docker를 사용하면 하나의 EC2에서도 여러 개의 서비스를 배포할 수 있다. Docker는 Linux 환경에서만 동작한다 4. docker의 구조 docker engine의 구조 Persistent storage, Containerd, Networking\n도커의 구조는 매우 복잡하지만 크게 보면 3가지로 구분된다.\nPersistent Storage: 데이터 저장 공간\nContainerd: 만든 프로그램을 컨테이너 안에 담는 역할로, 도커 엔진 밖에 존재한다.\nNetworking: 컨테이너끼리의 통신 또는 컨테이너와 외부 간 통신하는 역할\ndocker의 구조 Client, Registry client: 사용하는 노트북 Registry: 도커 이미지 저장소 https://hub.docker.com/ 기본적으로 도커 허브에 있는 이미지를 찾도록 설정되어 있다. Docker hosts docker가 설치된 서버로서, 나는 ec2를 사용할 것이므로 EC2가 된다.\nDocker engine : 클라이언트-서버 역할을 수행\ndockered와 같은 DAEMON process가 실행되는 서버 dockerd에서 d는 daemon을 말한다. 도커 데몬과 의사소통하기 위한 API 역할 CLI client docker 도커 명령어를 dockered가 받아서 실행하는데, 이는 API를 호출하는 것이다. docker daemon : host에서 메모리에 상주(프로세스)하며 백그라운드에서 클라이언트의 요청에 따라 컨테이너를 관리하는 프로세스\n메모리에 상주하면서 클라이언트의 요청이 오면 즉시 대응할 수 있도록 대기 중인 프로세스 docker 사용자는 이 daemon과 통신하는 것 docker image : 도커 컨테이너를 실행하기 위해 필요한 모든 걸 모아놓은 패키지\n어떻게 인스턴스화되어야 하는지에 대한 내용 포함 실행 중인 도커 컨테이너의 특정 시점을 나타내는 가상 환경의 스냅샷 특정 시점: 나의 tool들을 설치한 시점 docker container : 실행 가능한 도커 이미지의 인스턴스\n다른 프로세스들과 완전히 분리된 하나의 프로세스 가상화된 런타임 환경 build, pull, run build : client로부터 직접 dockerfile를 image로 만드는 과정\n사람이란 개념(클래스)과 철수라는 구체적인 예시(인스턴스) image는 클래스 인스턴스의 개념에서 클래스 Container는 instance 하지만 build는 image까지만 만들어낼 수 있다. pull : Image를 만드는데, 내 컴퓨터에서 만드는 게 아닌 registry로부터 image를 만드는 과정\nrun : image로부터 container를 만드는 과정\nDocker host에 image가 없다면 자동적으로 pull을 실행한다. 실행한 컨테이너는 IP 주소를 가지는 하나의 독립된 서버처럼 동작한다. 각 컨테이너는 고유의 IP 주소와 포트 번호를 가진다. 컨테이너는 실행할 때마다 새로운 IP 주소를 가진다. 5. 컨테이너는 운영체제일까? 컨테이너는 해당 image를 실행하기 위한 최소 파일들이지, 운영체제가 아니다.\n위의 컨테이너 가상화 이미지를 보자.\nhost OS는 있지만, 컨테이너 안에는 OS가 없다.\n그러면 운영체제가 아닌데, 어떻게 우분투를 실행할 수 있을까?\n컨테이너의 최하단은 Bins/libs다.\n해당 image를 실행하기 위한 최소 파일들을 말한다.\n그래서 운영체제와 헷갈릴 수 있지만, 엄밀히 얘기하면 운영체제가 아니다.\nReference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/docker/02_what-is-docker/","summary":"첫 번째, PaaS란 무엇인지, 컨테이너 가상화란 무엇인지를 통해서 docker가 무엇인지 알아본다. 두 번째, docker의 build, pull, run은 무엇을 하는 건지 알아본다.","title":"What is a docker?"},{"categories":"Book Study","content":"0. Introduction 아래 book study는 알 스웨이가트가 지었고, 박재호님이 번역하신 클린 코드, 이제는 파이썬이다. 를 읽고 진행한 book study 입니다. 영문 원본으로 온라인 공개된 자료가 있어서 영문으로 학습합니다.\n기존에 읽었던 Clean Code는 자바 코드로 되어 있어서, 먼저 파이썬 클린 코드를 학습 후 시작할려고 합니다.\n이번 book study를 진행하면서 code에 대한 철학이 생기고, code를 바라보는 눈이 깊어지고, 넓어지기를 바랍니다.\n각 chapter를 읽고 내용 정리하는 식으로 진행합니다.\n이번 chapter의 주제는 \u0026lsquo;Chapter 04: Naming\u0026rsquo; 입니다.\n1. Concise and descriptive names 작명은 cs 지식과, 알고리즘과는 전혀 상관이 없지만, 가독성 있는 코드에서 중요한 부분을 차지한다.\n간결한 이름을 작명할 수 있지만, 이 코드가 무엇을 위해 만들어졌는지 설명되지 않는다.\n충분히 설명했지만, 간결하지 않은 이름도 있다.\n이 두 가지 조건을 만족하는 작명을 하기는 어렵다.\n그래서 이번 챕터에는 나쁜 이름은 피하고 좋은 이름을 선택할 수 있는 가이드 라인을 제공한다.\n2. Casing style: snake_case underscore 를 각 단어들 사이에 사용하는 작명법 모든 문자들은 소문자를 사용하나, 상수는 대문자로만 작성한다. ex) UPPER_SNAKE_CASE camelCase 첫 단어 이후로는 각 단어들의 첫 글자는 대문자로 작성하는 작명법 PascalCase 첫 단어부터 각 단어들의 첫 글자는 대문자로 작성하는 작명법 3. PEP 8’s Naming Conventions 영어 글자들은 악센트 표시를 하지 않는다. 모듈들의 이름은 짧고, 모두 소문자로 작명한다. 클래스 이름은 PascalCase로 작성 상수는 모두 대문자인 SNAKE_CASE로 작성한다. function, method 그리고 변수는 소문자 snake_case로 작성한다. 메서드의 첫 번째 인자인 self는 소문자로 작성한다. 클래스 메서드의 첫 번째 인자인 cls는 소문자로 작성한다. 클래스의 private 속성들은 1개의 underscore로 시작한다. 클래스의 public 속성들은 underscore로 시작하면 안된다. 개발자들은 위 사항들을 엄격히 따를 필요는 없다. 그래서 저자는 변수 이름을 snake_case로 작성하는 게 아닌 camelCase로 작성하고 있다. 4. Appropriate Name Length Too short names 작명할 때 가장 흔히들 하는 싫수가 바로 너무 짧은 작명이다.\n짧은 작명은 처음에는 이해가 될 지 몰라도 몇 일 뒤에는 그 의미를 잊은다.\n영문자 1개 또는 2개: g 생략된 단어: mon 무엇을 의미하는지 정확히 알 수 없다. 하나의 영어 단어 하지만 허용되는 몇 가지 경우가 있다.\n반복문의 i(index) 좌표계를 나타내는 x, y Too long names 변수명의 길이는 전역 범위인지 지역 범위인지에 따라서도 달라진다.\n매우 긴 코드의 경우, 많은 내용을 포함하기 때문에 예를 들어 한 단어만으로는 부족할 수 있다. 그러나, 지역 변수라면 충분할 수 있다.\nPrefixes in names 예를 들어서 Cat class 안에 속성으로 weight를 넣는다면 catWeight라고 할 필요가 없다. weight만 하면 된다.\n작명에 숫자는 사용하지 않는다. payment1, payment2 는 읽는 사람으로 하여끔 충분히 디테일한 정보를 전달하기 어렵다.\nMake names Searchable 너무 변수명이 짧으면 검색해도 원하는 결과를 얻기 어렵다.\n예를 들어서 ‘email’은 너무 짧기 때문에, ‘emailAddress’, ‘downloadEmailAttachment’, ‘emailMessage’, ‘replyAddress’ 로 리팩토링하자.\nAvoid jokes, puns, and cultural references 작명 시에, 조크나, 문화적인 배경들을 집어넣어 만들 수 있지만, 이는 뒤에 다른 사람이 봤을 때 이해하기가 어렵다.\n그래서 영어가 모국어가 아닌 사람들도 코드를 보고 쉽게 이해할 수 있도록 작성해야 한다.\nDon’t overwrite built-in names 파이썬의 내장 함수로 사용되는 이름들과, ‘data’ 는 사용하지 않는다.\nReference 클린 코드, 이제는 파이썬이다. ","permalink":"http://jeha00.github.io/post/bookstudy/pythoncleancode/chapter04_naming/","summary":"알 스웨이가트가 지었고, 박재호님이 번역하신  \u0026lsquo;클린코드, 이제는 파이썬이다\u0026rsquo;를 읽고 학습한 내용이다. 이번에는 naming에 대한 가이드 라인에 대해 학습해보자.","title":"클린 코드, 이제는 파이썬이다: naming"},{"categories":"Book Study","content":"0. Introduction 아래 book study는 알 스웨이가트가 지었고, 박재호님이 번역하신 클린 코드, 이제는 파이썬이다. 를 읽고 진행한 book study 입니다. 영문 원본으로 온라인 공개된 자료가 있어서 영문으로 학습합니다.\n기존에 읽었던 Clean Code는 자바 코드로 되어 있어서, 먼저 파이썬 클린 코드를 학습 후 시작할려고 합니다.\n이번 book study를 진행하면서 code에 대한 철학이 생기고, code를 바라보는 눈이 깊어지고, 넓어지기를 바랍니다.\n각 chapter를 읽고 내용 정리하는 식으로 진행합니다.\n이번 chapter의 주제는 \u0026lsquo;Chapter 03: CODE FORMATTING WITH BLACK\u0026rsquo; 입니다.\n1. Why we need ‘code formatting’ ? What is code formatting 여러 규칙들을 외적으로 소스 코드에 적용하는 걸 ‘code formatting’ 이라 한다.\nFirst reason: maintaining code 외적으로 소스 코드가 어떻게 보이는지는 컴퓨터에게 중요하지 않지만, 유지보수의 관점에서 중요하다.\n유지 보수의 관점에서 ‘가독성’은 중요하다. 이 가독성이 좋지 않아 다른 사람들이 이해하기 어렵다면 버그를 고치기도, 새로운 기능들을 추가하기도 어렵다. 즉, ‘code formatting’은 단지 외적인 이유에서만 그런 게 아니다.\nSecond reason: python’s critical reason 가독성은 파이썬 언어의 인기에 핵심적인 부분이기 때문에, 파이썬 언어를 사용하는 개발자에게는 ‘code formatting’ 은 필수다.\nAnd the solution is BLACK 포맷팅을 손쉽게 하는 방법 중 하나가 바로 ‘BLACK’이다.\n프로그램의 행동을 바꾸는 것 없이 자동적으로 포맷팅을 해주는 라이브러리다.\n2. An inconsistent mess due to non-formatting 입문자들은 언어의 문법과 프로그램 작동에만 신경쓰고 이 formatting 부분을 간과하는 면이 있어서, 각자 자신만의 스타일로 코드를 작성한다.\n만약 우리가 우리 자신만의 스타일로 코드를 작성하기 시작한다면 각 사람마다 작성하는 스타일이 달라서, 코드 작성 시 다른 사람의 코드를 각자 자신만의 스타일로 수정하는데 많은 시간이 할애될 것이다.\nThe answer about the mess is PEP8 (Python Enhancement Proposal 8)\n그래서 가독성 있는 코드를 작성하는데 쉬운 방법은 바로 ‘style guide’를 따르는 것이다.\n이 문서는 소프트웨어 프로젝트가 반드시 따라야만 하는 포맷팅 규칙들을 안내해준다.\n3. Spaces between a line: Horizontal spacing 한 라인에서 적용되는 간격 규칙들에 대해 알아보자.\n들여쓸 때, tab이 아닌 space를 사용하라 대부분 tab을 사용하여 들여쓰기를 한다. 하지만 BLACK을 사용하면 이 탭을 자동적으로 빈 문자열로 바꿔준다.\n연산자와 식별자 사이에 공백 하나 넣기 1 2 3 4 5 # good case blanks = blanks[:i] + secretword[i] + blanks[i + 1 :] # bad case blanks==blanks[:i]+secretWord[i]+blanks[i+1:] 쉼표(,) 앞이 아닌 뒤에 공백을 둡니다. 1 2 3 4 5 6 7 # good case def span(eggs, bacon, ham): weights = [42.0, 3.1415, 2.718] # bad case def span( eggs , bacon , ham ): weights = [42.0,3.1415,2.718] 마침표(.) 앞이나 뒤에 공백을 넣지 말기 1 2 3 4 5 # good case \u0026#39;Hello, world\u0026#39;.uppser() # base case \u0026#39;Hello, world\u0026#39; . upper() 함수, 메서드, 슬라이싱을 사용할 변수 이름 뒤에 공백을 넣지 말기 1 2 3 4 5 # good case print(\u0026#39;Hello, world!\u0026#39;) # bad case print (\u0026#39;Hello, World!\u0026#39;) 열린 괄호 후 또는 닫힌 괄호 전에 공백을 넣지 말기 1 2 3 4 5 6 7 # good case def span(eggs, bacon, ham): weights = [42.0, 3.1415, 2.718] # base case def span( eggs, bacon, hame ): weights = [ 42.0, 3.1415, 2.718 ] 줄 끝 주석 앞에 공백 두 개 넣기 1 2 3 4 5 6 7 8 # good case print(\u0026#39;Hello, world!\u0026#39;) # display a greeting # base case: space 1개 print(\u0026#39;Hello, world!\u0026#39;) # display a greeting # base case print(\u0026#39;Hello, world!\u0026#39;)#display a greeting 4. A space between lines: Vertical spacing 다른 줄 사이에서 적용되는 space 규칙들에 대해 알아보자.\nPEP 8는 함수들 간 구분은 2줄로, 클래스들 간 구분은 2줄로, 한 클래스 내의 메서드들 구분은 1줄로 하라고 명시한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # good case class ExampleClass: def exampleMethod1(): pass # 1줄 def exampleMethod2(): pass # 2줄 def exmampleFunction(): pass # base case class ExampleClass: def exampleMethod1(): pass def exampleMethod2(): pass def exmampleFunction(): pass 이외에 전역 변수 범위에서 나누는 것에 대해서 PEP8은 언급된 게 없지만, BLACK은 한 줄로 구분하고 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # good case def __call__(self, value): if not value or \u0026#39;@\u0026#39; not in value: raise ValidationError(self.message, code=self.code) user_part, domain_part = value.rsplit(\u0026#39;@\u0026#39;, 1) if (domain_part not in self.domain_whitelist and not self.validate_domain_part(domain_part)): try: domain_part = punycode(domain_part) except UnicodeError: pass else: if self.validate_domain_part(domain_part): return raise ValidationError(self.message, code=self.code) import 시에는 아래와 같은 우선순위로 묶으라고 권고하고 있다. 선택사항이다.\nmath, os, sys 같은 Python standard libary 안에 모듈들을 묶기 Django, Requests, Selenium 같은 써드 파트들 끼리 묶기 해당 프로그램의 지역 모듈들끼리 묶기 5. Install black: code formatter 1 2 # install black python3 -m pip install --user black 또는 특정 파일에 대해서만 실행해보기\n1 2 # yourScript.py에 대해 실행해보기 python3 -m black yourScript.py Black 실행 후, 변할 부분 미리 보기\n1 python3 -m black --diff yourScript.py Reference 클린 코드, 이제는 파이썬이다. ","permalink":"http://jeha00.github.io/post/bookstudy/pythoncleancode/chapter03_formatting./","summary":"알 스웨이가트가 지었고, 박재호님이 번역하신  \u0026lsquo;클린코드, 이제는 파이썬이다\u0026rsquo;를 읽고 학습한 내용이다. 이번에는 PEP8에서는 python code formatting을 어떤 방식으로 의무적으로 또는 권고하는지 알아보자. 마지막으로 code formatting을 위한 라이브러리인 black을 설치해본다.","title":"클린 코드, 이제는 파이썬이다: code formatting and black"},{"categories":"Project: Devket","content":"1. DOM 생성과 fetch function 사용을 위한 Javascript 학습 후기 1.1 새로운 언어의 학습 방법 선택하기 파이썬 언어를 학습한 후, 또 다른 프로그래밍 언어를 학습하는 건 처음이어서 파이썬을 학습했던 것처럼 똑같이 하면 될지 고민이 되었다. 만약 파이썬을 학습한 것처럼 파이썬 자체만을 깊이 파는 문법 강의를 통해서 한다면 짧은 프로젝트 기간을 고려하면 좋지 않다.\n고민 중에 이번 부트캠프에서 book study 시간에 읽었던 함께 자라기에서 본 내용이 문득 기억났다. 프로그래밍 언어는 도구임을 기억하여 바로 사용하고, 막히면 문법 내용으로 돌아오는 이 전환과 피드백이 빠를수록 학습이 빠르다고 했다. (독서를 할 때 단지 읽은 것에서 끝내지 않고, 정리하는 것과 함께 읽는 것이 필요하며 나에게 맞는 학습 방법임을 느낀 계기였다.)\n그래서 짧은 기간 안에 만들어야 하기 때문에 해외 유튜브에서 DOM을 자바스크립트로 생성하는 외국 엔지니어의 영상을 따라하며 이해했다. 그리고 바로 프로젝트에 적용했고, 그 과정에서 막히는 부분과 에러 부분은 MDN 문서로 바로 돌아와 놓친 부분을 빠르게 매꿔서 진행했다.\n그 결과가 다음과 같다. PR 날짜만을 보고 판단했을 때 event를 추가하는 것 없이 렌더링 부분만 대략 5일 정도 걸린 것으로 판단된다. 멘토링을 해줬던 멘토님이 처음 프로젝트를 진행하는데 이 속도로 진행한 건 많이 한 것이라는 평가를 들어서 기분이 좋았다.\nFEAT: Rendering mylist view and bottom-toolbar under each item #28 1.2 자발적으로 더 맡아서 진행하기 이 평가가 기분이 유독 좋았던 이유는 다음과 같다. 팀원들을 위해서 스스로 더 압박감을 느끼며 진행했지만, 그 결과 팀 전체 도움과 내 자신의 성장을 이끌 수 있었기 때문이다.\n이 화면단 개발은 우리 프로젝트에서 화면적으로 반드시 개발되어야하는 부분이었다. 하지만 각자 맡은 메인 기능들에 대해 완성된 후 위 이미지의 사이드바 부분을 나눠서 개발하기로 했기 때문에, 자신이 맡은 개발 기능들에 연구 개발을 하느라 팀원들은 시간을 할애하지 못하는 상황이었다.\n이런 상황에서 내 자신에게 도전적인 과제를 던져주기로 결정했다.\n첫 번째 이유 이런 결정을 한 첫 번째 이유는 프로젝트 기한을 고려했을 때 누군가가 더 맡아서 이 부분을 빠르게 구현한다면 프로젝트를 진행하는데 있어서 진행률이 많이 빨라지고, 다른 팀원들도 시각적으로 작동되는 게 보이기 때문에 프로젝트를 이해하고 개발하는데 도움이 될거라 판단했기 때문이다. 왜냐하면 위 이미지의 \u0026lsquo;내 목록\u0026rsquo;에 각 저장된 사이트들과 하단툴바가 나타나는 것처럼 사이드바 부분의 각 탭에서 나오는 방식이 다 동일하기 때문이다. 단지 ORM을 사용하여 filter로 가져오는 값들이 다를 뿐이다.\n두 번째 이유 또한, 전체 팀원 4명 중 개발 경험이 거의 없는 인원이 나 포함 3명이었기 때문에, 최악의 경우로 각자 맡은 기능들을 개발하다가 시간적인 여유가 없어서 이 부분을 개발하지 못하는 상황까지 고려했다.\n그래서 스스로 도전 과제를 주어 기한을 1주일 정도 정하여 내 자신에게 압박감을 주면서 진행했다. 그 결과, 기본적으로 저장된 사이트를 렌더링하는 DOM은 다 형성했다. 사이드 바에서는 즐겨찾기, 아티클, 동영상 부분의 ORM filter 부분을 짜서 끝냈다.\n1.3 DOM 학습 후기 처음 DOM을 조작하는 것이기 때문에, 저장된 사이트들을 목록에 보여주는 DOM을 생성하는 건 시간이 걸렸다. 그 이유는 진행한 프로젝트는 클론 코딩이기 때문에, html 구조와 css는 거의 그대로 사용하기 위해 html의 class name과 id name을 브라우저의 개발자 도구로 분석하며 가져오느라 오래 걸렸다.\n또한, html 구조와 css는 거의 그대로 사용할 것이기 때문에 class name이 직관적이지 않아도 가져온 이유다. 직접 수정할 수도 있겠지만, 이 프론트 영역까지 파고들고 싶지 않았으며 그 시간에 백엔드 구축에 집중하고 싶었다.\n이후에 \u0026lsquo;하단 툴바\u0026rsquo;와 modal 창을 렌더링할 때는 금방 DOM 생성 코드를 짤 수 있었다. 이후부터 DOM을 지정하고, 삭제하고, 수정하는 것에 어려움을 느끼지 못했다.\n하지만, React를 사용하지 않고 vanilla js로 다 하다보니 코드 길이가 많이 길어졌다. 하지만 React를 사용하면 손쉽게 생성된다고 한다. 프레임워크의 중요성을 느낀 계기가 되었다.\n1.4 fetch 함수 학습 및 사용 후기 Front와 Back 간의 흐름 이해 fetch 함수를 사용하기 전까지는 api를 통해서 프론트와 백엔드가 어떻게 통신을 하는지 코드적으로 이해할 수가 없었다. 즉, 눈에 보이지 않았다. 하지만 내가 구축한 api를 fetch를 사용해서 통신을 직접 해보니 확실히 이해할 수 있었다. 백엔드에서 구축한 api를 fetch를 사용하여 request를 보내면 django의 views.py의 view method(or function)에서 request로 받아 그 과정에서 짜놓은 로직에 따라서 CRUD 상황이 이뤄지고, response를 반환하면 fetch 함수에서 response로 그 결과 값을 반영할 수 있다. 이 response 값에 따라서 DOM 조작이 이뤄진다.\n그래서 Django가 MTV (Model - Template - View) pattern에서 View가 controller의 역할을 한다는 걸 느꼈다. Django의 MTV 는 기본적으로 MVC 패턴과 동일하다.\n출처: 루나의 TIL 기술 블로그\nMVC에 대응되는 MTV 설명은 Django - MVC 패턴과 MTV 패턴을 참조한다.\nfetch 학습 DOM을 익히면서 유튜브와 공식문서를 반복하여 개발하는 동안, 공식 문서로 빠르게 피드백을 받은 경험을 통해서 fetch 함수를 익힐 때는 유튜브 영상은 안보고 공식 문서와 stackoverflow만을 사용하여 작성할 수 있었다. 하지만 fetch의 경우 비동기적으로 작동하기 때문에 어려움이 있었다. 하지만 이 부분에 대해서도 글로 정리한다.\n2. DOM 렌더링 코드 작성 시 issue 사항 2.1 Custom 함수 만들어 팀 공용으로 사용하기 렌더링 시 자주 사용되는 함수들은 별도로 정의하여 코드 수를 줄이고, 보다 직관적으로 만들기 위해 노력했다. 그 이유는 React가 아닌 vanilla JS로 렌더링하는 것이기 때문에 코드 양이 상대적으로 매우 많아지기 때문이다. 계속해서 document.createElement를 사용해도 되겠지만, 이보다는 createNode 함수를 만들어서 보다 코드를 짧고 직관적으로 만들었다.\n아래 함수로 끝나는 것이 아닌 계속해서 추가했으며, common.js라는 이름의 별도 파일을 생성하여 앞으로 팀 공용으로 사용하면 좋은 함수들에 대해 PR 승인 후 합쳐서 같이 사용하는 방식으로 팀 방식을 진행했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 // common.js function createNode(tag) { /* tag를 생성하는 함수 */ return document.createElement(tag); } function appendTag(parent, element) { /* parent tag에 child tag를 추가하는 함수 */ return parent.appendChild(element); } 2.2 함수 기능 분리 크롤링으로 가져온 사이트들을 hover 시, 하단에 뜨는 툴바를 렌더링하는 함수다. 하단 툴바에는 즐겨찾기 기능, 카테고리 분류 기능, 태그 추가 기능, 삭제 기능이 있어서 이를 위한 태그 렌더링이 필요하다.\n처음에는 makeBottomToolbar function에 위 기능을 제공하는 태그 렌더링 코드를 다 작성했다.\n하지만, 코드의 길이가 너무 길어지고 내부 내용을 구분하기 어렵기 때문에, 다음과 같이 makeFavoriteInToolBar, makeCategoryInToolBar 등등 별도의 함수로 만들어서 makeBottomToolbar 를 통해 실행되도록 설계했다. 그리고 주석을 작성하여 다시 한번 구분했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 function makeBottomToolbar(parentNode) { /*각 사이트마다 하단 툴바를 만드는 함수*/ // bottom toolbar container - footer const footer = createNode(\u0026#39;footer\u0026#39;) footer.className = \u0026#39;footer\u0026#39; appendTag(parentNode, footer) const itemActionsContainer = createNode(\u0026#39;div\u0026#39;) itemActionsContainer.className = \u0026#39;i18uycg6 actions\u0026#39; appendTag(footer, itemActionsContainer) const itemActions = createNode(\u0026#39;div\u0026#39;) itemActions.className = \u0026#39;item-actions\u0026#39; appendTag(itemActionsContainer, itemActions) // bottom toolbar - favorite makeFavoriteInToolBar(itemActions) // bottom toolbar - category makeCategoryInToolBar(itemActions) // bottom toolbar - tag makeTagInToolBar(itemActions) // bottom toolbar - delete makeDeleteInToolBar(itemActions) } 2.3 렌더링 시 시간 복잡도 고려 issue 각 저장된 사이트(post)를 내 목록에 렌더링할 때, 전체 항목을 렌더링하고 나서 각 항목에 하단 툴바를 렌더링했다. 즉 크롤링해서 가져온 사이트들을 먼저 각각 렌더링 후, 각 사이트마다 하단툴바를 렌더링을 시도했다.\n실행결과를 보면서 이럴 경우 저장된 사이트의 수 만큼 다시 또 반복하는 것이기 때문에, 파이썬으로 생각하자면 for문을 두 번 돌리는 것과 동일하다고 판단하여 시간 복잡도가 O(2n)이 되므로, 각 항목을 렌더링할 때 하단 툴바도 같이 렌더링하여 O(n)이 되도록 수정했다. 또한, 현재는 DB에 저장된 사이트 수가 적어서 문제가 없겠지만, 저장된 데이터량이 많아진다면 렌더링 속도에 가시적으로 영향을 줄 거라 판단했기 때문이다.\n그래서 다음 아래와 같이 renderItem function에 makeBottomToolbar function을 포함시켰다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 function renderItem(post) { /* 각 post의 tag를 rendering 하는 함수 */ const article = createNode(\u0026#39;article\u0026#39;) article.className = \u0026#39;c18o9ext grid hiddenActions noExcerpt\u0026#39; appendTag(root, article) const item = createNode(\u0026#39;div\u0026#39;) item.className = \u0026#39;cardWrap\u0026#39; appendTag(article, item) ... // 각 항목(item)의 하단 툴바 makeBottomToolbar(article) } 2.4 svg icon이 인식되지 않는 문제 문제점 [Pull requests]\nEdit html about premium, mylist and Refactor bottom-toolbar.js #51 Rendering mylist view and bottom-toolbar under each item #28 각 항목에 mouse를 hover 시, 하단에 뜨는 하단 툴바를 만들기 위해서 DOM을 생성하는 과정에서 부딪힌 문제점이다. svg icon을 사용하기 위해서 \u0026lt;svg\u0026gt; node를 생성해야 하는데, 생성되지 못한 문제점이 있었다.\n프로젝트의 클론 코딩 대상 사이트는 아이콘을 \u0026lt;i\u0026gt; tag보다 \u0026lt;svg\u0026gt;\u0026lt;path d=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/path\u0026gt;\u0026lt;/svg\u0026gt; 를 사용한다. 그래서 다른 태그를 생성하는 것과 동일한 방식을 사용했다.\ncreateNode와 appendTag function을 사용하여 svg tag와 path tag를 생성 .className을 사용하여 class name을 추가 속성명에 -가 있는 건 dot annotation으로 추가 못하기 때문에 setAttribute() 사용 하지만 아이콘이 브라우저에 형성되지 않는 문제를 발견했다. 클론 코딩 대상의 프로젝트 tag 속성을 개발자 도구로 분석하면서 관련 속성들을 하나씩 지워보고, 순서도 바꿔보고, 새로운 html을 생성하여 해당 태그들만 추가해보고, stackoverflow와 여러 구글링을 통해 피드백 받은 방안들을 적용해봤지만 svg icon이 형성되지 않았다.\n이 문제로 2~3일을 소비했기 때문에, 임시로 i tag를 사용하기로 결정하여, fontawesome site를 선택하여 유사한 icon을 선택하여 사용했다.\n마지막으로, 팀원들이 이 시행착오를 겪지 않도록 하기 위해 코드 리뷰 시간에 공유했다.\n해결책 다른 팀원 또한 렌더링하는 과정에서 svg icon 문제에 똑같이 부딪혔고, 내가 공유한 과정들을 통해 다른 방식을 적용하여 문제를 해결했다.\n해결한 방법은 setAttribute로 하면 인식되지 않았지만 html를 통채로 입력하니 가능했다.\n이 때 변수를 insertAdjacentHTML을 사용한 이유는 다음과 같다.\nclassName과 속성들을 별도로 입력하는 방식이 작동되지 않기 때문에, 통째로 입력하는 방법을 선택했다. 그래서 HTML을 통째로 원하는 DOM tree 안에 node들을 추가하기 위해 함수 \u0026lsquo;insertAdjacentHTML\u0026rsquo; 를 사용했다.\n사용 방식은 element.insertAdjacentHTML(position, text)와 같다. 이 함수의 사용 방법 출처는 MDN - Element.insertAdjacentHTML()을 참고했다.\n\u0026rsquo;text\u0026rsquo;에 들어갈 svg를 담은 변수를 let으로 선언한 이유는 재정의할 수도 있기 때문이다. 클론 코딩의 상단 툴바의 경우 아이콘이 변하는 경우가 있어서 let으로 선언했지만, 하단 툴바의 경우에는 그렇지 않기 때문에 아래 코드의 let은 const로 수정해야하는 부분이다.\nlet \u0026amp; const\n재선언 재할당 let X O const X X position\nposition 설명 beforebegin element 앞에 afterbegin element 안에 가장 첫번째 chid beforeend element 안에 가장 마지막 child afterend element 뒤에 클론 코딩의 대상 사이트의 svg DOM 구조가 다음과 같았다.\n1 2 3 4 5 \u0026lt;span\u0026gt; \u0026lt;svg\u0026gt; \u0026lt;path\u0026gt;\u0026lt;/path\u0026gt; \u0026lt;/svg\u0026gt; \u0026lt;/span\u0026gt; 그래서 favoriteIconContainer이 \u0026lt;span\u0026gt;에 \u0026lt;svg\u0026gt;가 들어가기 위해서 favoriteIconContainer.insertAdjacentHTML('beforeend', favoriteIconSvgHTML)을 한 후, \u0026lt;svg\u0026gt; 안에 \u0026lt;path\u0026gt;를 넣기 위해서 favoriteIconSvg.insertAdjacentHTML('beforeend', favoriteIconPathHTML)으로 작성했다.\n여기서 beforeend를 선택한 이유는 \u0026lt;path\u0026gt;의 경우, svg icon의 종류에 따라서 복수로 존재하기도 했다. 그래서 \u0026lt;path\u0026gt; tag 순서를 작성한대로 순서를 원래의 것과 유지하여 직관적으로 순서를 바로 확인할 수 있도록 이를 사용했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 const favoriteButton = createNode(\u0026#39;button\u0026#39;) ... const favoriteIconContainer = createNode(\u0026#39;span\u0026#39;) favoriteIconContainer.className = \u0026#39;i1qqph0t icon\u0026#39; appendTag(favoriteButton, favoriteIconContainer) let favoriteIconSvgHTML = `\u0026lt;svg class=\u0026#39;favorite-icon-svg\u0026#39; fill=\u0026#34;currentColor\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34;aria-hidden=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;/svg\u0026gt;` favoriteIconContainer.insertAdjacentHTML(\u0026#39;beforeend\u0026#39;, favoriteIconSvgHTML) const favoriteIconSvg = getElement(\u0026#39;.favorite-icon-svg\u0026#39;) let favoriteIconPathHTML = \u0026#39;\u0026lt;path fill-rule=\u0026#34;evenodd\u0026#34; clip-rule=\u0026#34;evenodd\u0026#34; d=\u0026#34;M12 1a1 1 0 0 1 ... 1-.753-.548L12 4.26Z\u0026#34;\u0026gt;\u0026lt;/path\u0026gt;\u0026#39; favoriteIconSvg.insertAdjacentHTML(\u0026#39;beforeend\u0026#39;, favoriteIconPathHTML) ❗️ let을 const로 수정하기\n2.5 Modal 창을 통한 삭제 기능 issue 발생된 issue [Pull requests]\nModifiy api-url and add delete function by bottom-toolbar #42 [Issue 배경]\n저장된 사이트의 하단 툴바 삭제 기능을 클릭하여, 모달 창이 뜨면 이 모달 창으로 삭제를 진행하는 방식으로 개발했다. 모달 창을 통해서 삭제를 진행하는 이유는 삭제하면 이 사이트 저장을 되돌릴 수 없기 때문에, 경고를 하는 게 유저 편의성을 높이는 방향이라고 생각했기 때문이다.\n[발생된 issue]\n한 사이트의 하단 툴바 삭제 아이콘을 클릭하여 모달 창의 삭제버튼으로 삭제를 진행할 때, 하단툴바가 달려있던 한 사이트만 삭제가 되야하는데 저장된 모든 사이트가 다 삭제되는 이슈가 발생했다.\nissue 발생했을 때 삭제 기능 함수 호출 순서 원인 코드와 해결과정을 작성하기에 앞서 먼저 하단 툴바의 삭제 버튼을 클릭하여, 모달창이 띄어지고, 삭제를 실행하는 전체 흐름 함수를 확인해보자.\n저장된 사이트(site)의 정보를 토대로 목록에 렌더링하는 함수인 renderItem(site) 에서 시작된다.\nrenderItem(site) -\u0026gt; makeBottomToolbar(, site) -\u0026gt; makeDeleteInToolBar(, site) -\u0026gt; openModal() -\u0026gt; Modal 창 오픈\nmakeModal() -\u0026gt; deleteSite() -\u0026gt; closeModal -\u0026gt; window.location.reload()\nmakeModal에 의해서 모달창은 브라우저 창이 load 시, 기본적으로 만들어지지만 화면에 나타나지 않도록 설계했다. 미리 만든 이유는 기본적으로 만들어서 있는 게 버튼을 클릭 이벤트 때마다 렌더링하는 것보다 속도가 빠르다고 생각했기 때문이다. 그래서 openModal()은 기존 class와 tag에 class name을 추가하여 모달창이 보이도록 한다.\n또한, makeModal()을 makeDeleteInToolBar() 안에 넣을 수 없는 이유는 모달창은 1개만 필요하기 떄문이다. 만약 makeDeleteInToolBar 안에서 makeModal이 호출된다면 저장된 사이트 수만큼 하단 툴바가 생성되고, 그만큼 모달창이 생성된다.\n원인 저장된 사이트들을 화면에 렌더링할 때 태그 속성을 식별자로 만들기 위해서 태그 속성 id의 값으로 각 site의 DB에 저장된 id 값으로 정했다.\n❗️ 태그 속성 id의 값으로 db의 id 값을 입력한 것은 보안적으로 좋지 않기 때문에, 프로젝트 완성을 위해 다시 개발할 때 수정할 예정이다.\n리액트의 경우, 자동적으로 이 태그들을 구분하기 때문에 식별자가 필요하다고 한다. 하지만 우리는 바닐라 js로 하기 때문에 필요했다.\n하지만 모달 창을 통해 삭제할 때 이 모든 site의 id를 가져오기 때문에 발생된 issuse다. 식별을 위해서 입력했지만, 정작 코드 상 식별의 역할을 하지 못했다.\n해결 과정 이 issue를 해결하는 초기 과정에서는 무엇이 원인인지 알 수 없어서, 다음과 같이 views.py의 해당 method를 print 문을 통해서 확인해보았다.\n1 2 3 4 5 6 7 8 9 10 def delete(self, request, pk): site = self.get_object(pk) print(f\u0026#39;before delete site: {site}\u0026#39;) site.delete() print(f\u0026#39;after delete site: {site}\u0026#39;) return Response({\u0026#39;msg\u0026#39;: \u0026#39;Deleted successfully\u0026#39;}, status=status.HTTP_200_OK) 실행한 결과 터미널에서 모든 항목들이 하나씩 하나씩 출력되었다. 의도치 않게 자바스크립트에서 전체 사이트들이 포함된 배열로 보내져서 이것이 하나씩 삭제되는 건가 추측했지만, 터미널의 결과를 보니 그렇지 않았다. 한 항목의 하단 툴바 삭제 기능을 눌러 실행한 것이지만, 각 항목의 하단 툴바 삭제 버튼을 모든 항목에 대해서 클릭하여 일어난 것과 동일한 결과이기 때문이다.\n1 2 before delete site: .... before delete site: .... 그래서 이번에는 javascript 함수인 makeDeleteInToolBar, makeModalActive, deleteSite 에 각각 console.log(site) 를 입력하여 브라우저 콘솔 창에 확인하니 삭제 버튼을 실행하지 않아도 위 각 함수에서 모든 항목이 출력되는 걸 확인했다. 이는 js 문제이며 식별자 문제임을 확인했다.\n만약 리액트로 이를 구현했다면, 리액트에서는 각 항목들을 구분하는 별도의 값을 자동적으로 만들어주기 때문에 이런 문제에 부딪히지 않는다고 멘토님을 통해 확인했다.\n그래서 각 항목들을 확실하게 구별할 수 있는 식별자를 만들어, 이 식별자에 접근하여 삭제하는 방식을 권하셨다. 이에 대한 구체적인 방안으로 각 항목의 하단 툴바 삭제 버튼을 클릭하면 해당 항목의 class에 selected 를 추가한다.\n1 2 3 4 5 6 7 8 9 10 function makeDeleteInToolBar() { deleteButton.addEventListener(\u0026#39;click\u0026#39;, () =\u0026gt; { const article = document.getElementById(`${site.id}`) // 추가 article.classList.add(\u0026#39;selected\u0026#39;) openModal(deleteButton) })} 그리고 selected가 클래스 값에 있는 태그를 가져와, 이 태그의 id 값을 fetch에 입력하여 view 단에 보내는 흐름으로 구성했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 function deleteSite() { /* DELETE http message를 보내는 함수 */ const site = getElement(\u0026#39;.c18o9ext.grid.hiddenActions.noExcerpt.selected\u0026#39;) const csrftoken = getCookie(\u0026#39;csrftoken\u0026#39;); const data = { method: \u0026#39;DELETE\u0026#39;, headers: { \u0026#39;content-type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;X-CSRFToken\u0026#39; : csrftoken, }, } fetch(`/api/sites/${site.id}`, data) .then(response =\u0026gt; { const status = response.status if (status === 200) { console.log(\u0026#39;삭제 완료했습니다.\u0026#39;) } else if (status === 404) { console.log(\u0026#39;해당 항목이 존재하지 않습니다.\u0026#39;) } return response.json() }) .catch(error =\u0026gt; console.log(\u0026#39;Error:\u0026#39;, error)) } 삭제 후, 화면을 다시 불러오기 위해서 window.location.reload()를 사용한다.\n최종 호출 순서 문제 상황을 해결하고, 다른 팀원들도 공통으로 사용할 수 있도록 모달창을 모듈화한 최종 함수 호출 흐름은 다음과 같다.\nissue 발생 시 함수 호출 흐름: renderItem(site) -\u0026gt; makeBottomToolbar(, site) -\u0026gt; makeDeleteInToolBar(, site) -\u0026gt;\n최종 함수 호출 흐름: renderItem(site) -\u0026gt; makeBottomToolbar(, site) -\u0026gt; makeDeleteInToolBar(, site) -\u0026gt; openModal(param) -\u0026gt; makeModal(param) -\u0026gt; deleteSite()\n내가 코드를 작성했을 때 모달창 렌더링은 하단 툴바에서만 사용하는 경고 텍스트, 버튼 이름이었지만, 이를 상단 툴바나 이외의 곳에서 팀원들이 같이 사용하기 위해서 팀원들 모두 동의 하에 모듈화를 진행했다. 그래서 param의 역할은 모듈로 사용되기 위해서 다음과 같이 만들어진 객체다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 하단 툴바의 모달창 Parameter let modalParam = { func : deleteSite, type : \u0026#39;bottom\u0026#39;, alarm_txt : `이 항목을 삭제하겠습니까? 삭제한 항목은 복원할 수 없습니다.`, title : \u0026#39;항목 삭제\u0026#39;, buttonName : \u0026#39;삭제\u0026#39;, args : \u0026#39;\u0026#39;, } // 상단 툴바의 즐겨찾기 추가 복수 작업 let modalParam = { func : bulkFavorite, type : \u0026#39;bulk\u0026#39;, alarm_txt : alarm_txt, title : \u0026#39;선택 항목 즐겨찾기\u0026#39;, buttonName : \u0026#39;추가\u0026#39;, args : favorite, } 또한, 추가로 article.classList.add('selected') 였지만 코드 리뷰 시간에 .toggle()이란 걸 사용하면 없으면 추가하고, 있으면 빼는 작업을 자동적으로 해주는 걸 알게되어 article.classList.toggle('selected')로 수정했다.\n2.6 Document.querySelector() issue 발생된 issue 와 원인 코드 첫 번째 article tag에 저장된 모든 사이트 수만큼 svg, path tag가 다 들어간 상황\n아래 첫 번째 article tag의 하단 툴바 svg tag에 저장된 사이트의 갯수만큼 path 태그가 추가되어, 다른 항목들의 하단 툴바 이미지 아이콘이 보이지 않는 문제가 발생했다.\n아래 이미지는 두 항목 모두 hover 된 상태이지만, 첫 번째에만 하단툴바 아이콘 이미지가 뜨고 있다.\n즐겨찾기 만드는 함수 외에 카테고리 함수, 태그 함수, 삭제 함수 모두 다 발생된 문제이지만 예로서 즐겨찾기만 가져왔다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 function makeFavoriteInToolBar(parentNode, site) { /* 하단 툴바의 즐겨찾기 버튼 Dom을 만드는 함수 - 특정 문자열로 className에 할당되는 값들은 클론코딩으로 가져오는 css를 반영하기 위한 것입니다. */ const favoriteButtonContainer = createNode(\u0026#39;span\u0026#39;) appendTag(parentNode, favoriteButtonContainer) const favoriteButton = createNode(\u0026#39;button\u0026#39;) favoriteButton.className = site.favorite == false ? \u0026#39;m11fpiro t1221eea pmdugmx d1mp5exd favorite\u0026#39; : \u0026#39;m11fpiro t1221eea pmdugmx d1mp5exd favorite active\u0026#39; favoriteButton.setAttribute(\u0026#39;data-tooltip\u0026#39;, site.favorite == false ? \u0026#39;즐겨찾기\u0026#39; : \u0026#39;즐겨찾기 해제\u0026#39;) appendTag(favoriteButtonContainer, favoriteButton) const favoriteIconContainer = createNode(\u0026#39;span\u0026#39;) favoriteIconContainer.className = \u0026#39;i1qqph0t icon\u0026#39; appendTag(favoriteButton, favoriteIconContainer) let favoriteIconSvgHTML = `\u0026lt;svg class=\u0026#39;favorite-icon-svg\u0026#39; fill=\u0026#34;currentColor\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34;aria-hidden=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;/svg\u0026gt;` favoriteIconContainer.insertAdjacentHTML(\u0026#39;beforeend\u0026#39;, favoriteIconSvgHTML) // issue가 발생된 원인 const favoriteIconSvg = getElement(\u0026#39;.favorite-icon-svg\u0026#39;) let favoriteIconPathHTML = \u0026#39;\u0026lt;path fill-rule=\u0026#34;evenodd\u0026#34; clip-rule=\u0026#34;evenodd\u0026#34; d=\u0026#34;M12 1a1 1 0 0 1 .897.557l2.706 5.484 6.051.88a1 1 0 0 1 .555 1.705l-4.38 4.268 1.034 6.027a1 1 0 0 1-1.45 1.054L12 18.13l-5.413 2.845a1 1 0 0 1-1.45-1.054l1.033-6.027-4.379-4.268a1 1 0 0 1 .555-1.706l6.051-.88 2.706-5.483A1 1 0 0 1 12 1Zm0 3.26L9.958 8.397a1 1 0 0 1-.753.548l-4.567.663 3.305 3.221a1 1 0 0 1 .287.885l-.78 4.548 4.085-2.147a1 1 0 0 1 .93 0l4.085 2.147-.78-4.548a1 1 0 0 1 .287-.885l3.305-3.22-4.567-.664a1 1 0 0 1-.753-.548L12 4.26Z\u0026#34;\u0026gt;\u0026lt;/path\u0026gt;\u0026#39; favoriteIconSvg.insertAdjacentHTML(\u0026#39;beforeend\u0026#39;, favoriteIconPathHTML) changeFavoriteValue(favoriteButton, site) } 위 코드에서 getElement function이 문제의 원인이다. 이 function은 공통으로 사용하고자 custom function이다.\n1 2 3 4 5 function getElement(elemVal) { /* 단일 요소 가져오는 함수 */ return document.querySelector(elemVal); } 이 함수를 사용했지만 해당 issue를 확인하지 못 했던 이유는 그 당시 내 목록에 추가했던 항목이 1개 밖에 없었기 때문이다. 팀원한테 이 issue를 듣고서 해결하기 시작했다.\nquerySelector 는 전체 document에서 해당되는 태그들 중 첫 번째를 가져오기 때문에 발생한 이슈였다. getElement를 사용할 때 공식문서를 확인했지만, 놓친 부분이 있었던 것이다. 이는 Document.querySelector()의 설명 부분을 보니 알 수 있었다.\n해결과정 그래서 아래 2가지 방법을 생각해냈다.\ndocument.querySelector() 에서 document의 범위를 좁히기 getElement() 의 매개변수에 들어가는 부분을 보다 정확하게 타겟팅하기 만약 첫 번째 방법을 사용한다면 만든 getElement를 사용할 수가 없어서 통일성이 깨지기 때문에, 먼저 getElement를 사용하는 방향을 선택했다.\n1 2 3 4 5 6 7 8 9 10 11 function getElement(elemVal) { /* 단일 요소 가져오는 함수 */ return document.querySelector(elemVal); } function makeFavoriteInToolBar(parentNode, site) { ... const favoriteIconSvg = getElement(\u0026#39;.favorite-icon-svg\u0026#39;) ... } site.id를 id 값으로 입력한 이유는 저장한 각 항목들을 구분하기 위한 식별자로 각 사이트를 렌더링할 때마다 속성값으로 입력했기 때문이다.\nReact라면 각각의 식별자가 자동적으로 추가된다고 하지만, vanilla JS를 사용했기 때문에 수동적으로 입력하는 게 필요했다. 그래서 아래 코드로 수정해서 화면을 확인하니 console에 입력한 id값은 타당하지 않은 선택자라고 한다.\n1 2 3 4 5 // 변경 전 const favoriteIconSvg = getElement(\u0026#39;.favorite-icon-svg\u0026#39;) // 변경 후 const favoriteIconSvg = getElement(`\u0026#39;#${site.id}\u0026#39; .favorite-icon-svg`) 그래서 getElementById로 가져올 수도 있지만, 코드 통일성을 위해서 getElement는 사용하지 못 해도 querySelector를 사용하는 게 낫다는 판단으로 두 번째 방법은 사용하지 않고 첫 번째 방법으로 사용하기로 했다.\nsvg tag의 상위 태그인 span tag를 Container로 명명하여 document 대신에 이 컨테이너를 사용하여 범위를 좁혀서 접근하는 방식으로 해결했다.\n1 2 3 4 5 6 7 8 9 const favoriteIconContainer = createNode(\u0026#39;span\u0026#39;) favoriteIconContainer.className = \u0026#39;i1qqph0t icon\u0026#39; appendTag(favoriteButton, favoriteIconContainer) let favoriteIconSvgHTML = `\u0026lt;svg class=\u0026#39;favorite-icon-svg\u0026#39; fill=\u0026#34;currentColor\u0026#34; viewBox=\u0026#34;0 0 24 24\u0026#34; xmlns=\u0026#34;http://www.w3.org/2000/svg\u0026#34;aria-hidden=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;/svg\u0026gt;` favoriteIconContainer.insertAdjacentHTML(\u0026#39;beforeend\u0026#39;, favoriteIconSvgHTML) // 수정된 부분 const favoriteIconSvg = favoriteIconContainer.querySelector(\u0026#39;.favorite-icon-svg\u0026#39;) 그 결과, 다음 이미지와 같이 하단 툴바가 몰리는 issue를 해결할 수 있었다.\n3. Fetch 함수 사용 시 issue 사항 3.1 Custom 함수 만들어 팀 공용으로 사용하기 DOM rendering을 위해 커스텀 함수를 만든 것처럼 fetch 함수의 두 번째 인자로 보낼 HTTP message를 그 때 그 때마다 다 작성하는 건 효율적이지 못하다고 판단하여 method와 Http body에 담을 data를 인자로 받는 setFetchData를 작성했다. 여기서 content-type을 application/json으로 정한 이유는 MDN을 통해 iana을 들어가니 위 content-type에 대한 설명이 있었고, 구글링을 해도 application에서 json 타입으로 데이터를 주고 받을 때는 content-type에 위 형식을 사용한다고 나와서 이 방식으로 선택했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ... function setFetchData(method, body){ /* Fetch data 셋팅 */ let csrftoken = getCookie(\u0026#39;csrftoken\u0026#39;); const data = { method: method, headers: { \u0026#39;content-type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;X-CSRFToken\u0026#39; : csrftoken, }, body: JSON.stringify(body) } return data } 3.2 아임포트 Javascript SDK에 fetch 사용하기 아임포트 결제 연동 서비스를 사용하기 위해서는 아임포트 Javascript SDK(Software Development Kit)를 사용해야 한다. 이 SDK를 통해서 내가 생성한 주문번호와 금액을 아임포트에 전달하고, 아임포트는 결제 번호를 나에게 전달한다.\n그래서 이 SDK를 통해 결제 각 단계에서의 데이터 처리를 js function을 통해서 django의 view로 전달하고, DB에 결제 상태와 정보를 저장한다. 그리고, django의 view에 전달하기 위해서 fetch를 사용했다.\n🔆 아임포트 Javascript SDK는 정확하게는 Ajax 문법으로 작성되어 있다. 구글링을 해도 SDK에 사용되는 function을 Ajax로 작성되어 있어서 javascript만 알고 있기 때문에, 이를 function은 js로 다 바꾸고, IMP.request_pay 부분은 다른 아임포트 라이브러리 ajax파일을 호출하기 때문에, 이 부분을 제외한 나머지 부분들도 js로 바꿨다.\n🔆 이 문서에서는 Javascript SDK와의 전체적인 흐름이 아닌 fetch 함수의 비동기적 특징에 대해서만 다룬다.\n아임포트 Javascript SDK를 사용한 결제 흐름 발생된 issue와 원인 코드 아래 코드에 나와있다시피 결제 금액과 결제 방식을 입력받은 함수가 주문 번호(merchant_id)를 반환하는 함수 과정에서 11번째 줄에는 merchant_id가 확인되지만, 15번째줄 console.log(result)에서는 merchant_id가 확인되지 않는 issue가 있었다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // IMP.request_pay를 호출하기 위한 merchant_id 반환 function passMerchantId(e, amount, type) { e.preventDefault(); const data = setFetchData(\u0026#39;POST\u0026#39;, { amount: amount, type: type, }) const result = fetch(`/api/payment/checkout`, data) .then(response =\u0026gt; response.json()) .then(result =\u0026gt; { console.log(result.merchant_id) //58b9dea713 merchant_id = result.merchant_id return merchant_id }).catch(err =\u0026gt; alert(`${err}`)) console.log(result) // \u0026#39;\u0026#39; return result } 그래서 아임포트 IMP.request_pay()에 주문번호가 undefined로 전달되어 결제가 실패했다. 이를 방지하고자 아래와 같이 merchant_id !== undefined 또는 merchand_id !== '' 를 했지만, 올바른 값이 아니기 때문에 결제가 진행되지 못 했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 import {getElement ,setFetchData} from \u0026#39;./common.js\u0026#39;; window.onload = function () { const IMP = window.IMP; IMP.init(\u0026#39;imp62676076\u0026#39;); const paymentButton = getElement(\u0026#39;.order\u0026#39;) paymentButton.addEventListener(\u0026#39;click\u0026#39;, (e) =\u0026gt; { ... const merchant_id = passMerchantId(e, amount, type); if (merchant_id !== \u0026#39;\u0026#39; \u0026amp;\u0026amp; merchant_id !== undefined) { IMP.request_pay({ pg: \u0026#39;html5_inicis\u0026#39;, merchant_uid: merchant_id, name: \u0026#39;Devket Premium 서비스\u0026#39;, pay_method: \u0026#39;card\u0026#39;, amount: amount, }, // 결제창 오픈 function (response) { // 결제한 유저의 이름과 이메일 확인하고 결제 버튼 누른 후, 진행되는 로직 if (response.success) { ... } else { ... } }); } return false; }) }; 해결과정 [첫 번째 고려사항: Scope 상의 문제]\nfetch의 기본적인 사용법과 scope 극복을 참고하여 다음 코드와 같이 fetch scope 외부에 merchant_id를 선언했고, 값이 재할당 되기 때문에 let을 사용했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // IMP.request_pay를 호출하기 위한 merchant_id 반환 function passMerchantId(e, amount, type) { e.preventDefault(); // 추가된 코드 let merchant_id = \u0026#39;\u0026#39; const data = setFetchData(\u0026#39;POST\u0026#39;, { amount: amount, type: type, }) const result = fetch(`/api/payment/checkout`, data) .then(response =\u0026gt; response.json()) .then(result =\u0026gt; { console.log(result.merchant_id) //58b9dea713 merchant_id = result.merchant_id return merchant_id }).catch(err =\u0026gt; alert(`${err}`)) console.log(result) // \u0026#39;\u0026#39; return result } 하지만, 그럼에도 결과는 동일했다.\n[두 번째 고려사항: 비동기]\nJavaScript - 자바스크립트 fetch와 async/await 블로그에 따르면 merchant_id 값이 다르게 출력되는 이유는 fetch가 비동기로 작동하기 때문이다. 이전 작업이 완료될 때까지 기다리지 않고, 따로 처리하며 다른 코드들도 먼저 실행할 수 있도록 하는 작업 이다. 그러므로 fetch 밖에 정의한 merchant_id에는 할당되지 않는 상황인 순서가 정확히 보장되지 못하는 상황 에 처할 수 있다.\n그래서 순서를 보장받고자 async와 await을 사용한다.\nawait은 MDN - await에 따르면 Promise 객체를 리턴하는 부분 앞에만 작성될 수 있고, await 연산자는 async function 내부에서만 사용할 수 있다고 하여 다음과 같이 async와 await을 추가했다. 왜냐하면 Promise가 await 연산자에 넘겨지면, await은 Promise가 완전히 실행되기를 기다렸다가 해당 값을 반환하기 때문이다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // async 추가 async function passMerchantId(e, amount, type) { e.preventDefault(); let merchant_id = \u0026#39;\u0026#39; const data = setFetchData(\u0026#39;POST\u0026#39;, { amount: amount, type: type, }) // await 추가 await fetch(`/api/payment/checkout`, data) .then(response =\u0026gt; { const result = response.json(); if (response.status === 200) { console.log(\u0026#39;result.mechant_id: \u0026#39;, result.merchant_id) merchant_id = result.merchant_id } else if (response.status === 401) { alert(\u0026#39;로그인 해주세요.\u0026#39;) } else { alert(\u0026#39;문제가 발생했습니다. 다시 시도해주세요.\u0026#39;) } }) return merchant_id }; 하지만 그럼에도 merchant_id는 빈 값으로 반환되었다.\n[세 번째 고려사항: 정확한 사용방법이 맞는가?]\nMDN - await와 위 블로그들을 보면서 await과 then을 같이 사용하는 코드를 발견하지 못하여 이에 대해 구글링을 했다.\n구글링을 하는 과정에서 async/ await 사용방법 (feat. then과 함께 쓰기), Promise 정리: async/await 사용법 \u0026amp; then과의 차이 문서뿐만 아니라 여러 문서들을 보면서 잘못된 방식으로 사용했다는 걸 알았다. 또한, 프로젝트 멘토님도 then과 await은 같이 사용하는 게 아니라는 의견을 주셨다.\n그래서 then을 사용하지 않고 const로 변수를 선언하여 사용하기로 했다. result.works는 아임포트에서 success, fail를 판단할 때 사용하는 변수이기 때문에 그 외 함수 분기처리에도 사용하는 게 통일성 있는 방식으로 생각하여 아래와 같이 선택했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // IMP.request_pay를 호출하기 위한 merchant_id 반환 async function passMerchantId(e, amount, type) { e.preventDefault(); let merchant_id = \u0026#39;\u0026#39; const data = setFetchData(\u0026#39;POST\u0026#39;, { amount: amount, type: type, }) const response = await fetch(`/api/payment/checkout`, data) const result = await response.json() if (result.works) { merchant_id = result.merchant_id console.log(\u0026#39;merchant_id after then:\u0026#39;, merchant_id) return merchant_id } else if (result.status === 401) { alert(\u0026#39;로그인 해주세요.\u0026#39;) } else { alert(\u0026#39;문제가 발생했습니다. 다시 시도해주세요.\u0026#39;) } }; Javascript Promise 배경부터 then catch 그리고 async await까지 문서 뿐만 아니라 여러 문서들에서 보면 then ~ catch 이후에 새롭게 나온 방식이 async 와 await이라고 한다. then을 계속해서 사용하면 코드가 길어져 가독성이 좋지 않기 때문에, async 와 await 방식을 권장한다고 나온다.\nReference FEAT: Rendering mylist view and bottom-toolbar under each item #28 루나의 TIL 기술 블로그 Django - MVC 패턴과 MTV 패턴 MDN - Element.insertAdjacentHTML() iana fetch의 기본적인 사용법과 scope 극복 JavaScript - 자바스크립트 fetch와 async/await MDN - await async/ await 사용방법 (feat. then과 함께 쓰기) Promise 정리: async/await 사용법 \u0026amp; then과의 차이 Javascript Promise 배경부터 then catch 그리고 async await까지 ","permalink":"http://jeha00.github.io/post/project/devket/js/dom_fetch_issue/","summary":"첫 번째, DOM 생성과 fetch 사용을 위한 Javascript 학습 후기를 남겨본다. 두 번째, DOM을 조작하여 개발한 과정과 fetch를 사용하여 개발한 각 과정에서 일어난 여러 개발 issue들에 대해 정리해본다.","title":"Project: DOM 생성과 fetch 사용을 위한 Javascript 학습 후기 및 각 과정에 일어난 개발 issues"},{"categories":"Django","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 김형종 강사님의 django 강의를 학습한 내용입니다.\n그리고, Django REST framework를 함께 참고하여 학습했습니다.\n이번 챕터에서는 지난 챕터에서 언급한 DRF의 Policy에 대해 학습해봅니다.\nthrottle_scope pagination_class authentication_classes \u0026amp; permission_classes DRF 강의 내용을 정리한 이유는 DRF는 api 설계에 주로 사용하기 때문에, 정답이라는 게 없어서 많이 사용하는 내용을 정리할 필요를 느꼈습니다.\n1. Throttle Scope settings.py에 환경 변수 추가 호출 제한하기 위해서는 config/base.py 또는 config/settings.py에서 환경 변수 하나를 추가한다.\nThrottling을 참고한다.\n1 2 3 4 5 6 7 8 9 REST_FRAMEWORK = { \u0026#34;DEFAULT_THROTTLE_CLASSES\u0026#34;: [ \u0026#34;rest_framework.throttling.ScopedRateThrottle\u0026#34; ], \u0026#34;DEFAULT_THROTTLE_RATES\u0026#34;: { \u0026#34;basic\u0026#34;: \u0026#34;3/day\u0026#34;, \u0026#34;premium\u0026#34;: \u0026#34;100/day\u0026#34;, } } 해당 위치에다가 작성한 이유는 api 호출 전체 횟수를 여기서 관리하기 위함이다.\n4번 새로고침하면 끊긴다. 왜냐하면 \u0026lsquo;basic\u0026rsquo;으로 하루 3번으로 설정했기 때문이다.\n원래는 DB에 호출횟수를 입력해야 한다.\n1 2 3 4 5 6 7 from rest_framework.viewsets import ModelViewSet class EmployeeViewSet(ModelViewSet): queryset = Employee.objects.all() serializer_class = EmployeeSerializer throttle_scope = \u0026#34;basic\u0026#34; 2. pagination_class Pagination도 함께 참고했다.\nViewSet에 pagination_class 추가 1 2 3 4 5 6 7 8 9 10 11 12 from rest_framework.pagination import PageNumberPagination from rest_framework.viewsets import ModelViewSet class CustomPagination(PageNumberPagination): page_size = 1 class EmployeeViewSet(ModelViewSet): queryset = Employee.objects.all() serializer_class = EmployeeSerializer pagination_class = CustomPagination throttle_scope = \u0026#34;basic\u0026#34; 하지만, pagination_class도 throttle_scope 처럼 전역적으로 관리하기 위해서는 settings.py에 아래와 같이 추가할 수 있다.\n1 2 3 4 REST_FRAMEWORK = { \u0026#39;DEFAULT_PAGINATION_CLASS\u0026#39;: \u0026#39;rest_framework.pagination.LimitOffsetPagination\u0026#39;, \u0026#39;PAGE_SIZE\u0026#39;: 100 } 3. authentication \u0026amp; permission authentication_classes = [] 과 permission_classes = [IsAuthenticated]를 추가한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from rest_framework.pagination import PageNumberPagination from rest_framework.viewsets import ModelViewSet from rest_framework.permissions import IsAuthenticated class CustomPagination(PageNumberPagination): page_size = 1 class EmployeeViewSet(ModelViewSet): queryset = Employee.objects.all() serializer_class = EmployeeSerializer authentication_classes = [] permission_classes = [IsAuthenticated] pagination_class = CustomPagination throttle_scope = \u0026#34;basic\u0026#34; 3.1 Custom permission 만들기 공식문서: Custom Permissions도 함께 참고했다.\ndrf에서 기본으로 제공하는 Permission이 아니라 이를 상속받는 custom permission을 만들어본다.\n1 2 3 4 5 6 7 8 9 10 11 12 from rest_framework import permissions class CustomPermission(permissions.BasePermission): # list를 받을 때 def has_permission(self, request, view): print(f\u0026#34;has_permission\u0026#34;) return True # queryset이 all이냐 아니면 last냐 def has_object_permission(self, request, view, obj): print(\u0026#34;has_object_permission\u0026#34;) return True 그러면 이를 class EmployeeViewSet 의 permission_classes의 list data type에 넣는다.\n1 2 3 4 5 6 from .permissions import CustomPermission class EmployeeViewSet(ModelViewSet): ... permission_classes = [IsAuthenticated, CustomPermission] ... 만약 has_permission 부분을 False로 바꾸면 다음과 같은 결과가 뜬다.\n1 2 3 { \u0026#34;detail\u0026#34;: \u0026#34;자격 인증데이터(authentication credentials)가 제공되지 않았습니다.\u0026#34; } True로 바꾸면 다음과 같다.\n1 has_permission return True 대신에 return request.user.is_staff을 추가하여 staff 여부를 확인할 수 있다.\n3.2 authentification 인증 방식에는 4가지가 있는데, 이번 학습에는 TokenAuthentication에 대해 알아본다.\nBasicAuthentication TokenAuthentication SessionAuthentication JSON Web Token(JWT) TokenAuthentication 추가하기 from rest_framework.authentication import TokenAuthentication을 추가하여 authentication_classes에 추가하여 token 방식으로 인증을 진행하겠다는 걸 의미한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from rest_framework.pagination import PageNumberPagination from rest_framework.viewsets import ModelViewSet from .permissions import CustomPermission from rest_framework.authentication import TokenAuthentication class EmployeeViewSet(ModelViewSet): queryset = Employee.objects.all() serializer_class = EmployeeSerializer # Policy authentication_classes = [TokenAuthentication] permission_classes = [IsAuthenticated, CustomPermission] pagination_class = CustomPagination throttle_scope = \u0026#34;basic\u0026#34; token 발행 경로 추가하기 master url에 아래 코드를 추가하여 token 발행 경로를 추가해보자.\n1 2 3 4 5 6 from rest_framework.authtoken.views import obtain_auth_token api_patterns = [ ... path(\u0026#34;auth/token/\u0026#34;, obtain_auth_token) ] settings.py 또는 settings/base.py 에 app 추가하기 1 2 3 4 INSTALLED_APPS = [ ... \u0026#34;rest_framework.authtoken\u0026#34; ] 실행해보기 그러면 해당 url를 입력해보면(GET) 다음과 같은 결과가 뜨면 올바르게 작동된 것이다.\n1 2 3 { \u0026#34;detail\u0026#34;: \u0026#34;메소드(Method) \\\u0026#34;GET\\\u0026#34;는 허용되지 않습니다.\u0026#34; } 그러면 POSTMAN 을 사용해서 POST로 하여 다시 보내보자. 다음과 같은 결과가 뜨면 올바르게 작동된 것이다.\n1 2 3 4 5 6 7 8 { \u0026#34;username\u0026#34;: [ \u0026#34;이 필드는 필수 항목입니다.\u0026#34; ], \u0026#34;password\u0026#34;: [ \u0026#34;이 필드는 필수 항목입니다.\u0026#34; ] } 그러면 Body tab을 포스트맨에서 선택 후, form-data를 선택하여 데이터를 입력해보자.\nsuperuser로 만들었던 아이디와 비밀번호를 입력하면 아래와 같이 토큰이 발급된다.\n1 2 3 { \u0026#34;token\u0026#34;: \u0026#34;626ccf92~~~~~\u0026#34; } 그러면 이 Token을 http message header에 추가하여 GET으로 함께 해당 api_url를 보내면 user 정보를 받을 수 있다.\nReference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/django/drf/drf_study03/","summary":"DRF에는 많은 기능들이 존재한다. 그 중에서 자주 사용하는 throttle_scope, pagination, auththentication \u0026amp; permission에 대해 학습했다.","title":"Django study: DRF의 Policy - Throttle_scope, pagination, authentication \u0026 permission"},{"categories":["AWS"],"content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 lukas 강사님의 AWS 강의를 정리한 내용입니다.\n왜 DevOps가 중요한지, 클라우드와 AWS를 소개하면서 이에 대한 이론을 학습한다.\n1.1 백엔드 개발의 업무 범위 주 목적: 장기적으로 안정적으로 서비스를 배포하고 운영하기\nbackend 안에는 DevOps, Data 분야, 추천 서비스 AI 까지 파고들 수 있다.\n구체적인 범위들 보다 구체적으로 정리하자면 다음과 같다.\n서버 개발(API, 비즈니스 로직, 라이브러리/프레임워크 개발) DB 연동/관리/스키마 정의 등: 위에 서버 개발과 관련된 부분은 DBA가 아니어도 백엔드 개발자의 역할 서버 및 기타 미들웨어 연동 ex) redis 테스팅, 통합(Integration), 배포(Deployment), 운영(Operation), 모니터링(Monitoring) Architecture 설계: 확장성, 가용성, 비용효율성 고려 신규 프로젝트가 시작되면 이 업무를 시니어와 함께할 것 등등.. 과거와 달라진 업무 범위 과거에는 개발팀과 운영팀이 분리되었지만, 현재는 DevOps라는 문화로 향하고 있다.\nDevOps를 직군으로 많이 설명하지만, 사실상 \u0026lsquo;문화\u0026rsquo;다.\n아래 이미지에 적힌 대로 무한히 돌아가는 것을 말한다. 협업 관계자들 주로 DevOps, Cloud Engineer, System Engineer와 함께 일하기 때문에 이 분야에 대해서도 알아야 한다.\n전체 프로세스 설계 -\u0026gt; 2. 개발(구현) -\u0026gt; 3. 테스트 및 배포 -\u0026gt; 4. 운영 및 모니터링 설계: Application Design \u0026amp; System Design\nSystem Design 비용 최적화 고가용성 확장성 개발(구현)\n환경 구축 및 설정 프로그래밍 미들웨어 연동 테스트 코드 작성/유닛 테스트 테스트 및 배포\n통합 테스트, 빌드, 배포 이 단계를 통해서 서버를 몇 대 돌려야하는지 알 수 있다. 운영 및 모니터링\n어느 시간대에 사용량이 많은지도 분석 등등 CPU 사용률이 떨어졌다. 1.2 왜 배우는지 해야할 일이 매우 많기 때문에, 최대한 많은 것을 자동화하고, 외주화(있는 걸 잘 사용)해야 한다. 이를 위해서 Cloud를 배워야 한다.\n자동화는 DevOps의 핵심 왜 클라우드를 배워야할까?\n초기 투자 비용 없이 확장성 있는 설계 가능 운영 비용 절감: 사용한 만큼만 지불 확장 가능한 설계, 신뢰성 높은 설계 핵심 비즈니스에 집중 빠른 시간 내에 글로벌 서비스 구현 가능 레고 조립하듯 아키텍처 설계 가능 1.3 DevOps \u0026amp; AWS/Cloud 소개 DevOps란? 애플리케이션과 서비스를 빠른 속도로 제공할 수 있도록 조직의 역량을 향상시키는 문화 철학, 방식 및 도구의 조합. [from AWS]\nDevelop + Operate의 합성어\n설계-개발-테스트-배포-운영-유지보수를 옛날처럼 설계-개발-테스트 와 배포-운영-유지보수로 나누는 게 아닌 한 팀으로 하는 것 그래서 이 전체를 다 맡은 대신 서비스를 잘게 쪼갠다. 이게 바로 MSA다. 엔지니어 또는 해당되는 팀이 개발, 테스트, 배포, 운영에 이르기까지 전체 애플리케이션 수명 주기에 걸쳐 작업하는데, 이를 위해서 많은 것들을 자동화하고, 많은 도구나 플랫폼을 개발\n문제를 빠르게 파악하고 수정 및 개선하기 위해서 logging \u0026amp; monitoring이 중요하다.\nCI/CD 옛날에는 위에서 언급한 각 단계마다 팀을 쪼개서 커뮤니케이션 문제와 빠르게 확인할 수 없었다. 하지만 현재는 DevOps로 직군이 아닌 서비스로 쪼개기 때문에, 빠르게 확인하고, 빠르게 반영해서, 빠르게 개선하자 는 방식으로 작업한다.\n이를 위해서 CI/CD 가 필요해졌다.\nCI(Continuous Integration): 자동 통합 test, build, dockerize CD(Continuous Deployment/Delivery): 자동 배포(전달) remote push \u0026amp; run 아마존은 하루에 136,000번 배포되는데, 초당 1.6번 배포되고 있다.\nMonolithic VS MSA MSA는 단일 애플리케이션을 나누어 작은 서비스의 조합으로 구축하는 방법이며, 각 개별 서비스는 API로 연결된다. [Martin Fowler]\n여러 코드 구조를 하나의 구조로 관리하는 게 Monolithic 이라 한다. 그래서 수십, 수백만줄 코드를 위에 아마존처럼 빌드/배포를 할 수 없다.\n그래서 코드를 서비스 기준으로 쪼개면서, 전체 생명주기를 서로 긴밀하게 통합하기 시작했다. 즉, 이것이 DevOps이며, DevOps를 실현하기 위한 수단이 바로 MSA(Micro Service Architecture)다.\n서비스를 쪼개서 더 빠르게 문제 파악과 해결이 가능하고, 새로운 기술 도입이나 고가용성, 무중단 등에도 탁월하다.\n1.4 AWS 주요 개념과 서비스 소개 왜 AWS인가? 다른 클라우드 서비스도 많은데 AWS(Amazon Web Service)를 많이 사용하는 이유는 압도적인 점유율 1위다.\n그러면 왜 점유율 1위인가?\n첫 번째, 제일 먼저 시작해서 점유율이 높고, 클라우드와 인프라는 한 번 결정되면 바꾸는데 비용이 매우 크다.\n두 번째, 지원 가능한 국가가 매우 다양하다.\n세 번째, 클라우드와 인프라는 규모의 경제 영향이 커서, 이 규모를 점차 늘리고 있어서 비용이 줄어들고 있다.\n네 번째, cost를 점차 낮추고 있다.\nregion이 많으면 적은 나라보다 더 싸다. 그래서 북미가 제일 싸다. 하지만, Data Engineering의 관점에서 현재 GCP로 옮겨가고 있다.\nAWS 경험 우대 네카라에서는 private cloud(on-premise) 환경에서 회사별 클라우드 서비스를 사용하지만, 정작 채용할 때는 AWS 경험을 우대한다.\n요즘은 직군 구분치 않고 필수 또는 우대사항으로 AWS 경험을 언급한다.\n주요 개념 설명 Region\n전 세계의 데이터 센터를 뭉치는 물리적 위치 각 AWS 리전은 지리적 영역 내에서 격리되고, 물리적으로 분리된 다수의 AZ로 구성 ex) US East, US West, Asia Pacific(Seoul) etc AZ\nregion을 구성하는 개별 데이터 센터 단일로 사용하는 것보다 더 높은 가용성, 확장성, 안전성을 확보할 수 있다. 자연재해 등으로 안전하게 격리하기 위해서 모든 AZ는 서로 멀리 떨어져 있다. Serverless\nSaaS(Software-as-a-Service)형 서비스 인프라를 소유하거나 관리하지 않고, 서비스나 컴퓨팅 리소스를 사용할 수 있는 것 On-premise (private cloud)\n서버와 데이터 센터를 자체적으로 보유하고 관리하는 방식 Public cloud와 반대되는 개념 네이버, 카카오 등등 PM(Physical Machine) \u0026lt;-\u0026gt; VM(Virtual Machine)\n물리 서버와 가상 서버의 차이 VM: 하드웨어와 OS 상에서 하이버파이저(Hypervisor)라는 계층을 둬서 리소스를 공유하고 게스트 OS를 담을 수 있도록 만든 가상의 서버 VPC(Virtual Private Cloud)\n나만의 클라우드 네트워크 / 나만의 데이터센터 VPC 내부에 서버, 게이트웨이, 가상 라우터, 가상 방화벽, VPN 등을 둘 수 있다. 네트워크 지식이 많이 필요 IAM(Identity and Access Management)\n클라우드 리소스에 대한 접근을 안전하게 제어하고 관리하는 방식 또는 서비스 Zero-trust를 기본 전제로 한 클라우드 환경에서 반드시 필요한 white list 믿을 게 한 명도 없으니, 특정 사람만 허용하겠다. 1.5 Old vs New (with Server vs serverless) 인스턴스 생성하기 지역: 서울 택하기\nlatency가 적어서 서울 선택한다. Ubuntu Server 22.04 LTS 프리 티어 사용 가능 선택\n22년 04 버전을 의미한다. 만약 프리 티어 외를 사용한다면 무엇을 선택하는가? 이것보다는 \u0026lsquo;인스턴스 유형\u0026rsquo; 이 더 중요하다. 인스턴스 유형: t2.small\n키 페어 없이 계속 진행: 웹 브라우저로 편하게 진행하는 방법 사용\n나머지는 default 유지\n콘솔에 연결하기 생성된 인스턴스 선택 후, \u0026lsquo;연결\u0026rsquo; 클릭\n\u0026lsquo;인스턴스 EC2 연결\u0026rsquo; 탭 클릭 후 \u0026lsquo;연결\u0026rsquo; 클릭\n콘솔에서 가상환경 생성 후, 프로젝트 생성하기 아래 명령어를 순차적으로 입력\n1 2 3 4 5 6 7 8 9 10 sudo apt update sudo apt install -y python3.10-venv mkdir nanodegree cd nanodegree python3 -m venv venv source venv/bin/activate pip install Django django-admin startproject sample cd sample python manage.py runserver 0:8000 인바운드 보안 편집으로 8000번 포트 추가 인바운드: 내 로컬에 들어올 수 있는 범위\n소스: IPv4 anywhere 이 포트가 막혀있기 때문에, runserver PublicIPv4:8000으로 접속해도 데이터를 가져올 수 없었다. 아웃바운드: 내 local에서 밖으로 갈 수 있는 영역\n인스턴스의 PublicIPv4 복사하기 python manage.py runserver 0:8000을 입력한 후,\nPublic IPv4:8000 을 입력하여 장고 서버가 돌아가는 걸 확인한다.\n인스턴스 종료하기 서버가 올린 것을 확인했기 때문에, 생성했던 인스턴스를 종료한다. 이는 컴퓨터의 전원을 끈 것이다.\nReference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/aws/lecturenote01/","summary":"백엔드 개발자의 업무 범위가 과거와 달리 변하면서 DevOps로 어떻게 이어지고, DevOps와 MSA가 어떻게 연결되어 있는지, 그래서 왜 AWS를 배워야하는지 알아본다.","title":"AWS study: DevOps란 무엇인가? \u0026 AWS를 배워야하는 이유"},{"categories":"Django","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 김형종 강사님의 django 강의를 학습한 내용입니다.\n그리고, Django REST framework를 함께 참고하여 학습했습니다.\n이번에는 django의 외부 라이브러리인 DRF(Django Rest-Framework)에 대해 학습한 걸 정리했습니다.\nDRF와 DRF의 핵심인 직렬화가 무엇인지 어떤 흐름으로 설계를 진행하는지 ModelViewSet, @api_view, ViewSet 각각으로 view를 만드는 방법 Serializer 설계 DRF 강의 내용을 정리한 이유는 DRF는 api 설계에 주로 사용하기 때문에, 정답이라는 게 없어서 많이 사용하는 내용을 정리할 필요를 느꼈습니다.\n1. DRF의 이점 모든 것을 DRF로 구현하는 게 아닌, DRF 기능 중 선별적으로 필요한 것만 골라서 사용한다.\n최종적으로는 API를 만드는 것이지만, 구체적으로는 다음과 같다. 하지만, 아래 언급한 기능 외에도 매우 많은 기능들이 있으므로, 아래 기능들을 기본으로 살을 붙여나가자.\n첫 번째, Serializer 두 번째, Response 세 번째, APIView 네 번째, Policy DRF - Serializer json library는 json으로 직렬화가 가능하지만, Django object까지는 처리하지 못한다.\nDRF - Response DRF의 모든 기능을 사용하여 API를 만드는 게 아니라, DRF의 기능을 선별적으로 사용한다. 1 2 3 4 5 ## django에서는 다음 모듈을 사용 from django.http import JsonResponse ## DRF에서는 다음 모듈을 사용 from rest_framework.response import Response DRF - APIView DRF로 API를 만들 때 사용하는 방법들 3가지: APIView, @api_view, ModelViewSet\nAPIView 1 2 3 4 5 # CBV # TemplateView와 유사 class LessonAPIView(APIView): def get(self, request): return @api_view([\u0026ldquo;GET\u0026rdquo;]]) 1 2 3 4 # FBV @api_view([\u0026#34;GET\u0026#34;]) def get_lesson(request): return ModelViewSet 상속 1 2 3 4 5 # DRF에서 제공하는 ModelViewSet # FormView와 유사 class LessonViewSet(ModelViewSet): queryset = Lesson.objects.all() serializer_class = LessonSerializer DRF - Policy DRF에서 제공하는 유용한 기능 \u0026lsquo;Policy\u0026rsquo;\nauthentication_classes \u0026amp; permission_classes\napi 서버에 접근하여 가져올 때, 권한 부여 pagination_class\npagination 만들기 throttle_scope\napi를 다룰 때 횟수 제한이 있다. 이 횟수제한을 다루는 기능 2. DRF에 사용할 models.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 from django.db import models from django.contrib.auth.models import User class Company(models.Model): SCALES = [(0, \u0026#34;10명미만\u0026#34;), (1, \u0026#34;50명미만\u0026#34;), (2, \u0026#34;100명미만\u0026#34;), (3, \u0026#34;300명미만\u0026#34;), (4, \u0026#34;500명미만\u0026#34;)] name = models.CharField(verbose_name=\u0026#34;회사명\u0026#34;, max_length=30) scale = models.IntegerField(verbose_name=\u0026#34;규모\u0026#34;, choices=SCALES, null=True) def __str__(self): return f\u0026#34;{self.name} ({self.get_scale_display()})\u0026#34; class Meta: verbose_name = \u0026#34;회사\u0026#34; verbose_name_plural = \u0026#34;회사 목록\u0026#34; class Employee(models.Model): company = models.ForeignKey(Company, on_delete=models.CASCADE, verbose_name=\u0026#34;소속(회사)\u0026#34;) user = models.OneToOneField(User, on_delete=models.CASCADE, verbose_name=\u0026#34;유저\u0026#34;) name = models.CharField(verbose_name=\u0026#34;이름\u0026#34;, max_length=10) phone = models.CharField(verbose_name=\u0026#34;연락처\u0026#34;, max_length=11) team = models.CharField(verbose_name=\u0026#34;소속(팀)\u0026#34;, max_length=30) is_agreed = models.BooleanField(verbose_name=\u0026#34;이용약관 동의\u0026#34;, default=False) def __str__(self): return f\u0026#34;{self.name} ({self.company})\u0026#34; class Meta: verbose_name = \u0026#34;임직원\u0026#34; verbose_name_plural = \u0026#34;임직원 목록\u0026#34; 3. View 설계: APIView APIView를 사용하여 View를 설계해보고, django에서 제공하는 JsonResponse와 DRF에서 제공하는 Response를 비교해본다.\n3.1: from django.http import JsonResponse 3.2: from rest_framework.response import Response 3.3: 직렬화 추가 🔆 url에 매핑하는 방식은 기존 CBV 방식과 동일하다.\n3.1 JsonResponse TypeError: Object of type Queryset is not JSON serializable 위 모델들이 바로 직렬화가 안되면 이 모델들을 dictionary 형태로 바꾸고 나서 직렬화를 진행하면 가능하다. 이를 아래 view 코드를 통해서 확인해보자. 아래 result의 결과는 Json 직렬화를 할 수 없다는 Error가 발생한다. TypeError: Object of type QuerySet is not JSON serializable 왜냐하면 queryset은 jsonresponse로 던질 수 있는 적합한 타입이 아니다. queryset은 파이썬이 아닌 장고에서 만든 것이다. 그래서 파이썬에서 만들 수 있는 자료형으로 형변환 후, 이를 JsonResponse에 전달한다. 1 2 3 4 5 6 7 8 9 10 11 # user/views.py from rest_framework.views import APIView from django.http import JsonResponse class EmployeeListAPIView(APIView): def get(self, request): employee_qs = Employee.objects.all() result = {\u0026#34;employee_list\u0026#34;: employee_qs} return JsonResponse(result) queryset을 다른 data type으로 변환 후, 직렬화하기 그래서 위 내용을 다음과 같이 python의 다른 형태로 형변환하면 화면 상에서 볼 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 # user/views.py from rest_framework.views import APIView from django.http import JsonResponse class EmployeeListAPIView(APIView): def get(self, request): employee_qs = Employee.objects.all() # 아래처럼 입력하면 employee_list 라는 key 값에 value가 list형태인 것으로 직렬화되어 출력된다. result = {\u0026#34;employee_list\u0026#34;: list(employee_qs.values_list(\u0026#39;name\u0026#39;, flat=True))} return JsonResponse(result) 3.2 Response 아래 코드를 기반으로 화면을 보면 위에 JsonResponse와 달리 Http message 형태로 볼 수 있다. 1 2 3 4 5 6 7 8 9 10 11 from rest_framework.views import APIView from rest_framework.response import Response class EmployeeListAPIView(APIView): def get(self, request): employee_qs = Employee.objects.all() # 아래처럼 입력하면 employee_list 라는 key 값에 value가 list형태인 것으로 직렬화되어 출력된다. result = {\u0026#34;employee_list\u0026#34;: list(employee_qs.values_list(\u0026#39;name\u0026#39;, flat=True))} return Response(result) 3.3 Serializers 추가하기 먼저 ./serializers.py에서 EmployeeSerializer 를 만든다.\n1 2 3 4 5 6 7 8 from rest_framework.serializers import ModelSerializer from user.models import Employee class EmployeeSerializer(ModelSerializer): class Meta: model = Employee fields = \u0026#34;__all__\u0026#34; 그리고 이를 APIView에 추가한다.\n1 2 3 4 5 6 7 8 9 10 from rest_framework.views import APIView from rest_framework.response import Response class EmployeeListAPIView(APIView): def get(self, request): employee_qs = Employee.objects.all() serializer = EmployeeSerializer(employee_qs, many=True) return Response(serializer) 결과는 2.2 Response 방식과 동일하다.\n하지만, 코드는 보다 간결해진 걸 알 수 있다.\n만약 모든 필드가 아닌 원하는 필드면 입력하여 뽑아낼 수 있다.\nfields = '__all__'이 아닌 fields = ['name']을 입력하면 \u0026rsquo;name\u0026rsquo;에 관련된 것만 가져온다.\n4. View 설계: @api_view([\u0026rsquo;\u0026rsquo;]) @api_view([''])를 사용하여 위에 CBV로 만든 것과 내용을 동일하게 하면서 FBV로 만들어보겠다.\n데코레이터의 인자로는 리스트 데이터 타입으로 입력해야 한다.\n1 2 3 4 5 6 7 8 9 from rest_framework.serializers import ModelSerializer from rest_framework.decorators import api_view from user.models import Employee @api_view([\u0026#39;GET\u0026#39;]) def employee_list(request): employee_qs = Employee.objects.all() serializer = EmployeeSerializer(employee_qs, many=True) return Response(serializer.data) 🔆 url에 매핑하는 방식은 기존 FBV 방식과 동일하다.\n5. View 설계: ViewSet CBV 방식으로서, naming은 class \u0026lt;Model name\u0026gt;ViewSet(ModelViewSet):로 한다.\nModelViewSet을 받아서 ViewSet을 만든다. 이 때 2가지 옵션을 단다. queryset, serializer_class 를 만든다. queryset 은 \u0026lt;모델명\u0026gt;.objects.all() 을 만들어 할당한다. serializer_class에 해당하는 건 \u0026lt;모델명\u0026gt;Serailizer로 작성한다. 1 2 3 4 5 6 7 8 # course/views.py from rest_framework.viewsets import ModelViewSet from .serialization import EmployeeSerializer class EmployeeViewSet(ModelViewSet): queryset = Course.objects.all() serializer_class = EmployeeSerializer url에 mapping 하기 일반적인 cbv 방식과 달리 다음과 같이 DefaultRouter를 가져온다.\nRouter의 역할 router는 nginx처럼 여러 군데로 보내는 역할을 수행한다.\nrouter를 만들어서 여기에 .register를 사용하여 등록했다.\nrouter가 ModelViewSet을 사용하여 url를 여러개 만들어주는 역할을 한다.\nurl 뒤에 pk 입력하는 url 설계는 하지 않았음에도 불구하고, 뒤에 pk를 입력하면 해당되는 데이터가 뜬다. router.register의 수는 ModelViewSet으로 만들고 싶은 Model의 갯수만큼 입력한다.\n1 2 3 4 5 6 7 8 9 10 11 # users/views.py from django.urls import path, include from rest_framework.routers import DefaultRouter from .views import EmployeeViewSet router = DefaultRouter() router.register(\u0026#39;employee\u0026#39;, EmployeeViewSet) urlpatterns = [ path(\u0026#34;\u0026#34;, include(router.urls)) ] 6. 자주 사용되는 view 설계 ViewSet보다 APIView를 훨씬 많이 사용한다.\nFormView를 잘 사용하지 않는 이유\n요구사항이 바껴서 적용하기 힘들 때, form에 post를 전달하는 것 대신에 Ajax로 API를 체크한다. ModelViewSet을 잘 사용하지 않는 이유: 최적화의 어려움\nModelViewSet으로는 API를 자세하게 다룰 수 없어서, APIView를 주로 사용한다. 왜냐하면 ModelViewSet에는 CRUD가 다 존재하기 때문이다. Reference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/django/drf/drf_study02/","summary":"API url을 만드는 방법으로 APIView, @api_view() 그리고 ModelViewSet을 사용한다. 이 방법들 중에서 자주 사용하는 방식은 APIView다. ModelViewSet은 중복을 방지하여 여러 url들을 만들어주지만, 최적화가 어렵기 때문이다.","title":"Django study: DRF의 API url 만드는 방법 3가지 - APIView, @api_view([]), ModelViewSet"},{"categories":"Project: Devket","content":"Introduction 이 repository는 현재 러닝스푼즈 나노디그리 - django backend 부트캠프에서 팀 프로젝트를 진행하면서 다음과 같은 내용들에 대해 정리하고자 만들었습니다.\n팀 정책을 이것으로 정한 이유 개발하면서 부딪힌 문제들에 대한 원인, 해결방안, 해결과정, 그리고 그 이유들 이번 포스팅에서는 왜 PR template을 팀 프로젝트에 도입하려한 이유를 설명하고자 합니다.\nAdd template for pull request #5에 정리된 내용에 대해 설명하겠습니다. 선택한 PR template은 PULL_REQUEST_TEMPLATE 입니다. Why we use PR template? 1. Template을 사용하여 모두의 가독성을 높이고 시간을 절약하기 위해서\n2. PR을 작성하는 과정에서 작성해야할 것을 놓치지 않기 위해서\n3. commit message로는 부족한 부분을 설명하기 위해서\n템플릿을 반드시 사용해야하는 이유는 없다.\n하지만 템플릿을 사용하여 얻을 수 있는 이점들은 있다.\n위 두 가지 이점에 대해 설명해보겠다.\n모두의 가독성을 높이고 시간을 절약하기 위해서 template 이라는 형식이 없다면 각자 자유롭게 작성하기 때문에, 눈에 익숙하지가 않아 글이 손쉽게 읽혀지지 않는다.\n그리고 이 문단에서 또는 이 위치에서 말하는 바가 내가 이해한 그 의도가 맞는지 확신을 갖기 어렵다. 왜냐하면 평소에 각자 작성하는 글의 스타일이 달라서 어느 사람은 문두에 단지 이유를, 다른 사람은 바로 결론을 말하기 때문이다. 이를 이해하기 위해서 작성자에게 다시 질문을 해야하고, 이를 위해서 또 시간을 할애해야 한다.\n그래서 템플릿을 통해 형식을 정한다면 계속해서 일정한 형식에 노출되면 이해하려는데 쏟는 시간이 단축되어 절약할 수 있다. 시간도 자원이기 때문에 이를 절약하여 개발에 시간을 더 쏟기 위해서다. 또한, 우리는 현재 부트캠프로 짧은 시간에 완성된 프로덕트를 만들기 위해 스프린트 기간을 1주일로 잡아 진행하고 있어서 시간을 절약하는게 중요하다.\n작성해야할 것을 놓치지 않기 위해서 템플릿은 작성자가 읽는 대상들이 반드시 이해해야하는 부분을 놓치지 않고 작성하도록 도와주는 가이드다. 저희는 PR을 작성하는 내용에 무엇이 들어가야하는지 정확히 알지 못하는 것뿐만 아니라, 체화되지 않았기 때문에 놓칠 수 있다. 그래서 템플릿 \u0026lsquo;가이드\u0026rsquo;의 도움을 받아서 작성하는 게 없이 작성하는 것보다 개발자 준비생으로서 큰 도움이 될 거라 판단했다.\ncommit message로는 부족한 부분을 설명하기 위해서 commit message를 작성할 때, commit convention에 맞춰서 header와 body 부분을 작성한다.\n팀원들끼리 의논한 결과, commit message body 부분에 상세히 적는 것보다 body 부분도 개략적으로 짧게 적은 후 PR template에 상세히 적는 것을 다들 선호하여 PR template에 보다 자세히 작성하기로 결정했다.\nWhat size is good for PR? 한 개의 PR 당 code size를 최대 300줄로 유지하자.\n단, css와 html은 이 줄에 포함시키지 않는다.\n아래 reference를 참고하면 다음과 같은 그래프를 확인할 수 있다.\n사이즈가 너무 작아도 너무 커도 cost가 증가하는 걸 확인할 수 있다. 저희가 프로젝트를 진행하면서 너무 PR이 크면 모든 코드를 보기 힘들고, 너무 작게 여러 번하는 것도 불편하고 시간이 많이 드는 걸 느꼈다.\n그래서 여러 멘토님들과 여러 블로그를 참조하고, 저희가 진행하면서 느낀 결론은 \u0026lsquo;한 개의 PR 당 code size를 최대 300줄로 유지하자\u0026rsquo; 는 결론을 내렸다.\nReference 참고한 PR template\n좋은 Pull Request를 만드는 방법과 PR Template 구성 러닝스푼즈에서 VOD로 제공된 github 강의 PR 크기에 대한 근거 자료: SMALL BUSINESS PROGRAMMING\n","permalink":"http://jeha00.github.io/post/project/devket/docs/why-pr-template/","summary":"프로젝트 진행에 Pull Request templates를 사용하는 이유와 적절한 PR size는 얼만큼 정했는지에 대해 공유해본다.","title":"Project: Pull Request templates를 도입한 이유"},{"categories":"Docker","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 장철원 강사님의 docker 강의를 학습한 내용입니다.\ndocker는 운영체제와 많이 연관되어 있어서, docker를 잘 사용하고 한다면 운영체제에 대해 자세히 알아야 한다. 하지만, 많은 개발자들이 운영체제를 깊이 이해하지 못하여 docker를 잘 사용하지 못하는 상황이라고 한다.\n1. 컴퓨터 시스템 서버의 용량이 가득찼을 때 할 수 있는 해결책 2가지: scale up \u0026amp; out\n해결책 1: Scale up 장점: 더 고사양의 서버를 사용하여 1대로 운영가능 단점: 한번 먹통이 되면 서비스가 중단 가능성 있음 해결책 2: Scale out 수많은 서버에 프로그램을 배포하는 방식 서버를 1대에서 3대로 늘렸다고 생각을 했을 때, 3대에 배포를 다 해야한다. 문제점: 그러면 우리가 올리는 프로젝트가 다 제대로 올라갈 수 있을까? 그렇지 않다… 왜냐하면 사람의 컴퓨터 환경에 따라 다르기 때문이다. 10대 ~ 20대로 늘어나면 더 많은 어려움이 존재한다. 그래서 어떻게 보면 운이 기대야하는 문제점이다. 해결책 2 문제점의 해결책: docker docker를 사용하고 나서 위 문제점이 해결되었다. 2. 좁은 의미의 컴퓨터 컴퓨터란? compute라는 어원이 시작된 것으로 computer 계산하는 기계를 의미한다. 여기서 ‘계산’이란 우리가 생각하는 산수가 아닌 좀더 포괄적인 의미다. 좁은 의미의 컴퓨터: CPU + RAM 컴퓨터를 열었을 때 main board에 있는 CPU와 RAM이 제일 중요하다.\nCPU\n계산을 담당하는게 CPU CPU가 좋아질수록 처리속도가 그만큼 빠르다 RAM\n노트에 수학문제에 대한 풀이를 적어놓는데, 이 풀이는 머리에서 처리한 결과를 잠깐 적어놓은 것이다. 그러면 왜 적어놓을까? 이를 기억하면서 풀 수 없기 때문이다. 내 두뇌를 이용해서 문제를 풀고 있지만 노트라는 보조장치를 이용해서 더 손쉬운 풀이를 가능하게 만들어준다. RAM을 바로 이 용도로 생각하자. 보조장치\n좁은 의미의 컴퓨터는 CPU와 RAM을 합친거라고 보면 되고 나머지는 보조 장치라 할 수 있다. 입출력 장치\n키보드, 마우스, 모니터 보조 기억 장치 (HDD, SSD)\nRAM도 사실상 용량이 그렇게 크지 않기 때문에 보조 기억 장치를 사용 3. 운영체제 개념 컴퓨터는 하드웨어와 소프트웨어로 구성되어 있다. 그리고 이 소프트웨어는 User application과 OS로 구성되어 있다.\n하드웨어 : 마우스, 키보드 실제로 존재하는 컴퓨터를 구성하는 장치 소프트웨어 : 눈으로는 볼 수 있지만 손으로는 만질 수 없는 것들 이 OS를 또 쪼개면 kernel, OS 라이브러리, OS 외 라이브러리로 구성된다.\n전원이 켜지면? 전원이 켜지면 이 kernel이 보조기억장치에서 RAM으로 올라간다. 이 커널도 하나의 코드이고, 하드디스크에 존재한다.\n컴퓨터 전원을 종료할 때까지 메모리에 올라가 있다.\n만약 이상한 에러가 있을 때 컴퓨터를 껏다키면 에러가 해결이 될 때가 있는데 커널이 메모리에 올라가있는 순간 발생한 문제들이 초기화됨\nshell이란? 커널과 사용자 간 다리 역할을 하는 프로그램으로, 이 shell을 사용하여 사용자는 운영체제와 상호작용이 가능하다.\n종류: bash, zsh 운영체제의 기능 프로세서, 기억장치, 파일 정보 등 자원 관리 자원을 효율적으로 관리하기 위해 스케쥴링 기능 제공 여러 명령어 중 무엇을 먼저 처리할 지 일정을 짜주는것 사용자와 시스템 간 편리한 인터페이스 제공 하드웨어와 네트워크 관리 프로그램이 실행될 수 있는 환경 제공 운영체제가 제공하는 서비스 프로그램 실행\n프로그램을 메모리에 올리고 실행 하는게 가능 I/O 운영(operations)\n프로그램을 실행할 때는 파일이나 I/O 디바이스와 같은 I / O이 요구 될 수 있다. 예를 들어 네트워크 인터페이스로부터 무언가를 읽는다거나 파일 시스템에 무언가를 쓸때 특정 디바이스의 특정 기능이 요구될 수 있다. 효율성을 위해 이는 유저가 직접 I/O 디바이스를 컨트롤 할 수는 없고, 이는 운영 체제가 담당한다. 파일 시스템\n프로그램은 파일이나 디렉토리를 읽거나 써야할 때가 있음 파일이나 디렉토리의 이름을 짓거나 특정 파일을 검색할 때도 잇음 커뮤니케이션\n프로세스들끼리 정보를 교환해야하는 경우가 있는데 이처럼 프로세스들 간의 커뮤니케이션이나 네트워크를 이용해서 서로 다른 컴퓨터가 커뮤니케이션 해야할 경우가 있다. 이 경우 커뮤니케이션은 shared memory를 이용하는데 이때 shared memory에 데이터를 읽고 쓰는 일을 운영체제가 담당한다. resource allocation(할당)\n다수의 프로세스가 동시에 실행될 때 운영체제는 각 프로세스에 자원을 할당하는 역할을 한다. 이때 자원이라는 것은 CPU, memory, storage같은 것을 의미한다. 4. Process와 Thread 프로그램(program) 프로그램이란? 실행 가능한 명령어의 집합\n프로그램은 하드디스크와 같은 저장 장치에 저장되어 있지만 메모리에는 올라가지 않은 정적인 상태\n프로그램은 메모리가 아닌 디스크에 존재한다.\n결론적으로 실행을 하지 않은 코드를 즉 프로그램이라고 한다. 컴파일된 바이너리 이미지 형태 or 파이썬 스크립트 같이 인터프리터 형태\n디스크에 저장된 실행 가능한 명령어의 집합이기만 하면 프로그램 컴파일러와 인터프리터 컴파일러(compiler)\n원시 코드 → 컴파일 언어 → 목적코드 원시 코드를 목적 코드로 변환해주는 것 실행속도는 빠르지만, 배우기는 어렵다 ex) C, JAVA 인터프리터(interpreter)\n한꺼번에 컴파일 단계를 거치는 컴파일 언어와 다르게 한줄 한줄 실행 실행속도가 느리지만, 배우기는 빠르다 Process 실행 중인 프로그램\n하드디스크에 있는 프로그램을 메모리(RAM) 상에 올린 것\n실상 프로그램을 여러개 사용했다라고 하는 건 프로그램이 아닌 프로세스를 여러개 돌리는 것이다. 그래서 프로세스를 너무 많이 사용하게 되면 더 이상의 프로그램(프로세스)를 띄울 수가 없다. 왜냐하면 RAM을 다 사용했기 때문이다.\nThread 프로세스가 할당 받은 자원을 이용하는 실행단위이자 프로세스 내에 실행되는 여러 흐름의 단위\n프로세스는 최소 한 개 이상의 쓰레드를 가짐, 이를 메인 쓰레드(main thread)라고 한다.\n쓰레드는 독자적인 스택 메모리를 가진다.\n프로세스는 쓰레드의 컨테이너이다. 프로세스는 쓰레드의 정보를 담고 있는 것에 불과하다.\n쓰레드 예시(웹 브라우저의 경우)\n하나의 쓰레드는 이미지와 텍스트를 보여주는 일을 수행 다른 쓰레드는 네트워크 상의 데이터를 가져오는 일을 수행 🔆 파이썬에서 멀티쓰레드가 존재하니까 여유가 생기면 공부해보자!\n5. 메모리 구조 Kernel space 우리가 컴퓨터를 실행하는 순간 커널 스페이스에 커널이 올라간다. 어떤걸 하더라고 커널 스페이스에는 프로세스를 못올린다. Process의 메모리 상에서 4가지 구조 메모리에 올라간 프로세스는 Stack - Heap - Data - Code 구조를 가진다. Stack 방향으로 갈수록 높은 메모리 주소를 가지며, code 방향으로 갈수록 낮은 메모리 주소를 가진다. 🔆 Stack 지역변수, 매개변수, 함수 리턴값 - 위에서 아래로 쌓인다. (높은 메모리 주소 -\u0026gt; 낮은 메모리 주소 방향으로 할당)\n지역 변수(local variable) 저장 매개 변수(parameter) 저장 함수 호출과 함께 할당 함수 호출이 종료되면 소멸 재귀 함수처럼 무한정 반복되는 함수 호출시 stack overflow 문제 발생 해킹 시에는 일부러 stack overflow를 만들어서 들어간다. 🔆 Heap 동적 할당 데이터 stack과 반대방향으로 쌓인다. (낮은 메모리 주소 -\u0026gt; 높은 메모리 주소 방향으로 할당)\n사용자가 직접 관리하는 영역\nC언어에서는 사용자가 직접 입력하고, 지정하여 지정한 것만 사용한다. 그래서 지우는 것도 사용자가 직접 한다. 하지만 java에서는 java가 heap 할당을 해주기 때문에, garbage collector가 필요하다. 사용자에 의해 메모리 할당 및 해제\nC언어에서 malloc 명령어를 수행했을 때 메모리가 할당되는 곳\n자바에서 가비지 컬렉션을 할 때, 정리되는 영역\nData 전역변수, 정적변수\n전역변수 (global), 정적 변수(static)를 저장 프로세스 시작과 함께 할당 프로세스 종료와 함께 소멸 Code 코드, 함수, 제어문\n실행할 프로그램의 소스 코드가 저장되는 곳 그래서 텍스트(text) 영역이라고도 한다. CPU는 코드 영역에 저장된 명령어를 하나씩 가져가서 처리한다. 6. Namespace 프로세스를 실행할 때 시스템 리소스를 분리해서 실행할 수 있도록 도와주는 기능\n네임스페이스는 컨테이너 개념과 이어진다. namespace의 종료와 역할 네임스페이스 의미 역할 pid PID: Process ID 리눅스 커널의 프로세스 ID 분리 net NET: Networking 네트워크 인터페이스(NET) 관리 ipc IPC: Inter Process Communication 프로세스 간 통신(IPC) 접근 관리 mnt MNT: Mount 파일 시스템의 마운트 관리 uts UTX: Unix Timesharing System 커널과 버전 식별자 분리 실습 EC2 로그인 후, work directory를 생성한다. 그 안에 test directory 생성 ls -al 또는 ll 입력하여 확인하기 프로그램 생성하기 vim 으로 아무 파일 생성하기 ex) vi while_loop.py 프로그램 실행하기 python while_loop.py \u0026amp;\n\u0026amp;의 의미는 백그라운드 실행한다는 의미다. 그러면 다음과 같은 값이 뜬다. [1] 25514 이는 PID 를 의미한다. 다음으로 ps -ef | grep while_loop을 입력하면 다음과 같이 뜬다.\n1 2 3 #UID PID PPID C STIME TTY CMD ubuntu 25514 25390 99 10:14 pts/0 00:01:03 python3 while_loop.py ubuntu 25522 25390 0 10:15 pts/0 00:00:00 grep --color=auto while_loop 프로그램을 담고 있는 컨테이너 확인하기 프로세스는 쓰레드를 담고 있는 컨테이너라고 했는데, 위 PID를 담고 있는 컨테이너를 확인해보자. ls /proc를 실행하면 여러 목록들이 나오는데 거기서 25514를 확인할 수 있다. ls /proc/25514 를 입력하면 여러 파일 목록들이 나온다. /proc/25514는 프로그램이 실행하는 동안 이 프로그램을 닫고 있는 컨테이너를 말한다. 프로그램 종료 시키기 만약 실행한 프로그램을 종료시키면 위에 생성된 /proc/25514는 사라진다. 명령어: kill -9 25514 PID를 입력할 때는 복붙해서 한다. 1 2 ubuntu 25543 25390 0 10:25 pts/0 00:00:00 grep --color=auto while_loop [1]+ Killed python3 while_loop.py ❗️ root 계정이 아닌 사용자 추가하여 사용하기\nReference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/docker/01_os-for-docker/","summary":"Docker 학습을 시작하기에 앞서 Docker가 왜 필요한지, 컴퓨터 시스템의 핵심은 무엇이고, 운영체제는 무슨 역할을 하는지, process와 thread란 무엇인지, 메모리 구조는 어떻게 구성되어 있는지, 마지막으로 컨테이너에 대해 체험해본다.","title":"Docker 학습을 위한 OS background knowledge"},{"categories":"Django","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 김형종 강사님의 django 강의를 학습한 내용입니다.\n그리고, Django REST framework를 함께 참고하여 학습했습니다.\n이번에는 django의 외부 라이브러리인 DRF(Django Rest-Framework)에 대해 학습한 걸 정리했습니다.\nDRF와 DRF의 핵심인 직렬화가 무엇인지 Serializer 설계 DRF 강의 내용을 정리한 이유는 DRF는 api 설계에 주로 사용하기 때문에, 정답이라는 게 없어서 많이 사용하는 내용을 정리할 필요를 느꼈습니다.\n1. DRF(Django RestFramework)란? REST 규격에 맞는 api 설계를 간편하게 해주는 django library\nREST API REST란?\nresource와 행위를 구분하고, 행위는 HTTP method를 사용하여 표현하는 방식 특정 리소스를 고유하게 식별하는 식별자 ex) id 요청 및 응답 포맷으로는 JSON을 많이 사용 균일한 인터페이스를 적용 이러한 REST 설계 원칙을 준수한 API를 준수한 RESTful API라 한다.\n동사를 사용하지 않는다. 슬래시(/)로 계층 관계를 표현한다. URL 마지막 문자로 슬래시(/)를 포함하지 않는다. 밑줄(_)을 사용하지 않고, 하이픈(-)을 사용한다. 소문자로만 구성한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ## 나쁜 예시 /get/lesson/ /create/lesson/ /delete/lesson/1 /groups/8SUE9E/courses/finance/lessons/ ## 좋은 예시 /lessons 와 GET method 사용 /lessons 와 POST method 사용 /lessons/1 와 DELETE method 사용 # 긴 api가 아니라, courses로 이동한다. /groups/8SUE9E/courses courses/finance/lessons CRUD: HTTP method POST, GET, UPDATE \u0026amp; PATCH, DELETE DRF는 위 HTTP 메서드에 해당되는 CRUD 수행을 간편하게 해주는 외부 라이브러리다.\n장고의 기본 모듈이 아닌 외부 라이브러리지만, 잘 만들어져서 다들 다양하게 사용한다.\nDRF는 장고 공식문서에서는 내용을 확인할 수 없고 별도의 사이트가 존재한다. django-rest-framework.org/ DRF installation 설치 명령어 1 pip install djangorestframework 그리고, settings/base.py 의 INSTALLED_APPS에 추가한다. 1 2 3 4 INSTALLED_APPS = [ ... \u0026#34;rest_framework\u0026#34;, ] 2. 직렬화와 역직렬화 - 직렬화(Serialization): instance -\u0026gt; dict(json) -\u0026gt; bystring\n- 역직렬화(Deserialization): bystring -\u0026gt; dict(json) -\u0026gt; instance\n직렬화(Serialization) 데이터를 네트워크를 통해서 전달한다는 의미는 API로 전달하는 것 이라 생각하면 된다.\n그런데 이 데이터를 웹 애플케이션은 https, http 프로토콜을 사용하여 전달하며, 이는 HTTP message의 body 부분에 담아서 보낸다는 걸 의미한다.\n이때 담기 위해서는 json 형태여야하고, 이를 네트워크 기계를 통해서 전달해야하므로 최종적으로 bystring 형태로 보내야 한다.\n이 네트워크를 통해 전달하기 위해서 수행되는 instance -\u0026gt; json: dictionary -\u0026gt; bystring 과정을 직렬화라고 한다.\n역직렬화(Deserialization) api를 통해서 전달받은 데이터를 원하는 객체 타입으로 전환하는 과정을 말한다.\nbystring -\u0026gt; json:dictionary -\u0026gt; instance\nserialization.py 직렬화를 수행하기 위해서는 views.py, urls.py, models.py, forms.py 처럼 serialization.py 가 존재해야 한다.\nsettings.py 가 분기되어 있을 때라면 다음과 같이 실행한다.\n1 python mange.py serialization --settings=config.settings.develop 코드를 통해 이해해보기 그러면 코드를 통해 직렬화를 간단히 이해해보자.\nSerializer 작명법\n아래 코드에서 LessonSerializer는 \u0026lt;model 명\u0026gt;Serializer로 작성하는 작성법에 맞춰서 작성한 것이다. 아래 내용은 DRF 튜토리얼 내용을 학습하면서 정리한 내용이다.\n직렬화 instance 생성하기 1 2 3 4 5 6 7 8 9 10 11 from snippets.models import Snippet from snippets.serializers import SnippetSerializer from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser ## instance 생성 \u0026gt;\u0026gt;\u0026gt; snippet = Snippet(code=\u0026#39;foo = \u0026#34;bar\u0026#34;\\n\u0026#39;) \u0026gt;\u0026gt;\u0026gt; snippet.save() \u0026gt;\u0026gt;\u0026gt; snippet = Snippet(code=\u0026#39;print(\u0026#34;hello, world\u0026#34;)\\n\u0026#39;) \u0026gt;\u0026gt;\u0026gt; snippet.save() instance를 dictionary json으로 전환: Serializer 1 2 3 4 5 6 7 8 9 \u0026gt;\u0026gt;\u0026gt; serializer = SnippetSerializer(snippet) \u0026gt;\u0026gt;\u0026gt; print(type(serializer)) \u0026lt;class \u0026#39;\u0026lt;app 이름\u0026gt;.serializer.SnippetSerializer\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; serializer.data {\u0026#39;id\u0026#39;: 2, \u0026#39;title\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;code\u0026#39;: \u0026#39;print(\u0026#34;hello, world\u0026#34;)\\n\u0026#39;, \u0026#39;linenos\u0026#39;: False, \u0026#39;language\u0026#39;: \u0026#39;python\u0026#39;, \u0026#39;style\u0026#39;: \u0026#39;friendly\u0026#39;} \u0026gt;\u0026gt;\u0026gt; print(type(serializer.data)) \u0026lt;class \u0026#39;rest_framework.utils.serializer_helpers.ReturnDict\u0026#39;\u0026gt; dictionary json을 bystring으로 전환: JSONRender 네크워크를 통해서 전달될 때는 JSON 형태로 전달되므로 JSONRenderer를 사용한다. 1 2 3 4 5 6 7 \u0026gt;\u0026gt;\u0026gt; content = JSONRenderer().render(serializer.data) \u0026gt;\u0026gt;\u0026gt; print(type(content)) \u0026lt;class \u0026#39;bytes\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; print(content) b\u0026#39;{\u0026#34;id\u0026#34;:null,\u0026#34;title\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;code\u0026#34;:\u0026#34;foo=\\\\\u0026#34;bar\\\\\u0026#34;\\\\n\u0026#34;,\u0026#34;linenos\u0026#34;:false,\u0026#34;language\u0026#34;:\u0026#34;python\u0026#34;,\u0026#34;style\u0026#34;:\u0026#34;friendly\u0026#34;}\u0026#39; 역직렬화 bystring을 dictionary json으로 전환: JSONParser 1 2 3 4 5 6 7 8 9 10 11 \u0026gt;\u0026gt;\u0026gt; import io \u0026gt;\u0026gt;\u0026gt; stream = io.BytesIO(content) \u0026gt;\u0026gt;\u0026gt; stream \u0026lt;_io.BytesIO object at 0x7fcc89a27f40\u0026gt; \u0026gt;\u0026gt;\u0026gt; data = JSONParser().parse(stream) \u0026gt;\u0026gt;\u0026gt; data {\u0026#39;id\u0026#39;: None, \u0026#39;title\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;code\u0026#39;: \u0026#39;foo=\u0026#34;bar\u0026#34;\\n\u0026#39;, \u0026#39;linenos\u0026#39;: False, \u0026#39;language\u0026#39;: \u0026#39;python\u0026#39;, \u0026#39;style\u0026#39;: \u0026#39;friendly\u0026#39;} \u0026gt;\u0026gt;\u0026gt; print(type(data)) \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; dictionary json을 다시 instance로 전환: Serializer 1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt;\u0026gt;\u0026gt; serializer = SnippetSerializer(data=data) \u0026gt;\u0026gt;\u0026gt; print(type(serializer)) \u0026lt;class \u0026#39;quickstart.serializer.SnippetSerializer\u0026#39;\u0026gt; \u0026gt;\u0026gt;\u0026gt; serializer.is_valid() True \u0026gt;\u0026gt;\u0026gt; serializer.validated_data OrderedDict([(\u0026#39;title\u0026#39;, \u0026#39;\u0026#39;), (\u0026#39;code\u0026#39;, \u0026#39;foo=\u0026#34;bar\u0026#34;\u0026#39;), (\u0026#39;linenos\u0026#39;, False), (\u0026#39;language\u0026#39;, \u0026#39;python\u0026#39;), (\u0026#39;style\u0026#39;, \u0026#39;friendly\u0026#39;)]) \u0026gt;\u0026gt;\u0026gt; print(type(serializer.validated_data)) \u0026lt;class \u0026#39;collections.OrderedDict\u0026#39;\u0026gt; formView에서 항상 valid 체크를 했었다. 이것이 통과되면 값을 뽑아낸다. 딕셔너리로 받은 것을 유효성 체크 후, 모델로 받은 것이다. instance가 아닌 querysets을 직렬화하기 쿼리셋을 직렬화할 때는 옵션으로 \u0026lsquo;many=True\u0026rsquo;를 사용한다.\n1 2 \u0026gt;\u0026gt;\u0026gt; serializer = SnippetSerializer(Snippet.objects.all(), many=True) \u0026gt;\u0026gt;\u0026gt; serializer.data 3. 직렬화 코드 작성하기 Serializer는 FormView와 유사하다.\nSerializer의 class name은 \u0026lt;Model명\u0026gt;Serializer 로 작성한다.\nfields의 역할은 가져오는 정보 종류를 의미한다.\n\u0026quot;__all__\u0026quot; 이면 모든 정보를 다 가져온다. 하지만 \u0026quot;code\u0026quot; 를 하면 code만 가져온다. drf의 view인 APIView 라는 걸 이용해서 하나 하나 api를 구현할 수 있지만, drf는 설정한대로 하면 금방한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # course/serialization.py from rest_framework import serializers from course.models import Course, Group, Registration class CourseSerializer(serializers.ModelSerializer): class Meta: model = Course fields = \u0026#34;__all__\u0026#34; # fields = [\u0026#34;code\u0026#34;] # 만약 이렇게 하면 code만 가져온다. class GroupSerializer(serializers.ModelSerializer): class Meta: model = Group fields = \u0026#34;__all__\u0026#34; class RegistrationSerializer(serializers.ModelSerializer): class Meta: model = Registration fields = \u0026#34;__all__\u0026#34; Reference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course Django REST frameworkrial/) ","permalink":"http://jeha00.github.io/post/django/drf/drf_study01/","summary":"RESTful API가 무엇인지, 이를 간편하게 수행하는 Django의 library인 Django-RestFramework를 소개하고, 직렬화와 역직렬화 개념을 학습한다. 마지막으로 이를 사용하기 위한 Serializer를 작성해본다.","title":"Django study: DRF의 직렬화(serialization)와 역직렬화(deserialization)"},{"categories":"Django","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 김형종 강사님의 django 강의를 학습한 내용입니다.\n만든 프로젝트를 EC2에 올리고, S3에는 STATIC 파일들을 저장하고, RDS를 연결해보는 실습을 해보고 나서 정리한 것을 올린다.\n실제 현업에서는 STATIC 파일을 올리는 방법들 중 S3를 사용하는 방식을 사용 한다고 한다.\nDB를 나눠서 적용해보는 걸 실습해본다.\n개발자 DB 와 운영 DB로 나누기 첫 번째: config/settings 생성하기 config/settings directory 생성 후, 그 안에 다음과 같이 생성하기 __init__.py base.py develop.py production.py 두 번째: 기존 내용 base.py에 담기 기존 settings.py의 내용은 base.py에 담는다. 그리고, 기존 settings.py는 삭제한다.\n세 번째: ALLOWED_HOSTS 내용 옮기기 기존에 있던 ALLOWED_HOSTS는 develop.py 와 production.py 에 옮긴다.\nconfig/settings/develop.py\n1 2 3 4 5 from .base import * DEBUG = TRUE ALLOWED_HOSTS = [\u0026#34;*\u0026#34;] config/settings/production.py\n1 2 3 4 5 6 # config/settings/production.py from .base import * DEBUT = False ALLOWED_HOSTS = [\u0026#34;127,0,0,1\u0026#34;] 네 번째, settings option을 사용하여 runserver 실행 그러면 settings를 나눴기 때문에, 옵션을 사용하여 적절한 설정을 택하여 서버를 실행시켜보자.\n1 2 3 4 5 6 7 ## terminal에 입력하기 # develop setting 적용하기 $ python manage.py runserver --settings=config.settings.develop # production setting 적용하기 $ python manage.py runserver --settings=config.settings.production 하지만 FileNotFoundError가 발생된다. 그 이유는 settings directory가 생기면서 기존 설정 파일의 디렉토리 레벨이 한 단계 깊어져서, BASE_DIR의 값이 달라졌기 때문이다.\n다섯 번째, BASE_DIR 수정하기 처음에는 BASE_DIR = Path(__file__).resolve().parent.parent 이랬지만,\n이처럼 BASE_DIR = Path(__file__).resolve().parent.parent.parent 수정하자.\n그 후, 다시 아래 명령어를 실행하여 결과를 확인해보자.\n1 python manage.py runserver 0:8000 --settings=config.settings.production 그 결과, 화면에 Disallowed Error가 발생하는데, 정상적으로 잘 되었다는 걸 의미한다.\n🔆 DB를 production과 develop를 나눈 이유 develop 단계에 사용한 DB는 테스트를 위한 DB이기 때문에, production 단계에서의 DB와 다를 수 밖에 없다.\nRDS를 연결하면 그 때 DB는 production 단계에서 사용한다.\n코드로 확인해보자.\nproduction.py 에는 RDS DATABASES를 적용한다. develop.py 에는 기존 장고 프로젝트 생성 시, DB 내용을 적용한다고 하자. develop.py 1 2 3 4 5 6 7 8 9 10 from .base import * ALLOWED_HOSTS = [\u0026#34;*\u0026#34;] DATABASES = { \u0026#34;default\u0026#34;: { \u0026#34;ENGINE\u0026#34;: \u0026#34;django.db.backends.sqlite3\u0026#34;, \u0026#34;NAME\u0026#34;: BASE_DIR / \u0026#34;db.sqlite3\u0026#34; } } production.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 from .base import * ALLOWED_HOSTS = [\u0026#34;127.0.0.1\u0026#34;] DATABASES = { \u0026#34;default\u0026#34;: { \u0026#34;ENGINE\u0026#34;: \u0026#34;django.db.backends.postgresql_psycopg2\u0026#34;, \u0026#34;HOST\u0026#34;: \u0026#34;ls-django.cvhmktue5rnw.ap-northeast-2.rds.amazonaws.com\u0026#34;, \u0026#34;NAME\u0026#34;: \u0026#34;postgres\u0026#34;, \u0026#34;PORT\u0026#34;: \u0026#34;5432\u0026#34;, \u0026#34;USER\u0026#34;: \u0026#34;learningspoons\u0026#34;, \u0026#34;PASSWORD\u0026#34;: [비밀번호], } } Reference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/django/deployment/deployment-with-nginx-uwsgi-ec2_4/","summary":"uwsgi, nginx 를 연결한 후, R3에 연결하여 static file을 적용했다. 그 다음으로 DB를 develop 단계와 product 단계로 나눠서 적용하기 위해 DB를 나누는 작업을 해본다.","title":"Django study: nginx와 uwsgi를 사용한 django application deployment 04 - DB 나누기"},{"categories":"Django","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 김형종 강사님의 django 강의를 학습한 내용입니다.\n만든 프로젝트를 EC2에 올리고, S3에는 STATIC 파일들을 저장하고, RDS를 연결해보는 실습을 해보고 나서 정리한 것을 올린다.\n실제 현업에서는 STATIC 파일을 올리는 방법들 중 S3를 사용하는 방식을 사용 한다고 한다.\n지난 배포 과정에서 nginx 와 uwsgi 를 연결하여 EC2 public IPv4 만 입력해도 장고 웹 애플리케이션이 돌아가도록 했다. 하지만, CSS 가 적용되지 않는 문제점이 있다. 이를 해결하고자 S3에 연결하는 과정을 진행해본다. 그 다음으로 동적 데이터 처리를 위해 RDS와도 연결해본다.\n1. Static file serving 3가지 방식으로 static file을 서빙해본다.\n이 3가지 방식을 경험해보면서 왜 S3를 현업에서 사용하는지 이해해보자.\n첫 번째 방법: \u0026rsquo;location /static/\u0026rsquo; 추가 경로: /etc/nginx/sites-enabled/default 명령어: sudo vi /etc/nginx/sites-enabled/default 위 경로 파일에 아래 내용을 추가한다. 1 2 3 4 5 6 location /static/ { alias /home/ubuntu/www/ls-django/static/; } # nginx를 수정하면 다시 reload를 반드시 해야 한다. $ sudo service nginx reload 의미: /static/ 이라는 url이 들어오면 alias로 가리키는 부분으로 이동해라.\n문제점: 이 방법을 사용하면 admin에 적용되는 css를 확인할 수가 없다.\n두 번째 방법: collectstatic 모든 static 파일을 public이라는 한 폴더 안에 모으기 때문에, 첫 번째 방법의 문제점을 해결할 수 있다. 하지만, 이 경우 public 폴더를 사용하기 위해서 location 설정을 바꿔야 한다.\n1. config/settings.py 에 아래 내용 추가하기 경로: www/ls-django 명령어: vi config/settings.py 1 2 3 4 5 6 # STATIC STATIC_URL = \u0026#34;static/\u0026#34; STATICFILES_DIRS = [BASE_DIR / \u0026#34;static\u0026#34;] # 위에 두 줄은 이미 입력되어 있을 것이다. 있다면 밑에 한 줄만 입력한다. STATIC_ROOT = os.path.join(BASE_DIR, \u0026#34;public\u0026#34;) STATIC_URL: static resources를 접근하는 URL STATICFILES_DIRS: django project에서 사용하는 static resources 경로 지정 위에 STATIC_ROOT로 collectstatic 명령어를 통해 static resources가 모이는 위치 2. python manage.py collecstatic 실행 실행 결과 -139 static files copied to '/home/ubuntu/www/ls-django/public'. /home/ubuntu/www/ls-django/public 이 생긴다. 3. nginx.conf의 /static/ -\u0026gt; /public/ 파일 경로: /etc/nginx/sites-enabled/default\n명령어: sudo vi /etc/nginx/sites-enabled/default\npython manage.py collectstatic을 실행한 결과, public이 생기면서 정적 파일들을 이 폴더로 모았기 때문에 아래 내용에서 /home/ubuntu/www/ls-django/static/을 /home/ubuntu/www/ls-django/public/으로 바꾼다.\n1 2 3 location /static/ { alias /home/ubuntu/www/ls-django/public/; } nginx를 수정했으므로, sudo service nginx reload를 실행하여 반영한다.\n문제점: 프로젝트 내부에 정적 파일들을 모아놓기 때문에, 서버 부하를 피할 수 없다.\n세 번째 방법: S3에 연결하기 두 번째 방법의 문제점을 해결하기 위해 내부가 아닌 외부 AWS S3에 모아놓은 정적 파일들을 올려서 서버 부하를 분산시킨다.\n1) AWS S3에서 Bucket 만들기 2) Django module 설치하기 경로: 프로젝트 내부\npip install boto3 실행\npip install django-storages 실행\nstorages는 settings.py 와 연관되어 있기 때문에, INSTALLED_APPS에 storages 등록한다.\n3) AWS IAM에서 다운 받은 key를 settings.py에 반영하기 먼저 아래 과정을 거친다.\nAWS IAM 들어가기 \u0026gt; 왼쪽에 액세스 관리 \u0026gt; 사용자 \u0026gt; 사용자 추가 사용자 세부 정보 설정 \u0026gt; 사용자 이름 입력 AWS 액세스 유형 선택 \u0026gt; 액세스 키 - 프로그래밍 방식 액세스 선택 다음 권한 클릭 \u0026gt; 권한 설정 \u0026gt; 그룹에 사용자 추가 \u0026gt; 그룹 생성 \u0026gt; 그룹 이름 입력 \u0026gt; 정책 이름 \u0026gt; AmazonS3FullAccess 클릭 \u0026gt; 그룹 생성 🔆실제 서비스에서는 AmazonS3FullAccess를 선택하지 않으므로, 나중에 조정해야 한다.\n다음: 태그 \u0026gt; 다음: 검토 \u0026gt; 사용자 만들기 를 거쳐서 총 5단계까지 진행한다. 5단계에서 .csv 다운로드 를 클릭하여 다운받는다. 다운받은 csv를 열어보면 secret access key를 가지고 있다. 위에 다운받은 key를 아래 settings.py 에 입력한다. AWS 설정값 구성을 settings.py에 추가하기\n1 2 3 4 5 6 7 8 9 10 11 12 # 경로: settings.py # 제일 아래에 추가한다. # 입력시 대괄호는 빼고 입력한다. AWS_ACCESS_KEY_ID = \u0026#34;[액세스키]\u0026#34; AWS_SECRET_ACCESS_KEY = \u0026#34;[비밀 키]\u0026#34; AWS_REGION = \u0026#34;[리전명]\u0026#34; AWS_STORAGE_BUCKET_NAME = \u0026#34;[버킷명]\u0026#34; AWS_S3_CUSTOM_DOMAIN = f\u0026#34;{AWS_STORAGE_BUCKET_NAME}.s3.{AWS_REGION}.amazonaws.com\u0026#34; AWS_DEFAULT_ACL = \u0026#34;public-read\u0026#34; DEFAULT_FILE_STORAGE = \u0026#34;config.storages.S3DefaultStorage\u0026#34; STATICFILES_STORAGE = \u0026#34;config.storages.S3StaticStorage\u0026#34; 액세스키, 비밀키는 csv에 존재한다. 버킷명과 리전명은 S3로 이동하여 확인한다. ap-northeast-2 맨 아래 DEFAULT_FILE_STORAG 와 STATICFILES_STORAGE 의 각 S3DefaultStorage , S3StaticStorage 는 밑에 config/storages.py 의 class를 의미한다. 4) config/storages.py 추가하기 config/storages.py는 위에 settings.py에 추가한 코드대로 config 밑에 추가한다.\n경로: config/storages.py\n1 2 3 4 5 6 7 from storages.backends.s3boto3 import S3Boto3Storage class S3DefaultStorage(S3Boto3Storage): location = \u0026#34;media\u0026#34; class S3StaticStorage(S3Boto3Storage): location = \u0026#34;static\u0026#34; 5) static directory 파일들을 S3로 옮기기 python manage.py collectstatic 실행하기\nconfig/settings.py의 AWS_STORAGE_BUCKET_NAME 을 AWS IAM의 사용자 이름과 착각하지 말기 6) nginx의 location url로 경로 바꾸기 다시 브라우저 화면의 inspector를 들어가서 css 파일 url을 보면 AWS S3 bucket으로 연결되지 않은 걸 확인할 수 있다.\n그 이유는 바로 /etc/nginx/sites-enabled/default 의 location /public/ url 안에 있는 경로 때문이다. 이를 S3 경로로 수정해야 한다.\n그러면 amazon S3 bucket 에 들어가면 static/ 이 존재한다. 그래서 각 파일을 클릭하여 들어가면 각 객체마다의 url 경로가 존재한다. 버킷의 url을 복사하는 방법\n버킷에 들어가서 static/ 왼쪽에 빈칸을 클릭하면 URL 복사가 활성화된다. 1 2 3 4 # 경로: /etc/nginx/sites-enabled/default location /static/ { alias. https://learningspoons-django-bucket1.s3.ap-northeast-2.amazonaws.com/static/; } 변경했으니 다시 reload 한다.\nsudo service nginx reload: nginx 재적용 하지만 그래도 css는 불려지지 않는다. 아래 명령어를 입력한 후, 다시 조회해보면 css가 불려질 것이다.\n1 2 3 $ uwsgi --ini .conf/uwsgi.ini $ sudo service nginx reload css 파일의 Request URL을 보면 다음과 같이 aws에서 오는 걸 확인할 수 있다.\n🔆 기타 개념: CloudFront\n인스타그램 같은 국제 서비스는 한국에서 미국으로 접속해야 한다. region과 여러 나라 간의 거리가 멀기 때문에, 스태틱 파일을 서빙하는게 오래 걸린다. 그래서 여러 중간 지점에 복사본(mirror image)을 저장하여 서빙 시간을 아낀다. S3를 본 딴 이미지가 여러 각 지역에 위치한다. 그래서 보다 더 빨리 서빙한다. CDN = 콘텐츠 전송 네트워크(Content Delivery Network) 로 옮겨서 응답시간을 개선. 지리적으로 분산된 서버의 네트워크 2. RDS 연결하기 RDS를 연결한 후, super user 계정을 생성하여 admin page에 들어가보자.\nadmin page에 들어가려는 이유는 이것으로 DB 연결 유무를 확인할 수 있다.\n❗️ 아래 연결 설정들은 단지 RDS를 연결해보자는 취지 에 맞게만 설정한 것이므로, 실제 프로젝트 시작 시에는 다를 수 있다.\n첫 번째, RDS DB 생성하기 AWS RDS 들어가기 -\u0026gt; \u0026lsquo;데이터 베이스 생성하기\u0026rsquo; 클릭\n데이터베이스 생성 방식 선택: \u0026lsquo;표준 생성\u0026rsquo; 클릭\n엔진 옵션: PostegreSQL 클릭\n템플릿: 개발/테스트 클릭\n설정\n\u0026lsquo;DB instance 식별자\u0026rsquo; 에 이름 입력 ex) learningspoons \u0026lsquo;마스터 사용자 이름\u0026rsquo;에 이름 입력 ex) learningspoons 인스턴스 구성\n\u0026lsquo;버스터블 클래스\u0026rsquo; 선택 -\u0026gt; \u0026lsquo;db.t3.micro\u0026rsquo; 클릭 스토리지: 스토리지 자동 조정 체크 해제\n왜냐하면 지금 바로 필요하지 않기 때문 가용성 및 내구성: 기본값을 유지\n연결:\n\u0026lsquo;퍼블릭 액세스\u0026rsquo;에서 \u0026lsquo;예\u0026rsquo; 선택 \u0026lsquo;VPC 보안 그룹(방화벽)\u0026rsquo; 에서 \u0026lsquo;기존 항목 선택\u0026rsquo; 클릭 데이터베이스 인증:\n\u0026lsquo;암호 인증\u0026rsquo; 선택 모니터링: \u0026lsquo;성능 개선 도우미\u0026rsquo;에서 \u0026lsquo;성능 인사이트 켜기\u0026rsquo; 체크 해제\n추가 구성:\n\u0026lsquo;초기 데이터베이스 이름\u0026rsquo; 작성하기 ex) postgres 두 번째, 인바운드 규칙 편집 AWS EC2에 들어가서 해당 인스턴스 선택\n왼쪽 \u0026lsquo;네트워크 및 보안\u0026rsquo; 에 \u0026lsquo;보안 그룹\u0026rsquo; 클릭\n1번 인스턴스의 보안그룹 선택 후, \u0026lsquo;인바운드 규칙 편집\u0026rsquo; 클릭\n\u0026lsquo;규칙 추가\u0026rsquo; 클릭 -\u0026gt; 유형: \u0026lsquo;postgresql\u0026rsquo; 선택 -\u0026gt; 소스: \u0026lsquo;Anywhere-IPv4` 선택\n❗️인바운드 규칙 미추가로 인한 Error 4번을 추가하지 않으면 나중에 python manage.py runserver를 실행할 때, 다음과 같은 안내문이 뜨면서 진행되지 않는다. 위 보안사항을 추가하면 자연스럽게 서버가 돌아간다.\n1 2 3 # ls-django.cvhmktue5rnw.ap-northeast-2.rds.amazonaws.com 는 생성한 RDS DB의 엔드포인트를 의미 Is the server running on host \u0026#34;ls-django.cvhmktue5rnw.ap-northeast-2.rds.amazonaws.com\u0026#34; (172.31.28.221) and accepting TCP/IP connections on port 5432? 세 번째, local django settings.py에 RDS정보 입력 기존에 있던 DATEBASES 내용을 다음과 같이 수정한다.\n해당 강의를 진행할 때는 local에서만 진행했지만, 나는 EC2 우분투 서버에서도 해본 결과 동일하게 진행하면 된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 # config/settings.py DATABASES = { \u0026#34;default\u0026#34;: { \u0026#34;ENGINE\u0026#34;: \u0026#34;django.db.backends.postgresql_psycopg2\u0026#34;, # 아래는 예시일 뿐, 리스트말고 문자열로 입력한다. “HOST\u0026#34;: [RDS 엔드포인트], \u0026#34;NAME\u0026#34;: [DB 이름], \u0026#34;PORT\u0026#34;: \u0026#34;5432\u0026#34;, \u0026#34;USER\u0026#34;: [마스터 사용자 이름], \u0026#34;PASSWORD\u0026#34;: [비밀번호], } } 생성한 DB 인스턴스를 들어가서 클릭하여 ‘연결 \u0026amp; 보안’ 탭에 들어가면 HOST가 존재한다. NAME, USER 는 “구성” 탭에 존재한다. 위 내용을 입력하고 runserver를 하면 ENGINE에서 psycopg2가 설치되지 않아 ModuleError가 발생된다.\n이를 해결하고자 psycopg2를 설치해보자.\n네 번째, psycopg2 설치하기 postgresql을 사용하기 위해서 psycopg2 를 설치해야 한다.\npsycopg2는 컴퓨터 OS마다, 버전마다 설치방법이 달라서 다양하게 시도해보았다.\nstackoverflow도 보고, github issue도 뒤져본 결과 맥북 에어 M1을 사용한다는 전제하에 다음 명령어를 입력하니 한 번에 해결되었다.\npip install psycopg2-binary==2.9.2 내가 시도해본 순서를 정리하여 아래에 기록한다.\n1 2 pip install psycopg2-binary wheel pip install psycopg2 위에 두 명령어 실행 후, python manage.py runserver를 돌릴 때 안되면 아래 명령어 실행하기\n1 2 3 4 5 6 7 8 9 10 11 # 아래 brew 명령어를 실행하기 위해서는 brew를 먼저 설치해야 한다. # 아래 두 명령어 실행 후, reinstall 명령어 안내가 뜨면 각각 다 실행하기 brew install libpq --build-from-source brew install postgresql openssl export LDFLAGS=\u0026#34;-L/opt/homebrew/opt/openssl/lib\u0026#34; export CPPFLAGS=\u0026#34;-I/opt/homebrew/opt/openssl/include\u0026#34; pip install psycopg2-binary --force-reinstall --no-cache-dir pip install psycopg2 --force-reinstall --no-cache-dir pip install --upgrade numpy 위 명령어들을 다 실행하고 runserver를 실행했을 때 psycopg2 module이 인식되지 않으면 pip install psycopg2-binary==2.9.2 을 실행해보자.\n다섯 번째, admin 들어가기 python manage.py createsuperuser를 실행 후, 어드민 로그인을 한다.\n로그인이 된다면 DB 연결이 잘 된 것이다.\nReference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/django/deployment/deployment-with-nginx-uwsgi-ec2_3/","summary":"uwsgi, nginx 를 연결했으니, R3에 연결하여 static file을 적용해본다.","title":"Django study: nginx와 uwsgi를 사용한 django application deployment 03 - static file 적용하기"},{"categories":"Book Study","content":"0. Introduction 아래 book study는 알 스웨이가트가 지었고, 박재호님이 번역하신 클린 코드, 이제는 파이썬이다. 를 읽고 진행한 book study 입니다. 영문 원본으로 온라인 공개된 자료가 있어서 영문으로 학습합니다.\n기존에 읽었던 Clean Code는 자바 코드로 되어 있어서, 먼저 파이썬 클린 코드를 학습 후 시작할려고 합니다.\n이번 book study를 진행하면서 code에 대한 철학이 생기고, code를 바라보는 눈이 깊어지고, 넓어지기를 바랍니다.\n각 chapter를 읽고 내용 정리하는 식으로 진행합니다.\n이번에 학습하는 chapter의 주제는 \u0026lsquo;Chapter 01: DEALING WITH ERRORS AND ASKING FOR HELP\u0026rsquo; 입니다.\n1. 파이썬 에러 메세지를 이해하는 방법 파이썬 에러 메세지를 이해하는 방법에는 총 2가지가 있다.\n첫 번째는 에러 메세지에 있는 traceback을 면밀히 살펴보는 것 두 번째는 이 에러 메세지를 검색으로 찾는 것 첫 번째 방법부터 찾아보자.\nTraceback을 면밀히 살펴보자. 파이썬은 예외처리문이 다루지 않는 예외를 코드가 발생시킬 때 중단되고, 화면에 예외 메세지와 Traceback이 나타난다. 이 traceback에는 예외가 발생된 코드 장소와, 맨 처음에 호출된 시점을 보여준다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 1. def a(): 2. print(\u0026#39;Start of a()\u0026#39;) 3. b() # Call b(). 4. 5. def b(): 6. print(\u0026#39;Start of b()\u0026#39;) 7. c() # Call c(). 8. 9. def c(): 10. print(\u0026#39;Start of c()\u0026#39;) 11. 42 / 0 # This will cause a zero divide error. 12. 13. a() # Call a(). ### Error message Start of a() Start of b() Start of c() Traceback (most recent call last): File \u0026#34;abcTraceback.py\u0026#34;, line 13, in \u0026lt;module\u0026gt; a() # Call a(). File \u0026#34;abcTraceback.py\u0026#34;, line 3, in a b() # Call b(). File \u0026#34;abcTraceback.py\u0026#34;, line 7, in b c() # Call c(). File \u0026#34;abcTraceback.py\u0026#34;, line 11, in c 42 / 0 # This will cause a zero divide error. ZeroDivisionError: division by zero most recent call last 의 의미 가장 처음에 호출된 게 Traceback 바로 밑에 메세지이고, 가장 최근의 것이 끝에 있다는 의미\nframe summary의 의미 다음과 같은 단위를 한 개의 frame summary라 한다. 즉, 위에 Error는 총 4개의 frame summary를 보여준다.\n1 2 File \u0026#34;abcTraceback.py\u0026#34;, line 13, in \u0026lt;module\u0026gt; a() # Call a(). 이 frame summary는 하나의 frame object의 내부 정보를 보여준다. Frame object는 함수가 호출될 때 생성되고, 반환될 때 파괴된다. 그리고 위에 소스 코드에서의 print는 frame summary에서 보여지지 않는다.\n왜냐하면 예외가 발생시킨 함수 호출이 포함된 line만 traceback에 나타나기 때문이다. 마지막 frame summary 마지막 frame summary에는 \u0026lsquo;예외메세지\u0026rsquo;는 물론, \u0026lsquo;예외 에러의 타입명\u0026rsquo;까지 알려준다. 그리고, traceback이 준 line number는 파이썬이 마지막으로 에러를 발견한 장소를 의미한다. 그래서 버그의 원인이 있는 소스는 이 알려준 line number 전 어딘가에 존재한다는 걸 말해준다. 문법적 에러를 늦게 발견하는 파이썬 인터프리터 1 2 3 4 5 6 7 8 9 # 예시 코드 print(\u0026#39;Hello.\u0026#39; print(\u0026#39;How are you?\u0026#39;) ## error message File \u0026#34;example.py\u0026#34;, line 2 print(\u0026#39;How are you?\u0026#39;) ^ SyntaxError: invalid syntax 위 frame summary에서 원인 위치를 두 번째 라인을 가리켰으나, 사실 원인은 첫 번째 줄이다.\n왜 늦게 알려주는 것일까?\n왜냐하면 파이썬 인터프리터는 다음 라인을 읽을 때까지 문법적 오류를 알아채지 못하기 때문 이다.\n그래서 오류가 난 줄의 다음 줄을 가리킨다.\ndebuggr 또는 로깅 메세지 확인 위의 경우처럼 원인의 위치를 정확하게 가리키지 않는 경우, 디버거를 사용하여 프로그램 내부를 살펴보거나, 로깅 메세지를 확인해야한다.\n에러를 직접 검색하기 하지만, 이런 경우는 상당히 많은 시간이 소모되기 때문에, 마지막 방법인 Error messages를 인터넷 상에서 검색해보는 것이 더 빠른 솔루션이다.\nLinter 사용하기 파이썬을 작성하면서 잠정적인 에러 부분을 보여주는 소프트웨어를 사용하는 방법이다. 그 한 예로 Linter가 있다. 이외에도 요즘은 다양하다. 이런 툴을 사용해서 맨 첫 장소에, 처음에 에러를 방지하는 것이 제일 좋은 방법이다.\npip install --user pyflakes를 사용하면 설치할 수 있다.\n2. 질문하는 방법 피해야할 질문 방법 질문해도 되는지 묻는 것 직접 질문하지 않고, 돌려서 말하는 것 적절하지 포럼이나 웹사이트에 질문하는 것 구체적이지 않은 게시물 표제나 이메일 제목 쓰는 것 구체적으로 어떻게 작동하기 원하는지를 설명하지 않는 것: 프로그램이 안돌아간다 전체 에러 메세지를 명시하지 않는 것 작성한 나의 에러 코드를 공유하지 않는 것 잘못 포매팅된 코드를 공유하는 것 os 또는 version에 대한 정보를 주지 않는 것 누군가가 나를 대신하여 프로그램을 작성해주기를 바라는 것 질문 잘 작성하는 방법 미리 충분한 정보를 제공하여 질문 응답 시간을 줄이자.\n오프라인에서는 질문해도 되는지 묻는 것은 좋은 예의다. 하지만 온라인에서는 응답하는데 시간이 걸리기 때문에, 충분한 정보를 제공하라. 확실하게 물음표(?)를 가진 질문 형식으로 질문하라.\n무엇을 말하는지 이해할거라 생각하지만, 그렇지 않다. ex) 잘못된 예시: 이렇게 되면 좋겠습니다, 코드가 작동하지 않습니다. 적절한 웹사이트에 질문하라. ex) 자바스크립트 사이트에 파이썬 지문 하지 말기\n질문 제목 란에 질문 내용을 한 문장으로 약하라.\n해당 작성된 코드로 무엇을 하고 싶은지, 그 의도를 설명하라.\n이거 왜 작동안하는 거에요? 라고 질문하지 말고, 이런 목적으로 작성했는데 왜 안될까요? Error message를 일부가 아닌 전체를 공유하라.\n소스 코드도 일부가 아닌, 전체를 공유하라.\n적절한 포매팅으로 코드를 읽기 쉽게 만들기\n이 에러를 해결하기 위해 무슨 시도를 했는지 알리기\n컴퓨터 및 환경 설정 사항을 공유하기 ex) version\n좋은 질문 예시 [Title] Selenium 웹드라이버 : 어떻게 해야 엘리먼트의 \u0026#39;모든\u0026#39; 속성을 찾을 수 있을까요? 파이썬 \u0026#39;Selenium 모듈\u0026#39; 에서 \u0026#39;WebElement\u0026#39; 객체에 대한 속성들을 다음과 같이 \u0026#39;get_attribute()\u0026#39; 함수로 가져오려고 했습니다. 그런데, \u0026#39;href\u0026#39; 로 이름 붙은 속성이 존재하지 않아 \u0026#39;None\u0026#39; 이 반환됐습니다. 엘리먼트가 가진 모든 속성을 어떻게 가져오는지가 궁금합니다. \u0026#39;get_attributes( )\u0026#39; 나 \u0026#39;get_attribute_name( )\u0026#39; 같은 메소드를 찾지 못했습니다. 저는 파이썬에서 2.44.0 버전 Selenium 모듈을 사용하고 있습니다. 질문 제목에 내용 요약 물음표 형식 사용 무엇을 시도했는지 설명 질문이 명확 버전 명시 Reference 클린 코드, 이제는 파이썬이다. ","permalink":"http://jeha00.github.io/post/bookstudy/pythoncleancode/chapter01_errorandasking/","summary":"알 스웨이가트가 지었고, 박재호님이 번역하신  \u0026lsquo;클린코드, 이제는 파이썬이다\u0026rsquo;를 읽고 학습한 내용이다. 파이썬 에러 메세지가 어떤 내용들로 구성되어 있는지, 그리고 온라인 상에 질문을 할 때 어떻게 질문해야하는지 질문의 올바른 방법을 배운다.","title":"클린 코드, 이제는 파이썬이다: error and question"},{"categories":"Django","content":"❗️ 502 Bad Gateway Error 해결 위 작업을 다 완료했음에도 불구하고도, sudo service nginx reload 후, 502 Bad Gateway Error가 뜬다면 무엇이 원인일까?\n더 정확하게 원인을 알고자 log에 접근했다.\nvi /etc/nginx/nginx.conf 로 들어가서 error_log 경로를 찾아보자.\n찾은 경로로 tail -f \u0026lt;찾은 경로\u0026gt; 를 입력하여 error 확인하기 1 2 3 4 5 6 7 2022/10/15 13:18:01 [error] 19512#19512: *71 upstream prematurely closed connection while reading response header from upstream, client: 27.34.20.255, server: _, request: \u0026#34;POST / HTTP/1.1\u0026#34;, upstream: \u0026#34;uwsgi://unix:///tmp/app.sock:\u0026#34;, host: \u0026#34;13.125.216.246\u0026#34; 위에 메세지에서도 HTTP response message의 header를 읽는 동안 연결이 완전히 닫혀졌다는 걸 알 수 있다.\n그러면 무엇과 무엇 사이가 닫힌 것일까?\nnginx와 uwsgi 사이일까?\n그래서 django과 nginx에서 \u0026lsquo;502 Bad Gateway\u0026rsquo;로 검색해봤지만, 마땅한 결과가 뜨지 않아 stackoverflow에 검색한 결과 다음과 같은 결과를 알 수 있었다. 출처: django with nginx uwsgi bad gateway 502\nnginx는 들어온 request를 전달했지만, nginx와 연결된 대상이 없어서 response를 받지 못한 상황이라고 한다. 즉, nginx와 uwsgi 와의 연결이 끊어져있다는 상황이다.\n그래서 uwsgi 가 제대로 설치되고 있는지 확인하라고 했다.\nwhich uwsgi 를 입력해보니 확실한 경로가 나와서 설치된 걸 확인할 수 있다. 그러면 uwsgi가 실제로 실행되고 있는지를 확인해보자.\n단지 명령어만 입력하면 실행될거라 생각했지만, 그렇지 않았던 것이다. $ tail -f uwsgi.log ... --- no python application found, check your startup logs for errors --- ... python application을 발견할 수 없다고 뜬다. 혹시 모르니 uwsgi가 작동이 잘되는지도 확인해보자.\n1 2 $ tail -f /var/log/nginx/error.log; 2022/10/16 17:47:11 [notice] 36887#36887: signal process started 또는 sudo service nginx status를 실행하여 running을 확인한다. 그러면 uwsgi 를 설치하는 것에 문제가 생긴 것으로 판단된다. 직접 확인해보자.\nls -al ./venv/lib/python3.9/site-packages 를 입력하여, uWSGI-2.0.20.dist-info 를 확인해보자. 그러면 존재하지 않는다는 걸 알 수 있다.\n원인을 분석해보면 위에 pip install uwsgi 명령어를 입력하여 오류가 떠서, 구글링을 통해 sudo apt install uwsgi가 이를 대체할 수 있다고 판단하여 설치했으나 정확하게 설치되지 않은 걸로 판단된다.\n뜬 Error를 면밀히 살펴보면 Exception: you need a C compiler to build uWSGI 내용을 확인할 수 있다.\n위 Error가 떴다면 Install package 과정의 명령어들을 다 실행하지 않은 것이니, 다시 실행해보자.\n그럼에도 안된다면 아래 명령어를 다시 실행해하여 Public IPv4/를 입력하자.\n1 2 # 경로: www/ls-django/.conf $ uwsgi --ini uwsgi.ini Reference django with nginx uwsgi bad gateway 502 ","permalink":"http://jeha00.github.io/post/django/deployment/deployment-with-nginx-uwsgi-ec2_2/","summary":"nginx와 uwsgi를 사용한 배포과정에서 발생한 502 Bad Gateway Error에 대한 해결과정과 해결책을 정리해본다.","title":"Django study: nginx와 uwsgi를 사용한 django application deployment 02 - 502 Bad Gateway Error"},{"categories":"Django","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 김형종 강사님의 django 강의를 학습한 내용입니다.\n만든 프로젝트를 EC2에 올리고, S3에는 STATIC 파일들을 저장하고, RDS를 연결해보는 실습을 해보고 나서 정리한 것을 올린다.\n또한, 실제 현업에서는 STATIC 파일을 올리는 방법들 중 S3를 사용하는 방식을 사용한다고 한다.\n1. EC2, S3, RDS란? AWS의 EC2, S3, RDS에 대해 간단히 알아보자.\nAWS EC2\n클라우드 인스턴스가 돌아가는 서버 AWS S3\n정적 데이터(static, media etc..)가 올라가는 서버 확장성이 높아서, 스토리지 규모를 확장/축소할 수 있다. 버킷: S3에 저장되는 파일들이 담기는 바구니 AWS RDS\n클라우드 스토리지로서, 인터넷 공간에 데이터를 저장하는 저장소를 의미 2. 인프라 구조 로컬 서버와 달리 다음과 같이 분산시키는 이유는 트래픽을 분산시키고, 확장성을 갖추기 위함이다.\n로컬 서버로 돌릴 때는 request가 들어오면 local에 있는 runserver가 모든 걸 해결한다. 하지만, 실제 서비스에서는 그렇지 않다.\n🔆 NGINX 와 uWSGI 란?\n무엇인지에 대해서는 [TIL]Web Application Basic study: client와 server / web server structure를 참고한다.\n위 구조에서는 \u0026lsquo;NGINX\u0026rsquo; 와 \u0026lsquo;uWSGI\u0026rsquo;를 사용했다.\n정적 데이터: NGINX -\u0026gt; S3 NGINX는 HTTP request가 들어오면 url를 통해서 정적 데이터인지, 동적 데이터인지를 구별하여 정적 데이터를 처리하는 서버다.\n그래서, 정적 데이터이면 AWS S3로 이동한다.\n동적 데이터: NGINX -\u0026gt; uWSGI -\u0026gt; Django -\u0026gt; AWS RDS 하지만, 그렇지 않은 루트로 시작되는 것들은 uWSGI로 보내지고, uWSGI가 EC2 위의 django application에게 전달한다. 그리고, 이를 거쳐서 AWS RDS로 저장된다.\n3. EC2 인스턴스 생성하기 + 탄력적 IP 설정 EC2 인스턴스 생성 첫 번째, AWS EC2로 이동하여 로그인 후, 인스턴스를 생성한다.\n두 번째, ubuntu 20.04 프리티어 선택 -\u0026gt; t2.micro 선택 -\u0026gt; 키 페어 생성(RSA, .pem 선택)\n세 번째, 네트워크 설정\n보안그룹 생성 클릭: 보안 그룹 이름은 임의의로 정한다. \u0026lsquo;인터넷에서 HTTPs 트래픽 허용\u0026rsquo;과 \u0026lsquo;인터넷에서 HTTP 트래픽 허용\u0026rsquo; 둘 다 체크 그리고, 인바운드 보안 그룹 규칙 1가지를 추가 유형: \u0026lsquo;사용자 지정 TCP\u0026rsquo; 포트 번호: 8000 왜냐하면 장고 시작하는 서버가 8000번 포트이기 때문 소스 유형: 위치 무관 🔆 보안그룹의 인바운드 그룹이란?\nrequest를 받을 때, 일부 프로토콜만 허용하는데 이 범위를 정하는 게 범위 그룹의 인바운드라는 그룹이다. 브라우저로 접근하기 때문에 HTTP에 대한 접근을 허용했다. 탄력적 IP 설정 첫 번째, 모든 인스턴스 목록이 보이는 창에 들어가서 왼쪽에 \u0026lsquo;네트워크 및 보안\u0026rsquo; 탭의 \u0026lsquo;탄력적 IP\u0026rsquo;를 클릭 두 번째, 오른쪽 위에 \u0026lsquo;탄력적 IP 할당\u0026rsquo;을 클릭 세 번째, region만 \u0026lsquo;ap-northeast-2\u0026rsquo; (서울을 의미)인지 확인하고 \u0026lsquo;할당\u0026rsquo; 버튼 클릭 네 번째, 생성된 인스턴스에 탄력적 IP 주소 연결하기 생성했으면 연결된 인스턴스가 없기 때문에, 연결작업을 해야 한다. \u0026lsquo;탄력적 IP 할당\u0026rsquo; 버튼 왼쪽에 작업 버튼을 클릭하여, \u0026lsquo;탄력적 IP 주소 연결\u0026rsquo;을 클릭한다. 그 후, 위에서 생성한 인스턴스를 클릭하여 연결한다. 🔆 왜 탄력적 IP 주소라고 하는가?\nEC2가 종료되었다가, 다시 시작하면 IP가 바뀐다. 예를 들어서 공유지 전원을 겄다가 키면 주소가 바뀐다. 그런데 사용 중인 IP주소가 바뀌는 걸 막고자 탄력적 IP를 사용한다. 탄력적 IP 주소를 사용한 결과, 외부에서는 이 IP가 고정된다. 4. pem key에 권한 부여하기 터미널을 실행한 후, 아래 명령어를 입력한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 $ pwd /Users/jehakim $ mkdir .ssh-ls # pem key 를 옮긴 directory로 이동하기 $ cd .ssh-ls # 다운 받은 pem key를 옮기기 $ mv ~/Downloads/\u0026lt;perm key name\u0026gt;.pem . # pem key에 권한 부여하기 $ chmod 400 \u0026lt;perm key name\u0026gt;.pem 그러면 ssh로 접근하기 위해서 생성한 인스턴스의 Public IP address를 복사하자.\n1 2 3 4 5 $ ssh -i \u0026lt;perm key name\u0026gt;.pem ubuntu@\u0026lt;public IP address\u0026gt; ... Are you sure you want to continue connecting (yes/no/[fingerprint])? yes ubuntu@ip-172-31-3-151:~$ 리눅스 수업에서 학습했듯이 root로도 접근할 수 있다.\n하지만, 현업에서는 거의 root로는 접근하지 않는다.\n❗️ ssh -i 과정에서 \u0026lsquo;Permission denied(publickey)\u0026lsquo;가 뜬다면 원인을 다음 경우들로 생각해보자.\nIP 주소가 잘못된 게 아닌 이상 어딘가 오타가 존재한다는 의미다. 현재 경로가 pem key file이 존재하지 않은 directory에 있다는 것 ❗️ Ubuntu OS에서는 우분투 계정을 기본적으로 제공하므로, 별도로 계정을 추가할 필요가 없다.\n❗️ pem 파일은 Owner read 권한만 존재해야 접근 가능하다.\n5. Install package \u0026amp; File structure 5.1 Install package ubuntu에서는 패키지 관리를 sudo apt-get을 사용한다.\n1 2 3 4 5 6 7 8 9 10 $ubuntu@ip-172-31-3-151:~$ sudo apt-get update ... $ubuntu@ip-172-31-3-151:~$ sudo apt-get install build-essential # 파이썬 규격을 맞추기 위한 명령어 실행 $ubuntu@ip-172-31-3-151:~$ sudo apt-get install python3.9 python3.9-dev c # 가상환경 모듈 설치 $ubuntu@ip-172-31-3-151:~$ sudo apt-get install virtualenv 위 명령어를 다 실행했으면 파이썬 규격을 맞추기 위해서 아래 명령어를 입력하여 파이썬을 설치한다. 위 작업을 놓치면 UWSGI 를 설치할 수 없다. sudo apt-get install python3.9 python3.9-dev 5.2 File structure 우분투 로그인 시, 기본 경로\n/home/ubuntu/ 프로젝트 경로\n/home/ubuntu/www/\u0026lt;project name\u0026gt; ex) project name: ls-django 1 2 3 4 5 6 7 8 9 10 ubuntu@ip-172-31-3-151:~$ pwd /home/ubuntu ubuntu@ip-172-31-3-151:~$ cd www ubuntu@ip-172-31-3-151:~/www$ git clone \u0026lt;git repository address\u0026gt; ubuntu@ip-172-31-3-151:~/www$ cd ls-django ubuntu@ip-172-31-3-151:~/www/ls-django$ 가상환경 경로\n/home/ubuntu/www/\u0026lt;project name\u0026gt;/\u0026lt;가상환경 이름\u0026gt; ex) 가상환경 이름: venv 1 2 3 4 5 ubuntu@ip-172-31-3-151:~/www/ls-django$ v ubuntu@ip-172-31-3-151:~/www/ls-django$ source ./venv/bin/activate (venv) ubuntu@ip-172-31-3-151:~/www/ls-django$ 장고 패키지 설치하기\n이미 만들어 놓은 프로젝트를 git clone 경우 이기 때문에 requirements.txt 가 이미 존재한다. 그래서 pip install -r requirements.txt 를 실행하면 자동적으로 장고 패키지들이 설치된다. 6. EC2 public IPv4와 django server 연결 python manage.py runserver 0:8000 을 입력하여 실행해보자.\n0:8000을 입력하지 않으면 EC2 인스턴스의 public IPv4를 사용할 수 없다. 위 명령어를 실행한 후, 브라우저 url 창에 \u0026lt;public IP address\u0026gt;:8000을 입력했을 때, 다음과 같은 Error가 뜨면 잘된 것.\n위 8000번을 사용하기 위해서 인바운드 그룹에 추가했다. 1 2 3 DisallowedHost at / Invalid HTTP_HOST header: \u0026#39;13.125.32.21:8000\u0026#39;. You may need to add \u0026#39;13.125.32.21\u0026#39; to ALLOWED_HOSTS. 그러면 Host 부분을 수정하기 위해 vi settings.py를 입력하여, ALLOWED_HOST 부분을 다음과 같이 수정해보자.\nALLOWED_HOST = ['*'] python manage.py runserver 0:8000 실행 후, \u0026lt;public IP address\u0026gt;:8000 을 입력하면 정상적으로 화면이 나타난다.\n🔆 uwsgi 를 설치하지 않아도, 화면이 정상적으로 뜬다. 하지만 이 경우, uwsgi가 없기 때문에 nginx 와 연결될 수 없다.\n7. uWSGI 설치 및 적용하기 local에서 하는 게 아니기 때문에 uwsgi를 반드시 설치해야 한다. uwsgi 설명: 파이썬으로 된 장고 프로젝트를 실행하는 역할을 한다. uWSGI installation uWSGI 설치 명령어 pip install uwsgi 만약 uwsgi가 설치되지 않는다면 아래 명령어를 실행하지 않은 것이다. sudo apt-get install python3.9 python3.9-dev uWSGI 파일 수정 및 적용 uWSGI 파일 수정 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 경로: /home/ubuntu/www/ls-django $ mkdir .conf $ cd .conf # 아래 명령어를 입력하여, 생성 및 내용 입력 $ vi uwsgi.ini ## uwsgi.ini # 아래 내용 입력 후 esc → `:wq!` 눌러 저장 종료한다. [uwsgi] # 아래 3가지 변수는 장고가 uWSGI를 실행할 수 있는 환경을 만들어주는 것 chdir = /home/ubuntu/www/ls-django module = config.wsgi:application home = /home/ubuntu/www/ls-django/venv socket = /tmp/app.sock chmod-socket = 666 vacuum = true master = true daemonize = /home/ubuntu/www/ls-django/uwsgi.log uwsgi 내부 변수 설명\ndjango가 uWSGI를 실행할 수 있는 환경을 만들어주는 변수 3가지 chdir : django project 경로 module : django project wsgi module 위치 home : 가상환경 위치 socket : IP 네트워크로도 이용할 수 있으나, 같은 os에 있는 프로세스 있으므로 이럴 때는 소켓을 사용하여 속도 개선을 한다. 동일 서버 내 요청을 중개하는 것으로 소켓 전송 방식으로 진행 대부분 이런 방식을 사용한다. chmod-socket : 권한 부여 vacuum : uWSGI 통하여 생성된 파일을 삭제하는 옵션 master : uWSGI 프로세스를 master로 동작하도록 하는 옵션 daemonize : 백그라운드로 동작하기 위한 옵션이며, log file을 남길 경로 지정 log file이란 uwsgi.log 를 의미 실제로는 더 많은 옵션들이 존재하므로, 더 찾아보자.\nuWSGI 파일 적용 uwsgi --ini uwsgi.ini 명령어를 통해 변경된 설정값을 적용한다. 변경된 설정값을 적용하는 명령어 1 2 3 4 5 6 7 8 9 10 # 경로: www/ls-django/.conf $ uwsgi --ini uwsgi.ini # 실행결과 [uWSGI] getting INI configuration from uwsgi.ini # 그리고, uwsgi.log 가 생성될 것이다. # 이 log를 확인하는 방법은 tail -f uwsgi.log 를 실행한다. # -f 의 의미는 log에 새로 생기면 바로 출력된다는 걸 의미한다. 🔆 uWSGI 과정에서 발생한 Error 정리 Case 1 만약 위 명령어를 입력했을 때 다음과 같은 Error가 뜬다면 다음과 같은 절차로 확인한다. Command 'uwsgi' not found, but can be installed with: 첫 번째, 가상환경이 활성화되어 있는지 확인하라. 두 번째, pip install uwsgi을 실행했는지 생각해라. Case 2 만약 다른 Error로 다음과 같이 뜬다면 경로를 uwsgi.ini file이 있는 경로로 이동하라. realpath() of uwsgi.ini failed: No such file or directory [core/utils.c line 3662] 만약 또 다른 다음 Error가 뜬다면 uwsgi.ini 에 입력한 프로젝트 경로에 root를 입력하지 않은 것이니, 수정하라. 수정 전: home/ubuntu/www/ls-django/uwsgi.log 수정 전: /home/ubuntu/www/ls-django/uwsgi.log 로그 확인 uwsgi --ini uwsgi.ini 의 실행 결과, uwsgi.log가 생성된다.\ntail -f uwsgi.log를 실행하여 로그를 확인할 수 있다.\n-f의 의미: follow의 약어로서, 계속해서 파일의 상태를 감시하며 파일에 내용이 뒤에 추가될 때마다 새로 추가된 내용을 보여준다. 8. NGINX 설치 및 적용하기 nginx 설치하기 Nginx 설치 명령어 실행하기\nsudo apt-get install nginx nginx.conf 수정하기 Nginx를 수정하기 위해서는 프로젝트 내부 파일이 아니기 때문에 \u0026lsquo;sudo\u0026rsquo;를 사용해야 한다.\n아래 경로 파일 두 가지를 수정할 것이다.\n/etc/nginx/nginx.conf\nsudo vi /etc/nginx/nginx.conf 만약 위 명령어를 입력 시, tab을 눌렀는데 위 단어들이 안나오면 nignx가 설치되지 않은 것이기 때문에 sudo apt-get install nginx 명령어를 실행하자. /etc/nginx/sites-enabled/default\nsudo vi /etc/nginx/sites-enabled/default nginx에 uWSGI socket 연결하기 nginx 안에 uWSGI 소켓을 입력하여 연결시킨다. 그래서 Nginx를 설치하기 전에 uWSGI를 먼저 설치했다.\nuWSGI에서 소켓을 열었다. 이를 어떻게 알 수 있냐면 uwsgi file의 socket = /tmp/app.sock이 바로 소켓을 열었다는 의미다. 이 path를 아래에 나와있다시피 location에 추가하여 연결하자. 그리고, uwsgi의 parameters(params)를 포함시키자. 1 2 3 4 5 6 7 8 9 10 ## 다음 경로 파일 두 가지의 내용 값을 아래와 같이 수정하기 # 파일 경로: /etc/nginx/nginx.conf user ubuntu; # 파일 경로: /etc/nginx/sites-enabled/default location / { uwsgi_pass unix:///tmp/app.sock; include uwsgi_params; } nginx와 uwsgi가 어떻게 연결되는가? 파일 경로: /etc/nginx/sites-enabled/default 내용을 살펴보자.\n포트번호 80을 보고 있다가, 일로 들어온 url 경로가 / 면 location / { } 의 내부 내용 중 uwsgi_pass로 전달해준다. uwsgi가 django app을 실행한다.\nlocation 옆은 url 주소를 의미하고, 내부는 url 주소에 대응되는 프로젝트 디렉토리 경로를 의미 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Default server configuration # server { listen 80 default_server; listen [::]:80 default_server; root /var/www/html; index index.html index.htm index.nginx-debian.html; server_name _; location / { uwsgi_pass unix:///tmp/app.sock; include uwsgi_params; } 그래서 httprequest가 들어오면 NGINX가 uWSGI로 전달해준다.\nstatic file을 실행시켜주는 것도 위에 location에서 실행한다.\nnginx 적용하기 위 내용을 파일에 입력했으면 다음 명령어 2가지를 실행한다.\nsudo service nginx reload: nginx 재적용 sudo service nginx status: nginx 상태 확인 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ubuntu@ip-172-31-3-151:~$ sudo service nginx reload ubuntu@ip-172-31-3-151:~$ sudo service nginx status nginx.service - A high performance web server and a reverse proxy server Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset:\u0026gt; Active: active (running) since Thu 2022-10-13 16:55:50 UTC; 12h ago Docs: man:nginx(8) Process: 24456 ExecReload=/usr/sbin/nginx -g daemon on; master_process on; \u0026gt; Main PID: 21207 (nginx) Tasks: 2 (limit: 1143) Memory: 7.9M CGroup: /system.slice/nginx.service ├─21207 nginx: master process /usr/sbin/nginx -g daemon on; master\u0026gt; └─24457 nginx: worker process Oct 13 16:55:50 ip-172-31-3-151 systemd[1]: Starting A high performance web ser\u0026gt; Oct 13 16:55:50 ip-172-31-3-151 systemd[1]: Started A high performance web serv\u0026gt; Oct 14 05:21:09 ip-172-31-3-151 systemd[1]: Reloading A high performance web se\u0026gt; Oct 14 05:21:09 ip-172-31-3-151 systemd[1]: Reloaded A high performance web ser\u0026gt; lines 1-16/16 (END) 위에 sudo service nginx reload 를 실행한 결과, :8000을 입력하지 않고, python manage.py runserver를 하지 않고 public IPv4 만 입력해도 애플리케이션을 불러올 수 있다.\n하지만, css가 전혀 적용되지 않는다.\n이를 직접 보고 싶으면 불러온 사이트의 inspection tool로 들어가서 Network \u0026gt; CSS 를 클릭하면 status code를 보고 알 수 있다.\nReference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/django/deployment/deployment-with-nginx-uwsgi-ec2_1/","summary":"django appliation을 nginx와 uwsgi를 사용하여 배포하는 과정을 학습한다.","title":"Django study: nginx와 uwsgi를 사용한 django application deployment 01 - nginx와 uwsgi 연결하기"},{"categories":"Book Study","content":"0. Introduction 로버트 C. 마틴이 지은 클린 코드(Clean code) 를 읽고 진행한 북 스터디입니다. 각 chapter를 읽고 내용 정리하는 식으로 진행했습니다. 이번 book study를 진행하면서 code에 대한 철학이 생기고, code를 바라보는 눈이 깊어지고, 넓어지기를 바라며 시작합니다. 어떤 자세로 읽어야 하는가? 장인 정신을 익히는 과정은 두 단계(: 이론 과 실전)로 나뉜다고 한다. 이론: 장인에게 필요한 원칙, 패턴, 기법, 경험이라는 지식을 습득하는 단계 실전: 열심히 일하고 연습하여 이론을 체화시키는 단계 예로 들자면 ‘자전거 타기’를 들 수 있다. 이 자전거 타는 것에 대해 수학적으로 미적분을 활용하여 물리적인 원리를 설명하고 이해할 수 있으나, 이를 가지고 자전거를 탈 수 있는 건 아니다. 코드도 그렇다. 이론만 안다고 깨끗한 코드를 작성할 수 없고, 직접 부딪히고 고생해보고 깍아내는 노력을 통해서 나오는 결과물이 ‘Clean code’ 다. 그래서 이 책은 마음 편히 읽을 책이 아닌, 손과 마음으로 고생할 준비로 읽어야 하는 책 이다. 책의 큰 구성 설명 책 구성 순서: 클린 코드(clean code)를 작성하는 원칙,패턴 → 여러 사례 연구를 보면서 타당한 이유를 통해 문제가 적은 코드로 바꿔보기 → 결론 그러면 첫 번째 순서부터 진행해보자. 2장 의미 있는 이름 소프트웨어에서 이름은 변수, 함수에도 이름을 붙이고, 인수 - 클래스 - 패키지, 소스 파일, 디렉토리 에도 붙인다.\n그 만큼 명명은 개발자에게 많은 비중을 차지하고, 중요하므로 이름을 잘 짓는 간단한 규칙을 몇 가지 소개한다.\n의도를 분명히 밝히는 것의 중요성 좋은 이름에는 시간이 걸리지만, 그 후에는 이 이름으로 절약하는 시간이 더 많다.\n그러므로, 이름을 주의 깊게 살펴 더 나은 이름이 떠오르면 개선하라.\n이름을 듣고, ‘존재이유 + 수행 기능 + 사용방법은 무엇인가?’ 라는 질문이 생각나고, 주석이 필요하다고 느낀다면 의도를 분명히 드러내지 못한 것이다.\n이름이 주석이 되도록 하라.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 ## case 1 # 잘못된 변수명 + 주석 O d = 0 # 경과 시간(단위: 날짜) # 좋은 변수명 + 주석 X elapsed_time_in_days = 0 days_since_creation = 0 days_since_modification = 0 file_age_in_days = 0 #################################### ## case 2 # 잘못된 변수명 + 주석 O a = 0 # A 학점을 받은 학생 수 b = [80, 20, 30, 50, 90, 95, 98] # 점수 목록 for i in len(b): if b[i] \u0026gt;= 90: # b[i] 점수를 의미 a += 1 # 좋은 변수명 + 주석 X count_students_get_a = 0 a_score_standard = 90 score_list = b = [80, 20, 30, 50, 90, 95, 98] for i in len(score_list): if\tscore_list[i] \u0026gt;= a_score_standard count_students_get_a += 1 그릇된 정보를 피하라 코드에 그릇된 정보를 남겨서는 안된다.\n그러면 그릇되었다는 기준이 무엇일까?\n첫 번째, 그 단어가 나름대로 널리 쓰이는 의미가 있다면 다른 의미로 작성했을 지라도, 의미가 그릇되어 전달될 수 있다. 여러 계정을 그룹으로 묶을 때, 실제 List가 아니면 accountList라 하면 안되는데, 왜냐하면 프로그래머에게 List는 특수한 의미를 가지기 때문이다. 실제 데이터 타입이 list가 아니면 그릇된 정보를 제공하는 것 두 번째, 서로 흡사한 이름을 사용하여 차이를 알아차리지 못하는 것도 그릇된 정보로서, 일관성이 떨어지는 표기법 이름 몇 글자만 입력한 후, 후보 목록이 뜨는데 그 목록들이 이름만 보고 각 개념 차이가 명백한다면 코드 자동 완성 기능은 굉장히 유용하다. 의미 있게 구분하라: 읽는 사람이 차이를 알도록 작명하라 단지 컴파일러나 인터프리터만 통과하려는 생각으로 코드를 구현하지 마라.\n읽는 사람이 차이를 알도록 작명하라.\n연속적인 숫자를 사용하지 말라\nex)a1, a2, …, aN 아무런 정보를 제공하지 못하는 이름으로, 저자 의도가 전혀 드러나지 않는다. 1 2 3 # 잘못된 예시 a1 = \u0026#39;\u0026#39; a2 = \u0026#39;\u0026#39; 불용어(noise word)를 추가한 이름도 아무런 정보를 제공하지 못 한다.\n아래 예시의 함수명은 확실하게 차이를 느낄 수 없다. info, data, record는 a, an, the와 마찬가지로 의미가 불분명한 불용어다. 확실한 차이가 있다면 사용해도 된다. 1 2 3 4 5 6 7 # 잘못된 예시 def getUserInfo(): pass def getClientData(): pass def getCustomerRecord(): pass # 좋은 예시 def getUser(): pass 또 다른 잘못된 예시 1 2 3 4 # 잘못된 예시 class GetActiveAccount: class GetActiveAccounts: class GetActiveAccountInfo: 발음하기 쉬운 이름을 사용하라 개발은 여러 사람과 의논을 하면서 진행하는 것이기 때문에, 변수를 언급하는 경우가 많다. 그래서 발음하기 쉬운 변수명으로 작성하라.\n1 2 3 4 5 6 7 8 ## 잘못된 예시 # generate date, year, month, day, hour, minute, second genymdhms = \u0026#39;\u0026#39; modymdhms = \u0026#39;\u0026#39; ## 좋은 예시 generation_time_stamp = \u0026#39;\u0026#39; modification_time_stamp = \u0026#39;\u0026#39; 검색하기 쉬운 이름을 사용하라 나중에 버그를 해결하기 위해서, 변수를 찾을 때 쉽게 찾을 수 있도록 작명하라.\n이런 관점에서 볼 때, 긴 이름이 짧은 이름보다 좋다. 검색하기 쉬운 이름이 상수보다 낫다. 1 2 3 4 5 6 7 8 9 10 11 12 # 잘못된 코드 for j in range(0, 34): s += (t[j]*4) / 5 # 좋은 코드 real_days_per_ideal_day = 4 work_days_per_week = 5 sum = 0 for j in range(number_of_tasks): real_task_days = task_estimate[j] * real_days_per_ideal_day real_task_weeks = real_task_days / work_days_per_week sum += real_task_weeks 인코딩을 피하라 유형이나 범위 정보까지 넣으면 해독이 어렵고, 발음하기도 어렵다.\n자신의 기억력을 자랑하지 말라. 문제 영역이나 해법 영역에서 사용하지 않는 이름을 변수로 사용하지 말라. 예를 들어서 자신이 아는 이름으로 작성한 경우를 말한다. 루프에서 반복 횟수를 세는 변수 i, j, k 는 괜찮다(l은 절대 안된다). 왜냐하면 전통적으로 이 부분에서는 한 글자를 사용하기 때문이다. 그 이외에는 적절하지 않다. 똑똑한 개발자가 아닌 전문가 개발자는 ‘명료함이 최고’라는 사실을 이해한다. 전문가 개발자는 남들이 이해하는 코드를 내놓는다. 해법 영역, 문제 영역에서 가져온 이름 사용하기 먼저, 각 영역에 관련이 깊은 코드면 그 영역에서 이를 가져와야 한다.\n그렇지 않다면 다음과 같은 순서를 따르자.\n해법 영역에서 가져오기 전산 용어, 알고리즘 이름, 패턴 이름, 수학 용어 등을 사용해도 괜찮다. 모든 이름을 문제 영역에서 가져온다면 변수를 이해하기 위해 매번 고객에게 의미를 물어봐야하기 때문이다. 기술 개념에는 기술 이름이 가장 적합한 선택이다. 문제 영역에서 가져오기 위에 해법 영역에서 적절한 용어가 없을 경우, 문제 영역에서 이름을 가져온다. 개발자는 그러면 전문가에게 의미를 물어 파악할 수 있다. 우수한 개발자와 설계자라면 해법 영역과 문제 영역을 구분할 줄 알아야 한다.\n클래스, 메서드 이름 클래스 이름 명사, 명사구 적합 + 동사 사용 x Manager, Processor, Data, Info 등 같은 단어는 피하기 메서드 이름 동사, 동사구 적합 ex) 좋은 예시: postPayment, deletePage, save 기발한 이름 피하기 재미난 이름보다 명료한 이름을 선택하라. 의도를 분명하고, 솔직하게 표현해라. 특정 문화에서만 사용하는 농담은 피하는 편이 낫다. 한 개념에 한 단어 사용하기 + 말장난 피하기 첫 번째, 추상적인 개념 하나에 단어 하나만을 사용하도록 선택하여 이를 고수하라. 일관성 있는 어휘는 코드를 사용할 프로그래머가 반갑게 여겨야 한다. 예를 들어 Manager, Controller 는 근본적으로 무엇이니 다른가? 이름이 다르면 독자는 당연히 클래스도 다르고, 타입도 다르리라 생각한다. 두 번째, ‘일관성’보다 문맥이 우선이다. 기존 add method는 기존 값 두 개를 더하거나, 새로운 값을 만드는 기능이라고 할 때, 집합에 값 하나를 추가하는 method를 만들려고 한다. 변수명을 어떻게 할 것인가? 맥락이 다르기 때문에, 동일하게 작성하면 안된다.\n집중적인 탐구가 필요한 코드가 아닌, 대충 훑어봐도 이해할 수 있는 코드 작성이 목표!\n의미 있는 맥락 추가하고, 불필요한 맥락 제거하기 의미가 분명한 경우에 한해서 짧은 이름이 긴 이름보다 낫다. 길이보다 분명한 의미 전달이 더 중요하다.\n의미가 분명하지 않은 이름들이 대다수이기 때문에 알고리즘, 클래스, 함수, 이름 공간에 넣어 맥락을 표현하라. 그래도 불분명하면 접두어를 사용 아래 코드는 끝까지 읽어야만 의미를 알 수 있다. 즉, 메서드만 훑어서는 변수의 의미가 불분명하다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 ## Case 1: 접두어 사용 예시 # 나쁜 코드: 맥락이 불분명한 변수 firstName = \u0026#39;\u0026#39; lastName = \u0026#39;\u0026#39; # 좋은 코드: 맥락이 분명한 변수 class Address(): def addFirstName(): pass def addLastName(): pass #################################### ## Case 2 # 나쁜 코드: 초반부만 읽어서 변수 세 개가 어디에 사용되는지 명확하지 않음 def printGuessStatistis(candidate: str, count: int) -\u0026gt; None: number = str() verb = str() pluralModifier = str() if not count: number = \u0026#39;no\u0026#39; verb = \u0026#39;are\u0026#39; pluralModifier = \u0026#39;s\u0026#39; elif count == 1: number = \u0026#39;1\u0026#39; verb = \u0026#39;is\u0026#39; pluralModifier = \u0026#39;\u0026#39; else: number = str(count) verb = \u0026#39;are\u0026#39; pluralModifier = \u0026#39;s\u0026#39; print(\u0026#34;There {} {} {}{}\u0026#34;.format(verb, number, candidate, pluralModifier)) # 좋은 코드 class GuessStatisticsMessage(): def __init__(self, number: str, verb: str, plural_modifier: str): self.number = number self.verb = verb self.plural_modifier = plural_modifier def make(self, candidate: str, count: int) -\u0026gt; str: self.candidate = candidate self.count = count self.createPluralDependentMessageParts(self.count) return f\u0026#39;There {self.verb} {self.number} {self.candidate}{self.plural_modifier}\u0026#39; def createPluralDependentMessageParts(self, count): if not count: self.thereAreNoLetters() elif count == 1: self.thereIsOneLetter() else: self.thereAreManyLetters(count) def thereAreManyLetters(self, count): self.number = str(count) self.verb = \u0026#39;are\u0026#39; self.plural_modifier = \u0026#39;s\u0026#39; def thereIsOneLetter(self): self.number = \u0026#39;1\u0026#39; self.verb = \u0026#39;is\u0026#39; self.plural_modifier = \u0026#39;\u0026#39; def thereAreNoLetters(self): self.number = \u0026#39;no\u0026#39; self.verb = \u0026#39;are\u0026#39; self.plural_modifier = \u0026#39;s\u0026#39; 다음으로 불필요한 맥락에 대해서 얘기해보겠다.\nGSD(고급 휘발유 충전소, Gas Station Deluxe의 약어) 라는 애플리케이션을 만든다고 하여, 클래스 이름 앞에 GSD를 붙이지 말자. G를 입력하고, 자동 완성을 누를 경우, 모든 클래스가 나타나서 효율적이지 못하다. GSD 회계 모듈에 메일 주소 클래스를 GSDAccountAddress로 했다. 이와 비교해서 MailingAddress class와 비교했을 때 무엇이 적절할까? 바로 후자다. 전자는 불필요한 맥락이 많다. 제일 어려운 점 좋은 설명 능력 + 동일한 문화적 배경 → 좋은 이름 선택 이 부분이 제일 어렵다. 이름을 바꾸지 않으려는 이유가 다른 개발자가 반대할까 두려워서다. 개발자들 대다수는 클래스와 메서드 이름을 모두 암기하지 못 하기 때문에, 암기는 도구에게 맡기자. 이름을 바꿔서 코드 가독성을 높여보자. Reference 클린 코드(Clean code) ","permalink":"http://jeha00.github.io/post/bookstudy/cleancode/chatper02_name/","summary":"로버트 C. 마틴이 지은 클린 코드의 Chapter 02를 읽고 남긴 후기다. 변수를 지을 때 유의사항들에 알려줬고, 파이썬 코드로 코드 개선 작업을 직접 해보았다. 변수 작명에 사용자의 의도를 어떻게 명확히 드러내야하는지 알았다.","title":"Clean Code: Chapter 02 변수"},{"categories":"Book Study","content":"0. Introduction 로버트 C. 마틴이 지은 클린 코드(Clean code) 를 읽고 진행한 북 스터디입니다. 각 chapter를 읽고 내용 정리하는 식으로 진행했습니다. 이번 book study를 진행하면서 code에 대한 철학이 생기고, code를 바라보는 눈이 깊어지고, 넓어지기를 바라며 시작합니다. 어떤 자세로 읽어야 하는가? 장인 정신을 익히는 과정은 두 단계(: 이론 과 실전)로 나뉜다고 한다. 이론: 장인에게 필요한 원칙, 패턴, 기법, 경험이라는 지식을 습득하는 단계 실전: 열심히 일하고 연습하여 이론을 체화시키는 단계 예로 들자면 ‘자전거 타기’를 들 수 있다. 이 자전거 타는 것에 대해 수학적으로 미적분을 활용하여 물리적인 원리를 설명하고 이해할 수 있으나, 이를 가지고 자전거를 탈 수 있는 건 아니다. 코드도 그렇다. 이론만 안다고 깨끗한 코드를 작성할 수 없고, 직접 부딪히고 고생해보고 깍아내는 노력을 통해서 나오는 결과물이 ‘Clean code’ 다. 그래서 이 책은 마음 편히 읽을 책이 아닌, 손과 마음으로 고생할 준비로 읽어야 하는 책 이다. 책의 큰 구성 설명 책 구성 순서: 클린 코드(clean code)를 작성하는 원칙,패턴 → 여러 사례 연구를 보면서 타당한 이유를 통해 문제가 적은 코드로 바꿔보기 → 결론 그러면 첫 번째 순서부터 진행해보자. 1장 깨끗한 코드 1.1 코드가 존재하리라 코드는 요구사항을 컴퓨터가 이해할 수 있도록 정확히 명시하는데 반드시 사용해야 하는 언어로서, 도구이자 결과다.\n언젠가 코드가 사라질 거라 믿는 사람들이 존재하는데, 이는 요구사항을 모호하게 줘도 우리의 의도를 정확히 궤뚫어 프로그램을 완벽하게 실행하는 기계가 생길거라 믿는 것과 동일하다.\n요구사항을 어느 순간이든 정밀하게 표현하는 게 필요하기 때문에, 코드는 항상 존재할 수 밖에 없다.\n1.2 나쁜 코드 나쁜 코드는 회사가 망할 수 있을 정도의 원인이 된다.\n그러면 어째서 나쁜 코드를 짠 것일까? 모두가 경험한 흔한 이유들 때문이다.\n우린 자신이 짠 쓰레기 코드를 나중에 손보겠다고 생각하지만, 결코 나중은 오지 않는다.\n1.3 나쁜 코드로 치르는 대가 나쁜 코드 누적 → 생산성 저하\n나쁜 코드를 개선하기 위해서 인력을 추가한다고 해도, 시스템 설계에 대한 조예가 깊지 않으면 결국 더 많이 양산한다.\n1.3.1 원대한 재설계의 꿈 결국 재설계를 요구하여, 기존 기능들을 다 할 수 있을 정도의 새 시스템을 짤려고 시도한다. 이 시도는 예상 밖으로 매우 오래 진행되기도 한다. 10년이 넘게 걸리기도 하다.\n시스템 재설계가 끝날 때쯤 초창기 팀원들은 떠나가고, 다시 새 시스템을 설계하자는 의견이 나온다.\n깨끗한 코드를 만드는 노력이 비용 절감 뿐만 아니라, 전문가로서 살아남는 길이다.\n1.3.2 태도 우리는 여러 이유로 나쁜 코드를 작성하게 된다. 그리고, 그 이유로 합리화를 한다.\n하지만, 우리는 전문가이기 때문에 우리의 탓으로 인정하고 받아들여야 한다.\n대다수의 관리자는 진실을 원하고, 좋은 코드를 원한다. 일정과 요구사항을 그들이 밀어붙이는 이유는 그것이 그들의 책임이기 때문이다.\n우리가 의사고, 코드를 짜는 게 환자를 구하는 수술이라고 생각한다면 과연 우리는 함부로 그렇게 할 수 있을까?\n1.3.3 원초적 난제 나쁜 코드를 작성하는 시점에서는 시간을 줄이는 방법이라 생각하지만, 보다 거시적인 관점에서 보면 시간을 날리고, 기한을 맞추기 어렵게 만드는 방법이다.\n하지만, 좋은 코드를 작성하는 시점에서는 시간을 낭비하는 방법이라 생각하지만, 보다 거시적인 관점에서 보면 시간을 아끼고, 빨리 가서 기한을 맞출 수 있는 방법이다.\n1.3.4 깨끗한 코드라는 예술? 깨끗한 코드를 작성하기 위해서는 ‘코드 감각’이 타고나야 한다. 이는 투쟁해서 얻어야 하기도 한다. 이 감각이 있으면 좋은 코드와 나쁜 코드를 구분하는 것을 넘어서 나쁜 코드를 좋은 코드로 바꾸는 전략도 파악한다.\n1.3.5 깨끗한 코드란? 세세한 사항까지 꼼꼼하게 처리하는 코드 ex) 메모리 누수, 경쟁 상태, 일관성 없는 명명법 가독성 있는 코드 : 읽는 동안 자연스럽게 흐름이 떠올리는 것 ⇒ 명쾌함(단호함) 테스트 케이스가 있는 코드 → 다른 사람이 고치기 쉬운 코드 중복 줄이기 + 간단한 추상화 고려하기 + 아이디어 명확히 표현하기 독해하면서 머리를 쥐어짤 일이 없는 코드 1.4 우리들 생각 이 책에서 가르치는 기법을 따른다면 깨끗하고 수준 높은 코드를 작성하리라 장담한다. 하지만, 절대적으로 옳다는 생각은 금물 수십 년에 걸친 경험과 반복적인 시행착오로 습득한 교훈과 기법이므로, 이해하기 1.5 우리는 저자다 코드를 읽는 시간이 코드를 짜는 시간의 10배를 훌쩍 넘는다.\n그렇기 때문에 읽기 쉬운 코드가 매우 중요하다.\n급해서 서둘러 끝내려면, 그리고, 쉽게 짜려면, 읽기 쉽게 만들자.\n1.6 보이스카우트 규칙 나갈 때는 들어올 때보다 더 깨끗하게 하고 떠나라.\n변수 이름 하나 개선 조금 긴 함수 하나 분할 약간의 중복 제거 복잡한 If 문 하나로 정리 1.8 결론 좋은 코드와 나쁜 코드의 구체적인 사례를 보면서 개선 방법도 소개하고, 예제도 많으므로 연습하자.\nReference 클린 코드(Clean code) ","permalink":"http://jeha00.github.io/post/bookstudy/cleancode/chatper01_cleancode/","summary":"로버트 C. 마틴이 지은 클린 코드의 Chapter 01를 읽고 남긴 후기다. 왜 깨끗한 코드로 작성해야하는지, 이 태도를 가져야만 하는 이유에 대해 설명하는 소단원이었다. 보다 거시적인 관점으로 봤을 때, 깨끗한 코드가 시간을 절약한다.","title":"Clean Code: Chapter 01 클린 코드"},{"categories":"Book Study","content":"짧은 소감 나는 ‘교육’ , ‘ 시스템’ 그리고 ‘문화’ 에 대해 정말 중요하게 생각한다.\n‘교육’ 과 ‘시스템’에 따라 구성원과 공동체의 잠재력을 최대한 끌어올릴 수 있고, ‘문화’ 가 어떠냐에 따라 집단의 분위기가 결정되고, 이는 결과로 나타난다.\n이것이 바로 애자일에 속한다.\n애자일하게 살아가보자.\nP.S 나중에 나이를 많이 먹든, 경력이 많아지면 이를 하드스킬이든 소프트 스킬이든 이를 코칭하는 역할을 해보고 싶다. 내가 가진 것들을 나누고 싶다. 많은 사람들이 오로지 자신의 노력으로만 성취와 그 자리를 얻었다고 생각하지만, 우리 삶은 우리가 생각하는 것 이상으로 엄청나게 많은 부분에서 일명 ‘운’이라는 부분으로 받은 게 많다.\n새로 알게된 점 1) 의도적인 수련 1만 시간의 법칙을 단지 그 분야에 사용한 시간으로 다들 잘 못 알고 있는데, 의도적인 수련에 사용한 시간만 1만 시간이라는 것이다. 즉, 그 분야에 사용한 시간은 그 이상이라는 것 2) 프로그래밍 언어 배우기의 달인 프로그래밍 언어 문법을 배우는데 있어서, 문법 자체에 focus를 두기보다는 언어는 도구라는 걸 명심하고, 특정 프로그램을 만들 생각으로 ‘튜토리얼’을 통해 문법을 학습해가면서 문법을 바로 바로 사용해보는 것 이는 다른 개발자 학습 관련 기사에서도 나오는 내용이다. 바로 사용하고, 막히면 다시 문법 내용으로 돌아오고, 이 전환과 피드백이 빠를 수록 빨리 학습한다. 튜토리얼 문서를 잘 사용하자. 그런데 이 부분은 한 문법에 깊이 학습해본 사람이어야 가능하지 않을까 싶다. 3) 뛰어난 선생에 대한 미신 지식의 양이 뛰어난 선생이 아닌, 어떠한 사고와 관점으로 바라보는지를 통해 잘 알려주는 사람이 뛰어난 선생이다. 이는 수능 강사들만 봐도 충분히 알 수 있다. 일명 ‘강의력’ 이라고 하지 않는가? 그래서 교육하는 능력도 ‘재능’ 이고, 연구가 필요하다. 즉, 구체적인 사례를 알려주는 것이다. 우리가 사용할 것은 멘토님들에게 단순히 학습 내용만을 물어보는 게 아닌, 그 내용을 학습하고 바라보는데 가지는 관점과 태도를 물어봐야겠다. 뛰어난 선생이 아니라면, 우리가 뛰어난 학습자로서 선생으로부터 뽑아내자. 4) 나홀로 전문가에 대한 미신 전문가 특히 여러 분야 중 개발자는 소프트 스킬보다 하드 스킬이 더 큰 영향을 준다고 생각했다. 1명의 천재가 혁신을 일으킨다고 하지 않는가? 하지만, 많은 전문가들은 이 소프트 스킬 또한 뛰어나다고 한다. 그런데, 스티븐 잡스는 이 소프트 스킬이 좋지 않다고 했는데 최상위 1% 를 제외한 전문가들을 의미하는 것 같기도 하다. 5) 신뢰를 쌓는 공유 내가 만든 것과 이를 공유하는 상대방 사이의 신뢰를 쌓기 위해 공유할 때가 있다. 이 때는 단 한가지만을 또는 여러 개 중 최고의 것만을 공유하는 게 아닌, 만든 모든 것을 공유하는 게 신뢰를 쌓는 것이다. 신뢰를 쌓는 게 중요한 이유는 ‘사회적 자산’ 이기 때문이다. 이 자산이 있어야만 ‘설득’ 을 할 수 있다. 이를 위해서는 소프트 스킬도 중요하지만, 신입으로서 하드 스킬의 준비도 중요하다. 6) 구글이 밝힌 탁월한 팀의 비밀 팀원들이 어떻게 상호작용하고, 자신의 일을 어떻게 바라보는지, 그리고 심리적 안정감을 가지는 지가 탁월한 팀을 결정하는 요소 여기서 특히 심리적 안정감에 대해 말하자면 팀원이 부족한 의견, 어리석은 질문, 불편한 문제 제기, 어처구니 없는 실수를 저지를 때 놀림받지 않거나, 처벌받지 않을 거라는 안정감을 말한다. 한국은 특히 경쟁 문화에서 살아와서 이 심리적 안정감을 형성하는 게 쉽지 않다. 하지만, 팀원들 간의 안정감과 신뢰를 쌓기 위해서는 정말 중요한 요소라는 판단이 된다. ‘심리적 안정감’을 구축하자. 가장 기억에 남는 내용 소프트 스킬의 기본은 ‘신뢰’ 즉, ‘사회적 자본’ 이라고 생각한다. 이 신뢰가 있어야 ‘심리적 안정감’ 을 가지고 일할 수 있고, ‘설득’ 을 할 수 있다.\n‘이 사람은 믿을 만한 사람이야’ 라는 사람이 되고 싶다.\n앞으로 이뤄질 팀들과 함께 탁월한 팀을 이뤄보자.\n한줄평 현재 참여 중인 부트캠프에서 팀 프로젝트를 시작하기에 앞서서 이 책을 읽은 건 참으로 행운이고 감사하니, 실패할지라도 팀 프로젝트에 이 책 내용을 적용해보자.\n그래서 이 책 내용을 적용하여 성공한 것과 실패한 것을 review 02로 올려보겠다.\nReference 함께 자라기: 애자일로 가는 길 ","permalink":"http://jeha00.github.io/post/bookstudy/agile/review/","summary":"김창준님이 작성하신 함께 자라기- 애자일로 가는 길에 대한 후기","title":"함께 자라기: 애자일로 가는 길 review"},{"categories":"Linux","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 Jason.Kim 강사님의 Linux 강의로부터 학습한 자료입니다.\n지난 챕터에는 AWS를 사용한 Linux 명령어 학습 환경 조성을 하는데 목적을 두었다면, 이번에는 Linux 기본 명령어를 실습해보겠다.\nLinux의 기본 명령어는 모두 중요하므로, 다 학습해야 한다.\n이번 소챕터에서는 리눅스 명령어를 사용하여 시스템 종료 및 재시작하는 것을 실습해보고, 어떤 과정을 거쳐서 진행되는지 알아본다.\n5. 시스템 종료 및 재시작 5.1. Shutdown 시스템을 안전하게 종료하는 시스템 관리 명령어\n시스템을 종료하거나 재부팅\n현재 수행중인 프로세스(Program)들은 모두 종료하며 Sync 를 수행하여 아직 저장되어 있지 않은 데이터를 디스크에 저장한 후, 모든 파일 시스템을 Unmount 후 시스템을 종료\nunmount: 모든 장비를 해제시킨다. 5.2. 🔆 Shutdown과 시스템 종료 절차 shutdown 하기 전에 sync 작업(= 동기화)을 수행 한다. [sync]\n접속해 있는 사용자들에게 시스템이 종료된다는 메시지를 전달 한다.\n새로운 사용자의 로그인을 금지 한다.\n지정된 시간 내에 종료되지 않은 프로세스를 강제 종료 한다. [KILL]\n지정된 시간 내에 로그아웃하지 않은 사용자(계정)를 강제 종료 한다. [logout]\n메모리에 남아있는 데이터를 디스크에 저장 한다. [sync]\n시스템 종료와 관련된 정보를 시스템 로그 파일에 기록 한다. [wtmp, utrmp]\n마운트 되어 있는 디바이스들을 언마운트 한다. [unmount]\n시스템을 종료 한다. [system halt]\n5.3 Shutdown 명령어 명령어 사용법: shutdown [옵션] [시간] \u0026ldquo;전달메시지\u0026rdquo;\n옵션 의미 -k 시스템에 접속된 모든 사용자에게 경고 메시지만 전달 -h 시스템 셧다운(shutdown) 후, 시스템 종료 ex) shoutdown -h now -r 시스템 셧다운(shutdown) 후, 시스템 재시작 ex) shutdown -r now -f 빠른 재부팅(fsck 수행을 하지 않음) -c 실행 중인 셧다운(shutdown) 취소. 종료 예약 작업 시 종료 작업을 취소(ctrl +c) +m 현재 시간으로부터 종료시점 시간 지정(분) hh:mm 절대 시간으로 종료시점 시간 지정 (시간 : 분) now 명령어를 수행하는 순간 바로 종료 Reference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/linux/lecturenote06/","summary":"지난 내용에 이어서 linux의 기본 명령어로 shutdown과 이 명령어가 이뤄지는 과정에 대해 알아본다.","title":"[TIL]Linux: 기본 명령어 익히기 - shutdown과 그 과정"},{"categories":"Linux","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 Jason.Kim 강사님의 Linux 강의로부터 학습한 자료입니다.\n지난 챕터에는 AWS를 사용한 Linux 명령어 학습 환경 조성을 하는데 목적을 두었다면, 이번에는 Linux 기본 명령어를 실습해보겠다.\nLinux의 기본 명령어는 모두 중요하므로, 다 학습해야 한다.\n이번 소챕터에서는 date, rdate, file, find를 학습해본다.\n4. date, rdate, file, find 4.1 date와 rdate 타임 서버에서의 시간 정보를 시스템에 반영\nUTC를 KST로 전환하기 UTC 를 KST로 전환하기 1 2 3 4 5 6 7 [root@ip-172-31-8-107 ec2-user]# data Fri Sep 2 15:17:03 UTC 2022 [root@ip-172-31-8-107 ec2-user]# sudo rm /etc/localtime [root@ip-172-31-8-107 ec2-user]# sudo ln -sf /usr/share/zoneinfo/Asia/Seoul /etc/localtime [root@ip-172-31-8-107 ec2-user]# data Sat Sep 3 01:00:31 KST 2022 Linux 시간을 현재 시간으로 세팅하기 date 월 일 시 분 년 을 직접 입력하여 맞출 수 있으나, 정확히 맞히기 어렵다.\nex) date 073115302022 그래서 아래 절차를 통해 일치시킨다.\n타임 서버: 각 나라의 표준 시간을 관리하는 서버\nrdate 명령을 이용하여 타임 서버의 현재 시간을 화인\n1 2 3 # -p 에서 P는 Present를 의미 [root@ip-172-31-8-107 ec2-use]# rdate -p time.bora.net rdate: [time.bora.net]\tFri Sep 2 15:57:42 2022 rdate 명령을 이용하여 HOST 시간을 타임서버와 동기화\n1 2 # -s 에서 s는 setting을 의미 [root@ip-172-31-8-107 ~]# rdate -s time.bora.net 4.3 file 확장자를 기본으로 사용하지 않는 파일 종류 확인\nfile 명령어를 이용한 파일 유형[type] 확인 1 2 3 4 # ls 명령어는 bin 폴더에 포함되어 있다. # 빈 디렉토리 속에 있는 ls 명령에 해당되는 파일의 유형을 확인하라는 의미 [root@ip-172-31-8-107 ec2-user]# file ./temp/ ./temp/: directory file 명령어를 이용한 디스크 filesystem 종류 확인 1 2 [root@ip-172-31-8-107 ~]# file ./lib/ ./lib/: symbolic link to \u0026#39;usr/lib\u0026#39; 4.4 find ❗️ 파일 및 디렉토리 검색\n1. 시스템에 있는 \u0026lsquo;이름\u0026rsquo;으로 검색\nfind [경로] - name [파일명 or 디렉토리] 1 2 3 4 5 6 [root@ip-172-31-8-107 ec2-user]# ls -l total 0 drwxr-xr-x 2 root root 24 Sep 3 14:44 temp [root@ip-172-31-8-107 ec2-user]# find ./temp ./temp ./temp/login.defs Access Time이 n일보다 작거나 큰 파일 및 디렉토리 검색 find [경로] - atime -n(+n) test 파일 이후에 수정된 모든 파일들을 검색\nfind /home/ -newer test 명령 수행\nfind -name [문자열] - exec [명령] {} \\; find.-name\u0026quot;test*\u0026quot; -exec rm {}\\; root 권한으로 실행되는 파일 find . -user root -perm +4000 2\u0026gt; /dev/nul Reference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/linux/lecturenote05/","summary":"지난 내용에 이어서 linux의 기본 명령어들 중 date, rdate, file, find에 대해 학습해본다.","title":"[TIL]Linux: 기본 명령어 익히기 - date, rdate, file, find"},{"categories":"Linux","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 Jason.Kim 강사님의 Linux 강의로부터 학습한 자료입니다.\n지난 챕터에는 AWS를 사용한 Linux 명령어 학습 환경 조성을 하는데 목적을 두었다면, 이번에는 Linux 기본 명령어를 실습해보겠다.\nLinux의 기본 명령어는 모두 중요하므로, 다 학습해야 한다.\n이번 소챕터에서는 cat, head, tail, more를 학습해본다.\ncat는 전체 내용을 확인할 수 있으나, 너무 긴 내용일 경우 화면을 넘어가면 확인할 수 없다는 단점이 있다.\nhead와 tail은 전체 내용을 확인할 수 없고, head는 앞부분만 확인할 수 있고, tail은 끝 부분만 확인할 수 있다는 단점이 있어서 가운데 내용을 확인하기가 어렵다.\nmore의 단점: 지나간 내용을 볼 수 없다.\n3. cat, head, tail, more 이번 챕터 내용은 더 많이 중요하다.\n3.1 cat 기본 기능: 파일의 내용을 출력[보기]\n텍스트 파일의 내용을 표준 출력장치(모니터를 의미)로 출력하는 명령어\n5가지 기능 보기: 문서 파일 안을 보는 것 생성 추가 출력 생성: 생성된 내용에 추가한 내용을 합쳐서 출력 병합 보기 1 2 3 4 [root@ip-172-31-8-107 ec2-user]# cat /etc/passwd ... tcpdump:x:72:72::/:/sbin/nologin ec2-user:x:1000:1000:EC2 Default User:/home/ec2-user:/bin/bash 생성 cat 로 생성된 파일은 ls -al로도 확인할 수 없다. 1 2 3 4 5 6 7 [root@ip-172-31-8-107 ec2-user]# cat /etc/passwd \u0026gt; /testfile [root@ip-172-31-8-107 ec2-user]# ls -l /testfile -rw-r--r-- 1 root root 1312 Sep 2 08:51 /testfile # 아래 명령어 2개로 출력된 결과는 동일하다. [root@ip-172-31-8-107 ec2-user]# cat /testfile more [root@ip-172-31-8-107 ec2-user]# cat /etc/passwd 추가 아무런 경로 없이 cat \u0026gt; '생성될 파일 명칭' 을 입력하면 내용을 입력하기 위해 아무것도 뜨지 않는다. 입력을 완료했으면 fn + enter 를 입력하여 종료한다. 1 2 3 4 5 6 7 8 9 10 11 [root@ip-172-31-8-107 ec2-user]# cat \u0026gt; a Learningspoons nanodegree [root@ip-172-31-8-107 ec2-user]# ls -l -rw-r--r-- 1 root root 29 Sep 2 09:45 a ... [root@ip-172-31-8-107 ec2-user]# cat a Learningspoons nanodegree 그러면 동일한 파일명으로 다시 추가하면, 내용이 달라지고 생성 시간과 크기도 달라졌다는걸 알 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@ip-172-31-8-107 ec2-user]# cat \u0026gt; a Learningspoons: nanodegree Python \u0026amp; Django backend course # 까지 입력 후 fn + enter를 입력 [root@ip-172-31-8-107 ec2-user]# cat a learningspoons: nanodegree Python \u0026amp; Django backend course [root@ip-172-31-8-107 ec2-user]# ls -l ... total 20 -rw-r--r-- 1 root root 58 Sep 2 09:54 a ❗️❗️ 만약 리눅스의 한 시스템과 동일한 명칭의 파일을 위 명령어로 추가한다면 리눅스가 작동하지 않아, 다시 깔아야할 일이 발생하므로 매우 조심해야 한다.\n출력 생성 기존 내용에 추가하여 출력하기: cat \u0026raquo; \u0026lt;기존에 있던 파일명\u0026gt;\n1 2 3 4 5 6 7 [root@ip-172-31-8-107 ec2-user]# cat \u0026gt;\u0026gt; a jeha00 trainee majoring aerospace and mechanical engineering [root@ip-172-31-8-107 ec2-user]# cat a learningspoons: nanodegree Python \u0026amp; Django backend course jeha00 trainee majoring aerospace and machanical engineering 병합 다른 파일과 합치기\n다른 파일과 합치기 위해서 2개의 파일을 준비하자. 그래서 위의 코드에서 만든 a를 이어서 사용한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # b를 생성 [root@ip-172-31-8-107 ec2-user]# cat \u0026gt; b I\u0026#39;m on boarding of this bootcamp [root@ip-172-31-8-107 ec2-user]# ls -l total 20 -rw-r--r-- 1 root root 119 Sep 2 14:48 a -rw-r--r-- 1 root root 34 Sep 2 14:54 b ... [root@ip-172-31-8-107 ec2-user]# cat a b \u0026gt; c [root@ip-172-31-8-107 ec2-user]# ls -l total 24 -rw-r--r-- 1 root root 119 Sep 2 14:48 a -rw-r--r-- 1 root root 34 Sep 2 14:54 b -rw-r--r-- 1 root root 153 Sep 2 14:58 c [root@ip-172-31-8-107 ec2-user]# cat c learningspoons: nanodegree Python \u0026amp; Django backend course jeha00 trainee majoring aerospace and machanical engineering I\u0026#39;m on boarding of this bootcamp 위 c를 보면 a와 b의 크기가 합쳐진 값임을 알 수 있다.\n반대로 cat b a \u0026gt; d를 하면 입력된 내용이 반대인 d file이 생성된다.\n3.2 head 기본 기능: 파일의 내용 중 위에서부터 아래로 10줄 출력\nhead [-n] [파일명]\nn의 수 만큼 줄을 읽는다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 위에 cat은 다 읽었지만, head를 써보면 다르다. # 위에 언급한 대로 위에서부터 10줄을 읽었다. [root@ip-172-31-8-107 ec2-user]# head /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin sync:x:5:0:sync:/sbin:/bin/sync shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown halt:x:7:0:halt:/sbin:/sbin/halt mail:x:8:12:mail:/var/spool/mail:/sbin/nologin operator:x:11:0:operator:/root:/sbin/nologin 이번에는 위에서부터 5줄만 읽어보자. 1 2 3 4 5 6 [root@ip-172-31-8-107 ec2-user]# head -5 /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin adm:x:3:4:adm:/var/adm:/sbin/nologin lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin 3.3 tail 기본 기능: 파일의 내용 중 아래(마지막)에서부터 위로 10줄 출력\ntail [-n] [파일명]\nn의 수 만큼 줄을 읽는다. 하지만 기본적으로 n을 입력하지 않고, 파일명만 입력하면 10줄을 읽는다. 1 2 3 4 5 6 7 8 9 10 11 12 13 # 마지막에서부터 10줄임을 알 수 있다. [root@ip-172-31-8-107 ec2-user]# tail /etc/passwd libstoragemgmt:x:999:997:daemon account for libstoragemgmt:/var/run/lsm:/sbin/nologin sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin rpcuser:x:29:29:RPC Service User:/var/lib/nfs:/sbin/nologin nfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologin rngd:x:998:996:Random Number Generator Daemon:/var/lib/rngd:/sbin/nologin ec2-instance-connect:x:997:995::/home/ec2-instance-connect:/sbin/nologin postfix:x:89:89::/var/spool/postfix:/sbin/nologin chrony:x:996:994::/var/lib/chrony:/sbin/nologin tcpdump:x:72:72::/:/sbin/nologin ec2-user:x:1000:1000:EC2 Default User:/home/ec2-user:/bin/bash 이번에는 아래에서부터 5줄만 읽어보자. 1 2 3 4 5 6 [root@ip-172-31-8-107 ec2-user]# tail -5 /etc/passwd ec2-instance-connect:x:997:995::/home/ec2-instance-connect:/sbin/nologin postfix:x:89:89::/var/spool/postfix:/sbin/nologin chrony:x:996:994::/var/lib/chrony:/sbin/nologin tcpdump:x:72:72::/:/sbin/nologin ec2-user:x:1000:1000:EC2 Default User:/home/ec2-user:/bin/bash 3.4 more 기본 기능: 내용이 많은 파일을 화면 단위로 끊어서 출력\nmore [파일명]\n출력장치(모니터)의 높이만큼 출력한다.\n엔터를 누르면 한 줄씩 보여준다. 스페이스를 누르면 한 화면씩 넘어가준다. 실습을 위해 터미널 화면의 세로 폭을 반으로 줄여보자.\n1 [root@ip-172-31-8-107 ec2-user]# more ./etc/passwd 하지만, 단점으로 지나간 내용은 볼 수 없다. 이럴 경우, 마우스 휠을 사용해야 한다.\n3.5 less more의 단점을 해결한 명령어로 Vim 모드처럼 j와 k로 볼 수 있다.\n1 [root@ip-172-31-8-107 ec2-user]# less ./etc/passwd 위 명령어대로 입력한 후, enter를 누르면 j와 k로 움직이도록 변한다. q 를 사용하여 나간다. 3.6 nl cat처럼 보여주지만, 각 줄에 넘버가 붙여져 출력된다.\n1 2 3 4 5 6 7 [root@ip-172-31-8-107 ec2-user]# nl ./etc/passwd ... 22\tec2-instance-connect:x:997:995::/home/ec2-instance-connect:/sbin/nologin 23\tpostfix:x:89:89::/var/spool/postfix:/sbin/nologin 24\tchrony:x:996:994::/var/lib/chrony:/sbin/nologin 25\ttcpdump:x:72:72::/:/sbin/nologin 26\tec2-user:x:1000:1000:EC2 Default User:/home/ec2-user:/bin/bash 3.7 파이프 사용하기 두 개의 명령어를 | 파이프라인을 사용하여 함께 사용한다.\n❗️ 파이프라인 앞에 명령어가 뒤 명령어에 영향을 미친다는 걸 알고 있어야 한다.\nnl 과 less 함께 사용하기 1 2 3 4 5 [root@ip-172-31-8-107 ec2-user]# nl ./etc/passwd | less ... 20 nfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologin 21 rngd:x:998:996:Random Number Generator Daemon:/var/lib/rngd:/sbin/nologin : more을 부가적인 명령어로 사용하기 만약 메인 명령어로 사용한다면, 뒤에 파일이 와야 한다. 1 2 3 4 5 6 7 8 9 [root@ip-172-31-8-107 ec2-user]# ls -l /etc/ | more ... -rw------- 1 root root 541 Jan 16 2020 anacrontab -rw-r--r-- 1 root root 1 Jan 16 2020 at.deny drwxr-x--- 3 root root 43 Aug 15 20:22 audisp drwxr-x--- 3 root root 83 Aug 30 04:09 audit drwxr-xr-x 2 root root 94 Aug 15 20:22 bash_completion.d -rw-r--r-- 1 root root 2853 Feb 21 2020 bashrc --More-- Reference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/linux/lecturenote04/","summary":"지난 내용에 이어서 linux의 기본 명령어들 중 cat, head, tail, more, less, nl에 대해 학습해본다.","title":"[TIL]Linux: 기본 명령어 익히기 - cat, head, tail, more, less, nl"},{"categories":"Linux","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 Jason.Kim 강사님의 Linux 강의로부터 학습한 자료입니다.\n지난 챕터에는 AWS를 사용한 Linux 명령어 학습 환경 조성을 하는데 목적을 두었다면, 이번에는 Linux 기본 명령어를 실습해보겠다.\nLinux의 기본 명령어는 모두 중요하므로, 다 학습해야 한다.\n이번 소챕터에서는 mkdir, rmdir, rm, alias, touch를 학습해본다.\n2. mkdir, rmdir, rm, alias, touch 2.1 mkdir 기본 기능: 디렉토리 생성(make directory)\nmkdir [옵션] [디렉토리명]\n옵션 의미 -m, \u0026ndash;mode 디렉토리의 기본 권한을 지정 -p, \u0026ndash;parents 필요한 경우, 상위 경로까지 생성 \u0026ndash;help 도움말 표시 -version 버전 정보 표시 디렉토리 생성하기 1 2 3 4 [root@ip-172-31-8-107 ~]# cd /home/ec2-user [root@ip-172-31-8-107 ec2-user]# mkdir ./test2 [root@ip-172-31-8-107 ec2-user]# ls adjtime test test2 하지만 아래와 같이 생성하려고 한다면 Error가 발생한다.\n왜냐하면 존재하지 않은 디렉토리 안에다가 생성하려고 했기 때문이다. 1 2 3 [root@ip-172-31-8-107 ec2-user]# rmdir test2 [root@ip-172-31-8-107 ec2-user]# mkdir ./test2/test3 mkdir: cannot create directory \u0026#39;test2/test3\u0026#39;: No such file or directory 위 Error의 해결책: -p 1 2 3 4 [root@ip-172-31-8-107 ec2-user]# mkdir -p ./test2/test3 [root@ip-172-31-8-107 ec2-user]# cd ./test2/test3 [root@ip-172-31-8-107 test3]# pwd /home/ec2-user/test2/test3 2.2 rmdir 기본 기능: 빈 디렉토리만 삭제(remove directory)\nmkdir [옵션] [디렉토리명]\n옵션 의미 -p, \u0026ndash;parents 필요한 경우 상위 경로까지 삭제 \u0026ndash;help 도움말 표시 -version 버전 정보 표시 빈 디렉토리만 삭제한다는 걸 확인해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@ip-172-31-8-107 test3]# pwd /home/ec2-user/test2/test3 [root@ip-172-31-8-107 test3]# cd .. [root@ip-172-31-8-107 test2]# rmdir test3 [root@ip-172-31-8-107 test2]# ls # 아무것도 확인할 수 없다. [root@ip-172-31-8-107 ec2-user]# cp ./adjtime ./test2 [root@ip-172-31-8-107 ec2-user]# ls ./test2 adjtime [root@ip-172-31-8-107 ec2-user]# rmdir ./test2 rmdir: failed to remove \u0026#39;./test2\u0026#39;: Directory not empty 옵션 -p의 경우, 상위 경로도 빈 directory여야만 삭제 가능하다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [root@ip-172-31-8-107 ec2-user]# mkdir -p ./a/b/c [root@ip-172-31-8-107 ec2-user]# ls -lR ./a ./a: total 0 drwxr-xr-x 3 root root 15 Sep 2 06:20 b ./a/b: total 0 drwxr-xr-x 2 root root 6 Sep 2 06:20 c ./a/b/c: total 0 [root@ip-172-31-8-107 ec2-user]# rmdir -p ./a/b/c [root@ip-172-31-8-107 ec2-user]# ls adjtime test test2 # 즉, ./a 까지 다 삭제되었다. [root@ip-172-31-8-107 ec2-user]# mkdir -p ./test2/test3/test4 [root@ip-172-31-8-107 ec2-user]# rmdir -p ./test2/test3/test4 rmdir: failed to remove directory \u0026#39;./test2\u0026#39;: Directory not empty # ./test2 에는 파일이 존재하기 때문에 ./a와 달리 삭제되지 않았다. 2.3 rm ❗️ 기본 기능: 파일 or 디렉토리 삭제 rm [옵션] [디렉토리명]\nrm 명령을 사용하면 삭제를 진짜할 것인지 물어본다. 옵션 의미 -f, \u0026ndash;force 파일 및 디렉토리 삭제 시, 의사(y/n)를 물어보지 않는다 -r, -R, \u0026ndash;recursive 일반 파일이면 그냥 삭제. 하지만, 디렉토리이면 디렉토리를 포함한 하위 경로와 파일을 모두 삭제 -v, \u0026ndash;verbose 각 파일 지우는 정보를 상세히 확인 \u0026ndash;version 버전 정보 표시 ❗️rm 명령어를 사용할 때는 항상 경로를 확인 후 사용해야 하며, -rf 옵션도 신중히 사용해야 한다.\n1 2 3 4 5 6 7 [root@ip-172-31-8-107 ec2-user]# cd ./test2 [root@ip-172-31-8-107 test2]# ls adjtime [root@ip-172-31-8-107 test2]# rm adjtime rm: remove regular file \u0026#39;adjtime\u0026#39;? y [root@ip-172-31-8-107 test2]# ls -f 사용하여 삭제하기 다시 다른 directory에 복사해오자. 1 2 3 4 5 6 7 [root@ip-172-31-8-107 ec2-user]# mkdir -p ./a/b/c/d/ [root@ip-172-31-8-107 ec2-user]# cp ./adjtime ./a [root@ip-172-31-8-107 ec2-user]# cp ./adjtime ./a/b/c [root@ip-172-31-8-107 ec2-user]# cp ./adjtime ./a/b/c/d/ [root@ip-172-31-8-107 ec2-user]# rm -f ./a/b/c/d/adjtime/ [root@ip-172-31-8-107 ec2-user]# ls -l ./a/b/c/d/ total 0 위에서 삭제한 것과 달리, 물어보지 않고 바로 삭제했다. 1 [root@ip-172-31-8-107 ec2-user]# rm ./a/b/c/d/adjtime -r 사용하여 삭제하기 삭제하려는 디렉토리를 포함하여 그 안에 있는 디렉토리와 파일들도 삭제하도록 묻는 옵션 1 2 3 4 5 6 7 8 9 10 [root@ip-172-31-8-107 ec2-user]# rm -r ./a/ rm: descend into directory \u0026#39;./a/\u0026#39;? y rm: descend into directory \u0026#39;./a/b\u0026#39;? y rm: descend into directory \u0026#39;./a/b/c\u0026#39;? y rm: remove directory \u0026#39;./a/b/c/d\u0026#39;? y rm: remove regular file \u0026#39;./a/b/c/adjtime\u0026#39;? y rm: remove directory \u0026#39;./a/b/c\u0026#39;? y rm: remove directory \u0026#39;./a/b\u0026#39;? y rm: remove regular file \u0026#39;./a/adjtime\u0026#39;? y rm: remove directory \u0026#39;./a/\u0026#39;? y -rf 로 함께 사용하여 삭제하기 묻지 않아서 손쉽게 삭제할 수 있지만, 1 2 3 4 5 6 7 8 9 [root@ip-172-31-8-107 ec2-user]# mkdir -p ./a/b/c/d/ [root@ip-172-31-8-107 ec2-user]# cp ./adjtime ./a [root@ip-172-31-8-107 ec2-user]# cp ./adjtime ./a/b/c [root@ip-172-31-8-107 ec2-user]# cp ./adjtime ./a/b/c/d/ [root@ip-172-31-8-107 ec2-user]# rm -r ./a/ [root@ip-172-31-8-107 ec2-user]# ls adjtime test # \u0026#39;a\u0026#39; directory가 삭제된 걸 알 수 있다. 삭제 시, 경로에 * 입력 1 2 3 [root@ip-172-31-8-107 ec2-user]# rm -rf ./* [root@ip-172-31-8-107 ec2-user]# ls -l total 0 하지만 ./*이 아니라, /*을 입력한다면?? 시스템 전체가 삭제되므로, 재설치해야한다. 2.4 alias 기본 기능: 별칭 지정, 복잡한 명령어와 옵션을 간단한 문자열로 치환(❗️일회성)\nalias [변수] = [값]\n1 2 3 4 5 [root@ip-172-31-8-107 ec2-user]# alias rrf=\u0026#39;rm -rf\u0026#39; [root@ip-172-31-8-107 ec2-user]# mkdir -f ./a/b/c/d [root@ip-172-31-8-107 ec2-user]# rrf ./a/ [root@ip-172-31-8-107 ec2-user]# ls total 0 2.5 touch 기본 기능: 파일 시간정보 변경 및 파일 생성\ntouch [파일명]\n크기가 0인 신규파일을 생성할 때, 많이 사용된다.\n1 2 3 4 5 6 [root@ip-172-31-8-107 ec2-user]# touch jeha00 [root@ip-172-31-8-107 ec2-user]# ls -l total 0 -rw-r--r-- 1 root root 0 Sep 2 07:39 jehakim # 위에 root root 0 에서 0을 통해서 파일 크기가 0임을 알 수 있다. 기존에 동일 이름의 파일이 있을 경우, 생성시간 및 최종 수정시간 변경\n1 2 3 4 5 6 7 8 9 # 위 코드에서 이어서 진행한다. # 다시 touch를 실행해보자. [root@ip-172-31-8-107 ec2-user]# touch jeha00 [root@ip-172-31-8-107 ec2-user]# ls -l total 0 -rw-r--r-- 1 root root 0 Sep 2 07:41 jehakim # 생성된 시간이 달라진 것을 알 수 있다. Reference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/linux/lecturenote03/","summary":"지난 내용에 이어서 linux의 기본 명령어들 중 mkdir,rmdir, rm, alias, touch에 대해 학습해본다.","title":"[TIL]Linux: 기본 명령어 익히기 - mkdir,rmdir, rm, alias, touch"},{"categories":"Django","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 김형종 강사님의 django 강의를 학습한 내용입니다.\ndjango 프로젝트를 만들고, 가상환경을 사용할 때 directory 구조의 좋은 방식을 알게 되어 이를 정리해놓는다.\n또한, 실제 현업에서 사용하는 방식이라고 하니 알아두자.\n기존에 사용한 방식 mkdir \u0026lt;directory명\u0026gt;으로 가상환경과 프로젝트를 담을 directory를 생성\nex) mkdir pjt1 cd \u0026lt;1에서 생성한 directory명\u0026gt; 으로 생성한 directory로 이동\n가상환경 생성: virtualenv \u0026lt;가상환경 이름\u0026gt; --python=\u0026lt;python version 명\u0026gt;\nvirtualenv env-before --python=3.8.9 ❗️ RuntimeError: failed to find interpreter for Builtin discover of python_spec=\u0026rsquo;'\n가상환경 실행: source ./\u0026lt;가상환경 이름\u0026gt;/bin/activate\nex) source ./env-before/bin/activate 장고 설치: pip install django==3.2.13\n장고 프로젝트 설치: django-admin startproject \u0026lt;project명\u0026gt;\nex) django-admin startproject before 1 2 3 4 5 6 7 8 9 10 11 12 13 # directory 구조 \u0026lt;project명\u0026gt; directory # ex) pjt1 ㄴ \u0026lt;project 명\u0026gt; # before ㅣ ㄴ \u0026lt;project 명\u0026gt; # before ㅣ ㅣ ㄴ __init__.py ㅣ ㅣ ㄴ asgi.py ㅣ ㅣ ㄴ settings.py ㅣ ㅣ ㄴ urls.py ㅣ ㅣ ㄴ wsgi.py ㅣ ㅣ ㅣ ㄴ manage.py ㅣ ㄴ db.sqlite3 ㄴ \u0026lt;가상환경 이름\u0026gt; # env-before 가상환경의 위치가 장고 프로젝트 파일들을 담고있는 폴더보다 상위 경로에 존재하기 때문에, 별도로 활성화해야한다. 새롭게 배운 방식 mkdir \u0026lt;project명\u0026gt; 으로 원하는 경로에 직접 directory를 만든다.\nex) mkdir pjt1 cd \u0026lt;project명\u0026gt; 으로 생성한 directory로 이동한다.\n그리고 나서 아래 명령어로 가상환경을 생성한다.\nvirtualenv \u0026lt;가상환경 이름\u0026gt; --python=\u0026lt;python version 명\u0026gt; ex) virtualenv env-after --python=3.8.9 가상환경 실행: source ./\u0026lt;가상환경 이름\u0026gt;/bin/activate\nex) source ./env-after/bin/activate 가상환경 실행 후, django 설치: pip install django==\u0026lt;version\u0026gt;\nex) pip install django==3.2.13 프로젝트 생성: django-admin startproject config .\n현재 경로에 프로젝트명으로 config를 생성하여 그 안에 프로젝트 파일들을 담는다. 설치된 모듈 문서화: pip freeze \u0026gt; requirements.txt\n이런 방식으로 만들면 위에 프로젝트 경로로 들어오면 바로 가상환경이 실행된다!\n1 2 3 4 5 6 7 8 9 10 11 12 # directory 구조 \u0026lt;project명\u0026gt; directory # ex) pjt1 ㄴ config ㅣ ㄴ __init__.py ㅣ ㄴ asgi.py ㅣ ㄴ settings.py ㅣ ㄴ urls.py ㅣ ㄴ wsgi.py ㅣ ㄴ \u0026lt;가상환경 이름\u0026gt; # env-after ㄴ manage.py ㄴ db.sqlite3 가상환경과 장고 프로젝트 파일들을 담고 있는 폴더의 level이 동일하여 들어가면 바로 활성화된다. ❗️만약 자동적으로 활성화되지 않는다면 터미널을 껐다가 새 터미널을 키면 자동 활성화가 된다.\nReference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/django/virtualenv_path/","summary":"경로에 들어오면 자동적으로 가상환경이 활성화되는 directory 구조에 대해 이전 방식과 비교하여 정리해놓는다.","title":"Django study: 가상환경 자동 활성화를 위한 directory 구조 및 설치 경로"},{"categories":"Linux","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 Jason.Kim 강사님의 Linux 강의로부터 학습한 자료입니다.\n지난 챕터에는 AWS를 사용한 Linux 명령어 학습 환경 조성을 하는데 목적을 두었다면, 이번에는 Linux 기본 명령어를 실습해보겠다.\nLinux의 기본 명령어는 모두 중요하므로, 다 학습해야 한다.\n이번 소챕터에서는 pwd, cd, ls, cp, mv를 학습해본다.\n1. pwd, cd, ls, cp, mv 1.1 pwd 현재 경로 보기(parent working directory)\n1 2 [root@ip-172-31-8-107 ~]# pwd /root 1.2 cd 원하는 디렉토리로 이동 (change directory의 약자)\n인자값 의미 . 현재 디렉토리 .. 상위 디렉토리 ~ 로그인 되어 있는 계정(사용자)의 Home directory ~계정명 지정한 계정(사용자)의 Home directory 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 [root@ip-172-31-8-107 ~]# pwd /root # 아래 명령어는 동일 [root@ip-172-31-8-107 ~]# cd /home/ [root@ip-172-31-8-107 ~]# cd /home [root@ip-172-31-8-107 home]# pwd /home [root@ip-172-31-8-107 home]# cd . [root@ip-172-31-8-107 home]# cd ./ [root@ip-172-31-8-107 home]# pwd /home [root@ip-172-31-8-107 ~]# cd ~ /root # 계정명 [root@ip-172-31-8-107 ~]# cd ~ec2-user [root@ip-172-31-8-107 ec2-user]# pwd /home/ec2-user [root@ip-172-31-8-107 ec2-user]# cd / [root@ip-172-31-8-107 /]# pwd / [root@ip-172-31-8-107 /]# ls -l total 16 lrwxrwxrwx 1 root root 7 Aug 15 20:20 bin -\u0026gt; usr/bin dr-xr-xr-x 4 root root 4096 Aug 15 20:23 boot drwxr-xr-x 15 root root 2900 Aug 30 04:09 dev drwxr-xr-x 80 root root 8192 Aug 30 04:09 etc .... [root@ip-172-31-8-107 /]# cd boot [root@ip-172-31-8-107 boot]# pwd /boot # 아래 error는 올바르다. 왜냐하면 boot는 계정이 아닌, directory이기 때문이다. # 현재 계정에서 계정은 Root와 user 2가지 밖에 없기 때문이다. [root@ip-172-31-8-107 /]# cd ~boot -bash: cd: ~boot: No such file or directory [root@ip-172-31-8-107 /]# cd home/ec2-user # 상위 경로로 이동해보자. # 아래 두 명령어는 동일하다. [root@ip-172-31-8-107 ec2-user]# cd ../ [root@ip-172-31-8-107 ec2-user]# cd .. [root@ip-172-31-8-107 home]# pwd /home [root@ip-172-31-8-107 home]# cd .. [root@ip-172-31-8-107 /]# pwd / # 또는 한 번에 최상위 경로로 이동할 수 있다. [root@ip-172-31-8-107 ec2-user]# cd ../../../ [root@ip-172-31-8-107 /]# pwd / # 아래 ls 실습으로 이어진다. 1.3 ls 기본 기능: 디렉토리 목록을 확인 ls [옵션] [디렉토리 or 파일]\n각 옵션들을 한 번에 합쳐서 입력 가능하다. ex) -ald, 순서는 상관 X 옵션 의미 -a, -all .을 포함한 경로 안의 모든 파일 및 디렉토리 -l, \u0026ndash;format = long 지정한 디렉토리의 내용을 상세하게 출력 -d, \u0026ndash;directory 지정한 디렉토리의 정보를 출력 -F, \u0026ndash;classfiy 파일 형식을 알리는 문자를 각 파일 뒤에 추가 -R,\u0026ndash;recursive 하위 경로와 그 안에 있는 모든 파일들도 같이 나열 위에 cd 명령어 실습으로부터 바로 이어진다. 디렉토리 목록 확인 1 2 [root@ip-172-31-8-107 /]# ls bin boot dev etc home lib lib64 local media mnt opt proc root run sbin srv sys tmp usr var 숨긴 내용까지 다 확인 1 2 [root@ip-172-31-8-107 /]# ls -a . .. .autorelabel bin boot dev etc home lib lib64 local media mnt opt proc root run sbin srv sys tmp usr var 목록 상세히 확인 하지만, 위 명령어로는 무엇이 폴더이고, directory인지 구분할 수 없다.\nd는 최상위 디렉토리를 의미 1 2 3 4 5 6 7 [root@ip-172-31-8-107 /]# ls -l lrwxrwxrwx 1 root root 7 Aug 15 20:20 bin -\u0026gt; usr/bin dr-xr-xr-x 4 root root 4096 Aug 15 20:23 boot drwxr-xr-x 15 root root 2900 Aug 30 04:09 dev drwxr-xr-x 80 root root 8192 Aug 30 04:09 etc drwxr-xr-x 3 root root 22 Aug 30 04:09 home ... 옵션 합쳐서 사용하기 만약 숨겨진 내용까지 상세히 목록을 보고 싶으면 ls -al로 옵션을 합쳐서 사용한다. 경로 이동 없이 목록 보기 경로 이동 없이, 찾고 싶은 경로의 목록을 보고 싶을 때: ls -l /\n1 2 3 4 5 6 # 현재 경로 [root@ip-172-31-8-107 ec2-user]# pwd /home/ec2-user [root@ip-172-31-8-107 ec2-user]# ls -l / # 그러면 위에 / 경로에서 ls -l 을 입력한 결과와 동일하다. 이번에는 경로 이동 없이, 원하는 디렉토리 정보만을 출력해보자.\n1 2 [root@ip-172-31-8-107 ec2-user]# ls -ld /var/ drwxr-xr-x 19 root root 269 Aug 30 04:09 /var/ -d 옵션 없이 사용하면 /var/ directory 안의 리스트를 볼 수 있다.\n하지만, 디렉토리 경로를 모르면 속성을 확인해볼 수 없다는 단점이 있다. 1 2 3 4 5 6 7 8 [root@ip-172-31-8-107 ec2-user]# ls -l /var/ total 8 drwxr-xr-x 2 root root 19 Aug 15 20:22 account drwxr-xr-x 2 root root 6 Apr 9 2019 adm drwxr-xr-x 6 root root 63 Aug 15 20:22 cache drwxr-xr-x 3 root root 18 Aug 15 20:22 db drwxr-xr-x 3 root root 18 Aug 15 20:22 empty ... 파일 형식 자세히 알기 -F를 사용하니, /가 뜬 것을 알 수 있다.\n이는 directory임을 의미한다.\n화살표가 있는 것들은 앞에 l임을 알 수 있다.\n이 l이 의미하는 바는 symbolic link를 의미한다.\n실제로 존재하는 것이 아닌, 화살표가 가리키는 것을 가리킨다는 의미다. 그리고 10이란 숫자를 볼 수 있는데, 이는 10byte를 의미하며, 이 크기는 바로가기 파일의 크기와 동일하다. 1 2 3 4 5 6 7 [root@ip-172-31-8-107 ec2-user]# ls -lF /var/ total 8 ... lrwxrwxrwx 1 root root 11 Aug 15 20:20 lock -\u0026gt; ../run/lock/ drwxr-xr-x 7 root root 4096 Sep 1 03:50 log/ lrwxrwxrwx 1 root root 10 Aug 15 20:20 mail -\u0026gt; spool/mail/ ... 또한, 아래 출력을 보면 *이 명칭 뒤에 붙어 있고, 각 출력행들의 맨 앞을 보면 -이 붙어있다. 이는 파일 을 의미한다.\n1 2 3 4 5 6 7 8 [root@ip-172-31-8-107 ec2-user]# ls -lF /bin/ total 153928 ... -rwxr-xr-x 1 root root 32552 Aug 17 2018 auvirt* lrwxrwxrwx 1 root root 4 Aug 15 20:20 awk -\u0026gt; gawk* -rwxr-xr-x 1 root root 818 Sep 28 2020 aws* -rwxr-xr-x 1 root root 1139 Sep 28 2020 aws_completer* ... 그리고, 아래 출력과 비교를 해보면 /가 없는 것들은 위와 같이 파일인데, 차이점은 -x가 아니라, -- 임을 알 수 있다. 그 차이는 -x가 붙은 건 실행파일 을 의미한다. 1 2 3 4 5 6 [root@ip-172-31-8-107 home]# ls -lF /etc/ total 1112 ... drwxr-xr-x 6 root root 100 Aug 15 20:22 yum/ -rw-r--r-- 1 root root 862 Jun 23 22:26 yum.conf drwxr-xr-x 2 root root 54 Aug 15 20:24 yum.repos.d/ 경로의 하위 내용까지 출력하기 경로에 최상위 경로를 입력하면 다 출력되기 때문에, 이런 문제점으로 사용하지 않는 것이 나을 수도 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@ip-172-31-8-107 ec2-user]# ls -lR /var/ ... /var/cache/man/es/cat8: total 0 /var/cache/man/fr: total 20 -rw-r--r-- 1 root root 190 Aug 31 03:39 CACHEDIR.TAG drwxr-xr-x 2 root root 6 Aug 30 05:48 cat1 drwxr-xr-x 2 root root 6 Aug 30 05:48 cat3 drwxr-xr-x 2 root root 6 Aug 30 05:48 cat5 drwxr-xr-x 2 root root 6 Aug 30 05:48 cat8 -rw-r--r-- 1 root root 16384 Sep 1 03:50 index.db ... 1.4 cp 기본 기능: 파일 또는 디렉토리를 복사 (copy)\ncp [옵션] [원본] [목적지]\n옵션 의미 -r, -R, \u0026ndash;recursive 하위 디렉토리와 파일을 모두 복사 -p, \u0026ndash;preserve 원본 파일의 권한과 함께 복사 디렉토리 하나를 만들어보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 현재 ec2-user 경로에는 아무것도 없다. [root@ip-172-31-8-107 ec2-user]# ls -l total 0 # 디렉토리 생성 후, 생성한 디렉토리로 파일 복사 [root@ip-172-31-8-107 ec2-user]# mkdir /home/ec2-user/test [root@ip-172-31-8-107 ec2-user]# ls test [root@ip-172-31-8-107 ec2-user]# cp /etc/adjtime /home/ec2-user adjtime test [root@ip-172-31-8-107 ec2-user]# cd test [root@ip-172-31-8-107 test]# cp /etc/adjtime /home/ec2-user [root@ip-172-31-8-107 test]# ls adjtime # test 안에 만들어지는 게 아닌, /home/ec2-user 안에 만들어진다. -r 사용하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 상위 경로에 있는 adjtime을 현재 test로 복사해온다는 의미 [root@ip-172-31-8-107 test]# cp -r ../adjtime . [root@ip-172-31-8-107 test]# cd ../../../ # 다음과 같은 안내문이 뜬다. # 이는 해당 디렉토리는 복사되지 않았다는 걸 의미한다. [root@ip-172-31-8-107 /]# cp /home/ec2-user/test/ ./ cp: omitting directory \u0026#39;/home/ec2-user/test/\u0026#39; # 옵션 -r을 사용하면 [root@ip-172-31-8-107 /]# cp -r /home/ec2-user/test/ ./ [root@ip-172-31-8-107 /]# ls ... test ... # 21 Sep 로 복사한 날짜와 시간을 확인할 수 있다. [root@ip-172-31-8-107 /]# ls -l ... drwxr-xr-x 2 root root 21 Sep 2 05:21 test ... [root@ip-172-31-8-107 /]# ls -l /test/ ... -rw-r--r-- 1 root root 16 Sep 2 05:21 adjtime 1.5 mv 기본 기능: 파일 또는 디렉토리 원본을 이동(move) mv [옵션] [원본] [목적지]\n위에 cp 실습에서 이어진다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@ip-172-31-8-107 /]# mv /test/ /home/ [root@ip-172-31-8-107 home]# ls ec2-user test [root@ip-172-31-8-107 home]# mv ./test/adjtime ./ [root@ip-172-31-8-107 home]# ls -l ./ ./test ./: total 4 -rw-r--r-- 1 root root 16 Sep 2 05:21 adjtime drwx------ 4 ec2-user ec2-user 122 Sep 2 04:52 ec2-user drwxr-xr-x 2 root root 6 Sep 2 05:31 test ./test: total 0 Reference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/linux/lecturenote02/","summary":"linux의 기본 명령어들 중 pwd, cd, ls, cp, mv에 대해 학습해본다.","title":"[TIL]Linux: 기본 명령어 익히기 - pwd, cd, ls, cp, mv"},{"categories":"Linux","content":"0. Introduction 해당 강의는 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course의 Jason.Kim 강사님의 Linux 강의로부터 학습한 자료입니다. 인스턴스 접속 환경 조성하기 aws 사이트가 아닌 terminal에서 손쉽게 인스턴스에 접속할 수 있는 환경 조성해보자.\n이 환경을 조성하는 이유는 aws 사이트에서 인스턴스 생성 및 연결 시, SSH 클라이언트 탭에서 예시로 입력한 명령어를 입력할 수 있지만, 매우 길고 효율적이지 않기 때문이다. 🔆 ssh란 secure shell의 줄임말로, 원격 호스트에 접속하는데 사용되는 보안 프로토콜을 의미한다. 이는 비밀번호로 인증하는 것이 아닌, key로 인증하는 방식이다.\n사용자와 관리자 명령 프롬프트 차이에 대해 알아보자.\nssh directory 생성부터 시작 첫 번째, Pem key가 있는 경로로 이동한다. 두 번째, mkdir .ssh 세 번째, chmod 700 .ssh .ssh/config 생성하기 cp dalkom.pem ~/.ssh 으로 복사\n경로는 위에 언급된 경로와 동일\npem key의 권한을 수정\nchmod 600 \u0026lt;pem key 이름\u0026gt;.pem config 생성하기\nvi .ssh/config 그러면 vim 모드로 전환하면 i를 입력하면 내용 입력이 가능하다. 밑에 내용을 입력한다.\n1 2 3 4 5 6 7 8 9 10 11 12 # 여기서 user는 서비스명을 의미한다. Host user # 자신이 생성한 인스턴스의 IPv4를 입력한다. HostName 43.200.244.241 user ec2-user IdentityFile ~/.ssh/dalkom.pem Host root # 자신이 생성한 인스턴스의 IPv4를 입력한다. HostName 43.200.244.241 User root IdentityFile ~/.ssh/dalkom.pem 입력을 다 맞쳤으면 esc를 누르고, :wq를 입력한다.\nconfig 생성 잘 되었는지 확인하기 cat .ssh/config 를 입력했을 때, 위에 입력한 값들이 뜨면 잘 나온 것이다. 마지막으로 권한 수정 chmod 700 ~/.ssh/config를 입력하여 프로그램의 실행 권한을 수정한다. 접속 확인 ssh \u0026lt;host name\u0026gt; root 권한으로 로그인하기 aws-ec2 는 보안상의 이유로 루트를 통한 접근을 보안 상의 이유로 금지하고 있다. 보통은 sudo su 명령어로 루트 권한을 사용할 수 있으나, 혹시 모르니 루트 권한을 활성화하는 방법을 알아보자.\nsudo vi /etc/ssh/sshd_config 을 입력한다.\n보다 보기 편하게 line을 표시하기 위해서 set nu를 사용하자.\n밑으로 내리다보면 38번째 줄에 PermitRootLogin에 yes가 있는지 확인한다.\n확인되면 :q! 를 입력하여 저장 없이 나간다.\n그후, sudo cp /home/ec2-user/.ssh/authorized_keys /root/.ssh를 입력한 후, sudo systemctl restart sshd 를 마저 입력한다.\n마지막으로 exit 을 입력하여 나간다.\n리눅스는 클라이언트가 아닌 서버 형태로 운영하기 때문에, Root로만 로그인하겠다.\n만일 user로서 로그인 하여 pwd를 입력하면 /home/ec2-user가 뜬다.\n하지만, root로 접근하여 pwd를 입력하면 /root가 뜬다.\n리눅스 구조에서 설명드린 디렉토리와 폴더의 차이는 디렉토리는 내가 현재 위치한 것 밖에 볼 수 없다.\n하지만, 폴더는 내가 현재 보고 있는 디렉토리 이외의 디렉토리도 볼 수 있는지가 차이다.\nls -l를 입력하면 d가 맨 앞에 있는 것을 볼 수 있는데, 이것이 directory이고, l로 된 것이 폴더이다.\nls -l은 현재 디렉토리 외의 디렉토리를 확인하고자 할 때 사용하는 명령어\nError 보고 첫 번째: Error 위 과정 중에서 다음과 같은 error가 발생했다.\n1 cd: .ssh: No such file or directory 위 명령어를 입력한 경로에 .ssh는 존재했다.\n하지만 계속해서 이와 같은 error가 발생하여 stackoverflow에서 확인했다.\n.ssh directory not being created 에서는 ssh-keygen으로 .ssh를 생성하려고 시도했으나, 나와 동일한 error가 발생한 것이다.\n기존에 있던 것을 삭제하고, 내가 직접 mkdir ~/.ssh를 입력하여 .ssh directory를 생성했다.\n생성을 해보고 나서, 기존에 있던 것은 directory 형태가 아니었음을 알았다.\n맥북을 처음 사용하면서 기본적으로 있었기 때문에, 맥북이어서 특이한 것이라 생각했지만 잘못된 판단이었다.\n디렉토리 생성 후, chmod 700 ~/.ssh를 입력하여 권한을 부여했다.\n그 후, ssh-gen을 입력하여 key를 생성했고, 위와 같은 error는 뜨지 않았다.\n두 번째: Error 하지만, 또 다른 Error가 발생했다.\n1 ssh: connect to host localhost port 22: Connecction refused 구글링을 하여 스택오버플로우도, 다른 여러 사이트들도 찾아봤지만 이에 대해 기초 지식이 없어서 섣부르게 시도하기가 어려웠다.\n그래서 먼저 내가 강의에서 말한 의도를 정확히 이해하여 했는지 처음부터 다시 한 번 체크했다.\n기존에 만든 config 파일을 수정하는 과정에서 원인을 알았다.\nConfig 내에 IdentityFile 의 경로가 잘못 입력된 것이었다.\n왜 잘못 입력했는지 생각을 해보니, 강사님과 다른 경로에서 해보고 싶어서 시도를 했고 이 과정에서 ~에 대해 정확히 이해하지 못 했기 때문에 생긴 오류였다.\n그래서 경로를 올바르게 작성한 후, 다시 시도해보니 Error가 완전히 해결되었다.\n이제 ssh root 와 ssh user를 사용하면 손쉽게 AWS를 통해서 Linux를 학습할 수 있게 되었다.\nReference 러닝스푼즈 - 나노디그리 Python \u0026amp; Django backed course ","permalink":"http://jeha00.github.io/post/linux/lecturenote01/","summary":"aws 사이트가 아닌 terminal에서 손쉽게 aws ec2 인스턴스에 접속할 수 있는 환경을 조성해보고, 그 과정에서 error 상황과 대처법을 기록했다.","title":"[TIL]Linux: terminal에서 AWS ec2 instance 접속 환경 조성하기"},{"categories":"Network","content":"0. Introduction: 웹 애플리케이션 기초 사용자가 눈에 보이는 부분을 개발하는 부분을 프론트엔드 , 사용자 눈에 보이지 않는 부분을 개발하는 부분을 백엔드 라 한다.\n프론트엔드는 코드 실행 결과를 눈으로 직접 바로바로 확인이 가능하다.\n하지만, 백엔드는 코드의 결과를 눈으로 확인하기 어렵다. 그래서 오류의 원인을 찾는 디버깅이 어렵다.\n이 디버깅을 하기 위해서는 기반지식이 필요하다. 입문자가 생각하는 개발은 코드라고 생각하지만, 실제 개발에 필요한 내용은 기반지식이다.\n기반지식 클라이언트 - 서버 구조 웹 서버 구조 설계 네트워크 이번에는 네트워크에 대해 학습해본다.\n네트워크 기초 서로 다른 컴퓨터 회사들의 컴퓨터들이 자유롭게 통신할 수 있도록, 그리고 네트워크 통신 중 어느 부분에서 문제가 발생했는지를 알 수 있도록 ISO(International Organization for Standardization, 국제표준화기구)에서 OSI (Open System Interconnection) Model이라는 표준 규격을 만들었다. 이 모델이 바로 OSI 7 계층이다.\n왜 표준 Model이 필요할까? Agnostic application 측면 이 Model 도 또한 거대한 네트워크 application이다. 단 다른 것들과 다른 것은 바로 agnostic application으로 모든 곳에서 작동가능한 애플리케이션이다.\n그러면 왜 네트워크와 관련하여 이 OSI 표준 모델(standard)을 왜 만든 것이고, 왜 필요한 것일까?\n표준 모델이 없다면 애플리케이션을 만들 때 이 네트워크 영역까지 설계해서 만들어야 한다. 그러면 지금 세상에서는 당연하게 생각하는 Wi-Fi, LTE, fiber 를 통해서 통신하는 것이 어려울 수도 있다.\nkernel 이 있는 이유와 동일하다. kernel이 존재하지 않는다면 모든 application은 hardware 관리 측면까지 설계해야 한다.\n대신해서 kernel이 하드웨어 관리를 해주는 거고, OSI 7 Model이 있어서 네트워크 통신을 구체적으로 신경쓰지 않아도 쉽게 사용할 수 있다.\n네트워크 장비 관리 측면 네트워크 장비를 업데이트하는데 있어서, 표준 모델이 다르면 업데이트하는데 있어서 매우 어려워진다. 달라진 모델에 맞춰서 호환성을 위해 다 업데이트를 여러 버전으로 해야하기 때문에 어렵다.\n하지만 표준 모델이 있고, 이를 다 준수하기 때문에 장비를 쉽게 사용할 수 있다.\nlayer마다 개별적인 개선 가능 (Decoupled Innovation) Model은 여러 Layer 별로 구축되어 있기 때문에, 한 layer만 개선해도 다른 layer에 영향을 미치지 않는다.\n예를 들어서 1계층에서 보다 더 빠른 방식의 전송 매체를 알게되어 이를 바꿔도 2계층과의 interface만 동일하게 유지하면 전혀 문제가 없다.\nOSI 7 layer 개요 OSI 7 layer의 구성은 다음과 같다. 그리고, 이 OSI 7 layer 를 4개의 계층으로 단순화하여 표현한 것을 TCP/IP 4 layer 라 한다. 설명은 OSI 7 layer를 기준으로 한다.\n그리고, 각 계층마다 통신하기 위해 사용되는 형식, 약속, 규약들이 존재하는데 이를 Protocol(프로토콜) 이라 한다.\nOSI 7 layer TCP/IP 4 layer 사용되는 프로토콜 설명 PDU(Protocol Data Unit) 주요 네트워크 기기 응용 계층 4. 응용 계층 HTTP, FTP, SMTP, DNS 애플리케이션 서비스 제공 메시지 혹은 데이터 - 표현 계층 4. 응용 계층 HTTP, FTP, SMTP, DNS 암호화, 직렬화, 복호화, 역직렬화 등으로 데이터 변환 메시지 혹은 데이터 - 세션 계층 4. 응용 계층 HTTP, FTP, SMTP, DNS 세션 연결/설정/해제와 통신 방식 결정 메시지 혹은 데이터 - 전송 계층 3. 전송 계층 TCP, UDP 신뢰성 있는 통신 구축 및 PORT를 통해 특정 프로세스 명시 segment - 네트워크 계층 2. 인터넷 계층 IP 한 네트워크에서 다른 네트워크와 통신하기 위한 IP 주소 결정 packet 라우터 데이터링크 계층 1. 네트워크 인터페이스 계층 이더넷, CMSA/CD MAC 주소를 통해 \u0026lsquo;네트워크 기기\u0026rsquo; 간의 데이터 전송과 물리 주소 결정 frame 스위치 물리 계층 1. 네트워크 액세스 계층 RS-232, RS-449 디지털 신호와 전기 신호 간 변환 리피터, 허브 위 각 계층에 대한 설명에 추가 설명\n1계층: 전기적 신호와 디지털 신호 bit가 상호 변환되는 계층 3계층부터는 네트워크 간 데이터를 주고 받는 과정 3계층: 여러 네트워크 간 데이터 전송을 위해 타 네트워크 주소 결정 4계층: 3계층에서 데이터가 유실되거나 더 정확하게 데이터를 전송하기 위한 정보 추가 5 ~ 7 계층 설명은 위 설명으로 충분하다. 송신 및 수신 순서 송신할 때 순서: 하위 계층으로 보내는 과정\n응용 계층 -\u0026gt; 표현 계층 -\u0026gt; 세션 계층 -\u0026gt; 전송 계층 -\u0026gt; 네트워크 계층 -\u0026gt; 데이터링크 계층 -\u0026gt; 물리 계층 수신할 때 순서는 송신 순서의 역방향으로 진행된다. (상위 계층으로 보내는 과정)\n헤더(Header), 캡슐화(Encapsulation) 그리고 역캡슐화(Decapsulation) from: 예술하는 개발자 - 캡슐화, 역캡슐화, PDU 우리가 현실세계에서 우편을 보낼 때 보낼 물건을 바로 보내는 게 아니라 우편 봉투에 넣고 주소 태그를 붙이는 것처럼 소프트웨어 세계에서도 데이터가 각 계층을 통해 보내질 때, 계층을 한 번 이동할 때마다 각 계층에 해당되는 header(헤더) 가 붙여진다. 이 헤더에는 목적지 정보, 출발지 정보, 에러 체크 등 필요한 정보들이 담겨져 있다.\n이 헤더는 전송되는 원본 데이터 앞에 추가적으로 붙는다.\n이렇게 송신 과정에서 데이터 앞에 헤더를 붙이는 것을 Encapsulation(캡슐화) 라고 한다.\n그리고 이와 반대로 헤더를 제거하는 것을 Decapsulation(역캡슐화) 라고 한다.\n캡슐화는 송신 과정에서 각 계층을 통과할 때마다 각 계층마다 일어나며, 역캡슐화는 수신 과정에서 각 계층을 통과할 때마다 각 계층마다 일어난다.\nReference 나노디그리 러닝스푼즈: Python \u0026amp; Django backend course osi 7 layer 네트워크 기초(1) - OSI 7계층이란? 예술하는 개발자 - 캡슐화, 역캡슐화, PDU Udemy - Fundamentals of Networking ","permalink":"http://jeha00.github.io/post/network/osi_7_layer/0_outline/","summary":"OSI 7 layer는 전체적으로 무슨 층으로, 무슨 프로토콜로, 각 계층의 데이터 타입은 무엇이고, 각 주요 기기들은 무엇인지 통합적으로 알아본다.","title":"[TIL]Web Application Basic study: OSI 7 layer outline"},{"categories":"Network","content":"0. Introduction: 웹 애플리케이션 기초 학습 목적 기반 지식을 다지기\n사용자가 눈에 보이는 부분을 개발하는 부분을 프론트엔드 ,\n사용자 눈에 보이지 않는 부분을 개발하는 부분을 백엔드 라 한다.\n프론트엔드는 코드 실행 결과를 눈으로 직접 바로바로 확인이 가능하다.\n하지만, 백엔드는 코드의 결과를 눈으로 확인하기 어렵다. 그래서 오류의 원인을 찾는 디버깅이 어렵다.\n이 디버깅을 하기 위해서는 기반지식이 필요하다.\n입문자가 생각하는 개발은 파이썬 코드라고 생각하지만, 실제 개발에 필요한 내용은 기반지식이다.\n그래서 이번에 기반 지식 아래 내용을 학습해본다.\n클라이언트 - 서버 구조 웹 서버 구조 설계 네트워크 1. 서버와 클라이언트의 개념 1.1 클라이언트-서버 구조 눈에 보이는 프론트엔드 부분을 어떻게 볼 수 있는 것일까?\n웹 브라우저의 내용 구성: html, css, js 이 클라이언트 상에서 필요한 내용을 서버에 요청하며 서버가 그 해당 페이지에 필요한 내용을 보내어 응답한다. 서버는 하나의 컴퓨터로 생각하면 된다.\n예전에는 하드웨어 컴퓨터를 직접 사용하여 서버를 구축하는 방식 하지만 지금은 AWS 서비스를 사용한다. AWS란 아마존 웹 서비스를 말하는데, AWS에 서버가 엄청 많아서, 이 서버를 빌려주는 서비스를 말한다.\n서버의 정의와 종류 서버(server)란?\n클라이언트가 요청한 서비스를 제공해주는 프로그램 서버가 어떤 서비스를 제공하느냐에 따라 종류가 나뉜다. 서버의 종류\n웹 서버 메일 서버 파일 서버 데이터베이스 서버 프록시 서버 웹서버 웹 서버(web server)란?: 웹 브라우저와 같은 클라이언트로부터 HTTP 요청을 받아들이고, HTML 문서와 같은 웹 페이지를 반환하는 \u0026lsquo;컴퓨터 프로그램\u0026rsquo; 또는 이 기능을 제공하는 프로그램을 실행하는 \u0026lsquo;컴퓨터\u0026rsquo;를 의미\n만일 \u0026ldquo;서버 만들겠다\u0026rdquo; 라는 말을 했다면, 컴퓨터 프로그램 을 의미한다.\n\u0026ldquo;물리 서버가 고장났다\u0026rdquo; 라는 말을 했다면, 컴퓨터 프로그램이 아닌 프로그램을 제공하는 컴퓨터 를 의미한다.\nHTTP Hypertext Transfer Protocol의 약어로, 웹 상에서 데이터를 전달할 때 사용하는 프로토콜 Protocol: 원거리 장비 사이에서 메시지를 주고 받을 때 지켜야하는 규칙 https = http + 보안기능(SSL: Secure Socket Layer) 2. 서버 구조 설계 웹서버 \u0026lt;=\u0026gt; WSGI \u0026lt;=\u0026gt; 웹 애플리케이션 \u0026lt;=\u0026gt; DB 이거나, 사용자가 많아지면 DB만 떼어놓는다\n이번에는 서버 구조에 대해 알아보자.\n만약 서버에서 Error가 발생했다면, 위 각 어느 부분에서 발생했는지를 알아야하기 때문에 이 기반지식이 필요하다.\n2.1 웹서버 웹 서버(web server)란? 정적 페이지(static page)를 처리하는 서버로, 정적 페이지는 db와 연결할 필요 X\nstatic page: 누가 접속하든 동일하게 보여주는 page dynamic page(동적): static page의 반대로서, web framework를 사용해야한다. 2.2 웹 서버의 종류 APACHE 와 NGINX\n2.2.1 아파치 HTTP 서버(Apache HTTP 서버) 프로세스 / 스레드 기반 구조\n사용자의 HTTP 요청이 올 때마다 프로세스 또는 쓰레드 생성 1000개의 HTTP 요청 -\u0026gt; 1000개의 프로세스 또는 쓰레드 생성 따라서 사용자의 요청이 많아지면 프로세스 생성으로 인한 메모리 부족, CPU 과부하 아파치 HTTP 서버의 단점: 커넥션이 1만개가 넘어가면 하드웨어 성능에 상관 없이 더 이상 커넥션을 형성하지 못하는 C10K문제 동시 접속자가 만명이 넘어가면 더 이상 커넥션 형성 X 그래서 규모 있는 서비스를 만들려면 아파치를 사용하면 안된다. 2.2.2 NGINX HTTP 서버(Apache HTTP 서버) 아파치의 문제점을 해결한, 비동기 이벤트 기반 구조\n이벤트란? 커넥션 생성 및 제거하거나, 새로운 요청을 처리하는 걸 의미 수 많은 요청이 들어와도 정해진 갯수의 프로세스만을 사용하여 비동기 방식으로 대기시켜서 먼저 등록된 요청부터 처리해주는 방식 예전에는 아파치를 자주 사용했지만, 요즘에는 Nginx를 사용하는 추세 그 외 내용 위의 아파치와 nginx 서버의 보다 자세한 구조와 내용을 알고 싶다면 먼저 아래 링크를 확인해보자.\n[nginx] 아파치와 nginx를 비교해보자 와 apache, nginx 차이 를 참고한다.\n2.2 WSGI(Web Server Gateway Interface) 웹 서버는 파이썬을 모르기 때문에, 웹 서버가 받아들인 요청을 WSGI가 파이썬 장고(웹 애플리케이션)에게 전달해주는 역할을 한다.\n비유를 하자면 웹 서버는 한국어를 사용하고 웹 애플리케이션은 영어를 쓰는 상황에서, WSGI가 이를 통역하여 웹 애플리케이션에 전달하는 역할을 한다. WSGI의 종류 gunicorn, uwsgi, uvicorn\ngunicorn: 프로그래밍하는 건 gunicorn이 더 쉽기 때문에, 입문자에게는 이를 권장한다.\nuwsgi: gunicorn보다는 어렵지만, 디테일하게 직접 설계하여 성능을 최대로 높일 수 있다.\nuvicorn: WSGI가 아닌 ASGI로 Asynchronous Server Gateway Interface로, 동기 기반 프레임워크에느 사용할 수 없다. 그래서 FastAPI의 경우 gunicorn과 사용할 수 없다. 그래서 uvicorn만 사용하던가, gunicorn + uvicorn으로 함께 사용할 수도 있다. FastAPI 공식 문서인 Server Workers - Gunicorn with Uvicorn를 보면 확인할 수 있다.\n2.3 WAS(Web Application Server, 웹 애플리케이션 서버) 동적 페이지(dynamic page)를 처리하는 서버로, 데이터베이스와 연결되어 필요한 데이터를 주고 받는다.\n정적 페이지: 고객님, 환영합니다.\n동적 페이지: 홍길동님, 환영합니다. -\u0026gt; 고객이 누구냐에 따라 보여주는 페이지가 다르다.\n웹 애플리케이션의 종류\nDjango(파이썬), Flask(파이썬), Ruby on Rails(루비), Spring(java) 등등 Django로 만들면 나중에 ML 을 적용할려면 호환이 좋다. 하지만 루비는 그렇지 않다. 2.4 DB RDB와 NoSQL\nRDB의 종류: MySQL, PostgreSQL, Oracle\n형식이 존재 NoSQL의 종류: MongoDB, Redis\n형식 존재하지 않음 Summary 클라이언트 \u0026lt;=\u0026gt; 서버\n예시로서 서버 안에서는 다음과 같은 구조를 가진다.\nweb server - WSGI - WAS (application server + db server\u0026hellip;) NGiNX \u0026lt;=\u0026gt; gunicorn \u0026lt;=\u0026gt; Django \u0026lt;=\u0026gt; PostgreSQL 서버개발자는 위 모든 것을 다 설치해야 하며, 장고 외의 것들도 어떻게 구성할지 고려해야한다. Reference 나노디그리 러닝스푼즈: Python \u0026amp; Django backend course ","permalink":"http://jeha00.github.io/post/network/webserver/clientandserver_webserver/","summary":"클라이언트와 서버란 무엇인지, 서버의 종류에는 무엇이 있고, 웹서버 - WSGI - 웹 애플리케이션 - DB라는 서버 구조에서 각각에 대해 알아본다.","title":"[TIL]Web Application Basic study: client와 server / web server structure"},{"categories":"HTML_CSS","content":"1. CSS의 속성: Block 과 Inline 아래 설명을 보기 전 예시 코드로 CSS의 display 속성: inline, block, inline-block을 참고하면 이해하기 보다 쉬울 것이다.\n1.1 block과 inline이란?? box들은 대부분 block 속성을 가지는데 옆에 다른 요소(element)가 못 오는 속성을 \u0026lsquo;block\u0026rsquo;, 옆에 다른 요소가 올 수 있는 속성을 \u0026lsquo;inline (in the same line)\u0026lsquo;이라 한다.\ncss의 여러 가지 속성들 중 \u0026lsquo;block\u0026rsquo; 과 \u0026lsquo;inline\u0026rsquo; 속성에 대해 알아보자.\nbox html은 box들로 디자인된다고 생각해도 무방하다. 큰 box들이 작은 box 들로 구성된다.\nBOX의 종류는 다음과 같다.\n가장 기본적인 BOX로는 \u0026lt;div\u0026gt; tag를 생각해볼 수 있다.\n이외에도 div, header, main, section, footer, article 태그 등이 있다.\n그래서 \u0026lt;span\u0026gt;, \u0026lt;a\u0026gt;, \u0026lt;image\u0026gt; 같은 block이 아닌 종류를 기억하는 게 편하다.\ninline 그리고, box 외에 \u0026lsquo;inline\u0026rsquo; 속성이 존재한다.\n\u0026lsquo;inline\u0026rsquo; 속성은 아주 작은 글, 링크 그림 등이 이에 속한다. box와 inline의 차이 그렇다면 \u0026lsquo;block\u0026rsquo;과 \u0026lsquo;inline\u0026rsquo;의 차이 는 무엇일까??\nblock: 옆에 다른 요소가 못 오는 속성\n옆에 다른 요소가 못 오도록 block 한다고 생각하자. 높이와 너비를 가지고 있다. inline: 옆에 다른 요소가 올 수 있는 속성\nline 한 줄에 다 올라온다고 생각하자. 높이와 너비를 가지고 있지 않다. box와 inline 속성을 바꾸는 방법 css의 display property로 block을 inline으로, inline을 block으로 바꿀 수 있다.\n❗ property와 attribute의 차이: 링크를 클릭하여 참고하자.\n1.2 Block과 Inline의 속성 display attribute Block Inline Inline -block height and width O X O other elements near X(one element on a row) O O Block의 속성\n이 tag를 block으로 인지하는지를 알기 위해서는 검사에 들어가서 확인하면 된다.\n높이와 너비를 가지고 있다.\n또한, box이기 때문에 3가지 속성(margin, padding, border) 을 가진다.\n원래 block인 것을 inline으로 바꾸면 높이와 너비 요소들은 사라진다.\nInline의 속성\ninline은 높이와 너비를 가질 수 없지만, 폭과 너비를 가지게 하고 싶으면 CSS 속성인 display를 사용한다. display: 'inline - block;을 입력한다. ❗ inline-block으로 했을 때는 여러 문제점들이 있다.\n첫 번째, 기본적으로 element 사이에 빈 공간이 기본으로 생긴다. 두 번째, 반응형 디자인(responsive design)을 지원하지 않아서 PC 모니터 사이즈에 따라 달라진다. 1.3 Box의 속성: border, margin, padding box attribute margin padding definition on Box space from the border of the box to the outside a spce from the border of the box to the inside directions on inline right, left top, bottom, right, left Box는 3가지 속성: border, margin, padding을 가진다.\n즉, block도 이 3가지 속성을 가진다는 것이다.\nborder 단어 명칭 그대로 a border of the box: box의 경계선을 의미한다. 많은 property를 가지고 있지만, 이쁘지 않아서 사용되지 않는다. \u0026lsquo;border style mdn\u0026rsquo;을 구글링하면 나온다. inline과 block에 다 적용된다. margin \u0026lsquo;padding\u0026rsquo;의 반대 개념으로, 정의는 다음과 같다. space from the border of the box to the outside : box의 border 바깥에 있는 공간 box의 크기에 따라 margin의 크기도 달라진다. ❗ Collapsing margins 현상 - 2개의 box가 있을 때, 경계선이 같은 부분에 있다면 이 두 margin은 하나로 취급된다. - 위, 아래쪽만 일어난다. 경계가 닿아서 margin이 같아졌다.\npadding \u0026lsquo;margin\u0026rsquo;의 반대 개념으로, 정의는 다음과 같다. space from the border of the box to the inside: box의 border 안쪽에 있는 공간 Inline에서의 padding과 margin padding은 사방으로 가능하나, margin은 좌우로만 가능하다. margin을 위아래로도 적용하고 싶다면, inline을 block으로 바꿔야 한다. 🔅 브라우저에서 box 속성 확인하기\n- 마우스 우클릭하여 검사 (or inspection)에 들어가면 Styles 항목에 \u0026lsquo;user agent stylesheet\u0026rsquo; 가 있다. - 이 \u0026lsquo;user agent stylesheet\u0026rsquo;를 보면 border, margin, padding의 크기를 확인할 수 있다. - 또한, border, margin 그리고 padding에 마우스 커서를 대면 브라우저 상에서 어디인지 확인할 수 있다.\nReference 노마드코더 - 코코아톡 클론 코딩 CSS의 display 속성: inline, block, inline-block property와 attribute의 차이 ","permalink":"http://jeha00.github.io/post/html_css/study03/","summary":"Block와 Inline의 차이는 무엇이고, box의 속성 3가지인 border, padding, margin에 대해 학습한다.","title":"[TIL] HTML \u0026 CSS study - CSS 02"},{"categories":["Python"],"content":"0. Introduction async 와 bs4 module을 사용하여 한 특정 웹 사이트를 스크랩핑하는 코드를 작성하고 있다.\n그 과정에서 Error가 발생하여 이에 대한 원인과 해결책을 기록두는 것뿐만 아니라, 모르는 것들에 대해 학습한 걸 기록한다.\n이번에는 \u0026lsquo;Serialization(직렬화)\u0026rsquo; 란 개념과 Flat data, Nested data 무엇인지 알아보자. 마지막으로, json.loads() 와 json.dumps()를 알아본다.\n이후 이 주제와 관련되어 새롭게 학습한 것이 있다면 이 포스팅에 정리한다.\n1. Serialization(직렬화) python docs-guide: Data Serialization와 stackoverflow - What is data serialization?에 따르면 data serialization의 정의를 다음과 같이 내린다.\n\u0026lsquo;Data serialization의(직렬화)\u0026lsquo;란 구조화된 데이터를 저장되거나 공유될 수 있는 한 가지 형식으로 전환하는 것으로 즉, 저장되거나 네트워크를 통해 보내지기 위해서 다른 형식으로 객체를 인코딩하는 걸 말한다. 이 과정에서 데이터의 사이즈를 줄이는 효과도 가진다.\n추가: 직렬화와 역직렬화 문서에 정리한 것처럼 직렬화 란 json을 string으로 바꾸는 것 을 말하며, 역직렬화 란 string을 json으로 바꾸는 것 을 의미한다.\n직렬화의 전환되는 형식: 두 가지 Flat vs Nested data\n전환되는 형식에는 두 가지 종류 가 있는데, 바로 Flat vs Nested data 다.\n각 데이터 예시는 Flat vs. Nested Data Layer을 참고하자.\n간단히 말하자면 이와 같다.\nFlat은 계층화되어 있지 않은 데이터 종류로 one level의 properties나 \u0026ldquo;key: value\u0026rdquo; 쌍으로 구성된 데이터를 의미하고, nested는 계층화되어 있어 몇 개의 level로 구성된다.\n각 데이터 타입에 대한 장단점도 위 링크에 있으니 참고하자.\nFlat data 파이썬은 data에 flat data가 포함되어 있다면 직렬화하기 위해 repr method나 csv module을 제공한다.\n[TIL]Python basic 20: with open as [TIL]Python basic 21: csv.read, write [TIL] Python basic 25: _ _str _ _ vs _ _repr _ _ Nested data Nested data의 종류에는 YAML, JSON, XML 등이 있다.\n이 type들 모두 import yaml, json, xml 을 통해 nested data를 다룰 수 있다.\n여기서는 import json에 대한 것만 다음 챕터에서 다룰 것이다.\n2. json.loads 와 json.dump JSON이란 무엇인지 학습한 후, json.loads()와 json.dumps()에 대해 알아본다.\n먼저 두 함수에 대해 그림으로 간략히 표현하면 이와 같다.\n이미지 출처: What is the difference between json.loads() and json.dumps() ? 즉, json.dumps() 는 직렬화를 하는 함수이고, json.loads()는 역직렬화를 하는 함수다.\nJSON이란? JavaScript Object Notation의 약어로, { } 중괄호(curly braces)로 둘러쌓여진 것으로, key와 value 쌍으로 쓰여진다.\npython에서는 dictionary data type을 생각해보자. json.loads string을 json Object 즉, dictionary 형태로 바꾼다. (역직렬화)\n1 2 3 4 5 6 7 BASE_DIR = Path(__file__).resolve().parent secrets_path = str(BASE_DIR / \u0026#34;secrets.json\u0026#34;) with open(secrets_path) as f: secret = f.read() secret2 = json.loads(secret) print(f\u0026#34;secret type: {type(secret)}\u0026#34;) print(f\u0026#34;secret2 type: {type(secret2)}\u0026#34;) 출력 결과는 다음과 같다.\n1 2 secret type: \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; secret2 type: \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; 즉, .read() 는 json 파일은 string 문자열로 읽어오고, json.loads()는 이를 dictionry인 json object로 읽어온다. 그러면 read()와 dumps() 의 차이는 무엇일까??? 둘 다 string 을 반환하지만, dumps는 json 형태의 string으로 바꾸고, read()는 작성된 형태 그대로 읽어온다.\njson.dumps json Object를 string으로 바꿔준다. (직렬화)\n위에 코드를 이어서 사용해보자. 1 2 3 4 5 dump = json.dumps(secret2) print(type(dump)) # 결과 \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; 즉, json object로 넘겨주면 데이터를 추출하여 이를 string type으로 반환한다는 걸 알 수 있다. Reference Data Serialization Flat vs. Nested Data Layer json - JSON 인코더와 디코더 stackoverflow - What is data serialization? [TIL]Python basic 20: with open as [TIL]Python basic 21: csv.read, write [TIL] Python basic 25: _ _str _ _ vs _ _repr _ _ What is the difference between json.loads() and json.dumps() ? ","permalink":"http://jeha00.github.io/post/python/others/2_loads_dumps/","summary":"Serialization이 무엇을 의미하고, 이에 따라 flat data, nested data가 무슨 형태의 data인지 알아본다. 그리고, flat data의 한 종류인 json과 관련된 module을 사용해본다.","title":"[TIL] Python study: Serialization 과 json.loads, dumps()  "},{"categories":"git","content":"0. Introduction GitHub Actions GitHub 추가 팁 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. Chapter 14에서는 아래의 것들을 학습한다. GitHub Action을 체험해본다. 이외에 GitHub CLI를 통해서 GitHub 작업을 하는 것을 학습해본다. 3. GitHub Actions GitHub Actions 를 사용한 자동화\nCI/CD: 지속적 통합과 배포 영상 참조 동종: GitLab CI/CD, BitBucket Pipelines 3.1 GitHub Actions 살펴보기 a) github.io page의 액션 해당 레포지토리 페이지에서 Actions tab 살펴보기 새로운 커밋 푸시한 직후 다시 살펴보기 b) 다른 프로젝트에서 액션 추가하기 Actions tab에서 액션들 살펴보기 적용해보기 Marketplace 살펴보고 적용해보기 커밋 후 pull 하여 로컬에서 확인 3.2 GitHub Actions 체험해보기 ❗ PR시마다 코드 테스트 후, 실패시 자동 close\n.github/workflows/test.yaml 살펴보기\n코드 수정(성공 \u0026amp; 실패)하여 main branch로 PR 날려보기\n4. GitHub 추가 팁 4.1 OctoTree GitHub repository의 directory를 보다 편하게 브라우징 크롬 익스테션의 종류 설치 링크 4.2 GitHub CLI GitHub 작업 전용 CLI 툴 설치 링크 주요 명령어 GitHub CLI 명령어 매뉴얼\n❗ 아래 명령어로 오류가 뜬다면, 해당 명령어 앞에 winpty를 붙인다.\n로그인/로그아웃\ngh auth (login/logout) 레포지토리들 보기\ngh repo list 프로젝트 클론\ngh repo clone (사용자명)/(레포지토리명) 프로젝트 생성/삭제\ngh repo (create/delete) 이슈 목록 보기\ngh issue list 이슈 열람/닫기\ngh issue (view/close) (이슈 번호) 이슈 생성\ngh issure create 풀 리퀘스트 만들기/목록 보기\ngh pr (create/list) 풀 리퀘스트 보기/코멘트/닫기/병합\ngh pr (view/comment/close/merge) (PR 번호) Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter14-02/","summary":"GitHub Action이 무엇인지 체험해보고, Github repository를 살펴보는데 좋은 확장 프로그램인 \u0026lsquo;Octotree\u0026rsquo;를 사용해본다. 마지막으로 GitHub CLI를 학습해본다.","title":"[TIL] Git study: Lecture Chapter 14 - GitHub Actions 체험, Octotree, GitHub CLI"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. Chapter 14-01 에서는 아래의 것들을 학습한다. SSH 키 생성 및 등록하여, remote 추가 시 HTTP가 아닌 SSH를 사용하는 방법 GPG 키 생성 및 등록하여, local에서 작업하여 푸쉬해도 Verified가 뜨도록 하는 방법 1. SSH로 접속하기 SSH 프로토콜을 통한 인증 SSH protocol을 통한 인증\n공개키 암호화 방식을 사용하는 방식으로, username과 토큰 사용할 필요 없다. 컴퓨터 자체에 키 저장 SSH 키 등록하기\n계정의 Settings - SSH and GPG keys 해당 페이지의 가이드 참조\n1) SSH키 존재 여부 확인 GitHub 계정 \u0026gt; settings \u0026gt; SSH and GPG keys\n터미널(윈도우의 경우, Bash Shell)에서 ~/.ssh로 이동\ncd ~/.ssh id_rsa.pub, id_ecdsa.pub, id_ed25519.pub 파일 중 하나 존재 여부 확인\nls\n.pub은 공개키로 다른 살마에게 알려줘도 되지만, .pub이 없는 id_\u0026lt;numbering\u0026gt; 파일은 다른 사람에게 알려주면 안된다.\n알려줬다면 두 가지 키 다 제거하고 다시해야 한다. 위 3개 파일 중 하나가 존재한다면 3번으로 이동\n2) SSH 키 생성 터미널(윈도우의 경우 Bash Shell)에서 키 생성\nssh-keygen -t ed25519 -C \u0026quot;(이메일 주소)\u0026quot; 원할 시 passphrase 입력\n1번의 과정으로 키 생성 확인\n3) Github에 키 등록 공개키 열람하여 복사\ncat ~/.ssh/id_ed25519.pub 또는 cat id_ed25519.pub New SSH Key 클릭하여 키 이름과 함께 등록\n4) SSH로 사용해보기 원격을 SSH 주소로 변경한 뒤 테스트 2. GPG로 커밋에 사인하기 GPG 키를 통한 검증\nGitHub 커밋 내역 살펴보기 로컬에서 푸시한 커밋과 GitHub에서 작성한 커밋 비교\nGitHub repository에 들어가서 code tab에서 들어갈 수 있는 커밋 내역에 들어가면 Verified를 확인할 수 있다. Verified: 신뢰할만한 출처에서 커밋되었다는 인증\nlocal이 아닌 GitHub에서 수정한 커밋을 의미하는 것으로, 즉 GitHub이 인증해주는 것이다. GPG 사용 1) GPG tool 설치 GPG를 사용하기에 앞서 GPG tool을 먼저 설치해야 한다.\n윈도우: 다운로드 사이트 맥: brew install gnupg gpg --version으로 확인 2) GPG 키 생성 GPG가 존재하는지 판단하기\n참고문서: Existing GPG keys Git bash에 gpg --list-secret-keys --keyid-format=long 입력 이 링크의 가이드에 따라 진행\n3) New GPG key 클릭하여 등록 이 링크의 가이드에 따라 진행 위 링크에 따라 진행하다가 Enter your user ID information에서 ID를 입력할 때는, GitHub에서 오른쪽 위 메뉴를 클릭할 때 뜨는 ID를 입력한다.\n이메일도 GitHub 이메일과 동일한 것을 입력한다.\ncomment: 시에는 그냥 엔터를 눌러도 된다.\n끝나면 gpg --list-secret-keys --keyid-format=long을 입력한 후, 위 메뉴얼에 따라 GPG key ID 부분을 복사해서 따로 기록해둔다.\n6D040741D60FEB1E gpg --armor --export \u0026lt;GPG key ID\u0026gt;를 입력한다.\n----BEGIN PGP PUBLIC KEY BLOCK----- 부터 -----END PGP PUBLIC KEY BLOCK----- 까지 복사한다. 이제 GPG key를 GitHub 계정에 추가한다.\n❗ 맥의 경우, 추가 절차(환경 변수) 있음\n그 다음으로, Telling Git about your GPG key 을 따라 진행한다. git config --global user.signingkey 6D040741D60FEB1E 4) 사인하기 커밋에 사인: 명령어에 -S 옵션 추가\ngit commit -S -m '(message)' 위 명령어를 실행하면 GPG key 등록과정에서 입력한 Passphrase를 입력한다. git push하여 GitHub commit 내역을 확인해보면 local에서 작업했음에도 불구하고 Verified 를 확인할 수 있다. tag에 사인: 명령어에 -s 옵션 추가\ngit tag -s (태그명) (커밋 해시) -m (메시지) git tag -s 3.0.0 -m 'Tag sign' 한 후, git push --tags 를 입력하여 GitHub의 Tags를 확인하면 Verified를 확인할 수 있다. Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter14-01/","summary":"SSH key를 생성하고, 계정에 등록하여 remote 추가 시 HTTP가 아닌 SSH를 사용하는 방법과 GPG key를 생성하고 계정에 등록하여 local에서 작업해도 \u0026lsquo;Verified\u0026rsquo;가 뜨는 것 실습해본다.","title":"[TIL] Git study: Lecture Chapter 14 - SSH \u0026 GPG"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. Chapter 13에서는 GitHub 여러 기능 중 pull request와 issue를 학습하고, 오픈소스 기여 체험을 해본다. 1. Pull request 변경사항을 merge하기 전 리뷰를 거치기 위함\n오픈 소스 외 다른 사람들과 프로젝트를 하기 위해서는 settings -\u0026gt; Collaborators로 이동한다. 그 후, Manage access 에서 Add poeple 로 추가한다.\n또한, 보다 조심스럽게 팀원들의 동의를 거친 뒤 대상 브랜치에 적용하기 위한 방식인 pull request를 사용해보자.\n1.1 풀 리퀘스트 사용해보기 local과 remote repository에 동일한 명칭의 새로운 브랜치 생성 후, 생성한 브랜치에 변경사항 커밋하여 푸시\ngit branch develop 임의의 파일 수정 및 커밋하기 git push origin develop 로 remote에 main branch 외에 생성한 브랜치에 push하기 GitHub 레포지토리 페이지에서 Compare \u0026amp; pull request 버튼 클릭\n또는 ~ branches에서 New pull request 클릭 메시지 작성 후 Create pull request 클릭\n❗ Open a pull request 시, Create pull request 외에 Create draft pull request 가 존재하는데, 이는 작업이 끝나지 않았지만 코드 리뷰를 요청하는 걸 말한다.\n1.2 풀 리퀘스트 검토 후 처리하기 GitHub 레포지토리 페이지에서 Pull requests 탭 클릭\n대상 풀 리퀘스트 클릭하여 내용 검토\n의견이 있을 시 코멘트 달기 반려해야 할 시 Close pull request 클릭 승인할 시 Merge pull request Merge 또한 Pull request에서 여러 방법을 선택할 수 있다.\nmerge 했으면, working directory에서 git pull을 사용하여 가져온다.\n🔅 그래서 Git flow 전략 과 함께 사용한다.\n2. Issue 버그나 문제 제보, 추가할 기능 등의 이슈 소통에 사용\n예시 네이버 지도 API 예제 Flutter 이슈 작성해보기 GitHub 레포지토리 페이지에서 Issues 탭 클릭\n필요시 label 또는 milestone 생성\nmilestone: 이슈의 주제 묶음 (특정 목표 등) label: 기존에 만들어진 것을 사용하거나, 다른 것을 선택하여 사용할 수도 있다. 이슈 작성\n필요시 label, milestone, asignee 지정 asignee 누가 담당해서 하는지를 지정 이슈 확인 후 처리\n코멘트 달기 관련 개발 착수 (브랜치명이나 커밋 footer에 이슈 번호 반영) 해결 뒤: Close issue Close issue를 클릭 후, Issues tab에서 바로 확인할 수 없다. 하지만, Open이 아니라, Closed를 클릭하면 해결된 이슈들만 볼 수 있다. Chapter 07-01 에서 Closes #125가 이슈 125번을 닫는다는 의미다 . 3. 오픈소스 프로젝트에 기여하기 프로젝트별 참여 가이드가 존재하므로 반드시 확인한다.\n- 예시: React GitHub page\n첫 번째, 프로젝트 fork 해보기 나 자신의 프로젝트가 아니기 때문에, 수정하기 위해서는 fork를 해서 가져와야 한다. 원하는 유명 프로젝트 내 레포지토리로 포크해보기 실습을 위해 아래 링크 프로젝트 포크하기 예제용 오픈소스 프로젝트 두 번째, 코드 기여하기 working directory에 git clone 명령어를 가져오기 PR용 branch로 전환하기 코드 수정 후 push -\u0026gt; code 주인에게 pull request 세 번째, 오픈소스 주인 관점 pull request 코멘트/반려/수락 Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter13/","summary":"협업 시에 사용하는 GitHub pull request를 하는 방법과 GitHub issue에 대해 알아본다.","title":"[TIL] Git study: Lecture Chapter 13 - pull request \u0026 issue"},{"categories":"HTML_CSS","content":"0. Introduction HTML과 CSS에 대한 기본적인 내용을 정리해보는 글이다.\n크롬, 익스플로어, 파이어폭스 같은 브라우저들은 서버에서 보내는 HTML, CSS 그리고 javascript 파일을 분석하여 구현한 후, 클라이언트들에게 보여준다.\n지난 \u0026lsquo;Study01.md\u0026rsquo;에서 이 3가지 중 HTML과 CSS가 무엇인지에 알아보았고, 더 나아가 HTML tag에 대해 알아보았다. 이번에는 CSS에 대해 더 알아보자.\n1. What is CSS ? 지난 study에서 css란 HTML의 tag를 꾸며주는 역할로, 클라이언트에게 보여주는 스타일을 담당한다는 걸 알았다.\n그렇다면 CSS라는 명칭은 무슨 의미일까??\nCSS란 \u0026lsquo;Cascading Style Sheets\u0026rsquo; 의 약어로, 여기서 Cascading이란 \u0026lsquo;one after the other\u0026rsquo; 순서대로 위에서부터 차례대로 흘러간다는 의미다.\n무슨 말인가??\n브라우저가 CSS를 읽은 방법이 위에서부터 아래로 읽는다는 것이다.\n즉, 동일한 부분에 대해 다른 방식으로 CSS가 코드 위에서와 아래에서 스타일을 적용했다면, 맨 마지막에 있는 아래의 것이 최종적으로 적용된다는 것이다.\nCSS란 Cascading Style Sheets의 약어로, 브라우저가 css를 읽는 방식을 나타내는데 브라우저가 CSS를 읽을 때 상대적으로 아래의 있는 css를 최종적으로 적용한다. 그리고, 이 CSS는 HTML tag를 꾸며주는 역할을 수행한다.\n❗ CSS의 속성들 또한 html의 tag처럼 매우 종류가 다양하므로 외우지 않고, 어떻게 동작하는지만 기억하자.\n2. CSS를 추가하는 방식: 두 가지 CSS를 추가하는 방식에는 inline 방식와 External 방식이 있다.\nCSS를 추가하는 방식인 inline 방식와 external 방식에 대해 알아보자.\n첫 번째, \u0026lsquo;Inline\u0026rsquo; 방식은 방식의 명칭대로 \u0026lsquo;코드 라인 내부에\u0026rsquo; CSS를 넣는 방식으로, HTML 파일에 HTML 코드와 CSS 코드를 다 작성하는 방식 이다.\n두 번째, \u0026lsquo;External\u0026rsquo; 방식은 첫 번째와 반대로 CSS와 HTML code를 분리하는 것으로, CSS를 별도의 파일로 만들어서 HTML 파일에서 불러와 사용하는 방식 이다.\n대부분 권장하는 방식은 \u0026lsquo;External\u0026rsquo; 방식이 있는데, 2가지 이유가 있다.\n첫 번째, 별도의 파일로 만들기 때문에 다른 더 많은 html page에서 사용할 수 있다. 두 번째, 분리된 파일을 가지고 있는 방식이 보기 깔끔하다. 2.1 Inline 방식 그러면 코드 라인 내부에 CSS를 입력한다면 html tag의 어디에 입력할까?\nhtml tag의 기본 템플렛이 다음과 같을 때, \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; tag 안에 \u0026lt;style\u0026gt; \u0026lt;/style\u0026gt;를 넣어서, 이 \u0026lt;style\u0026gt; \u0026lt;/style\u0026gt; tag 안에 입력한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ko\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; {css} \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 2.2 External 방식 외부에서 CSS 파일을 가져오는 방식은 \u0026lt;style\u0026gt; tag 사이에 입력하는 게 아닌 \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; tag 사이에 \u0026lt;link href ='css file 이름.css' rel = \u0026quot;stylesheet\u0026quot; \u0026gt;를 입력한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;kr\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; # External 방식 \u0026lt;link href=\u0026#34;css file 이름.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; /\u0026gt; \u0026lt;style\u0026gt;\u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;sub\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;subsub\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;subsub subsubelement\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;subsub\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 3. CSS를 입력하는 방식 3.1 css의 일반적인 입력 방식과 사용하면 안되는 문자 꾸미고자하는 HTML tag를 \u0026lsquo;selector\u0026rsquo;라고 한다.\n이 \u0026lsquo;selector\u0026rsquo;를 입력한 후 중괄호를 열어 원하는 css 속성 이름과 속성값을 입력한다.\n또한, css를 입력할 때는 띄어쓰기, 언더바(_). 슬래쉬(/)를 사용하면 안되며, css의 속성들은 각 줄이 세미클론(;)으로 끝나야 한다.\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!-- \u0026lt;h1\u0026gt; \u0026lt;/h1\u0026gt; tag에 대해 CSS를 적용한다고 하자. --\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;style\u0026gt; h1 { /* # 속성 이름: 속성값; */ color: yellowgreen; font-size: 50px; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;/html\u0026gt; 3.2 tag의 id 이용하여 css 입력하기 id라는 tag attribute를 사용하여 동일한 종류의 태그들이어도, 각각 지정하여 css를 적용할 수 있다.\n한 종류의 태그가 여러 개 있을 때, 이 태그들 각각에 서로 다른 css style을 적용하고 싶다면 어떻게 해야할까???\n바로 아래 코드와 같이 id attribute를 사용한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ko\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id = \u0026#34;red\u0026#34;\u0026gt; \u0026lt;div id = \u0026#34;yellow\u0026#34;\u0026gt; \u0026lt;div id = \u0026#34;green\u0026#34;\u0026gt; \u0026lt;div id = \u0026#34;blue\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 그러면 이 각 div에 서로 다른 css를 적용해보기 위해서, id 값을 css에 입력하는 방법을 밑에 코드로 확인해보자.\n1 2 3 4 5 \u0026lt;style\u0026gt; #id_name { css attibute name: attribute value; } \u0026lt;/style\u0026gt; 어떻게 id 를 사용하여 css를 입력할지 알았으니, 각각의 \u0026lt;div\u0026gt; 에 적용해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ko\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; div { height: 200px; width: 200px; } #red { background-color: red } #yellow { background-color: yellow } #green { background-color: green } #blue { background-color: blue } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id = \u0026#34;red\u0026#34;\u0026gt; \u0026lt;div id = \u0026#34;yellow\u0026#34;\u0026gt; \u0026lt;div id = \u0026#34;green\u0026#34;\u0026gt; \u0026lt;div id = \u0026#34;blue\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 기존 tag name을 사용하여 입력하는 방식에는 \u0026lsquo;공통사항\u0026rsquo;을 입력하고, id 값을 사용하여 각각의 tag에 id 값을 사용하여 구별해서 적용할 수 있다.\n\u0026lt;div\u0026gt; tag에만 관련하여 브라우저에게 이와 같이 말하는 것이다.\n\u0026lt;div\u0026gt; tag의 height와 width는 모두 200px로 해주고, \u0026lt;div\u0026gt; tag 중 id 값이 \u0026lsquo;red\u0026rsquo;인 것의 배경색은 red color로, id 값이 \u0026lsquo;yellow\u0026rsquo;인 것의 배경색은 yellow color로, id 값이 \u0026lsquo;green\u0026rsquo;인 것의 배경색은 green color로, id 값이 \u0026lsquo;blue\u0026rsquo;인 것의 배경색은 blue color로 정한다. 3.3 tag의 class를 이용하여 css 입력하기 tag의 속성 class는 속성 id처럼 각 tag element들을 구별해서 가리킬 수도 있고, id와는 다르게 겹쳐서 가리킬 수 있는 attribute다.\nclass attribute는 css에 입력하는 방법을 밑에 코드로 확인해보자.\nid attribute와는 달리 #아니라 .을 사용한다.\n1 2 3 4 5 \u0026lt;style\u0026gt; .class값 { css attibute name: attribute value; } \u0026lt;/style\u0026gt; 그러면 \u0026lsquo;id\u0026rsquo; 속성으로 구현한 css 코드를 \u0026lsquo;class\u0026rsquo; 속성을 사용해서 구현해보겠다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;style\u0026gt; .btn { height: 200px; width: 200px; } .red { background-color: red; } .yellow { background-color: yellow; } .green { background-color: green; } .blue { background-color: blue; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class = \u0026#34;btn red\u0026#34;\u0026gt; \u0026lt;div class = \u0026#34;btn yellow\u0026#34;\u0026gt; \u0026lt;div class = \u0026#34;btn green\u0026#34;\u0026gt; \u0026lt;div class = \u0026#34;btn blue\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; class는 id 속성과는 달리 속성값을 공백을 기준으로 여러 개를 입력할 수 있다.\nReference 노마드코더 - 코코아톡 클론 코딩 ","permalink":"http://jeha00.github.io/post/html_css/study02/","summary":"CSS 입력방식인 inline과 external 방식이 각각 무엇인지, css 속성값을 입력하는 방식과 html tag의 속성인 id, class를 사용하여 css 속성 값을 입력하는 방식을 알아본다.","title":"[TIL] HTML \u0026 CSS study - CSS 01"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.\nChapter 12로 Git 자체에 대한 마지막 강의로 gitmoji 와 git submodules를 학습한다.\n1. git hooks git 상의 이벤트마다 자동적으로 실행될 스크립트를 지정하는 것으로 \u0026lsquo;자동화\u0026rsquo; 라고 생각하자.\ngit hooks와 함께 Gitmoji에 대해 알아보자.\n커밋을 하면 자동적으로 푸쉬가 실행되게 하던가, 커밋 전 코드가 약속된 형식대로 되어있는지 확인하는 것 등등 \u0026lsquo;자동화\u0026rsquo;가 이뤄지게 한다.\n프로젝트 폴더 내의 .git \u0026gt; hooks 폴더를 들어가 확인하면 .sample이란 형식의 파일들이 들어있다.\n그러면 실습을 하기 위한 환경을 만들기 위해 gitmoji 를 설치해보자.\nGitmoji Gitmoji란?\ngitmoji - README.md를 참고한다. an initiative to standardize and explain the use of emojis on GitHub commit messages. 깃헙의 커밋 메세지에 대해서 이모지 사용을 표준화하고 설명하는 것으로서, 커밋 메세지에 관해 이모지를 사용하여 커밋의 의도 또는 목적을 쉽게 식별할 수 있는 방법이다. 그래서 gitmoji - list에 나와있는대로 각 이모지마다 독립적인 의미를 가진다. Gitmoji 설치하기\n먼저 node.js를 설치하기.\ncommand에 npm -v를 입력하여 version이 뜨면 성공적으로 설치된 것 ❗ node.js를 설치했어도 npm 명령어가 인식되지 않으면 vsc를 껐다가 다시 켜보자.\n터미널 명령어를 사용하여 gitmoji-cli를 설치한다.\nnpm i -g gitmoji-cli 그 후, gitmoji -i를 입력하면, 아래 코드처럼 진행되면서 prepare-commit.msg 가 생성.\n1 2 3 \u0026gt; gitmoji -i - Creating the gitmoji commit hook Gitmoji commit hook created successfully hook 과 Gitmoji 학습하기 그러면 본격적으로 hook과 gitmoji 둘 다 학습해보자.\n파일의 변화를 준 후, git add .를 실행한다.\n그 다음 git commit 만 입력하면, 이모지가 뜬다. 원하는 이모지 스펠링을 입력 후, 선택 및 엔터를 누른다. 남기기 원하는 commit mesage를 입력 후, 엔터를 누른다. vim 모드가 뜨면 :wq를 입력하여 저장 및 나간다. ❗ gitmoji-cli hook 해제하기 hooks 폴더에서 prepare-commit-msg file을 삭제하면 된다.\n2. git submodules 프로젝트 폴더 안에 또 다른 프로젝트가 포함될 때 사용한다.\n프로젝트 폴더 구성은 다음과 같다. 1 2 3 # 경로: main-project \u0026gt; dir main-project-files module-project-1 module-project-2 main-project와 main-project 안에 module-project-1,2 도 git으로 관리된다. 그런데, module project가 물리적으로는 main-project 안에 있지만, git 관리는 따로 하고 싶을 때 어떻게 해야할까? 즉, main-project에 대한 git 관리에 module-project-1,2를 별도로 떨어뜨려 관리하고 싶으면 어떻게 해야할까? ❗ module-project 또한 git이 지속해서 관리해야해서 .gitignore에 등록하면 안된다.\n여러 프로젝트에 사용되는 공통모듈일 때 유용하다. 2.1사용해보기 2.1.1. 두 프로젝트 생성하기 첫 번째, main-project에 git remote add origin \u0026lt;Github addess\u0026gt; 를 추가한다.\n두 번째, 두 개의 프로젝트를 생성하기\n2.1.2. submodule 추가하기 main-project에 서브모듈로 submodule 프로젝트 추가한다.\nmain-project 디렉토리상 터미널에서 아래 명령어 실행\ngit submodule add (submodule의 GitHub 레포지토리 주소) (하위폴더명, 없을 시 생략) 프로젝트 폴더 내 submodule 폴더와 .gitmodules 파일 확인 스테이지된 변경사항 확인 뒤 커밋 양쪽 모두 수정사항 만든 뒤 main-project 에서 git status로 확인 1 2 3 4 5 6 7 8 9 10 11 $ git status On branch main Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) (commit or discard the untracked or modified content in submodules) modified: main.txt modified: submodule1 (modified content) modified: submodule2 (modified content) no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 그러면 git add .를 실행한 후 다시 확인해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 $ git add . $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: main.txt Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) (commit or discard the untracked or modified content in submodules) modified: submodule1 (modified content) modified: submodule2 (modified content) submodule의 변경사항은 포함되지 않음을 확인 main-project에서 변경사항 커밋 후 푸시 -\u0026gt; submodule에서 변경사항 커밋 후 푸시 -\u0026gt; main-project에서 상태 확인 -\u0026gt; main-project에 커밋, 푸시 후 GitHub에서 확인\n즉, submodule로 등록되었으면 서브 모듈로 등록된 폴더 내부의 파일 변화는 감지할지라도, 서브 모듈 내부 파일들의 변화까지 한 번에 커밋되지는 않는다.\n2.1.3. 서브모듈 업데이트 main-project 새로운 곳에 clone하기\n서브모듈 폴더들은 존재해도 파일들은 없기 때문에 아래 단계를 진행한다. 아래 명령어들로 서브모듈 init 후 클론\ngit submodule init (특정 서브모듈 지정시 해당 이름만 입력)\n.gitmodules의 [submodule \u0026quot;\u0026lt;submodule name\u0026gt;\u0026quot;] 에서 \u0026lt;submodule name\u0026gt;을 입력한다. ex) git submodule init submodule1 git submodule update\n1 2 3 4 5 6 7 8 # 경로: main-project가 있는 folder $ git submodule init $ git submodule update Cloning into \u0026#39;C:/Users/rudtl/Desktop/Dev/GitHub/git-test/git-practice1/submodule1\u0026#39;... Cloning into \u0026#39;C:/Users/rudtl/Desktop/Dev/GitHub/git-test/git-practice1/submodule2\u0026#39;... Submodule path \u0026#39;submodule1\u0026#39;: checked out \u0026#39;0434727626afe874b8a0ccaa4cd89ce716f14b37\u0026#39; Submodule path \u0026#39;submodule2\u0026#39;: checked out \u0026#39;8f86fe62491d0930f4d93963a3c42f7db852447b\u0026#39; (base) 4. GitHub에서 submodule에 수정사항 커밋\ngit submodule update --remote 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ git submodule update --remote remote: Enumerating objects: 5, done. remote: Counting objects: 100% (5/5), done. remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), 627 bytes | 27.00 KiB/s, done. From https://github.com/JeHa00/git-submodule1 033d9fe..e46b343 main -\u0026gt; origin/main Submodule path \u0026#39;submodule1\u0026#39;: checked out \u0026#39;e46b3437d1b2d7c3e03ebc6fabbc9956572399c7\u0026#39; remote: Enumerating objects: 5, done. remote: Counting objects: 100% (5/5), done. remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), 626 bytes | 34.00 KiB/s, done. From https://github.com/JeHa00/sub2 8de549f..4e300ab main -\u0026gt; origin/main Submodule path \u0026#39;submodule2\u0026#39;: checked out \u0026#39;4e300ab56e9282da6278decca5e067ee025c7aa7\u0026#39; 서브모듈 안에 또 서브모듈 있을 시: --recursive 추가 Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter12/","summary":"hook을 사용하여 gitmoji 를 사용하는 방법을 학습한 후, submodule이란 무엇이고 어떠한 장점이 있는지를 학습한다. 그리고, git submodule 명령어를 통해 submodule 연결을 해본다.","title":"[TIL] Git study: Lecture Chapter 12 - Gitmoji \u0026 git submodules"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. Chapter 11에서는 분석하고 디버깅하는 것에 대해 다룬다. 그래서 이번 소단원에서는 git bisect 라는 명령어로 코드에서 문제가 발생한 지점을 찾아내보겠다. git bisect Problem: 아래와 같이 많은 커밋 버전을 하나 하나 실행해보면서 오류가 어디서부터 시작했는지 찾을려면 시간이 많이 걸린다.\ngit log로 commit 내역을 확인해본다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 $ git log ... commit 9a9304295288c28e0ddf6f66997c1f453831c14d Author: yalco \u0026lt;yalco@kakao.com\u0026gt; Date: Tue Jan 4 14:10:28 2022 +0900 v4 commit 7d167e9e36af71c5d42c77a30640610a1ba57164 Author: yalco \u0026lt;yalco@kakao.com\u0026gt; Date: Tue Jan 4 14:10:10 2022 +0900 v3 - suspicious! commit 37dd5cc8d9c8f93e293fa024dbdb48bf9d5b0170 Author: yalco \u0026lt;yalco@kakao.com\u0026gt; Date: Tue Jan 4 14:09:28 2022 +0900 v2 commit aded506c5583e1556ba052facb5aeb169afbc880 Author: yalco \u0026lt;yalco@kakao.com\u0026gt; Date: Tue Jan 4 14:09:20 2022 +0900 v1 Solution: git bisect를 사용한다.\n원리: 이진 탐색으로 점차 탐색 범위를 줄여가면서 오류의 원인을 찾아나간다. 탐색 순서\n첫 번째, 이진 탐색 시작\ngit bisect start 두 번쨰, 오류발생 지점임을 표시\n현재 시점에서는 오류가 발생된 걸 확인했으므로, git bisect bad 세 번째, 의심 지점으로 이동\ngit checkout (해당 커밋 해시) commiet message가 v3 지점으로 이동해본다. 네 번째, 오류 발생 않을 시 양호함 표시\ngit bisect good 이동했지만, 에러가 없는 시점이므로, 위와 같이 입력한다. 그러면 git bisect good 과 git bisect bad를 입력한 두 커밋의 중간 지점으로 자동적으로 이동한다. 다섯 번째, 원인을 찾을 때까지 반복\ngit bisect good/bad를 입력하면서 반복하며 좁혀지다가 끝에 다다르면 밑 메세지와 같이 동일한 메세지가 뜬다. 1 2 3 4 5 6 7 8 9 eb18f28cad35687a712ff2c58dbfcba6ac6d97a9 is the first bad commit commit eb18f28cad35687a712ff2c58dbfcba6ac6d97a9 Author: yalco \u0026lt;yalco@kakao.com\u0026gt; Date: Tue Jan 4 14:10:39 2022 +0900 v5 program.yaml | 4 ++-- 1 file changed, 2 insertions(+), 2 deletions(-) 이진 탐색 종료 git bisect reset Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter11-04/","summary":"git bisect 명령어를 통해서 이진 탐색과 commit hash number를 이용하여 오류 지점을 찾아본다.","title":"[TIL] Git study: Lecture Chapter 11 - Git bisect"},{"categories":"HTML_CSS","content":"0. Introduction HTML과 CSS에 대한 기본적인 내용을 정리해보는 글이다.\n크롬, 익스플로어, 파이어폭스 같은 브라우저들은 서버에서 보내는 HTML, CSS 그리고 javascript 파일을 분석하여 구현한 후, 클라이언트들에게 보여준다.\n그러면 이 3가지 중 HTML과 CSS가 무엇인지에 대해 알아보자.\n1. What is HTML and CSS ? 브라우저는 사람의 언어를 이해하지 못 하기 때문에, 만든 웹 사이트를 이해하기 위해서는 브라우저가 이해하는 언어로 전달해야 하기 때문에, 브라우저의 구성 요소인 3가지로 전달한다.\n그러면 웹 사이트의 구성 요소인 HTML, CSS, Javascript란 무엇일까??\n흔히들 이 3가지를 신체와 비교하여 다음과 같이 설명한다.\nHTML: 사람의 신체에 비유하자면 뼈대로서, Markup language 종류로 브라우저에게 tag 를 사용하여 이 컨텐츠의 종류가 무엇인지를 알려주는 역할 CSS: 사람의 신체에 비유하자면 근육으로서, 이 콘텐츠를 디자인하는 역할\nJavascript: 사람의 신체에 비유하자면 brain으로서, web site가 동적으로 움직여서 interactivity 하기 위해 필요하다.\n❗ 브라우저는 오류가 있어도 오류를 알려주지 않는다.\n2. HTML 브라우저에게 \u0026rsquo;tag\u0026rsquo;를 사용하여 컨텐츠의 종류를 알려주는 마크업 언어의 종류\n2.1 HTML의 tag tag란? \u0026rsquo;tag\u0026rsquo; 에는 아래 코드에서 보이듯이 괄호로 갇혀진 부분이 태그다.\nself-closing tag 와 그렇지 않은 태그 두 종류로 나눠진다. 그렇지 않은 태그는 여는 태그와 닫는 태그로 구성된다. 여는 태그와 닫는 태그 사이에 있는게 contents 내용이며, 태그로 이 컨텐츠의 종류를 결정한다. 1 2 3 4 5 6 # self-closing tag \u0026lt; input /\u0026gt; # non self-closing tag # 태그 사이에 있는 Home - My website가 content \u0026lt;title\u0026gt;Home - My website\u0026lt;/title\u0026gt; tag 작성과 찾는 방법 HTML \u0026rsquo;tag`는 매우 많은 종류가 있기 때문에, 암기하려고 하지않는다. 다만, 태그를 작성하는 방법과 찾는 방법을 알면 된다.\n태그를 찾는 방법: \u0026lsquo;html tag mdn\u0026rsquo;을 구글링하여 mozilla 에서 알아본다. 또한, 원하는 사이트의 html code 구성을 보고 싶다면 마우스 오른쪽 클릭을 하여 검사 또는 inspection을 클릭하면 확인할 수 있다.\nHTML tag의 기본 구성 Visual Studio Code로 doc만 입력하면 바로 아래의 코드가 펼쳐진다.\nhtml에는 반드시 따라야만 하는 틀이 있다.\n\u0026lt;!DOCTYPE html\u0026gt;로 html 문서는 시작한다.\n\u0026lt;html\u0026gt; tag 안에 \u0026lt;head\u0026gt;와 \u0026lt;body\u0026gt;로 크게 나눠진다.\n\u0026lt;head\u0026gt; : 브라우저에게 사이트의 정보를 알려주는 단계로 웹 사이트의 보이지 않는 부분인 환경을 설정한다. \u0026lt;body\u0026gt; : 브라우저 화면 상에 보여질 내용들인, 사용자가 볼 수 있는 content를 보여준다. \u0026lt;html lang = \u0026quot;ko\u0026quot;\u0026gt;: 웹 사이트에서 사용되는 언어를 이 웹 사이트의 검색 엔진에게 알려주는 속성\n\u0026lt;meta charset = \u0026quot;UTF-8\u0026quot;\u0026gt;은 문자 인코딩 방식을 브라우저에게 알려준다.\n\u0026lt;title\u0026gt;은 브라우저의 탭에 뜨는 문구를 브라우저에게 알려준다.\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ko\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; semantic tag와 non-semantic tag tag의 다른 나눠지는 기준으로 semantic tag와 non-semantic tag가 있다.\ntag 자체 명칭에 의미가 있는 tag를 semantic tag라 하고, tag 자체 명칭에 의미가 없는 tag를 non-semantic tag라 한다. non-semantic tag의 예로는 \u0026lt;div\u0026gt; \u0026lt;/div\u0026gt; 가 있다. division이란 단어에서 나온 것으로, 박스나 경계선이라 생각하면 된다.\n기능은 가지고 있지만, 의미론적으로는 아무런 값이 없는 box다. semantic tag의 예로는 \u0026lt;header\u0026gt; \u0026lt;/header\u0026gt;가 있다. \u0026lt;head\u0026gt; 와는 다른 것이며 \u0026lt;body\u0026gt; \u0026lt;/body\u0026gt;에 포함된다. 이 예시를 읽었을 때 그 의미를 짐작할 수 있기 때문에 semantic tag로 분류된다.\n코드를 짤 때는 최대한 semantic tag로만 코드를 짜는 거를 추천하는 이유가 코드만 보고도 무엇인지 빠르게 파악 가능하다. tag의 attribute 각 \u0026rsquo;tag\u0026rsquo;는 attribute(속성)을 가지는데, 태그의 부가적인 정보를 말한다. attribute를 입력할 때는 '' 이 아닌 \u0026quot;\u0026quot;를 사용해야 한다. attribute에는 아무거나 작성핻 되지만, 각 tag에 정해진 attribute를 작성하지 않으면 브라우저는 인식하지 않는다. 자주 사용되는 tag는 암기하는 것을 추천한다. tag에 사용되는 attribute 중 id는 어느 태그에서든 사용할 수 있다. 3. HTML tag의 다양한 예 h1 ~ h6 \u0026lt;body\u0026gt;의 \u0026lt;h1\u0026gt; 부터 \u0026lt;h6\u0026gt; 로 갈수록 title의 글자 크기가 작아진다. \u0026lt;h7\u0026gt; 부터는 title로 인식하지 않는다. 1 2 3 4 5 6 7 8 \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;website!\u0026lt;/h1\u0026gt; \u0026lt;h2\u0026gt;website!\u0026lt;/h1\u0026gt; \u0026lt;h3\u0026gt;website!\u0026lt;/h3\u0026gt; \u0026lt;h4\u0026gt;website!\u0026lt;/h4\u0026gt; \u0026lt;h5\u0026gt;website!\u0026lt;/h5\u0026gt; \u0026lt;h6\u0026gt;website!\u0026lt;/h6\u0026gt; \u0026lt;body/\u0026gt; \u0026lsquo;id\u0026rsquo; 속성 \u0026lsquo;id\u0026rsquo; 속성은 body 태그 안에 어떤 태그에든지 넣을 수 있는 속성이다. 이 속성은 고유 식별자(unique identifier) 역할을 하기 때문에, element 당 하나의 id만 가지는 것 이 id의 필수적인 규칙이다. 하나의 태그는 하나의 id만 가지면, 다른 태그의 id 값과 동일한 값을 가지면 안된다. 또한, CSS가 이 id 속성을 통해 디자인을 브라우저에게 지시할 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; \u0026lt;label for = \u0026#34;FullName\u0026#34;\u0026gt; site \u0026lt;/label\u0026gt; \u0026lt;input id = \u0026#34;FullName\u0026#34; requried placeholder= \u0026#34;Full name\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;label for = \u0026#34;first-name\u0026#34;\u0026gt; First Name \u0026lt;/label\u0026gt; \u0026lt;input id = \u0026#34;first-name\u0026#34; required placeholder = \u0026#34;first name\u0026#34; type = \u0026#34;text\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;label for = \u0026#34;password\u0026#34;\u0026gt; Password \u0026lt;/label\u0026gt; \u0026lt;input id = \u0026#34;password\u0026#34; required placeholder = \u0026#34;Password\u0026#34; type = \u0026#34;password\u0026#34; minlength = \u0026#34;10\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;body\u0026gt; for의 값과 id의 값을 동일하게 입력하여 연결시킨다. required placeholder: input 할 칸에 뜨는 설명 문자를 받는 속성 text: 입력받을 데이터의 type을 브라우저에게 알려줘서, type에 맞는 input 창을 생성한다. password type의 경우, text type과 달리 입력한 값이 드러나지 않고 숨겨진다. a href 링크 첨부하는 태그와 속성 1 2 3 4 5 \u0026lt;body\u0026gt; \u0026lt;a href = \u0026#34;www.google.com\u0026#34;\u0026gt;Go to google.com\u0026lt;/a\u0026gt; \u0026lt;a href = \u0026#34;www.google.com\u0026#34; target = \u0026#34;_self\u0026#34;\u0026gt;Go to google.com \u0026lt;/a\u0026gt; \u0026lt;a href = \u0026#34;www.google.com\u0026#34; target = \u0026#34;_blank\u0026#34;\u0026gt;Go to google.com \u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; target 속성은 새로운 tab에서 첨부한 링크를 열지, 아니면 tab을 새로 열지 않고 첨부한 링크로 이동할지를 결정하는 속성 _self는 후자이고, _blank는 전자다. target 속성을 사용하지 않으면 기본적으로 _self를 default로 인식한다. img src 이미지를 첨부하는 태그와 속성 img 라는 태그에 속성 src = 를 입력하여 이미지 주소를 입력한다. 1 2 3 \u0026lt;body\u0026gt; \u0026lt;img src = \u0026#34;img/id_img.jpg\u0026#34; \u0026lt;/body\u0026gt; Reference 노마드코더 - 코코아톡 클론 코딩 ","permalink":"http://jeha00.github.io/post/html_css/study01/","summary":"HTML, CSS가 무엇이고, 브라우저에서 무슨 역할을 하는지, html의 tag란 무엇인지, semantic tag과 non-semantic tag란 무엇인지 학습한다. 그리고, tag의 다양한 속성 중 몇 가지를 학습해본다.","title":"[TIL] HTML \u0026 CSS study - HTML이란?"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. Chapter 11에서는 분석하고 디버깅하는 것에 대해 다룬다. 그래서 이번 소단원에서는 git blame 명령어를 통해 각 라인의 작성자를 확인하는 법에 대해 알아본다. git blame 🔅 코드에 대한 책임을 따지는 것을 넘어서 이 코드를 수정해도 되는지, 왜 이렇게 했는지를 묻기 위해서도 필요하다.\n파일의 부분별로 작성자 확인하기\ngit blame (파일명) 파일명을 CLI에 입력할 때는 첫 글자를 입력하고 tab을 누르면 자동완성된다. 1 2 $ git blame whoCodedThis.txt 그러면 왼쪽 칼럼 부분에 괄호 치고 작성자가 누군지 알 수 있다. git config user.name 을 바꿔가면서 작성자를 바꿨다. 맨 오른쪽 칼럼 부분은 코드의 각 줄을 의미하는데, 각 줄마다 누가 작성했는지를 알 수 있다. 특정 부분 지정해서 작성자 확인하기\ngit blame -L (시작줄) (끝줄, 또는 +줄수) (파일명) 1 2 3 4 5 6 7 8 9 10 11 $ git blame -L 10,12 whoCodedThis.txt 65f63a2d (pikachu 2022-01-04 13:31:27 +0900 10) d1ef31c6 (mito 2022-01-04 13:31:45 +0900 11) 나 미친토끼 미토에요. d1ef31c6 (mito 2022-01-04 13:31:45 +0900 12) # 또는 다음과 같이 입력할 수 있다. $ git blame -L 10,+3 whoCodedThis.txt 65f63a2d (pikachu 2022-01-04 13:31:27 +0900 10) d1ef31c6 (mito 2022-01-04 13:31:45 +0900 11) 나 미친토끼 미토에요. d1ef31c6 (mito 2022-01-04 13:31:45 +0900 12) GitLens git 명령어로 하는 방법보다 권장되는 방법으로, 플러그 인 프로그램인 GitLens를 사용하는 것이다. source tree로도 볼 수 있지만, GitLens를 사용하는 걸 추천한다. Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter11-03/","summary":"git blame 명령어와 VSC의 extension program인 GitLens를 통해 각 라인의 작성자를 확인하는 법을 알아본다.","title":"[TIL] Git study: Lecture Chapter 11 - Git blame \u0026 GitLens"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. Chapter 11에서는 분석하고 디버깅하는 것에 대해 다룬다. 이번 단원에서는 차이를 살펴보는 git diff 명령어에 대해 알아본다. Git diff working directory의 변경사항을 확인하는 명령어\ngit diff 명령어를 통해서 현재 파일들의 변경사항, staging area에 올라간 파일들의 변경사항, 브랜치 간의 변경사항, 커밋 간의 변경사항들 여러 관계 사이의 변경사항을 알 수 있다.\n먼저 실습하기 위한 변경 사항을 임의로 만들어본다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 $ git diff # leopards.yaml diff --git a/leopards.yaml b/leopards.yaml index 9c8086a..eca1191 100644 --- a/leopards.yaml +++ b/leopards.yaml @@ -13,5 +13,3 @@ members: - Dongho - Drax - Groot - - Onepiece - - No jam Thore # panthers.yaml diff --git a/panthers.yaml b/panthers.yaml index 8e2ee18..fb9738a 100644 --- a/panthers.yaml +++ b/panthers.yaml @@ -11,3 +11,4 @@ members: - Freddie - Arachi - Hoki + - Harus \\ No newline at end of file # tigers.yaml diff --git a/tigers.yaml b/tigers.yaml index cd48481..c8ca3e0 100644 --- a/tigers.yaml +++ b/tigers.yaml @@ -11,5 +11,3 @@ members: - George - Tyler - Kim - - Gamora - - Nebula 파일명만 확인:\n변경사항 있는 파일의 이름들만 확인 git diff --name-only 1 2 3 4 $ git diff --name-only leopards.yaml panthers.yaml tigers.yaml 스테이지의 확인:\nworking directory에 있다가 staging area에 올라간 파일들의 변경사항을 확인하고자 할 때 사용 git diff --staged: git diff --caced도 이와 동일한 명령어 1 2 3 4 $ git add . $ git diff --staged # git diff를 한 것과 동일한 결과가 나온다. 커밋간의 차이 확인\ngit diff (커밋 1) (커밋 2) 또는 커밋 해시나 HEAD 번호로도 가능하다. 현재 커밋과 비교하려면 이전 커밋만 입력한다. 1 2 3 4 5 6 7 8 # 지난 번에 학습한 단축키 설정 명령어로 정한 git log 명령어를 사용한다. # 그래서 두 개의 커밋을 골라보자. $ git gg $ git diff 7a6d996 09994e8 # 또는 HEAD 번호를 사용해보자. $ git diff HEAD~ HEAD~10 그러면 git diff의 다른 옵션과 같이 사용해보자.\n1 2 3 4 5 $ git diff --name-only HEAD~3 HEAD~7 leopards.yaml panthers.yaml pumas.yaml tigers.yaml 브랜치간의 차이 확인\ngit diff (브랜치 1) (브랜치 2) 1 2 3 4 5 6 7 8 9 10 $ git branch -a citrus fruit * main root $ git diff main root diff --git a/onion b/onion deleted file mode 100644 index e69de29..0000000 Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter11-02/","summary":"git diff 명령어를 통해서 현재 파일들의 변경사항, staging area에 올라간 파일들의 변경사항, 브랜치 간의 변경사항, 커밋 간의 변경사항들 여러 관계 사이의 변경사항을 알 수 있다.","title":"[TIL] Git study: Lecture Chapter 11 - Git diff"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. 이번 단원에서는 git log를 옵션들과 함께 사용하여 더 자세히 살펴보겠다. 옵션들을 활용한 다양한 사용법 각 커밋마다의 변경사항 함께 보기 git log -p\n커밋 해쉬 번호만 보여주는 게 아닌, 각 커밋마다의 변경사항을 함께 보여준다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 $ git log -p commit 51075e540e06075761bd17080ef3a01b79f25056 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:06 2022 +0900 edit members of leopards.yaml diff --git a/leopards.yaml b/leopards.yaml index 2aaf3d2..ed823d4 100644 --- a/leopards.yaml +++ b/leopards.yaml @@ -13,5 +13,3 @@ members: - Dongho - Drax - Groot - - I\\\u0026#39;m groot - - Guardians of Glaxy commit 7a6d9965f2f366fb4d10e1739b804572beef0fcf (main2) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:14:35 2022 +0900 edit memebers in leopards.yaml diff --git a/leopards.yaml b/leopards.yaml index ed823d4..fb150cc 100644 --- a/leopards.yaml +++ b/leopards.yaml @@ -1,6 +1,6 @@ team: Leopards -manager: Peter +manager: Harry Poter^M coach: Rocket @@ -13,3 +13,4 @@ members: - Dongho - Drax - Groot + - No jam Thore^M 최근 n개 커밋만 보기 git log -(갯수)\n최근 커밋을 원하는 갯수만큼 볼 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 이전 커밋 3개만 보고 싶다. $ git log -3 commit 1dccdb61b999634cba358a0a27c5dd4d9fca7a30 (HEAD -\u0026gt; main) Merge: f217dc2 7a6d996 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Fri Jul 15 13:50:21 2022 +0900 Merge branch \u0026#39;main2\u0026#39; commit f217dc2eec6877db8a3e8828ba24e05c05f742f9 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:34 2022 +0900 edit memebers in leopards.yaml commit 51075e540e06075761bd17080ef3a01b79f25056 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:06 2022 +0900 edit members of leopards.yaml 또한 -p와 함께 사용하여 원하는 만큼의 커밋을 보는데, 각 커밋의 변경사항과 함께 볼 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 $ git log -p -3 commit 1dccdb61b999634cba358a0a27c5dd4d9fca7a30 (HEAD -\u0026gt; main) Merge: f217dc2 7a6d996 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Fri Jul 15 13:50:21 2022 +0900 Merge branch \u0026#39;main2\u0026#39; commit f217dc2eec6877db8a3e8828ba24e05c05f742f9 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:34 2022 +0900 edit memebers in leopards.yaml diff --git a/leopards.yaml b/leopards.yaml index ed823d4..24e6957 100644 --- a/leopards.yaml +++ b/leopards.yaml @@ -13,3 +13,4 @@ members: - Dongho - Drax - Groot + - Onepiece^M commit 51075e540e06075761bd17080ef3a01b79f25056 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:06 2022 +0900 edit members of leopards.yaml 통계와 함께 보기 git log \u0026ndash;stat\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 $ git log --stat commit f217dc2eec6877db8a3e8828ba24e05c05f742f9 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:34 2022 +0900 edit memebers in leopards.yaml leopards.yaml | 1 + 1 file changed, 1 insertion(+) commit 51075e540e06075761bd17080ef3a01b79f25056 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:06 2022 +0900 edit members of leopards.yaml leopards.yaml | 2 -- 1 file changed, 2 deletions(-) 한 줄로 보기 git log \u0026ndash;oneline\n--pretty=oneline --abbrev-commit을 줄인 것 1 2 3 4 5 6 7 $ git log ---oneline 1dccdb6 (HEAD -\u0026gt; main) Merge branch \u0026#39;main2\u0026#39; f217dc2 edit memebers in leopards.yaml 51075e5 edit members of leopards.yaml 7a6d996 (main2) edit memebers in leopards.yaml 9302244 edit memebers in leopards.yaml ... 변경사항 내 단어 검색 git log -S (검색어)\nS는 반드시 대문자를 입력해야 한다. George를 검색해본다고 하자. 1 2 3 4 5 6 $ git log -S George commit 679d1f1788575666f8b368c67dfbb14f69c6a637 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:28:44 2022 +0900 add George to tigers 커밋 메시지로 검색 git log \u0026ndash;grep (검색어)\n1 2 3 4 5 6 $ git log --grep Olivia commit 904db06ba9495801734d1fa81580a269e6f37ba6 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Fri Jun 24 13:40:58 2022 +0900 Add Olivia to Leopards 커밋 메시지로 검색하는 것에 대한 그 밖에 옵션들은 기타 옵션 보기를 참고한다. 자주 사용되는 그래프 로그 보기 git log \u0026ndash;all \u0026ndash;decorate \u0026ndash;oneline \u0026ndash;graph\n위 명령어 사용된 옵션들에 대한 설명은 다음과 같다. --all: 모든 브랜치 보기 --graph: 그래프 표현 --decorate: 브랜치, 태그 등 모든 레퍼런스 표시 --decorate=no --decorate=short: 기본 --decorate=full 🔅 이 명령어로 그래프를 보는 것보다 소스 트리로 보는 걸 추천한다.\n단축키를 설정하여 이 명령어를 자주 사용하기도 한다.\n단축키 설정은 Chapter06을 참고하자. 다음 명령어는 포맷된 로그의 한 종류다.\nlog --graph --all --pretty=format:'%C(yellow) %h %C(reset)%C(blue)%ad%C(reset) : %C(white)%s %C(bold green)-- %an%C(reset) %C(bold red)%d%C(reset)' --date=short 여기서 data를 relative로 바꿔보자. 위 명령어를 단축키를 통해 사용하고자 한다면\ngit config --global alias.(단축키) \u0026quot;명령어\u0026quot;\n위 명령어에 입력할 때, git은 빼고 입력한다.\ngit config --global alias.gg \u0026quot;log --graph --all --pretty=format:'%C(yellow) %h %C(reset)%C(blue)%ad%C(reset) : %C(white)%s %C(bold green)-- %an%C(reset) %C(bold red)%d%C(reset)' --date=short\u0026quot;\n그리고 나서 git gg를 입력하면 뜬다.\n❗ 단축키 설정을 했지만, Expansion of alias failed; not a git command 이와 같은 에러가 발생했다면 git update-git-for-windows를 사용하여 업데이트 후, 다시 해보자.\nReference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter11-01/","summary":"git log에 달려있는 여러 옵션들을 사용하여 log를 더 자세히 알아본다.","title":"[TIL] Git study: Lecture Chapter 11 - Git log 자세히 알아보기"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. 이번 단원에서는 Gitflow를 사용해서 협업을 위한 브랜치 활용법을 알아본다. 협업을 위한 branch 활용법 체계적으로 협업하기 위한 브랜칭 전략이 gitflow다. 사용되는 브랜치들 브랜치 용도 main 제품 출시/배포 develop 다음 출시/배포를 위한 개발 진행 release 출시/배포 전 테스트 진행(QA) feature 기능 개발 hotfix 긴급한 버그 수정 main\n실제로 사용자들에게 최종적으로 출시될 것들로서, tag가 붙여진다. develop\nmain을 만들어내기 위한 개발 작업은 이 브랜치에서 이뤄진다. 여기서 새로운 기능을 추가하거나, 문제들을 해결해가면서 커밋들을 추가해간다. feature:\ndevelop 과정에서 굵직한 것들은 이 feature branch에서 만들어진다. 그래서 여러 개의 feature branch가 만들어 질 수 있다. ex) feature - 기능 이름 기능이 완성되면 develop branch를 합쳐진다. release:\ndevelop branch에서 개발이 이뤄지다가, 이제 출시를 해도 될 정도로 성능과 버그 등등이 괜찮을 때 해당 브랜치에서 테스트하기 위해 이동된다. 이 브랜치에서 수정되면 develop branch에 합쳐진다. 이 브랜치에서 작업하다가 확실하게 출시해도 괜찮으면 main branch로 옮겨진다. hotfix:\nmain branch로 출시된 제품들 중에서 갑자기 오류가 발생했을 경우, hotfix branch에서 작업한다. 해결되면 다시 main branch를 병합하여 출시한다. Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 A successful Git branching model ","permalink":"http://jeha00.github.io/post/git/lec_chapter10-05/","summary":"협업 시 여러 branch를 생성하여 어떻게 활용하는지, 각 branch의 이름은 현업에서 주로 사용되는 이름이 있는지 Gitflow를 사용한 브랜치 활용법에 대해 알아본다.","title":"[TIL] Git study: Lecture Chapter 10 - Gitflow"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. 이번 단원에서는 git merge --squash 명령어를 사용해서 다른 가지의 마디들을 묶어서 가져와본다. 다른 가지의 마디들 묶어서 가져오기 git merge \u0026ndash;squash (대상 브랜치): 다른 branch의 구체적인 commit 내역을 기억하고 싶지 않아서 다른 branch의 커밋들을 묶어서 한 커밋으로 가져오는 명령어\n소단원 2,3과 동일한 branch와 commit을 사용한다.\n현재 branch는 main이며, root branch에 있는 커밋들을 묶어서 한 커밋으로 가져온다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 $ git merge --squash root $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: beet new file: potato new file: radish # git commit -m 으로 commit message를 별도로 적어도 되고, 아래와 같이 해도 된다. $ git commit Squashed commit of the following: git log를 통해서 합쳐진 것을 알 수 있다.\n1 2 3 4 5 6 $ git log commit b2d15aa2b4b9f7b7d63036fce1256274168fb7b7 (HEAD -\u0026gt; main) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jul 13 12:48:30 2022 +0900 Squashed commit of the following: 일반 merge와의 차이 일반 merge와 merge --squash는 실행 후, 코드의 상태는 같지만 내역 면에서 큰 차이가 있는 것이라 이해해자. 일반 merge: A와 B 두 브랜치를 한 곳으로 이어붙인다. merge \u0026ndash;squash: B 브랜치의 마디들을 복사하여, 한 마디로 모아 staged state로 A 브랜치에 붙인다. Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter10-04/","summary":"git merge \u0026ndash;squash 명령어를 사용해서 다른 브랜치의 여러 커밋들을 rebase와 달리 하나의 커밋으로 묶어서 가져와본다.","title":"[TIL] Git study: Lecture Chapter 10 - git merge --squash"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. 이번 단원에서는 git rebase --onto 를 사용하여 다른 브랜치에서 파생된 브랜치를 다른 브랜치로 옮겨 붙여본다. 파생된 브랜치 옮겨붙이기 git rebase \u0026ndash;onto (옮겨지는 브랜치가 붙여지는 브랜치) (옮겨지는 브랜치의 base branch) (옮겨지는 브랜치): 다른 브랜치에서 파생된 브랜치 옮겨붙이기\n이전 단원과 동일한 branch와 commit을 사용한다. fruit branch에서 파생된 citrus branch를 main branch로 옮겨붙이기\ncitrus로 fast forward 1 $ git rebase --onto main fruit citrus 실행한 결과 다음과 같다.\n그러면 마지막으로 main branch의 HEAD를 옮겨보자.\n1 2 3 4 # 위 명령어를 실행하면서 branch가ㅏ citrus로 전환됬다. $ git switch main $ git merge citrus $ git branch -d citrus rebase \u0026ndash;onto 되돌리기 ❗ 되돌리기 위해서는 관련된 브랜치는 삭제되지 않아야 한다.\n왜냐하면 해당 명령어 이전으로 되돌리기 위해서는 이 명령어로 영향을 받은 모든 브랜치들에서 하나하나 리셋을 진행해주어야 하기 때문이다. git reflog를 사용해서 내역을 살펴보면 rebase \u0026ndash;onto 명령 시 여러 내역들이 진행된 것을 볼 수 있다.\n1 2 3 4 $ git reflog c519fac (HEAD -\u0026gt; main) HEAD@{0}: merge citrus: Fast-forward a8bfbbf HEAD@{1}: checkout: moving from citrus to main c519fac (HEAD -\u0026gt; main) HEAD@{2}: rebase (finish): returning to refs/heads/citrus main branch\nmain이 fast-forward 되기 이전 기록으로 git reset --hard를 실행한다. citrus branch\n방법 A\ncitrus branch는 해당 branch가 옮겨지기 전 마지막 커밋인 commit: Lime 부분을 reflog에서 찾아 그리로 reset --hard한다. 방법 B\n다시 rebase --onto를 사용해서 citrus의 커밋들을 main으로부터 도로 fruit branch의 orange 부분으로 옮긴다. 이를 위해서 orange commit으로 checkout 후, 새로운 브랜치를 만들고 아래 명령어를 실행한다. git rebase --onto temp main citrus citrus branch는 main branch에 붙여진 것이므로, 시작 브랜치가 main이다. citrus의 두 커밋들을 해당 위치로 옮겨붙인 뒤, 새로 만든 브랜치를 삭제한다. Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter10-03/","summary":"git rebase \u0026ndash;onto 명령어를 사용하여 다른 브랜치에서 파생된 브랜치를 현재 브랜치로 옮겨서 붙여본다.","title":"[TIL] Git study: Lecture Chapter 10 - git rebase --onto"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. 이번 단원에서는 git cherry-pick 명령어를 사용하여 다른 브랜치에 있는 원하는 커밋만 따오는 실습을 해본다. 다른 브랜치에서 원하는 커밋만 따오기 git cherry-pick (가져올 commit hash): 다른 브랜치의 원하는 특정 커밋을 복사해서 가져오는 명령어\n새롭게 branch와 commit을 형성하여 다음과 같은 commit tree를 구성했다. 위 image에서 fruit branch에서 cherry commit을 main branch로 가져오기 위해, 가져올 브랜치의 커밋 해쉬 번호를 가져온다. 1 2 3 4 5 6 7 # git cherry-pick (가져올 commit hash) $ git cherry-pick cadfd026 [main 53ad573] Cherry Author: yalco \u0026lt;yalco@kakao.com\u0026gt; Date: Sat Jan 1 15:33:36 2022 +0900 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 cherry 그러면 파일 목록에 새로운 파일이 추가된 걸 확인할 수 있다.\n소스 트리에서도 확인해보면 cherry commit을 복사해서 가져왔기 때문에, fruit branch에는 여전히 존재한다.\nReference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter10-02/","summary":"git cherry-pick 명령어를 사용하여 다른 브랜치에 있는 원하는 commit만 따오는 실습을 해본다.","title":"[TIL] Git study: Lecture Chapter 10 - git cherry-pick"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. 이번 단원에서는 git의 merge 원리인 Fast-forward와 3-way merge에 대해 알아본다. Fastforward vs 3-way merge Git에서 merge가 이뤄지는 두가지 방식인 Fast forward 와 3-way merge를 비교해보자. Fast forward(빨리 감기) 두 브랜치가 공통 커밋을 조상으로 가지고 있는데, 한 쪽 브랜치에만 이후의 커밋이 있을 때, 병합하기 위한 다른 커밋을 만들지 않고, HEAD만 이동하여 병합한 방식\n아래 이미지처럼 A branch에서 B branch가 분기되었다. B branch의 최신 버전에는 A branch의 최신 버전을 가지고 포함하고 있다. 이런 상황에서 Fast forward는 A branch의 HEAD를 단지 아래처럼 B branch의 최근 commit으로 옮긴 후, B branch를 제거하는 방법이다. ❗ 단점: 작업을 하고나서 어떤 브랜치를 사용했고, 언제 병합했는지 기록에 남지 않는다.\n그러면 fast-forwad 방식으로 merge 작업을 해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026gt; $ git branch another-branch \u0026gt; $ git switch another-branch # leopards.yaml의 memeber에 하나를 추가한다. \u0026gt; $ git commit -am\u0026#39;Add memebers in Leopards.yaml\u0026#39; # leopards.yaml의 memeber에 또 하나를 추가한다. \u0026gt; $ git commit -am\u0026#39;Add memebers in Leopards.yaml\u0026#39; \u0026gt; $ git switch main \u0026gt; $ git merge another-branch Updating 3d75f7f..09994e8 Fast-forward leopards.yaml | 2 ++ 1 file changed, 2 insertions(+) (base) # 그리고 another-branch를 제거한다. \u0026gt; $ git branch -d another-branch 위 코드를 보면 Fast-forward 단어를 확인할 수 있다.\n만약 이 방식으로 하지 않고, 병합 커밋 을 만들어 merge하려면 아래 명령어를 사용한다.\ngit merge --no-ff (병합할 branch명) 3-way merge 이 방식은 Fast-forward와 달리 기록이 남는 방법으로, 한 branch에서 두 branch로 분기되고, 분기된 후 각 branch에서 추가적인 commit이 발생한 상황에서 merge를 할 때의 원리를 말한다.\n아래 총 3 군데 를 비교하여 어느 변화를 받아들일지 또한 어느 부분을 충돌로 인식하여 사용자에게 맡겨야 하는지를 결정한는 걸 3-way merge 라 한다. 아래 이미지 같은 상황에서 분기가 시작된 부분을 기준으로 A branch의 최근 commit 부분 B branch의 최근 commit 부분 그래서 새로운 merge commit이 생성된다. git merge --no-ff (병합할 branch명) 를 사용한다.\nff는 fastforward를 의미한다. 1 2 3 4 $ git merge --no-ff main2 Auto-merging leopards.yaml CONFLICT (content): Merge conflict in leopards.yaml Automatic merge failed; fix conflicts and then commit the result. Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 누구나 쉽게 이해할 수 있는 Git 입문 - merge ","permalink":"http://jeha00.github.io/post/git/lec_chapter10-01/","summary":"git의 merge 원리인 Fast-forward와 3-way merge에 대해 알아본다.","title":"[TIL] Git study: Lecture Chapter 10 - Fast forwad vs 3-way merge"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. 이번 단원에서는 reset으로 사라진 커밋을 복구할 수 있는 reflog 명령어를 알아본다. git reflog 프로젝트가 위치한 commit이 바뀔 때마다 기록되는 내역을 보여주고, 이를 사용하여 reset 하기 이전 시점으로 프로젝트를 복구할 수 있다. 즉, 내가 사용한 Git 작업을 기준으로 과거내역을 살펴보고 원하는 시점으로 프로젝트를 되돌릴 수 있다.\n현재 기준 15번째 전 commit으로 reset 해본 후, git reflog를 입력해보면 여태 입력했던 명령어들과 각 명령어에 해당되는 commit 번호를 확인할 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 $ git reset --hard HEAD~15 $ git reflog ed807a6 (HEAD -\u0026gt; main) HEAD@{0}: reset: moving to HEAD ed807a6 (HEAD -\u0026gt; main) HEAD@{1}: reset: moving to HEAD~15 c99c341 HEAD@{2}: reset: moving to HEAD~15 3d75f7f (origin/main) HEAD@{3}: merge remote-branch: Fast-forward 1b2bbcb (tag: v1.0.5) HEAD@{4}: checkout: moving from remote-branch to main 3d75f7f (origin/main) HEAD@{5}: checkout: moving from main to remote-branch 1b2bbcb (tag: v1.0.5) HEAD@{6}: checkout: moving from remote-branch to main 3d75f7f (origin/main) HEAD@{7}: checkout: moving from main to remote-branch 1b2bbcb (tag: v1.0.5) HEAD@{8}: pull origin main: Fast-forward ... 그러면 제일 최근 단계로 돌아가기 위해서는 commit 해쉬번호 를 복사한 후, git reset --hard \u0026lt;복사한 commit 해쉬번호\u0026gt; 를 입력한다. 가장 최근 상태의 커밋 번호가 3d75f7f 이므로 git reset --hard 3d75f7f을 입력하면 원 상태로 돌아온다. Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter08-03/","summary":"git reset 으로 사라진 커밋을 복구하기 위해서 git reflog 명령어를 통해 더 자세한 commit 번호를 확인 후, git reset \u0026ndash;hard 명령어를 통해서 사라진 커밋을 복구해본다.","title":"[TIL] Git study: Lecture Chapter 08 - git reflog"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. 이번 단원에서는 특정 파일을 지정된 상태로 복구하는데 사용하는 git restore에 대해 알아본다. git restore 특정 파일을 지정된 상태로 복구하는 것\ngit checkout에서 git switch와 git restore로 나눠졌다.\n파일 여러 개를 수정한 후, 명렁어 사용해보기\ngit restore (파일명)\nworking directory의 특정 파일의 변화를 staging area에서 working directory로 내린다. 또는 파일명 자리에 .을 입력하면 모든 파일이 복구된다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # panthers.yaml에서 members를 수정한다. # 수정하기 전 상태 \u0026gt; members: \u0026gt; - Violet \u0026gt; - Stella \u0026gt; - Anthony \u0026gt; - Freddie \u0026gt; - Arachi # 수정 후 상태 \u0026gt; members: \u0026gt; - Violet \u0026gt; - Stella \u0026gt; - Anthony \u0026gt; - Freddie \u0026gt; - Hoki # 변경된 부분 \u0026gt; - change # 변경된 부분 # git 명령어 실행 \u0026gt; git restore panthers.yaml # 수정하기 전 상태로 돌아간 걸 알 수 있다. 그러면 panthers.yaml 이외에도 pumas.yaml과 leopards.yaml을 마음대로 수정해본 후, git restore .을 입력하면 이 두 가지 파일 한 번에 수정 전 상태로 돌아가는 걸 확인할 수 있다. 변경 상태를 스테이지에서 워킹 디렉토리로 돌려놓기\n이번에는 위에 3가지 파일 모두 변경 후 상태로 다시 만든 후, git add .으로 staging area에 올려보자. 그리고 git status로 확인해보자.\n1 2 3 4 5 6 7 8 9 $ git status On branch main Your branch is up to date with \u0026#39;origin/main\u0026#39;. Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: leopards.yaml modified: panthers.yaml modified: pumas.yaml git restore --stage (파일명) 또는 git restore --staged (파일명)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $ git restore --stage leopards.yaml $ git status $ git status On branch main Your branch is up to date with \u0026#39;origin/main\u0026#39;. Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: panthers.yaml modified: pumas.yaml Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: leopards.yaml 특정 파일을 특정 커밋의 상태로 되돌리기\ngit restore --source=(head 또는 commit hash) 파일명\n첫 번째 commit으로 돌아가려는 상황이라고 가정하자. 그러면 첫 번재 commit의 해쉬번호를 복사하자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026gt; $ git restore --source=ed807a60e49db810008b8fcb5fd4deddf4f200ec leopards.yaml # 위 커밋 시점을 기준으로 현재 working directory에 있는 것과 다른 부분들은 수정된 부분으로 인식된다. \u0026gt; $ git status On branch main Your branch is up to date with \u0026#39;origin/main\u0026#39;. Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: panthers.yaml modified: pumas.yaml Changes not staged for commit: (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) deleted: leopards.yaml 마지막으로 git restore .으로 되돌리자.\nReference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter08-02/","summary":"git restore 명령어를 통해서 첫 번째, 변경 상태를 stage area에서 working directory로 돌려보는 것과 두 번째, 특정 파일을 HEAD나 커밋 해쉬번호를 사용하여 지정된 상태로 복구해보는 것을 해본다.","title":"[TIL] Git study: Lecture Chapter 08 - git restore"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다. 이번 단원에서는 git에 추적되지 않는 파일( Untracked file )들 즉, 관리되지 않는 파일들을 삭제하는 git clean에 대해 알아본다. git clean working directory에 존재하면 Untraced 상태인 파일들과 폴더가 git clean의 대상이다.\ngit clean으로 삭제되면 Utracked 상태에서도 사라진다.\n삭제하기 위해서는 아래 옵션들을 사용해야 한다.\n-i 또는 -f git clean option 아래 옵션들을 조합하여 사용하자. 옵션 설명 -n 삭제될 파일들 보여주기 -i interactive mode 시작 -d 폴더 포함 -f 강제로 바로 지워버리기 -x .gitignore에 등록된 파일들도 삭제 git clean -x의 경우, git clean은 기본적으로 .gitignore에 등록된 파일은 삭제하지 않기 때문에 존재하는 명령어다.\ninteractive mode는 관리하지 않은 파일들에 대해 하나하나 체크하고 싶을 때 사용하는 모드다.\ngit clean -x는 함부로 사용하지 않는다.\n실습 상황 구현해보기 아래 3개의 파일을 생성하자.\ntoClean1.txt toClean2.txt dir/toClean3.txt 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 \u0026gt; $ git clean -n Would remove toClean1.txt Would remove toClean2.txt \u0026gt; $ git clean -dn \u0026gt; $ git clean -nd Would remove dir/ Would remove toClean1.txt Would remove toClean2.txt # 폴더를 포함시켜서 interactive mode를 시작한다. \u0026gt; $ git clean -id \u0026gt; $ git clean -di Would remove the following items: dir/ toClean1.txt toClean2.txt *** Commands *** 1: clean 2: filter by pattern 3: select by numbers 4: ask each 5: quit 6: help # select by numbers mode를 선택한다. What now\u0026gt; 3 # 어떤 것을 선택할지 선택하세요. 1: dir/ 2: toClean1.txt 3: toClean2.txt Select items to delete\u0026gt;\u0026gt; 1, 3 # * 으로 선택된 파일들을 확인할 수 있다. * 1: dir/ 2: toClean1.txt * 3: toClean2.txt Select items to delete\u0026gt;\u0026gt; Would remove the following items: dir/ toClean2.txt *** Commands *** 1: clean 2: filter by pattern 3: select by numbers 4: ask each 5: quit 6: help # 삭제될 것으로 선택된 파일들에 대해 각각 물어봐달라 What now\u0026gt; 4 Remove dir/ [y/N]? y Remove toClean2.txt [y/N]? N Removing dir/ # 결국 \u0026#39;dir/\u0026#39; 만 삭제된 걸 알 수 있다. 그런데, 각 파일이 어떻든 상관 없이 폴더까지 포함하여 삭제하고 싶다면 아래 명령어를 사용한다.\n1 2 3 4 $ git clean -fd Removing toClean1.txt Removing toClean2.txt Removing /dir Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter08-01/","summary":"이번 단원에서는 git에 추적되지 않는 즉, 관리되지 않은 파일들(Untracked file)을 삭제하는 \u0026lsquo;git clean\u0026rsquo;에 대해 알아본다.","title":"[TIL] Git study: Lecture Chapter 08 - git clean"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다. 이번 단원에서는 Commit에 tage를 다는 것에 대해 알아본다. 9.1 Commit에 tag 달기 Commit에 tage를 다는 이유는 다음과 같다.\n특정 시점을 키워드로 저장하고 싶을 때 커밋에 버전 정보를 붙이고자 할 때 Github repository에 들어가보면 tage를 발견할 수 있다.\nbranch를 선택하는 곳 옆옆에를 보면 현재 시점 기준 225 tags 임을 알 수 있다. 이 tags를 클릭하면 다음 이미지를 볼 수 있다. 9.1 tag 규칙 tags를 입력할 때는 이 문서의 규칙 Semantic Versioning 정보을 따른다.\n요약하자면 다음과 같다. 주.부.수 숫자로 버전을 명시한다. 주: 기존 버전과 호환되지 않게 API가 바뀌면 \u0026lsquo;주 버전\u0026rsquo;을 올린다. 부: 기존 버전과 호환되면서, 새로운 기능이 추가되면 \u0026lsquo;부 버전\u0026rsquo;을 올린다. 수: 기존 버전과 호환되면서, 버그를 수정한 것이라면 \u0026lsquo;수 버전\u0026rsquo;을 올린다. 9.2 tag 종류 tag 종류는 lightweight와 annotated로 나눠진다.\nlightweight: 단지 특정 커밋을 가리키는 용도 annotated: 작성자 정보와 날짜, 메시지, GPG 서명 포함 가능 tag 종류 lightweight tag annotated tag 마지막 커밋에 tag 달기 git tag v2.0.0 git tag -a v2.0.0 1 2 3 4 5 6 # lightweight tag $ git tag v2.0.0 # annotated tag # 아래 명령어를 입력 후, 뜨는 창에 메시지를 작성 $ git tag -a v2.0.0 또는 아래와 같이 메시지를 같이 입력한다. 1 $ git tag v2.0.0 -m \u0026#39;(message)\u0026#39; 그리고 tag 명령어 종류는 다음과 같다. tag 명령어 종류 설명 git tag 현존하는 태그 확인 git show v2.0.0 원하는 태그의 내용 확인 git tag -d v2.0.0 태그를 삭제 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 현재 tag가 version 몇인지 보여준다. $ git tag v2.0.0 # 해당 태그가 달린 커밋에 무슨 변화가 있는지 보여준다. $ git show v2.0.0. Tagger: --- Date: --- # 위에 입력한 메세지 tag # 해당 태그 삭제 $ git tag -d v2.0.0 Deleted tag \u0026#39;v2.0.0\u0026#39; (was 3d75f7f) 원하는 방식으로 태그를 달거나, 필터링, checkout 할 수 있다. tag 명령어 설명 git tag (태그명) (커밋 해시) -m (메시지) 원하는 커밋에 태그 달기 git tag -l \u0026lsquo;v1.*\u0026rsquo; 원하는 패턴으로 필터링하기 git checkout v1.2.1 원하는 버전으로 체크 아웃 1 2 3 4 $ git tag v1.2.3 (커밋 해시) -m \u0026#39;Second version\u0026#39; $ git tag -l \u0026#39;v1.*\u0026#39; v1.2.3 9.2 원격의 태그 관리 특정 태그 원격에 올리기 git push (원격명) (태그명)\n1 $ git push origin v1.0.5 위 명령어를 입력한 후, GitHub 원격 저장소를 들어가면 tag의 수가 늘어난 걸 알 수 있다. 특정 태그 원격에서 삭제 git push \u0026mdash;delete (원격명) (태그명)\n1 $ git push --delete origin v1.0.5 tag의 갯수가 다시 줄어든 걸 확인할 수 있다. 로컬의 모든 태그 원격에 올리기 git push \u0026mdash;tags\ntag의 갯수가 다시 늘어난 걸 알 수 있다. tag 버전명을 따로 적지 않으면 모든 tag가 원격에 올라간다. GitHub의 release 기능 GitHub의 올라간 tag들 중, 배포하는 버전인 배포버전들을 의미하는게 Releases 다.\n이에 대해 보다 이해하기 위해서 네이버 나눔고딕 코딩글꼴 예시를 참고해보자.\n17개의 tags가 있지만, Releases는 14개다. 즉, tags 중에서 배포버전을 정하는 것이다. tags에 들어가서 원하는 태그의 오른쪽을 보면 점이 3개 있다. 이를 클릭하여 Create release를 클릭한다.\n그러면 배포하기 원하는 title과 그 내용을 markdown 명령어로 입력한다.\nPublish release를 클릭하여 배포한다.\nReference 제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions ","permalink":"http://jeha00.github.io/post/git/lec_chpater09/","summary":"v0.0.0 에서 각 자리가 무엇을 의미하는지, commit에 tag를 다는 명령어인 git tag, 그리고 여러 버전들 중 일부를 release하는 것을 배운다.","title":"[TIL] Git study: Lecture Chapter 09 - git tag"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.\n이번 단원에서는 git stash, git commit --amend 그리고, git rebase -i 명령어를 학습해본다.\n마지막으로 과거의 커밋을 수정, 삭제, 병합, 분할해보는 명령어를 학습해본다.\n7-3. git stash 커밋하기 애매한 변화를 치워두는 명령어\nStash 사용법 정리 명령어 설명 비고 git stash 현 작업들 치워두기 끝에 save 생략 git stash apply 치워둔 마지막 항목(번호 없을 시) 적용 끝에 번호로 항목 지정 가능 git stash drop 치워둔 마지막 항목(번호 없을 시) 삭제 끝에 번호로 항목 지정 가능 git stash pop 치워둔 마지막 항목(번호 없을 시) 적용 및 삭제 apply + drop git stash branch(브랜치명) 새 branch를 생성하여 pop 충돌사항이 있는 상황 등에 유용 git stash clear 치워둔 모든 항목들 비우기 변경사항을 먼저 만들어보자.\nTigers의 members에 Stash를 추가한다. tomcats.yaml을 추가한 후, git add를 실행 여기서 git add를 한 이유는 git stash라는 명령어를 실습하기 위해서는 먼저 tracked 상태여야 한다. git stash 실행: git add 했던 변화들이 사라진다.\n사라진 변화들은 sourcetree에서 스태시 란에서 확인할 수 있다. git stash pop 을 입력하여 원하는 시점, 브랜치에 다시 적용한다.\n다른 branch를 만들고 전환 후, 이 명령어로 적용해보자. git add -p처럼 원하는 것만 stash 할 수 있다.\nLeopards의 members에 Stash2를 추가한다. Jaguars의 members에 Stash3를 추가한다. git stash -p로 Stash2만 선택하여 스태시한다. 메시지와 함께 스태시를 할 수도 있다.\ngit stash -m 'Add Stash3'\n1 2 $ git stash -m \u0026#39;Add Stash3\u0026#39; Saved working directory and index state On remote-branch: Add Stash3 스태시 목록 보기\n-git stash list\n1 2 3 $ git stash list stash@{0}: On remote-branch: Add Stash3 stash@{1}: WIP on remote-branch: 1b2bbcb Edit Leopards and Tigers 스태시된 항목 삭제: git stash drop\n1 2 3 4 5 $ git stash drop stash@{0} Dropped stash@{0} $ git stash list stash@{0}: WIP on remote-branch: 1b2bbcb Edit Leopards and Tigers 7-4. git commit \u0026ndash;amend Commit message 변경하기\n커밋 메시지를 변경하거나, 커밋에 변화를 추가 또는 커밋 메시지를 한 줄로 변경할 수도 있다.\n커밋 메시지 변경\n파일에 변화를 준 후, 커밋 메세지를 와웅 으로 입력해보자. git commit --amend 를 입력하여 편집창을 띄운다. Commit message: Add a member to Panthers 를 입력 후, :wq를 입력하여 저장 종료한다. git log로 확인해보자. 커밋에 변화 추가: 지난 커밋에 줘야할 변화를 깜빡했을 경우\n파일들에 변화를 준 후, staging area에 올린다. git commit --amend로 마지막 커밋에 포함시킨다. 위에 처럼 git commit --amend를 실행한 후, 편집기가 뜨면 그 때 메세지를 수정하는 것 외에도 단 한 줄로도 수정할 수 있다.\ngit commit --amend -m '(커밋 메세지)' 또한 바로 staging area에 올리면서 한 번에 커밋메세지를 수정하는 방법도 있다.\ngit commit -a --amend -m '(커밋 메세지)' 7-5. git rebase -i i란 interactive를 의미하며, 과거의 커밋 내역들을 다양한 방법으로 수정 가능하다.\ngit rebase -i를 입력했을 때, 사용되는 명령어들 명령어 설명 p, pick 커밋 그대로 두기 r, reword 커밋 메세지 수정 e, edit 수정을 위해 정지 d, drop 커밋 삭제 s, squash 이전 커밋에 합치기 git log로 커밋 내역들을 확인한다. git rebase -i \u0026lt;commit 해시 번호\u0026gt;를 입력하며 다음과 같이 뜬다. 1 2 3 4 5 6 7 8 $ git rebase -i pick 1c799ad pick ff00ad8 pick f35344a pick b9d4eb7 pick 8605c74 pick 59b42f3 ❗ git rebase -i를 입력했지만, Vim 화면은 뜨지 않고, \u0026lsquo;There is no tracking information for the current branch..\u0026lsquo;가 뜰 때는 최신 커밋을 입력한 것이다. 해당 명령어는 입력한 커밋 해쉬 번호 이후부터를 보여주기 때문에, 최신 커밋을 보여줬으므로 당연히 아무것도 뜨지 않는다.\nVim에서 수정해보기 다음 수정사항들을 진행해보자.\nhash number가 1c799ad인 커밋 메세지를 버그 수정으로 변경한다.\nr 명령어를 사용한다. hash number가 ff00ad8인 커밋은 삭제\nd 명령어 사용 hash number가 b9d4eb7을 f35344a에 합치기\n첫 항목 뒤로 s명령어 사용하기 메시지 수정 후 저장 커밋 메세지는 하나만 있으면 되므로, 두 개중 하나의 커밋 메세지를 삭제한다. 위 명령어들을 입력하면 다음과 같다.\n1 2 3 4 5 6 7 8 $ git rebase -i r 1c799ad d ff00ad8 pick f35344a s b9d4eb7 pick 8605c74 pick 59b42f3 하나의 커밋을 두 커밋으로 나누기 한 커밋 안에 두 작업이 있으므로, 2개의 커밋으로 나누는 작업을 진행해보자. git rebase -i \u0026lt;나눌려고 하는 commit의 이전 commit 해시 번호\u0026gt; 입력 pick에서 e 로 수정하고 :wq git reset HEAD~ 변화들을 따로 스테이지 및 커밋 git rebase --continue Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter07-030405/","summary":"커밋하기 애매한 변화를 치워두는 명령어인 git stash, commit message를 수정하는 git commit \u0026ndash;amend, commit 과거 내역들을 수정하는 git rebase -i 를 학습한다.","title":"[TIL] Git study: Lecture Chapter 07 -  git stash \u0026 git commit --amend \u0026 git rebase -i"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.\n이번 단원에서는 hunk 단위로 stage 하는 git add -p 을 학습하고, 변경사항을 확인하고 커밋하는 git commit -v를 학습해본다.\n7-2. 보다 꼼꼼히 staging 하기 staging 환경 만들기 Tigers 변경\nmanager: Thanos coach: Ronan new members: Gamora, Nebula Leopards 변경\nmanager: Peter coach: Rocket new members: Drax, Groot hunk 별로 staging 진행하기 hunk란 code가 수정되는 부분에서 수정되지 않는 부분까지를 의미한다.\n위에 Tigers를 기준으로 보자면 manager와 coach는 연달아 있으므로 한 hunk에 해당하지만, members까지 수정안되는 부분이 있기 때문에 끊어지고, 추가되는 members가 별도의 hunk가 된다. 이 hunk 단위로 staging area에 올리고 싶으면 git add -p 이고, -p는 patch의 약자다.\n1 2 3 4 5 6 7 8 9 10 11 12 team: Leopards -manager: Dooli +manager: Peter -coach: Lupi +coach: Rocket members: - Linda (1/2) Stage this hunk [y,n,q,a,d,j,J,g,/,s,e,?]? 위와 같이 뜬다.\n각 옵션 설명을 보려면 ? 입력 후, 엔터 y 또는 n으로 각 헝크를 선택한다. 일부만 staging 하여 진행해보고, git status와 소스트리로 확인해보자. 1 2 3 4 5 6 7 8 9 10 11 $ git status Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: leopards.yaml modified: tigers.yaml Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: leopards.yaml modified: tigers.yaml 부분적으로 staging area에 올렸기 때문에, 위와 같이 뜬다. 그러면 아래 명령어를 입력하여 부분적으로 나눠서 commit 하자. 1 2 3 $ git commit -m \u0026#39;Edit Tigers and Leopards\u0026#39; $ git add . $ git commit -m \u0026#39;Edit Leopards and Tigers\u0026#39; 마지막으로 git diff --staged와 비교해보자.\n이 명령어는 git add 후 staging area에 올라간 snapshot을 기준으로 변경사항을 알려준다. git commit -v 와의 차이점은 커밋 유무도 있지만, git commit -v는 Vim 모드로 이동. 이 git commit -v는 커밋과 이 git diff --staged를 같이하는 명령어라고 생각하면 된다.\nReference 제대로 파는 Git \u0026amp; GitHub - by 얄코 ","permalink":"http://jeha00.github.io/post/git/lec_chapter07-02/","summary":"변경사항을 보다 쪼갠 hunk 크기로 나눠 staging area에 올리는 명령어인 git add -p 와 변경사항을 확인하고 커밋하는 git commit -v 에 대해 학습해본다.","title":"[TIL] Git study: Lecture Chapter 07 - git add -p \u0026 git commit -v"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다. 7-1. Commit message 작성 유의사항 Commit message 작성 시 유의사항 어떤 작업이 이뤄졌는지 다른 누가 보더라도 알아볼 수 있는 내용 이 담겨져야 한다.\n왜냐하면 혼자서만 프로젝트를 진행하는 게 아니기 때문이다. 하나의 커밋 에는 한 단위의 작업 을 넣는다.\n한 작업을 여러 버전에 걸쳐 커밋하지 않는다.\n여러 작업을 한 버전에 커밋하지 않는다.\n합의된 방식을 잘 준수하여 \u0026lsquo;일관된 형태의 커밋\u0026rsquo; 을 작성해야 한다.\nCommit message convention \u0026lsquo;Commit message convention\u0026rsquo;이란 commit message를 작성하는 방식으로, 전세계 개발자들 사이에 많이 공유되고 권장되는 방식을 알아보겠다.\nConvention: 팀원들끼리 어떤 것의 작성하는 방식을 합의를 해 놓은 것을 말한다.\n정해진 답이 아닌 각 팀과 그 업무에 가장 적합한 걸 택한 것 Commit message 방식\n1 2 3 4 5 6 7 8 type: subject body (optional) ... ... ... footer (optional) 예시 1 2 3 4 5 6 7 8 feat: 압축파일 미리보기 기능 추가 사용자의 편의를 위해 압축을 풀기 전에 다음과 같이 압축파일 미리보기를 할 수 있도록 함 - 마우스 오른쪽 클릭 - 윈도우 탐색기 또는 맥 파인더의 미리보기 창 Closes #125 그러면 type, subject, body, footer에 대해 알아보자.\ntype\ntype explanation feat 새로운 기능 추가 fix 버그 수정 docs 문서 수정 style 공백, 세미콜론 등 스타일 수정 refactor 코드 리팩토링 perf 성능 개선 test 테스트 추가 chore 빌드 과정 또는 보조 기능 수정 subject\n커밋의 작업 내용 간략히 설명 body\n길게 설명할 필요가 있을 시 작성 footer\nbreaking point 가 있을 때 특정 이슈에 대한 해결 작업일 때 Gitmoji Commit message에 이모지를 넣어서 입력하는 방식도 있다.\n이는 Chapter 12에서 학습할 예정이다.\nReference 제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions ","permalink":"http://jeha00.github.io/post/git/lec_chapter07-01/","summary":"commit message를 작성할 때 권장사항들과 commit message convention에 대해 학습하여 commit message를 보다 체계적으로 작성해본다.","title":"[TIL] Git study: Lecture Chapter 07 - Commit message 권장사항과 convention "},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다. 1. Git help git 명령어가 기억나지 않을 때, git 명령어의 상세한 옵션이 기억나지 않을 때 이에 대한 도움 받을 수 있는 git help에 대해 알아보자.\ngit의 전체 명령어가 궁금할 때 사용하는 명령어\ngit help : git의 여러 명령어를 간략히 보여준다.\ngit help -a: git의 모든 명령어를 보여준다.\nj: 내리기 k: 올리기 :q : 닫기 특정 명령어에 대해 궁금할 때 사용하는 명령어\ngit (명령어) -h: 해당 명령어의 설명과 옵션 보기\nex) git commit -h git help (명령어) or git (명령어) --help: 명령어에 대한 설명을 웹에서 자세한 설명을 보고 싶을 때\n웹에서 열리지 않을 시 끝에 -w를 붙여 명시 2. Git config Git을 설정하는 git config에 대해서 보다 자세히 알아보자.\nglobal 설정과 local 설정\nconfig를 --global과 함께 지정하면 전역으로 설정 된다. ex) git config --global user.name 현재 모든 설정값 보기\ngit config (global) --list 전역으로 모든 설정값을 볼 때랑 아닐 때랑 출력이 다르다. 설정값을 에디터에서 보기\n기본 설정값은 Vim editor git config -e 기본 에디터인 Vim에서 Visual studio code 등 IDE로 보고 싶으면 아래 명령어를 입력. git config --global core.editor \u0026quot;code --wait\u0026quot; code 자리에 원하는 편집 프로그램의 .exe 파일 경로를 연결해도 변경할 수 있다. 이 명령어를 실행한 후, git config -e를 실행한다. 이와 같이 설정하면 커밋 메시지 입력창도 해당 에디터에서 열리게 된다. --wait: 에디터에서 수정하는 동안 CLI를 정지한다. 에디터 설정을 되돌리고 싶으면?\ngit config --global -e로 편집기를 연 뒤, [core] 란에 excludesfile 과 editor 부분을 삭제하고 저장하면 된다. 이외의 유용한 설정들 줄바꿈 호환 문제 해결\ngit config --global core.autocrlf (윈도우: true / 맥: input) pull 기본 설정을 merge 또는 rebase로 설정\ngit config pull.rebase false 또는 git config pull.rebase true 기본 브랜치명 설정\ngit config --global init.defaultBranch main push 시, 로컬과 동일한 브랜치명으로 설정\ngit config --global push.default current 단축키 설정 2.7 Git의 기초 - Git Alias 를 참고한다.\ngit config --global alias.(단축키) \u0026quot;명령어\u0026quot; 를 사용한다.\n예를 들어 git config --global alias.cam \u0026quot;commit -am\u0026quot; 로 사용한다.\n하지만, 이 방식은 나중에 사용하는 게 낫다고 판단된다.\n전반적인 명령어를 안보고 사용할 수 있는 수준에 이르면 사용하자.\nReference 제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions ","permalink":"http://jeha00.github.io/post/git/lec_chapter06/","summary":"git 명령어가 기억나지 않아 설명서가 필요한 경우 사용하는 \u003ccode\u003egit help\u003c/code\u003e 명령어와 \u003ccode\u003egit config\u003c/code\u003e를 사용한 git 설정에 대해 자세히 알아본다.","title":"[TIL] Git study: Lecture Chapter 06 - git help \u0026 git config"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다. 5. Git의 HEAD HEAD: 현재 위치를 나타내기 위해 임의로 만든 branch\nhistory, 시간선은 그대로 두고, 파일들의 상태만 이동하는 방법에 대해 알아보자.\n5.1 git checout HEAD^~ 바로 git checkout을 사용하는 것이다.\ngit checkout HEAD^ 또는 git checkout HEAD~에서 ^와 ~의 갯수만큼 이전으로 이동하기\ngit checkout HEAD^^^ git checkout HEAD~5 실습상황을 만들어보자. 현재 브랜치와 커밋 상황은 다음 이미지와 같다.\n현재 위치는 branch c의 HEAD에 위치한다.\n여기서 git checkout HEAD~을 입력하면 c second commit으로 이동된다.\ngit status로 현재 commit 위치를 확인할 수 있다.\n1 2 $ git status HEAD detached at b99000a aa branch의 HEAD 지점으로 이동하기 위해서 git checkout HEAD~2 를 입력한 후, git status로 확인하여 잘 이동된 걸 알 수 있다.\n1 2 $ git status HEAD detached at d8a94fb 5.2 git checkout - 한 단계 되돌리기\n이동을 한 단계 되돌리고 싶으면 git checkout - 을 입력한다.\n되돌아간 걸 확인하기 1 2 $ git status HEAD detached at b99000a 5.3 git checkout 커밋해시 이번에는 커밋 해시를 사용해서 이동해보자.\nb 1st commit 으로 이동해보자. 1 2 3 $ git checkout 57386f752a27a3dc953361091d7a384e0fb6d3ea $ git status HEAD detached at 57386f7 위 이미지를 확인하면 HEAD의 위치가 현재 위치임을 알 수 있다.\n이 상태에서 git branch를 입력해보자. 1 2 3 4 5 6 $ git branch * (HEAD detached at 57386f7) a aa b c git switch (branch 명): branch의 최신 위치로 이동 우리가 만든 branch가 아닌 익명의 branch가 만들어져서 현재 위치를 나타낸다. 즉, 위에 HEAD는 또 하나의 branch라는 것이다. 그렇다면 해당 브랜치의 최신 버전으로 이동하고 싶다면 git branch (branch 명)으로 이동할 수 있다는 걸 알 수 있다.\n1 $ git switch c 그리고, 소스트리를 업데이트하면 현재 위치가 이동한 브랜치의 최신 위치임을 알 수 있다. 즉 기존 브랜치로 돌아오면 자동적으로 최신 커밋 위치로 온다.\n그러면 현재 위치에서 새로운 branch를 만들고, 새 commit을 만들어보자.\n1 2 $ git switch -c d $ git commit -am \u0026#39;d first commit\u0026#39; 이처럼 다른 branch로 이동 후, 분기된 branch에서 다시 새로운 branch를 만들 수 있다.\n5.4 HEAD 사용하여 reset 하기 git reset HEAD(원하는 단계) (옵션)\nHEAD(원하는 단계) 를 해쉬 번호 로 생각하자.\nc branch에서 실행해보자.\n1 2 $ git switch c $ git reset --hard HEAD~2 6. fetch와 pull의 차이 - fetch: 원격 저장소의 최신 커밋을 로컬로 가져와서 내용만 보고 싶을 때 사용한다.\n- pull: 원격 저장소의 최신 커밋을 로컬로 가져와 merge 또는 rebase를 실행하는 것으로서 fetch 과정을 포함 한다.\nfetch한 내역 적용 전 살펴보기\n원격의 main branch에 commit을 추가하자. 추가 후, git checkout origin/main으로 원격의 브랜치로 이동하기.\n원격의 변경사항을 fetch로 확인하기\ngit checkout origin/main으로 확인해보기. 아무것도 변화된 게 없다. -\u0026gt; 다시 git checkout main으로 로컬 branch로 돌아오기 다음으로 git fetch 입력하기 그리고, 아직 main branch에 적용하고 싶지 않고 살펴만 보고 싶다. 그러면 git checkout origin/main을 입력하여 확인 후, 다시 git switch main으로 돌아와 서 git pull을 적용한다. pull로 적용 원격의 새 브랜치 확인\ngit checkout origin/(branch명)\ngit switch -t origin/(branch명)\ngit fetch -\u0026gt; git branch -a 하면 확인가능 -\u0026gt; 이 branch를 확인만 하고 싶으면 git checkout origin/branch명 입력 -\u0026gt; git checkout main -\u0026gt; git switch -t origin/remote-local 1 2 3 4 5 6 7 8 9 10 11 #원격에 remote-local branch를 만든다. $ git fetch $ git branch -a * main remotes/origin/main remotes/origin/remote-local $ git checkout main $ git switch -t origin/remote-local Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions ","permalink":"http://jeha00.github.io/post/git/lec_chapter05-02/","summary":"다섯 번째, Git의 HEAD를 이동하기 위해서 git checkout 명령어. 마지막으로 fetch와 pull의 차이를 학습한다.","title":"[TIL] Git study: Lecture Chapter 05 - git checkout \u0026 fetch와 pull의 차이"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다. 1. Git의 장점: Snapshot과 DVCS Git의 장점인 Snapshot 방식과 DVCS에 대해 알아보자.\nWhat is git?에 대한 요약버전이다.\n1.1 Snapshot 방식 Snapshot 방식에 대해 알아보기 전에 git의 이전 버전들이 사용한 델타 방식 에 대해 알아보자.\n델타 방식 델타방식은 해당 파일 전체가 처음 시점을 기준으로 이어져서 그 이후 변경지점만 누적되어 저장된다.\n버전 5시점에서는 델타1, 델타2, 델타 3이 저장되는 것이다. snapshot 방식 스냅샷 방식은 새로운 버전이 만들어질 때, 해당 버전에서의 각 파일이 최종 상태 그대로 저장되어 있다.\n버전 5에서 A는 변화가 없으니까 버전 4에서 가져온다. 이 저장도 용량을 별로 차지하는 방식으로 저장된다. 차이점 그렇다면 이 2가지의 차이점을 이해하기 위해 한 상황을 가정해보자.\nVSC 프로젝트처럼 커밋이 몇 만개가 있는 레포지토리를 델타버전으로 다룬다면 어떨까??\n델타 방식은 Git에서 뭘 할 때마다 각 파일들을 그거가 처음 만들어진 시점부터 변경사항들을 쭈욱 더해서 현재 내용을 계산해야하니 history가 길수록 되게 느려진다.\n반면에 스냅샷은 그냥 현 시점에 각 파일들이 풀로 저장되어 있으니까 아주 빠르다.\n1.2 DVCS CVCS는 원격 저장소와의 인터넷 연결이 끊기면 로컬에서 할 수 있는 게 제한적이다.\n반면에 Git은 clone 명령어로 가져오면 전체 Git commit 내역과 branch까지 가져오기 때문에 인터넷 연결 상태와 상관없이 로컬에서 자유롭게 작업할 수 있다.\n밑에 이미지가 DVCS(Distributed Version Control System, 분산 버전 관리 시스템)이다.\n2. Git의 3가지 공간 Git의 3가지 공간: Working directory, Staging area, Repository 각 공간을 이동하는 git 명령어: Working directory == (git add) ==\u0026gt; Staging area == (git commit) ==\u0026gt; Repository Working directory = Untracked state + Tracked state commit되어 레포지토리에 들어간 후 수정사항이 발생하면 tracked 상태로 staging을 기다린다. Git basics을 참고한다.\nWorking directory Untracked: Add된 적 없는 파일, ignore된 파일 Add된 적 없는 파일이란? git이 관리한 적이 없는 파일, 새로 생긴 파일을 말한다. Tracked: Add된 적 있고, 변경내역이 있는 파일 git add 명령어에 의해서 Working directory에서 Staging area로 올라온다. Staging area 커밋을 위한 준비 단계 ex) 작업을 위해 선택된 파일들 git commit 명령어로 repository로 이동 Staging area에서 working directory로 CLI로 이동하기 git restore --staged (파일명) --staged를 빼면 working directory에서도 제거 = 변화를 제거한다. 소스트리로는 단지 스테이지에서 내리기를 클릭한다. Repository .git repository라고도 불린다. 커밋된 파일들이 들어간 곳 3. git 명령어로 파일 삭제, 이동 파일 삭제: git rm 삭제 후 area 위치 확인: git status로 확인\n삭제 방법 우클릭 삭제 git rm area 위치 working directory Staging area 복원 방법 git reset --hard git reset --hard git rm으로 삭제한 것을 바로 staging area에 있는 걸 알 수 있다. git rm은 바로 git add 명령어를 적용한 것이다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 우클릭 삭제 후, 상태 확인 $ git status Changes not staged for commit: deleted: tigers.yaml no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) # git rm으로 삭제 후, 상태 확인 $ gim rm tigers.yaml $ git status Changes to be committed: deleted: tigers.yaml 파일명 변경: git mv git mv (파일명을 변경할 파일) (바꿀 이름)\ntigers.yaml를 zzamtigers.yaml로 이름 변경 뒤, git status로 살펴보기\n변경 방법 우클릭 변경 git mv area 위치 working directory Staging area 복원 방법 git reset --hard git reset --hard git mv는 바로 git add 명령어를 적용한 것이다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 우클릭 변경 $ git status Changes not staged for commit: deleted: tigers.yaml Untracked files: zzamtigers.yaml # git mv 사용 $ git mv tigers.yaml zzamtigers.yaml $ git status Changes to be committed: renamed: tigers.yaml -\u0026gt; zzamtigers.yaml 4. reset의 세 가지 옵션 \u0026ndash;soft repository에서 staging area로 이동.\nstaging area에 남겨놓는다. --mixed에서 git add로 추가한 옵션 \u0026ndash;mixed default로 repository에서 working directory로 이동.\nworking directory에 남겨놓는다. \u0026ndash;hard 수정사항 내역을 완전히 삭제.\nworking directory에서조차 삭제한다. 실습 그러면 실습 해보자. 단, --hard는 생략한다.\n파일 일부를 변경한 후, 아래 명령어를 실행한다.\n1 2 3 4 5 6 \u0026gt; git reset --soft 1c1037862c2a5919f31ecf0f55874c8bf236fea5 \u0026gt; $ git status Changes to be committed: modified: panthers.yaml modified: tigers.yaml --soft를 사용하니 staging area로 이동된 걸 확인했다.\nReference 제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions ","permalink":"http://jeha00.github.io/post/git/lec_chapter05-01/","summary":"첫 번째 CVCS에 비해서 Git의 장점이 무엇인지, 두 번째 Git의 3가지 공간(Working directory, Staging area, Directory)이 무엇인지, 세 번째 git rm과 git mv 명령어로 파일이 어떤 영역으로 이동되는지, 네 번째 reset의 3가지 옵션에 대해 학습한다.","title":"[TIL] Git study: Lecture Chapter 05 - git rm, git mv 그리고, git reset의 3가지 옵션 등등"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다. 1. Github이란? Github이란 Gitlab, Bitbucket과 같이 코드 공유 및 협업 서비스\n보다 더 자세히 설명하자면 Git으로 관리하는 모든 프로젝트들을 온라인 공간에 공유해서 프로젝트 구성원들이 협업하는데 도와주는 서비스이다.\n그런데, 일반 클라우드 서비스와의 차이점은 무엇일까??\n일반 클라우드 서비스로 협업을 해야한다면 같은 파일을 공유해서 수정할 경우, 일반적인 공유 방법으로는 답이 없다. 왜냐하면 계속해서 덮어씌워지는 문제가 발생하기 때문이다.\n하지만, Github을 사용하면 모든 업로드와 다운로드를 커밋 단위로 주고받기 때문에, 서로의 작업을 덮어씌울 걱정할 필요 없이 협업하는데 문제점을 해결해준다.\n즉, 협업 시의 교통정리를 해준다.\n2. 토큰 만들기 Personal access token 만들고, 이 토큰을 컴퓨터에 저장하고자 한다면,\n또한, 새로운 Repository를 생성 후 협업할 팀원을 추가하고 싶으면\n아래 링크를 참고한다.\nSection 4. Github 사용하기 - Lesson 2. GitHub 시작하기\n위 링크에서 토큰을 컴퓨터에 저장하고자 할 때, 윈도우 컴퓨터의 경우,\nWindow 자격 증명 관리자 란 제어판 홈에 있는 메뉴를 의미한다.\nWindow menu bar에 이를 검색하면 바로 뜰 것이다.\n지금은 바로 필요하지 않으니 자세한 설명보다 링크를 통해 나중에 더 자세히 보자.\n3. 원격 저장소 만들기 Github repository를 생성 후, 이 링크 주소를 복사한다.\n새로운 repository를 생성하여 들어가면 Code tab 란에 |HTTPS|SSH| 칸이 있는데, 이중 HTTPS를 선택한다. local의 Git 저장소에 원격 저장소를 연결하기 위해서 아래 명령어를 입력한다.\n이 방식으로 hugo를 사용하여 gitub 기술 블로그를 만들었다. Window에서 Hugo로 Github page 만들고 배포하기 1 2 3 # 원격 저장소를 추가하는 명령어 git remote add origin (복사한 링크 주소 즉, 원격 저장소 주소) origin은 원격 저장소의 이름이다. 흔히 origin을 사용한다. 하지만, 다른 것으로도 사용 가능하다. 1 git branch -M main local 저장소의 commit 내역들을 원격으로 push (업로드) 한다.\n1 git push -u origin main -u 또는 --set-upstrea: 현재 브랜치와 명시된 원격 브랜치의 기본 연결을 origin main으로 하겠다는 의미다. 이 명령어를 입력한 이후에는 git push만 해도 이와 동일한 의미로 받아들인다.\n하지만, 업로드 branch를 여러 개로도 할 수 있다.\n💡 2번과 3번을 직접 입력해도 되지만, repository를 만들어서 클릭 후 들어가면 위 3가지 명령어 line을 한 번에 복사할 수 있도록 해놨다. 2. 토큰 만들기 가 잘 되었다면 순탄하게 진행될 것이다.\n원격으로 연결된 목록을 보고 싶으면 git remote 또는 자세히 보고 싶으면 git remote -v를 입력한다.\n원격으로 연결된 것을 지우고 싶다면 git remote remove (origin 등 원격 이름) 을 입력한다.\n이 때 Github repository가 삭제되는 것이 아니다. 단지 로컬과 Github의 연결만을 지운다. 4. GitHub에서 프로젝트 다운받기 GitHub에서 다른 동료의 프로젝트를 다운받으려고 할 때 몇 가지 방식이 있다. Download ZIP 으로, ZIP 파일로 다운받아 원하는 폴더에 푸는 방식이다. 하지만 이 방식은 파일들만 다운 받고, .git은 다운받지 않기 때문에 Git 관리내역은 제외되어 추천하지 않는다.\n다운받기 원하는 폴더에서 터미널이나 Git Bash를 열은 후, 그 경로에서 git clone (원격 저장소 주소) 를 입력하는 것이다. 그러면 .git도 다운받기 때문에, Git 관리 내역까지 포함된다. 그래서 이 방식을 추천한다.\n5. push와 pull 5.1 원격으로 커밋 push \u0026amp; pull 5.1.1 원격으로 커밋 밀어올리기(push) Leopards의 members에 Evie 추가\nCommit message: Add Evie to Leopards git push\n이미 git push -u origin main으로 대상 원격 브랜치가 지정되었기 때문에 가능하다. GitHub page에서 확인 가능하다.\n5.1.2 원격의 커밋 당겨오기(pull) local이 아닌 Github에서 Leopards의 members에 Dongho 추가\nCommit message: Add Dongho to Leopards git pull\nlocal에서 file과 log 살펴보기\n5.2 pull할 것이 있는데, push를 하면?? 이 상황은 local에서 수정한 것과 GitHub에서 동일한 것을 다르게 수정했을 경우, 충돌이 일어났을 때 pull을 먼저 하고 나서야 push를 할 수 있다.\n이 상황을 만들어보자.\nlocal에서 Leopards의 manager를 Dooli로 수정\ncommit message: Edit Leopards manager GitHub에서 Leopards의 coach를 Lupi로 수정\ncommit message: Edit Leopards coach push 해보기\n이 때 오류가 뜰 것이다. pull 해서 GitHub에서의 버전을 받아온 다음 push 가능하다. push 할 것이 있을 시, pull하는 두 가지 방법\ngit pull or git pull --no-rebase: merge 방식\n3번에서 push 전에 하는 pull 과 동일하다. git pull을 하면 자동적으로 git pull --no-rebase로 입력한다.\n소스트리에서 확인해보기\nreset으로 되돌린 다음 아래 방식도 해보기\ngit pull --rebase : rebase 방식\nGitHub에 시간선을 맞춘다. pull 상의 rebase는 일반 rebase와 상황이 다르므로, 협업시 사용해도 괜찮다.\n❗ pull 상의 rebase는 다르므로, 협업 시, 사용 OK ❗ git pull --rebase는 rebase 하려는 local commit 뒤로 시간선을 맞춘다.\npush 하기\nmerge 와는 달리 별도의 커밋이 추가되지 않는다. 5.3 협업상 충돌 발생 해결하기 Local에서 Panthers의 members에 Maruchi 추가\ncommit messge: Add Maruchi to Panthers 원격에서 Panthers의 members에 Arachi 추가\ncommit message: Add Arachi to Panthers pull 하여 충돌상황 마주하기\n--no-rebase 와 --rebase 모두 해볼 것\ngit pull --no-rebase 한 결과 git pull --rebase 한 결과 5.4 local의 내역 강제 push하기 언제 사용하는가?\nlocal 상의 내용이 원격보다 내용이 뒤쳐지면 push를 할 수 없을 때 그리고, 원격에서의 내용이 잘못되서 강제로 local에서의 내용으로 맞춰야할 때 하지만, 사용하기 전 미리 합의 후 실행해야 한다. 왜냐하면 다른 사람이 한 것이 날라갈 수 있기 때문이다.\ngit push --force 로 덮어씌울 수 있다.\n6. 원격의 브랜치 다루기 6.1 로컬에서 브랜치 만들어 원격에 push 해보기 from-local branch 만들기\n아래 명령어로 원격에 push\ngit push\n위 명령어를 입력하면 원격 저장소의 대상을 명시 하라는 메시지가 나타난다.\n1 2 3 4 fatal: The current branch from-local has no upstream branch. To push the current branch and set the remote as upstream, use git push --set-upstream origin from-local 그 때 이 명령어를 입력하여 원격 브랜치 명시 및 기본 설정한다.\ngit push -u origin from-local 이 명령어로 원격 저장소의 브랜치에 from-local이 생긴다. 원격 저장소의 from-local branch의 jaguars.yaml를 편집한다.\nmanager를 Cheolsu로 수정한다. Commit message: Edit Jaguars Manager branch 목록 살펴보기\nGitHub에서 목록 보기\n아래 명령어로 local과 원격의 branch 확인\ngit branch --all : git branch는 local만 확인한다. 1 2 3 4 from-local main remotes/origin/from-local remotes/origin/main 6.2 원격의 브랜치 로컬에 받아오기 GitHub에서 from-remote branch 만들기\nGitHub에서 branch를 선택하는 곳의 빈칸에 입력하면 Create branch: from-remote from 'main'이 뜬다. git branch -a에서 현재는 보이지 않는다. 아래 명령어로 원격의 변경사항 확인\ngit fetch 아래 명령어로 로컬에 같은 이름의 브랜치를 생성하여 연결하고 switch\ngit switch -t origin/from-remote\n소스트리에서 origin/branch 명 인 걸 확인할 수 있다. 이는 원격에 있는 branch를 의미한다.\nLocal에서 jaguars의 manager를 cheolsu로 바꾼다.\ncommit message: Edit Jaguars Manager 6.3 원격의 브랜치 삭제 아래 명령어를 입력하여 원격 저장소의 브랜치를 삭제한다.\ngit push (원격 이름) --delete (원격의 브랜치명) git push origin --delete from-local git push origin --delete from-remote 위 명령어를 입력하면 다음과 같이 뜬다.\n1 2 3 4 5 6 7 $ git push origin --delete from-local To https://github.com/JeHa00/git-practice.git - [deleted] from-local $ git push origin --delete from-remote To https://github.com/JeHa00/git-practice.git - [deleted] from-remote 6.4 Sourcetree로 진행하기 원격 추가하기: 원격에 새로운 repository를 만든 후, 새 repo.에 해당하는 HTTPS 주소를 복사한다. 2번부터 7번은 소스트리로 push와 pull을 해보는 단계다.\n소스트리의 위 메뉴들 중 저장소(R) -\u0026gt; 원격 저장소 추가 -\u0026gt;추가 -\u0026gt; 원격 이름에 origin2 입력 \u0026amp; URL에 복사한 주소 입력\nPush 클릭 -\u0026gt; 다음 저장소에 푸시: origin2로 설정\n로컬의 Pumas의 members에 Pororo 추가\nCommit message: Add Pororo to Pumas 소스트리에서 커밋 클릭 -\u0026gt; 스테이지에 올라가지 않은 파일을 클릭한 다음, 모두 스테이지에 올리기를 클릭합니다.\nCommit message를 입력 후, origin/main에 바뀐 내용 즉시 푸시 를 체크한 다음 커밋 실행\n마지막으로 소스트리를 사용하여 브랜치를 만들어 푸시한다.\n소스트리에서 브랜치 클릭 -\u0026gt; Push 클릭 -\u0026gt; from-local에도 체크 후 푸시 실행\n원격에도 from-local branch가 생긴 걸 확인할 수 있다.\n이번에는 원격에서 branch from-remote 를 만든 후, 소스트리에서 fetch(패치)를 실행하면 소스트리의 origin에 추가된 걸 확인할 수 있다.\n추가된 from-remote를 사용하는 브랜치에 추가하고 싶으면, 원격 \u0026gt; origin \u0026gt; from-remote 에서 오른쪽 클릭하여 체크아웃을 클릭한다.\nReference 제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions ","permalink":"http://jeha00.github.io/post/git/lec_chapter04/","summary":"GitHub에 원격 저장소를 만들고, 원격과 로컬에서 branch를 새롭게 만들어보면서 원격 저장소로부터 pull, push를 사용하여 프로젝트를 동기화 해본다. 마지막으로 이 과정을 소스트리로 실행해본다.","title":"[TIL] Git study: Lecture Chapter 04 - 원격 사용하기"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다. 1. 여러 branch (다른 차원) 만들어보기 아래의 모든 것을 하나의 프로젝트 폴더에서 진행할 수 있도록 여러 branch를 만든다.\n언제 branch를 여러 개 만들어서 작업을 할까??\n프로젝트를 하나 이상의 모습으로 관리해야할 때\n예) 실배포용, 테스트 서버용, 새로운 시도용 여러 작업들이 각각 독립되어 진행될 때\n예) 신기능 1, 신기능 2, 코드개선, 긴습 수정 \u0026hellip; 각각의 차원에서 작업한 뒤, 확정된 것을 메인 차원에 통합한다. 1.1 브랜치 생성 / 이동 / 삭제하기 / 이름 바꾸기 branch 생성: add-coach란 이름의 브랜치 생성\ngit branch add-coach branch 목록 확인\ngit branch *은 현재 branch를 의미한다. 1 2 3 4 \u0026gt; $ git branch add-coach \u0026gt; $ git branch add-coach * main 생성된 branch로 이동\ngit switch add-coach *가 add-coach로 옮겨진 걸 알 수 있다. checkut 명령어가 Git 2.23버전부터 switch와 restore로 분리되었다. 1 2 3 4 5 6 \u0026gt; $ git switch add-coach Switched to branch \u0026#39;add-coach\u0026#39; \u0026gt; $ git branch * add-coach main 💡 branch 생성과 동시에 이동하기\ngit swtich -c new-teams 기존의 git checkout -b (새 브랜치명)이 이를 의미한다. 1 2 3 4 5 6 7 \u0026gt; $ git switch -c new-teams Switched to a new branch \u0026#39;new-teams\u0026#39; \u0026gt; $ git branch add-coach * main new-teams 브랜치 삭제하기\ngit branch -d (삭제할 브랜치명) to-delete란 branch 만들고, 삭제해보기 브랜치 이름 바꾸기\ngit branch -m (기존 브랜치명) (새 브랜치명) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026gt; $ git branch add-coach * main new-teams to-delete \u0026gt; $ git branch -m to-delete to-eraser \u0026gt; $ git branch add-coach * main new-teams to-eraser \u0026gt; $ git branch -m to-eraser to-delete \u0026gt; $ git branch -d to-delete Deleted branch to-delete (was 1589712). \u0026gt; $ git branch add-coach * main new-teams 💡 브랜치 강제 삭제\n지워질 브랜치에만 있는 내용의 커밋이 있을 경우, 다른 브랜치로 가져오지 않은 내용이 있는 브랜치를 지울 때는 -d 대신 -D (대문자)로 강제 삭제해야 한다. 1.2 각각의 브랜치에서 서로 다른 작업해보기 총 3개의 branch: main, add-coach, new-teams branch에서 작업한다.\n각 작업을 실행할 때, git add를 실행한 후 git commit -m'()'을 해야 반영된다.\nChapter 02에서 알아봤듯이 모두 다 tracked file일 때, git commit -am'(commit message)' 로 한 번에 할 수 있다.\n1.2.1 main branch Leopards의 members에 Olivia 추가\n커밋 메시지: Add Olivia to Leopards Panthers의 members에 Freddie 추가\n커밋 메시지: Add Freddie to Panthers 1.2.2 add-coach branch Tigers의 매니저 정보 아래 coach: Grace 추가\n커밋 메시지: Add Coach Grace to Tigers Leopards의 매니저 정보 아래 coach: Oscar 추가\n커밋 메시지: Add Coach Oscar to Leopards Panthers의 매니저 정보 아래 coach: Teddy 추가\n커밋 메시지: Add Coach Teddy to Panthers 1.2.3 new-teams branch pumas.yaml 추가\n커밋 메세지: Add team Pumas jaguars.yaml 추가\n커밋 메세지: Add team Jaguars 1.3 결과 살펴보기 git log로도 볼 수 있지만 git log로 볼 경우에는 현재 branch 와 갈라지기 전 main일 때의 log만 볼 수 있다.\n별표는 하나의 줄기다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ git log --all --decorate --oneline --graph * 672d65f (HEAD -\u0026gt; new-teams) Add team Jaguars * af9742d Add team Pumas | * 2641114 (add-coach) Add Coach Teddy to Panthers | * e22aa3c Add Coach Oscar to Leopards | * f91d19a Add Coach Grace to Tigers |/ | * 7618a7e (main) Add Freddle to Panthers | * a9fe922 Add Olivia to Leopards |/ * 1589712 (to-eraser) replace cheetas with Panthers * f86046e Add team Cheetas * 679d1f1 add George to tigers * 3183106 Replace Lions with Leopards * ed807a6 first commit 하지만 이런 흐름을 볼 때는 실무에서는 CLI보다 source tree로 본다.\nsource tree로 보면 다음과 같다.\n2. branch를 합치는 두 가지 방법 branch를 합치는 실습을 해보기 전에, 위 실습과정을 이미지로 보자면 다음과 같다.\n주요 branch는 main branch다.\n그리고 양 옆에 add-coach branch, new-teams branch에서 실험적인 시도를 하고 있다.\n그리고 이 두 branch를 아래 이미지처럼 main branch로 합칠려고 한다.\n이를 위해서 2가지 방법으로 진행할 것이다.\nMerge vs Rebase ❗ 이 두 가지 중 무엇을 사용하냐는 프로젝트의 성격에 달려있다. 브랜치의 사용 내역들을 남겨둘 필요가 있으면 Merge를, 그보다는 히스토리를 깔끔하게 만드는게 중요하면 Rebase를 사용한다.\nMerge 두 브랜치를 한 커밋에 이어붙이는 방식으로, 두 branch의 끝 가지를 이어붙힌다.\n브랜치 사용 내역을 남길 필요가 있을 때, 적합한 방식 main과 add-coach branch를 합칠 방식 Rebase 브랜치를 다른 브랜치에 이어붙이는 방식으로, 곁가지들을 싹 다 잘라다가 몸통 줄기에 이어 붙여서 히스토리를 한 줄로 유지가능하다.\n한 줄로 깔끔히 정리된 내역을 유지하기 원할 때 적합하다. main 과 new-teams branch를 합칠 방식 ❗ 이미 팀원과 공유된 커밋들에 대해서는 사용하지 않는 것이 좋다. 즉, 있던 거를 없애다가 딴 데 이어붙이는 거인 만큼 같이 일하는 도중에 이러면 문제가 발생할 수 있다.\n2.1 Merge로 합치기 main branch로 먼저 이동 git merge add-coach 명령어로 병합 1 $ git merge add-coach ❗ 위 과정에서 충돌이 났을 경우, 3. 충돌해결하기를 참고한다.\n병합된 브랜치는 아래 명령어로 삭제한다. 삭제 전 소스트리에서 add-coach 위치 확인한다. 1 git branch -d add-coach 💡 Rebase와의 차이점: merge는 reset으로 되돌리기 가능하다.\nmerge 도 하나의 커밋이기 때문에, merge 하기 전 해당 브랜치의 마지막 시점으로 되돌리는 게 가능하다. Merge한 결과는 다음 이미지와 같다.\n2.2 Rebase로 합치기 git rebase는 연결할려는 commit 부분의 두 브랜치 상태를 동일하게 만든 후, git merge를 실행하는 명령어\nnew-teams 브랜치를 main 브랜치로 rebase 💡 Merge와의 차이점: merge와는 반대로 new-teams로 이동하여 아래 명령어로 병합한다.\n1 $ git rebase main 소스트리에서 상태를 확인하면 아래 이미지처럼 main 브랜치가 뒤쳐져있다. main 브랜치로 이동 후, 아래 명령어로 new-teams의 시점으로 앞으로 이동한다. 1 $ git merge new-teams 위 이미지와 달리 앞으로 이동된 걸 알 수 있다.\n그리고 new-teams 브랜치를 삭제한다.\n3. 충돌 해결하기 3.1 충돌 상황 만들기 conflict-1, conflict-2 브랜치 생성\nmain branch\nTigers의 manager를 Kenneth로 변경 Leopards의 coach를 Nicholas로 변경 Panthers의 coach를 Shirley로 변경 커밋 메시지: Edit Tigers, Leopards, Panthers conflict-1 branch Tigers의 manager를 Deborah로 변경 커밋 메시지: Edit Tigers conflict-2 branch Leopards의 coach를 Melissa로 변경 커밋 메시지: Edit Leopards conflict-2 branch Panthers의 coach를 Raymond로 변경 커밋 메시지: Edit Panthers 3.2 merge 충돌 해결하기 main 브랜치에서 git merge conflict-1 로 병합을 시도하기\n그러면 아래와 같은 충돌이 발생한다. 1 2 3 4 $ git merge conflict-1 Auto-merging tigers.yaml CONFLICT (content): Merge conflict in tigers.yaml Automatic merge failed; fix conflicts and then commit the result. 그러면 VSC에서 해당 파일 옆에 !로 뜬다. 해당 파일을 클릭하면 Accept Current Change, Accept Incoming Changes 등을 선택하라고 한다. 이 때, 해당 파일은 일반 폴더에서 더블 클릭하여 열면 단순 text로 나타난다. 이를 VSC에서 보기 좋게 표현한 것이다. 충돌되는 부분만 찾고 싶다면 VSC 검색에서 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; 을 입력하여 찾을 수 있다. Accept Current Change, Accept Incoming Changes 등을 선택하여, 충돌 부분을 수정한 뒤, git add. -\u0026gt; git commit으로 병합을 완료한다.\n하지만, 당장 충돌 해결이 어려울 경우, 아래 명령어로 merge를 중단한다. 1 git merge --abort 3.3 rebase 충돌 해결하기 conflict-2에서 git rebase main으로 rebase 시도하면 충돌 발생한다.\n오류 메시지와 git status 확인한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 $ git rebase main Auto-merging leopards.yaml CONFLICT (content): Merge conflict in leopards.yaml error: could not apply f8bddeb... Edit Leopards hint: Resolve all conflicts manually, mark them as resolved with hint: \u0026#34;git add/rm \u0026lt;conflicted_files\u0026gt;\u0026#34;, then run \u0026#34;git rebase --continue\u0026#34;. hint: You can instead skip this commit: run \u0026#34;git rebase --skip\u0026#34;. hint: To abort and get back to the state before \u0026#34;git rebase\u0026#34;, run \u0026#34;git rebase --abort\u0026#34;. Could not apply f8bddeb... Edit Leopards $ git status interactive rebase in progress; onto 528ecc7 ... Unmerged paths: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to mark resolution) both modified: leopards.yaml VS Code에서 해당 부분을 확인한다. Accept Current Change, Accept Incoming Changes 등을 선택하여, 충돌 부분을 수정한 뒤, git add. -\u0026gt; git commit으로 병합을 완료한다.\n하지만, 당장 충돌 해결이 어려울 경우, 아래 명령어로 merge를 중단한다. 1 git rebase --abort 해결 가능 시,\n충돌 부분을 수정한 뒤 git add . 후, git commit을 실행한다.\n충돌이 모두 해결될 때까지 반복한다.\n충돌이 다 해결되면 git rebase --continue 를 입력한다.\n1 git rebase --continue main에서 git merge conflict-2로 마무리한다.\nmain을 앞으로 이동 conflict-1 과 conflict-2를 삭제한다.\n다 사용한 branch는 바로 바로 지워서 혼란스럽게 만들지 말자. Reference 제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions ","permalink":"http://jeha00.github.io/post/git/lec_chapter03/","summary":"branch를 만든 후, 다른 branch로 이동해본다. 또한, 각 branch끼리 합치는 git merge와 git rebase를 실행하면서 CLI 와 Source tree로 branch 변화를 시각적으로 확인해본다. 마지막으로 병합 시 충돌을 해결해본다.","title":"[TIL] Git study: Lecture Chapter 03 - branch"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다. 1. 프로젝트의 변경사항을 타임캡슐(버전)에 담고, 묻기 파일을 저장해야 git이 변경사항을 인식할 수 있다.\n1.1 git add untracked state -\u0026gt; tracked state git add 개별 파일 추가와 전체 파일 추가 git status로 확인하면 Untracked files가 뜬다.\n1 2 3 4 5 6 7 8 9 On branch master No commits yet Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) .gitignore lions.yaml tigers.yaml 이 Untracted files란 **Git의 관리에 들어간 적 없는 파일**을 의미한다.\ntigers.yaml 파일을 수정한다.\ngit add tigers.yaml 로, tigers.yaml의 변경사항을 stage 상태로 올린다.\n1 2 3 4 5 6 7 8 9 10 11 12 On branch master No commits yet Changes to be committed: (use \u0026#34;git rm --cached \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: tigers.yaml Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) .gitignore lions.yaml 이렇게 git add로 개별 파일을 tracked 상태로 바꾼다.\n또한, 모든 파일이 git 관리에 들어가기 위해서는 git add .를 입력한다.\n그러면 아래와 같은 의문이 들 수 있다.\n\u0026lsquo;처음부터 git add . 으로 모든 file을 tracked 상태로 만들면 되지 않느냐?\n여러 file 중 A file만 A project에 필요하고, B file은 B project에 필요하다면 한꺼번에 하는 것이 아닌 개별적으로 해야 한다.\n위와 같은 경우를 제외하고는 통상적으로 한 프로젝트에 관련된 모든 것을 git add .로 추가한다.\n1.2 git commit 다음으로 아래 명령어를 사용하여 타임캡슐을 묻어보자.\n1 git commit 이 명령어를 입력하면 밑에 이미지와 같은 Vim 입력모드로 진입한다.\nVim mode에서 명령어는 다음과 같다.\n작업 Vi 명령어 상세 입력시작 i 명령어 입력 모드에서 텍스트 입력 모드로 전환 입력 종료 ESC 텍스트 입력 모드에서 명령어 입력 모드로 전환 저장 없이 종료 :q 저장 없이 강제 종료 :q! 입력한 것이 있을 때 사용 저장하고 종료 :wq 입력한 것이 있을 때 사용 위로 스크롤 k git log 등에서 내역이 길 때 사용 아래로 스크롤 j git log 등에서 내역이 길 때 사용 출처: 제대로 파는 Git \u0026amp; GitHub - by 얄코 FIRST COMMIT 을 입력한 뒤, 저장하고 종료한다.\nFIRST COMMIT은 보통 통상적으로 프로젝트의 첫 버전이 만들어질 때 쓰는 메세지다.\nCOMMIT와 Message를 같이 입력하고 싶으면 아래와 같이 입력한다.\n1 git commit -m \u0026#39;FIRST COMMIT\u0026#39; 아래 명령어와 소스트리로 확인한다.\n종료는 :q를 사용한다. git log 2. 변경사항 만들기 다음 소단원에서 과거로 돌아가는 실습을 수행하기 위해 몇 가지 변경사항을 만들어보자.\n그 결과, 소스트리의 히스토리에 다음과 같이 결과가 뜰 것이다.\n위로 올라갈수록 최근 commit message다.\n2.1 첫 번째 변경사항 변경사항\nlions.yaml 파일 삭제 tigers.yaml의 manager를 Donald 로 변경 leopards.yaml 파일 추가 git status로 확인\n1 2 3 4 5 6 7 8 9 10 11 12 On branch master Changes not staged for commit: (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) deleted: lions.yaml modified: tigers.yaml Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) leopards.yaml no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;) 그리고 message와 함께 commit 한다. 1 git commit -m \u0026#34;Replace Lions with Leopards\u0026#34; commit과 함께 add를 한 번에 하는 방법도 있다. 하지만 이 경우, 새로 추가된(untracked) 파일이 없을 때만 가능하다. 1 git commit -am \u0026#34;(메세지)\u0026#34; 2.2 두 번째 변경사항 변경사항\nTigers의 members에 George 추가 커밋 메세지: Add George to Tigers add 및 commit\n1 2 # commit message를 구분한다. git commit -am \u0026#39;add George to tigers\u0026#39; 2.3 세 번째 변경사항 변경사항 cheetas.yaml 추가 1 2 3 4 git add . # commit message를 구분한다. git commit -m \u0026#39;Add team Cheetas\u0026#39; 2.4 네 번째 변경사항 변경사항 cheetas.yaml 삭제 Leopards의 manager를 Nora로 수정 panthers.yaml 추가 1 2 3 4 git add . # commit message를 구분한다. git commit -m \u0026#39;Replace Cheetas with Panthers\u0026#39; 3. 과거로 돌아가는 두 가지 방법 커밋을 묻어놓은 타임캡슐을 버전이라고 생각하면 다음과 같은 순서로 버전이 만들어진다.\n그리고, 안에 무엇이 있는지를 알기 위해서 캡슐마다 작업한 것을 적어서 꼬리표를 달아놓은 것이다.\nGit에서 과거로 돌아가는 방법은 2가지 방법이 있다.\nReset vs Revert\n- reset: 원하는 시점으로 돌아간 뒤 이후 내역들을 지운다.\n- revert: 되돌리기 원하는 시점의 커밋을 거꾸로 실행한다.\nrevert 에 대해 더 설명하자면\n해당 과거 이후의 행적을 삭제하는 것이 아니라, 이 행적을 거꾸로 수행하는 commit을 하나 넣음으로서, 결과적으로 reset과 동일한 결과를 갖는 것이다. 하나 하나를 기록으로 남길 때 사용한다.\n우리가 한 남긴 commit message를 기준으로 Add team Cheetas로 돌아간다고 하자.\nreset은 다음과 같이 움직인다.\n하지만 revert는 이와 다르게 움직인다.\nReplace Cheetas with Panthers, Add team cheetas, Add Georage to Tigers는 그대로 두고, Replace Lions with Leopards만 삭제할려는 상황에서 revert를 사용한다.\n만약 협업 시에 reset으로 특정 history를 삭제하면 이 history를 기반으로 작업한 다른 개발자와 심각한 충돌을 일으킨다. 그래서 한 번 공유된 commit들은 revert를 이용해서 되돌려야 한다.\n4. 과거로 돌아가기 실습 먼저 .git을 백업 후, 원래 폴더에 있던 .git을 삭제한다.\n그러면 VSC에서 git status를 하면 fatal: not a git repository라는 오류가 발생하겠고, Sourcetree에서도 저장소 없음 이라는 에러가 발생한다.\n다시 원래 폴더에 .git 을 복사 붙여넣기하면 위 에러들은 다 사라진다.\n위 이미지들에서 commit message를 순서대로 확인할 수 있듯이, git log를 통해서도 순서대로 볼 수 있다. git log에서 나가기 위해서는 :q를 입력한다.\n그러면 Add team Cheetas message를 남긴 시점의 과거로 돌아가보자.\n돌아가기 위해서는 위 message를 남긴 시점의 hash 번호가 필요하다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $ git log commit 1589712e4324d8a017a8bbc5945e8f98a8085aad (HEAD -\u0026gt; master) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:30:06 2022 +0900 commit 1589712e4324d8a017a8bbc5945e8f98a8085aad (HEAD -\u0026gt; master) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:30:06 2022 +0900 replace cheetas with Panthers commit f86046e7549dde524f3be3729bd9d43281d2a486 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:29:13 2022 +0900 Add team Cheetas hash 번호란 위 log에서 commit 옆에 있는 알파벳과 숫자가 섞인 것을 의미한다.\n4.1 reset 4.1.1 reset으로 돌아가기 git reset \u0026ndash;hard (돌아갈 커밋 해시)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ git reset --hard f86046e7549dde524f3be3729bd9d43281d2a486 $ git log commit f86046e7549dde524f3be3729bd9d43281d2a486 (HEAD -\u0026gt; master) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:29:13 2022 +0900 Add team Cheetas commit 679d1f1788575666f8b368c67dfbb14f69c6a637 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:28:44 2022 +0900 add George to tigers git log를 통해 원하는 시점으로 돌아간 것을 알 수 있다.\n이번에는 \u0026lsquo;첫 커밋 시점\u0026rsquo; 으로 돌아가보자.\n1 2 3 4 5 6 7 8 $ git reset --hard ed807a60e49db810008b8fcb5fd4deddf4f200ec $ git log commit ed807a60e49db810008b8fcb5fd4deddf4f200ec (HEAD -\u0026gt; master) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:22:01 2022 +0900 first commit 위에서 git log로 확인했듯이 첫 커밋 시점으로 돌아간 걸 알 수 있다.\n소스트리에서도 first commit message만 남겨진 걸 확인할 수 있다.\n4.1.2 reset 전 시점으로 복원하기 실무해서 하는 방식은 아니지만, .git 을 이해해보자는 차원으로 공부한다. 실무에서는 .git 폴더를 직접 건드리는 일은 없다.\n백업해둔 .git 폴더를 복원\ngit log와 git status로 상태 확인\n.git을 복원하면서 현재 git은 맨 처음 상태에서 파일에 새롭게 변화가 된 것이라고 인식한다. 그래서 아래 명령어로 초기화하자. git reset --hard로 현 커밋 상태로 초기화\n커밋 해시가 없으면 마지막 커밋을 가리킨다. lions.yaml 삭제\n3번 명령을 실행한 후, git status로 확인해보면 달라진 것을 알 수 있다. lions.yaml은 추가된 것이므로, 삭제해보자. 4.2 revert로 돌아가기 4.2.1 add George to tigers 시점으로 돌아가기 source tree로는 해당 커밋 메세지를 클릭하면 바로 commit hash를 구할 수 있지만, git log를 입력하여 찾아보자.\n1 2 git revert 679d1f1788575666f8b368c67dfbb14f69c6a637 # :wq로 저장 4.2.2 Replace Lions with Leopards의 커밋으로 되돌려보기 이번에는 Replace Lions with Leopards 시점으로 돌아가려고 했으나, 다음과 같이 Error가 발생했다.\n또한, 이 다음 명령 창에는 (master|REVERTING) 로, revert가 진행 중임을 알 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; rudtl@DESKTOP-R1USJ9D MINGW64 ~/Desktop/Dev/GitHub/Git-practice (master) $ git revert 3183106276f5315380d6722971159db9d72e7fd1 CONFLICT (modify/delete): leopards.yaml deleted in parent of 3183106 (Replace Lions with Leopards) and modified in HEAD. Version HEAD of leopards.yaml left in tree. error: could not revert 3183106... Replace Lions with Leopards hint: After resolving the conflicts, mark them with hint: \u0026#34;git add/rm \u0026lt;pathspec\u0026gt;\u0026#34;, then run hint: \u0026#34;git revert --continue\u0026#34;. hint: You can instead skip this commit with \u0026#34;git revert --skip\u0026#34;. hint: To abort and get back to the state before \u0026#34;git revert\u0026#34;, hint: run \u0026#34;git revert --abort\u0026#34;. \u0026gt; rudtl@DESKTOP-R1USJ9D MINGW64 ~/Desktop/Dev/GitHub/Git-practice (master|REVERTING) 이처럼 에러가 뜨는 것은 컴퓨터가 결정할 수 없기 때문에, 내가 결정을 하라고 알려준 것이다. 그래서 어떻게 해결하면 되는지 hint를 알려주고, 그 후에 git revert --continue 를 하라고 안내해준다.\ngit rm \u0026lt;pathspec\u0026gt; 란 \u0026lt;pathspec\u0026gt;에 있는 파일을 삭제하라는 명령어다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ git rm leopards.yaml rm \u0026#39;leopards.yaml\u0026#39; $ git revert --continue :wq $ git log commit e27e462a65904a4f3ea890c6389c988423b40990 (HEAD -\u0026gt; master) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Thu Jun 23 11:22:12 2022 +0900 Revert \u0026#34;Replace Lions with Leopards\u0026#34; This reverts commit 3183106276f5315380d6722971159db9d72e7fd1. ❗ 만약 git revert --continue 명령어를 수행했늗네, 다음과 같은 Error가 뜬다면 git add/rm \u0026lt;pathspec\u0026gt; 명령어를 수행해야한다.\n1 2 3 4 $ git revert --continue error: Committing is not possible because you have unmerged files. hint: Fix them up in the work tree, and then use \u0026#39;git add/rm \u0026lt;file\u0026gt;\u0026#39; hint: as appropriate to mark resolution and make a commit. 4.2.3 commit을 동반하지 않은 revert revert는 기본적으로 commit을 동반한다. commit 없이 하고 싶다면 아래와 같이 명령어를 입력한다.\n1 git revert --no-commit (되돌릴 커밋 해시) 그래서 원하는 다른 작업을 추가한 후, 커밋을 별도로 해야 한다.\n마무리로 reset을 사용해서 revert 전으로 되돌아가보자.\nReference 제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions ","permalink":"http://jeha00.github.io/post/git/lec_chapter02/","summary":"git add 와  git commit 으로 변경사항을 stage에 올리고, 저장해본다. 이 과정에서 vim의 몇 가지 명령어를 알아본다.  git reset \u0026ndash;hard / git revert 를 학습하여 과거 시점으로 돌아가는 걸 학습한다.","title":"[TIL] Git study: Lecture Chapter 02 - reset vs revert"},{"categories":"git","content":"0. Introduction 해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다. 1. Git을 배워야 하는 이유 Git을 통해서 내가 만들고 있는 프로젝트의 시간과 차원을 종횡으로 넘나들 수 있다.\n시간: 한 버전 안에 있는 프로젝트의 버전을 과거로 되돌리거나, 특정 내역 취소 가능 차원: 프로젝트의 여러 모드(버전)를 쉽게 전환하고 관리할 수 있다. 1.1 시간 관점에서 Git 장점 아래의 문제들은 매우 큰 cost를 지불해야하지만, git은 손쉽게 가능하다.\n문제상황 1 초기 버전을 기준으로 각 파일의 변화를 시간 순으로 누적하여 관리하는 VCS 경우에는 모든 버전을 백업하면 프로젝트가 진행될수록 차지하는 용량이 커진다.\n문제상황 2 또한, v1 -\u0026gt; v2 -\u0026gt; v3 -\u0026gt; v4 -\u0026gt; v5 순서로 프로젝트가 진행되고 각 버전마다 백업할 때, v2에 잘못된 것을 찾았을 경우 v2부터의 버전을 다 수정해야 한다.\n1.2 차원과 관련된 Git 장점 아래 문제들 역시 Git에서 쉽게 해결할 수 있다.\n문제상황 1 회사에 현재 진행되고 있는 프로젝트에 나의 아이디어를 적용하고 싶다면??\n그런데, 회사 프로젝트에 멋대로 논의되지 않는 코드를 추가할 수 없다.\n이런 경우, 메인 프로젝트의 폴더를 복사해서 작업을 하면 되지만, 그러면 용량을 많이 차지할 것이다.\n문제상황 2 이 모든 안들의 변경사항을 모두 메인 프로젝트로 가져와야 한다면 어떻게 해야할까?\n문제상황 3 다른 버전의 프로젝트들의 변경사항을 하나 하나 확인해서 가져와야 하는데, 같은 파일에 다른 수정이 되어 있으면 어떻게 해야할까??\n2. Git과 Sourcetree 설치 Git과 sourcetree 설치 관련 설명은 이 링크 Git, Sourcetree 설치 를 참고한다.\n잘 설치되었는지를 확인하기 위해서 아래 명령어로 확인한다.\n1 \u0026gt; git --version 2.1 Git bash를 사용하는 이유 Git 사용에 적합한 터미널이고, Linux/Mac(Unix)에서 사용되는 CLI 명령어들을 윈도우에서 사용 가능하다.\nVSC 에서 Default terminal을 git bash로 설정하는 방법\nVScode에서 Ctrl + Shift + P 를 입력하여, Select Default Profile을 검색하여 선택한다.\nGit bash를 선택한 후, VSC의 termianl에서 + 로 새 창을 열어서 기본으로 Git Bash가 설정된 것을 확인한다.\n2.2 CLI vs GUI 실무에서 Git을 매일 사용하는 사람으로서 이 2가지를 다 사용하는데, 어떻게 나눠서 사용하면 될까???\nGit에서 뭔가를 실행하기 위한 어떤 명령들을 사용 할 때 -\u0026gt; CLI\n프로젝트의 상태를 Git상에서 자세히 살펴볼 때 -\u0026gt; Source Tree\n또한, 학습자로서 GUI보다 CLI를 먼저 학습한다.\nGUI는 편하지만 Git의 기능을 모두 사용할 수 없다. CLI로 다 익혀놓은 후, Git을 잘 알게되면 GUI와 혼용해서 사용하는 방식으로 학습한다. 3. Git 설정 vs 프로젝트 관리 시작하기 3.1 Git 최초 설정 3.1.1 Git 전역으로 사용자 이름과 이메일 주소를 설정 이 설정은 Github 계정과는 별개로 나중에 나중에 협업할 때 이 작업을 누가했는지를 알기 위함이다.\nWhat Is Git 을 참고한다.\n1 2 3 4 5 6 7 8 9 10 11 \u0026gt; git config --global user.name \u0026#34;(본인 이름)\u0026#34; \u0026gt; git config --global user.email \u0026#34;(본인 이메일)\u0026#34; # 위 명령어에서 입력한 본인 이름 \u0026gt; git config --global user.name (본인 이름) # 위 명령어에서 입력한 본인 이메일 \u0026gt; git config --global user.email (본인 이메일) 3.1.2 기본 branch명 변경 기본 branch명이 master 였지만, 이 용어가 옛날에 흑인 노예의 주인을 연상시켜서 main으로 변경하고 있다.\n그래서 Github 또한 기본 branch 명을 master로 바꿨다.\n1 \u0026gt; git config --global init.defaultBanch main 3.2 프로젝트 생성 \u0026amp; Git 관리 시작 git basics_1을 참고한다.\n4. Git에게 맡기지 않을 것들 Git의 관리에서 배제할 파일/폴더들은 어떠한 이유로 배제하고, 어떻게 배제할까??\nGit의 관리에서 특정 파일/폴더를 배제해야 할 경우\nGit 관리에 포함할 필요가 없을 때\n자동으로 생성 또는 다운로드 되는 파일들 (빌드 결과물, 라이브러리) Git 관리에 포함하지 말아야 할 때\n보안상 민감한 정보를 담은 파일 배제하는 방법으로 .gitignore 파일을 사용하여 배제할 요소들을 지정할 수 있다.\n각 언어의 framework에도 이 파일로 무시해도 되는 파일들이 적혀있다.\n.gitignore 형식 자세한 형식은 https://git-scm.com/docs/gitignore 을 참조한다.\n프로젝트 때마다 위 사이트를 참조하여 작성한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # 이렇게 #을 사용해서 주석을 단다. # 모든 file.c를 무시 file.c # 최상위 폴더의 file.c를 무시 /file.c # 확장자가 .a인 모든 파일 무시 *.a # 확장자가 .a 여도 lib.a는 무시하지 않는다. !lib.a # logs란 이름의 파일 또는 폴더와 그 내용들 무시 logs # logs란 이름의 폴더와 그 내용들을 무시 logs/ # logs 폴더 바로 안의 debug.log와 .c 파일들 무시 logs/debug.log logs/*.c # doc directory 아래의 모든 .pdf 파일을 무시 doc/**/*.pdf # logs 폴더 바로 안, 또는 그 안의 다른 폴더(들) 안의 debug.log 무시 log/**/debug.log .gitignore 사용해보기 폴더에 secrets.yaml 을 생성한다.\n다음과 같은 내용을 가진다.\n1 2 id: admin pw: 1234abcd git status로 상태를 확인한다.\n1 2 3 4 5 6 7 8 9 On branch master No commits yet Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) lions.yaml secrets.yaml tigers.yaml .gitignore을 생성하여, 그 안에 secrets.yaml 을 입력한다.\n다시 git status로 상태를 확인한다.\n1 2 3 4 5 6 7 8 9 On branch master No commits yet Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) .gitignore lions.yaml tigers.yaml secrets.yaml이 없다는 걸 확인할 수 있다.\n이처럼 .gitignore.yaml을 통해서 git의 관리 하에 두지 않을 것들을 정할 수 있다.\n다음 chapter 내용은 위 상태에 이어서 진행된다.\nReference 제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions ","permalink":"http://jeha00.github.io/post/git/lec_chapter01/","summary":"Git을 배워야하는 이유, Git 최초 설정 방법 그리고, Git의 관리에서 벗어나는 .gitigonre에 대해 알아본다.","title":"[TIL] Git study: Lecture Chapter 01"},{"categories":"git","content":"2.1 Git 저장소 만들기 Git 저장소를 만드는 방법에는 2가지가 있다. 기존 directory를 Git 저장소로 만들기 기존 repository를 clone 하기 2.1.1 기존 directory를 Git 저장소로 만들기 git init\ngit add\ngit commit -m \u0026lsquo;message\u0026rsquo;\n기존 project를 Git으로 관리하고 싶을 때, 프로젝트의 directory 경로로 이동해서 아래 명령을 실행한다. 1 2 3 \u0026gt; git init \u0026gt; git add . \u0026gt; git commit -m \u0026#39;Initial project version\u0026#39; git init은 .git 이라는 하위 directory를 만든다. .git directory 안에는 저장소에 필요한 뼈대 파일이 존재한다. 하지만 .git이 있다고 프로젝트의 파일이 관리되는 게 아니고, 저장소에 파일을 추가하고, 커밋해야 Git이 프로젝트를 관리한다. ❗❗ 주의사항: .git 폴더를 지우면 Git 관리내역이 삭제되어 과거의 내역으로 돌아갈 수 없다. (현 파일들은 유지)\n2.1.2 기존 저장소를 clone 하기 git clone [url].git\n언제 clone하는가? 다른 project에 참여하려거나 (contribute) Git 저장소를 복사하고 싶을 때 git clone은 project history를 전부 복사한다. 그래서, 서버의 디스크가 망가져도 client 저장소 중에서 아무거나 하나 가져와 복구하면 된다. (서버에만 적용하는 설정은 복구 불가능) git-practice 코드를 복사하려는 상황이라면 1 \u0026gt; git clone https://github.com/git-practice/git-practice.git 이 명령으로 git-practice라는 directory를 만들고, 그 안에 .git directory를 만든다. 그리고, 저장소의 데이터를 모두 가져와서 최신 버전으로 checkout 해놓는다. 2.2 수정하고 저장소에 저장하기 \u0026lsquo;2.1 저장소 만들기\u0026rsquo; 를 통해서\nGit 저장소를 하나 만들었다. 만든 Git 저장소를 Working directory에 checkout 했다. Chapter 2.2 내용을 들어가기에 앞서 한 가지 내용을 정리하겠다.\nWorking directory 의 모든 파일은 Tracked 와 Untracked 로 나눠진다.\nTracked 파일은 Unmodified , Modified 그리고, Staged 로 나눠진다. 나머지 파일은 다 Untracked 상태다. Untracked 상태는 snapshot에도, staging area에도 포함되지 않은 파일이다. 처음 저장소를 clone 하면 이 저장소 안에 있는 파일은 아무것도 수정하지 않았기 때문에, Tracked 상태이면서 Unmodified 상태다.\n다음으로 \u0026lsquo;2.2.1 파일의 상태 확인하기\u0026rsquo; ~ \u0026lsquo;2.2.3 Modified 상태의 파일을 Stage 하기\u0026rsquo; 내용을 정리하겠다. \u0026lsquo;2.2.1 파일의 상태 확인하기\u0026rsquo; 에서는 git status 명령어를 배운다. \u0026lsquo;2.2.2 파일을 새로 추적하기\u0026rsquo; 와 \u0026lsquo;2.2.3 Modified 상태의 파일을 Stage 하기\u0026rsquo; 에서는 git add 명령어를 배운다. 2.2.1 git status git status 는 현재 파일의 상태를 확인하기 위해 사용되는 명령어다.\ngit status 명령어로 파일의 상태를 먼저 확인하자.\n1 2 3 \u0026gt; git status On branch master nothing to commit, working directory clean 위 코드의 의미는 다음과 같다.\n현재 branch는 기본 branch인 master다. 현재 Tracked 이지만, Modified 상태인 파일이 없다. 만약 .git을 삭제한 후, git status를 입력하면, 다음과 같은 안내문이 뜬다.\n1 \u0026gt; fatal: not a git repository (or any of the parent directories): .git git이 관리하지 않는다는 의미다. 그래서 .git을 삭제하면 안된다.\n2.2.2 git add git add 명령어는 새로운 파일을 추적할 때 사용되는 명령어로서, Untracked상태에서 Tracked 상태로 이동된다. 새로운 파일을 추적할 때 뿐만 아니라, 수정한 파일을 Staged상태로 만들 때에도 사용된다. 파일을 프로젝트에 추가하는 명령어라기 보다는 다음 커밋에 추가하는 명령어로 생각하자. Untracked 1 2 3 4 5 6 7 8 9 \u0026gt; echo \u0026#39;My project\u0026#39; \u0026gt; README.md \u0026gt; git status On branch master Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) README.md nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track) echo 'My project' \u0026gt; README.md 명령어는 \u0026lsquo;My project\u0026rsquo;라는 내용을 가진 README.md 파일을 만들라는 명령어다. 파일을 만든 후, git status 실행하면 Untracked files 안에 새로 만든 파일이 있다는 걸 확인할 수 있다. 이는 README.md파일이 Untracked 상태임을 말한다. Git은 Untracked 상태의 파일을 아직 snapshot에 존재하지 않는 파일로 인식한다. Untracked -\u0026gt; Tracked 1 2 3 4 5 6 7 \u0026gt; git add README.md \u0026gt; git status On branch master Changes to be committed: (use \u0026#34;git rest HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: README.md 새로 생긴 파일의 상태가 Changes to be committed 안으로 들어왔다. 이는 Staged 상태임을 의미한다. 위에 개념에서 언급했듯이 Staged는 Tracked 상태에 포함되므로, Tracked 상태이면서 Staged 상태다. 이 상태에서 커밋을 하면 git add를 실행한 시점의 파일이 커밋되어, snapshot이 저장되어 저장소 히스토리에 남는다. Tracked: Unmodified -\u0026gt; Modified Tracked 상태인 README.md 파일을 수정한 후, git status 를 입력해보자. 1 2 3 4 5 6 7 8 \u0026gt; git status On branch master Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: README.md README.md 파일은 Changes to be committed: 에 있다가 Changes not staged for commit: 으로 옮겨졌다. 이는 수정한 파일이 Tracked 상태이지만, Staged 상태는 아니라는 것이다. 즉, 수정된 파일이므로 Modified 상태임을 말한다. Tracked: Modified -\u0026gt; Staged Modified 상태에서 Staged 상태로 바꿔보자. 1 2 3 4 5 6 7 \u0026gt; git add README.md \u0026gt; git status On branch master Changes to be committed: (use \u0026#34;git rest HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: README.md Changes to be committed: 로 옮겨졌다. Tracked 상태이면서 Staged 상태로 되었다. 이는 커밋을 실행할 때 이 파일이 포함된다는 걸 의미한다. Tacked: Staged \u0026amp; Unstaged 하지만, 더 수정할 게 있어 바로 커밋하지 못하는 상황이라고 생각해보자. 수정하고 나서 git status를 입력했다. 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026gt; git add README.md \u0026gt; git status On branch master Changes to be committed: (use \u0026#34;git rest HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: README.md Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: README.md Staged 상태이면서 Unstaged 상태로 동시에 나온다. 이게 가능한 이유는 git add 명령을 실행하면 바로 Staged 상태로 만든다는 걸 위 예시를 통해 알았다. git add 했을 때의 시점에서의 파일이 Staged에 오른다. git add 후에 다시 수정을 했고, 수정한 후 git add를 하지 않았기 때문에 unstaged 상태로도 나온다. 즉, git add 명령을 실행한 후에 또 파일을 수정하면 git add 명령을 다시 실행해서 최신 버전을 Staged 상태로 만들어야 한다. Tracked: Unstaged -\u0026gt; Staged 1 2 3 4 5 6 7 \u0026gt; git add README.md \u0026gt; git status On branch master Changes to be committed: (use \u0026#34;git rest HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: README.md Changes not staged for commit:에서 Changes to be committed:로 옮겨졌다. 최신 상태가 Staged에 올랐다는 걸 확인할 수 있다. Reference Pro git : Second editions ","permalink":"http://jeha00.github.io/post/git/1_gitbasics/","summary":"첫 번째, git 저장소 만들기. 두 번째, git add 와 git status 명령어를 통해서 Git introduction에서 알아본 git의 3가지 상태와 3가지 단계를 이해해본다.","title":"[Pro git 2/E study] Git basics"},{"categories":"git","content":"0. Introduction Pro git : Second editions 자체 스터디 내용이다. 이번 장은 Git을 처음 접하는 분들에게 필요한 내용이다. 이 챕터를 통해서 Git 탄생 배경, 사용 이유를 알 수 있다. 지속적인 복습을 위해 만든다. 1. What is Version Control System ??? Version Control System이란 무엇이고, 왜 필요할까??\n버전 관리 시스템(VCS) : 파일의 변화를 시간에 따라 기록했다가, 나중에 특정 시점의 버전을 다시 꺼내올 수 있는 시스템\nVCS를 통해서 큰 노력 없이\n각 파일을 이전 상태로 되돌릴 수 있다. 프로젝트를 통째로 이전 상태로 되돌릴 수 있다. 시간에 따라 수정 내용을 비교할 수 있다. 누가 문제를 일으켰는지 추적할 수 있다. 누가 언제 만들어낸 이슈인지 알 수 있다. 파일을 잃어버리거나 잘못 고쳤을 때도 쉽게 복구할 수 있다. VSC의 종류에는 LVCS, CVCS, DVCS가 있다.\n각 종류에 대해 알아보자.\n1.1 Local Version Control System (LVCS, 로컬 버전 관리) LVCS 탄생 계기 많은 사람은 버전을 관리하기 위해 directory로 파일을 복사하는 방법을 사용한다. 하지만 이러한 방식은 잘못되기 쉬어서 Local Version Control System을 만들었다. 간단한 DB를 사용해서 파일의 변경 정보를 관리했다. LVCS의 한 예: RCV 많이 사용하는 VCS 중 RCS (Revision Control System)가 오늘날까지도 많은 회사에서 사용하고 있다. RCS는 Mac OS에서도 개발 도구를 설치하면 함께 설치되며, 기본적으로 Patch Set(: 파일에서 변경되는 부분)을 관리한다. Patch Set을 통해 모든 파일을 특정 시점으로 되돌릴 수 있다. 1.2 Central Version Control System (CVCS, 중앙 집중식 버전 관리) CVCS 탄생 계기 위의 LVCS의 장점에도 불구하고, LVCS는 다른 개발자와 협업 시에 사용할 때에는 적절한 tool이 아니었다. 그래서 중앙 집중식 버전 관리 (CVCS, Central Version Control System) 를(을) 개발했다. CVCS 특징과 장점 CVCS는 LVCS에 비해 장점이 많다. 파일을 관리하는 서버가 별도로 있고, 클라이언트가 이 중앙 서버에 파일을 받아서 사용(checkout)하기 때문에, 누가 무엇을 하고 있는지 알 수 있다. 관리자의 입장에서는 누가 무엇을 할지 꼼꼼히 관리할 수 있다. 모든 client의 local DB를 관리하는 것보다 VCS 하나를 관리하기가 훨씬 쉽다. CVCS 단점 파일을 관리하는 중앙 서버가 별도로 있고, client가 checkout 방식으로 사용하고, 저장소를 전부 복제하는 게 아니기 떄문에, 서버가 다운되는 동안, 다른 사람과 협업할 수 없고, 백업할 방법도 없다. 중앙 DB가 있는 하드디스크에 문제가 생기면 project의 모든 history를 잃는다. (client가 가진 snapshot 제외) 🔅 snapshot: 특정 시점에서 파일, 폴더 또는 워크스페이스의 상태\n1.3 Distributed Version Control System (DVCS, 분산 버전 관리 시스템) DVCS 장점 첫 번째, Git과 같은 DVCS는 저장소를 전부 복제한다. 그래서 서버에 문제가 생기면 작업을 할 수 없었던 CVCS와는 달리, 이 복제물로 다시 작업을 시작할 수 있다. Client 중에서 아무거나 골라도 서버를 복원할 수 있다. 모든 checkout이 모든 데이터를 가진 백업이라는 의미다. 두 번째, 대부분의 DVCS 환경은 remote repository가 존재한다. 그래서, 사람들은 동시에 다양한 그룹과 방법으로 협업이 가능하다. 계층 모델 같은 CVCS으로는 할 수 없는 workflow를 다양하게 사용할 수 있다. 2. Histroy summaries of Git 리눅스(Linux) kernel은 굉장히 규모가 큰 open source project였다. 1991~2002년 단순 압축 파일로만 관리하다가 2002년 BitKeeper라 불리는 DVCS를 사용하기 시작했다. 그러다 2005년에 BitKeepr가 유료화가 되었다. Linux는 커뮤니티이고, BitKeeper는 이익을 추구하는 회사이기 때문에 이해관계가 달랐다. 이 계기로 Linux 개발 커뮤니티가 자체 도구를 만들었다. 그 도구가 Git이다. Git은 아래와 같은 목표로 세워져서 지금도 유지하고 있다. 빠른 속도 단순한 구조 비선형적인 개발 (동시다발적인 branch) 완벽한 분산 속도나 데이터 크기 면에서 대형 proejct에도 유용할 것 3. Key point of Git : 데이터를 다루는 방식의 차이 3.1 Snapshots, Not Differences VCS들과 Git의 가장 큰 차이점은 데이터를 다루는 방식에 있다.\nVCS는 각 파일의 변화를 시간 순으로 관리하면서 파일들의 집합을 관리한다. Git은 데이터를 파일 시스템 스냅샷으로 취급하여, 각 파일의 변화가 아닌 파일 전체를 스냅샷으로 찍어낸다. 그래서 Git은 데이터를 snapshot stream처럼 취급한다. 그래서 Git은 프로젝트의 상태를 저장할 때마다, 파일이 존재하는 그 순간을 중요하게 여긴다. 그래서 Git은 파일이 달라지지 않으면 성능을 위해 새로 저장하지 않는다. VCS와 Git 차이점 [VCS: Storing data as changes to a base version of each file]\n[Git: Storing data as snapshots of the project over time]\n3.2 거의 모든 명령을 로컬에서 실행 Git은 거의 모든 명령이 저장소 전체를 복사해서 로컬 파일과 데이터만 사용하는 방식으로,\n네트워크의 속도에 영향을 받는 다른 CVCS보다 매우 빠른 속도를 가진다. project의 history를 조회할 때, 서버 없이 local DB에서 조회하기 때문에 매우 빠르다. 어떤 파일의 현재 버전과 한 달 전의 상태를 비교하고 싶을 때도 이 두 상태를 로컬에서 찾는다. 오프라인 상태거나 네트워크와 연결할 수 없어도 막힘 없이 일할 수 있다. 3.3 Git의 무결성: checksum 방식 체크섬(checksum)이란\n40자 길이의 16진수 문자열인 SHA-1 해시를 사용하여 만든다. Git에서 사용하는 가장 기본적인(atomic) 데이터 단위이다. Git의 기본 철학이다. SHA-1: 24b9da6552252987aa493b52f8696cd6d3b00373 같은 40자 길이의 16진수 문자열이다.\n그래서 Git은 checksum을 사용하여 (중심으로)\n데이터를 저장하고 관리한다. 그래서 체크섬 없이는 어떠한 파일이나 디렉터리도 변경 할 수 없다. 모든 것을 식별한다. 파일을 저장하고, 파일 이름으로 저장하지 않는다. 3.4 Git은 데이터를 추가할 뿐 Git은 무엇을 하든 Git database에 데이터를 추가한다.\n그래서 데이터를 되돌리거나 삭제할 방법이 없다. 또한, 다른 VCS처럼 commit하지 않으면 변경사항을 잃어버릴 수 있다. 하지만, commit 하면 데이터를 잃기 어렵다. 3.5 Git의 3가지 상태와 3가지 단계 이 부분에 대한 자세한 내용은 Chapter 2를 참고한다.\nGit 파일은 3가지 상태(: Commited, Modified, Staged) 로 관리한다.\nCommited: 데이터가 local database에 안전하게 저장된 상태 Modified: 수정한 파일을 아직 local database에 커밋하지 않은 상태 Staged: 현재 수정한 파일을 곧 커밋할 것이라고 표시한 상태 - 이 3가지 상태는 Git project의 3가지 단계(: Working directory, Staging Area, .git Directory(Repository)와 연결된다.\nGit directory repository 라고도 불린다. 커밋된 상태 Git이 project의 meta data와 객체 datebase를 저장하는 곳이다. 다른 컴퓨터에 있는 저장소를 clone할 때 만들어지는 곳이다. Working directory project의 특정 버전을 checkout한 것이다. Git directory 안에 압축된 database에서 파일을 가져와서 만든 것이다. 파일을 수정하는 공간이므로, checkout하고 나서 수정했지만, 아직 staging area에 추가하지 않은 상태다. Staging Area 커밋을 위한 준비 단계 단순한 파일이고 곧 커밋할 파일에 대한 정보를 저장한다. 파일들이 Staged 상태 Summary working directory에서 파일을 수정한다. Staging area로 파일을 스테이지해서 커밋할 snapshot을 만든다. Staging area에 있는 파일들을 커밋해서 Git directroy에 영구적인 snapshot으로 저장. 4. CLI Git은 CLI (Command Line Interface)와 GUI (Grapic User Interface)로 사용할 수 있다. 하지만, Git의 모든 기능을 지원하는 것은 CLI 뿐이다. CLI를 사용할 줄 알면 GUI를 사용할 수 있지만, 반대는 성립되지 않는다. 5. Git initail setup 5.1 사용자 정보 등록 명령어 --global 은 전역 설정하는 명령어로, 딱 한 번만 하면 된다. git config --global user.name \u0026quot;user-name\u0026quot; git config --global user.email \u0026lt;user-email\u0026gt; 만약, 프로젝트마다 다른 이름과 이메일 주소를 사용하고 싶으면 --global전역 명령어를 빼고 입력한다. 5.2 설정 확인 명령어 설정 확인 방법은 git config --list 명령을 실행한다.\nGit은 같은 키를 여러 파일에서 읽기 때문에 같은 키가 여러 개 있을 수 있다. 그러면 Git은 나중값을 사용한다. git config \u0026lt;key\u0026gt; 명령으로 특정 Key에 대해 어떤 값을 사용하는지 확인할 수 있다. git config user.name 5.3 명령어 도움말 명령어 도움말 이 필요할 때는 방법은 3가지다. git help \u0026lt;verb\u0026gt; git \u0026lt;verb\u0026gt; --help main git-\u0026lt;verb\u0026gt; 예를 들어 git help config를 실행하면 config 명령에 대한 도움말만 볼 수 있다. Reference Pro git : Second editions 더북(TheBook:Git 교과서) git snapshot ","permalink":"http://jeha00.github.io/post/git/0_whatisgit/","summary":"Git이란 무엇이고, Git이 탄생하기까지의 VCS의 histroy에 대해 간략히 알아본다. 또한, Git의 3가지 상태와 3가지 단계를 학습한다. 마지막으로 Git의 사용자 등록 방법과 화인 방법을 알아본다.","title":"[Pro git 2/E study] What is Git ?"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 1. 다양한 caching 환경 1.1 caching 기법 한정된 빠른 공간(= 캐쉬)에 요청된 데이터를 저장해 두었다가 후속 요청시 캐쉬로부터 직접 서비스하는 방식\n저장장치 계층 간의 속도 차이를 완충시켜주기 위해 컴퓨터 구조, 운영체제, DB 등의 분야에서 각각 다음과 같은 기법 등으로 사용되고 있다.\npaging system 외에도 cache memory, buffer caching, Web caching 등 다양한 분야에서 사용된다.\ncache memory: CPU와 main memory 사이에 cache memory가 있다. 이 cache memory에 없는 file을 main memory에 요청한다. buffer caching: file system에 대한 read/write 요청을 memory에서 빠르게 서비스하는 방식 Web caching: web page를 server에서 가져오는데 동일한 url을 요청할 때를 대비해서 신속히 서비스를 제공하기 위해서, caching 기법으로 제공하는 방법 cache 운영의 시간 제약\n교체 알고리즘에서 삭제할 항목을 결정하는 일에 지나치게 많은 시간이 걸리는 경우, 실제 시스템에서 사용할 수 없다.\nBuffer caching이나 Web caching의 경우\nO(1)에서 O(log n) 정도까지 허용 Paging system인 경우\npage fault인 경우에만 OS가 관여한다. 페이지가 이미 메모리에 존재하는 경우, 참조시각 등의 정보를 OS가 알 수 없다. O(1)인 LRU의 list 조작 조차 불가능 1.2 웹캐싱이란? 웹 사용자에 의해 빈번히 요청되는 데이터를 사용자와 지리적으로 가까운 웹캐시 서버에 보관해, 빠른 서비스를 제공하여 서비스 지연시간을 줄이고 웹서버 부하도 줄이는 기법\n2. 웹캐시의 교체 알고리즘(Cache replacement algorithum) 한정된 캐시 공간 안에서 사용자들의 지속적인 요청을 처리하기 위해서, 미래에 참조될 가능성이 높은 객체를 선별한 후, 한정된 캐시 공간 안에 보관할 객체를 온라인으로 결정하는 알고리즘\n웹캐시는 객체를 가지고 있는 근원지 서버의 위치 및 특성에 따라 객체를 캐시로 읽어오는 비용이 다르다.\n하나의 URL에 대응되는 파일 단위로 캐싱이 이뤄져서 캐싱 단위의 크기가 균일하지 않다.\n2.1 교체 알고리즘의 성능 척도 캐시 교체 알고리즘의 목표는 참조 가능성이 높은 객체를 캐시에 보관해 \u0026lsquo;캐시적중률(Hit rate)\u0026lsquo;을 높이는 것\n캐시 적중률\n사용자의 총 요청 중 캐시에서 적중되어 서비스된 요청의 비율 하지만, 웹캐싱에서는 객체들의 크기와 인출 비용이 균일하지 않기 때문에 , 객체들의 참조 가능성과 이질성을 함께 고려해야 한다.\n이런 경우, 비용절감률(Cost-Savings Ratio: CSR) 로 정형화시킨다.\n객체 크기와 인출 비용이 모두 균일하면 비용절감률은 캐시 적중률과 동일한 의미를 가진다. 2.2 참조 가능성의 예측 캐시 교체 알고리즘은 전통적인 캐싱 기법인 LRU(Least Recently Used), LFU(Least Frequently Used) 등의 알고리즘처럼 최근 참조 성향과 참조 빈도에 근거해 미래의 참조 성향을 예측하는 방법을 사용한다.\n그러면 전통적인 교체 알고리즘들의 구체적인 예를 살펴보고, 웹캐시의 교체 알고리즘은 이들 중 어떤 방법을 채택하는지 알아보자.\n2.2.1 전통적인 교체 알고리즘 과거 참조 기록을 바탕으로 객체 A와 B를 평가한다고 하자.\nLRU는 최근 참조 성향만을 고려한다.\n(a) 객체 B가 더 최근(t1)에 참조되었기 때문에, (a) B에 더 높은 가치를 부여한다. 하지만, 이 방법은 자주 참조되는 객체와 그렇지 않은 객체를 구분할 수 없다는 단점이 있다. (b)에서는 A의 가치가 더 높게 평가된다는 사실은 LRU의 문제점을 보여준다. LFU는 참조 횟수만을 고려한다.\n(a) A의 참조 횟수가 (a) B보다 더 많기 때문에, (a) A에 더 높은 가치를 부여한다. 이 알고리즘의 문제점은 오래 전에 많이 참조된 객체에 높은 가치를 부여해, 새로 참조되기 시작한 객체를 캐시에서 쫓아낼 우려가 있다. 오히려 (c)에서 B의 가치가 더 높게 평가된다는 사실이 LFU의 문제점을 보여준다. 최근 참조 성향과 참조 횟수에 근거해 객체의 참조 가능성을 평가하는 방법은 최근에 참조된 객체가 다시 참조될 가능성이 높다는 점 ( 시간지역성, temporal locality )과, 참조 횟수가 많은 객체일수록 다시 참조될 가능성이 높다는 점 ( 인기도, popularity ), 이 두 가지 사실을 기본으로 가정한다.\n위에 두 가지가 컴퓨터 프로그램의 참조 성향을 모델링하는데 널리 사용되는 요소다.\n2.2.2 웹캐시의 교체 알고리즘 시간지역성 측면 -\u0026gt; 웹 캐시 알고리즘들은 객체의 직전 참조 시각을 활용\n참조 인기도 측면 -\u0026gt; 객체 참조 횟수에 노화 기법을 추가하여, 캐시 오염(cache pollution)을 방지한다.\n노화 기법: 오래전에 이루어진 참조에 대해 참조 횟수 계산할 때, 가중치를 줄이는 방법 2.3 객체의 이질성에 대한 고려 웹캐싱 같이 캐싱의 단위 객체들의 크기와 인출 비용이 균일하지 않은 환경에서는 이 특성을 고려한 합리적인 가치 평가를 해야 한다.\n이 합리적인 평가를 하기 위해서는 객체의 참조 가능성 과 캐시 적중률 로 실제 절약할 수 있는 비용을 동시에 고려해야 한다.\n캐시 적중률의 경우, 크기가 작은 객체에 높은 가치를 부여한다. 왜냐하면, 한정된 캐시 공간에 많은 객체를 보관하면 캐시 적중률이 높아지기 때문이다.\n2.4 알고리즘의 시간 복잡도 캐시 교체 알고리즘이 실제 시스템에 유효하게 사용되기 위해서는 시간 복잡도 측면에서 현실성이 있어야 한다.\n시간 복잡도 O(n): cache 내에 있는 객체의 수가 n개라고 할 때, 어떤 객체를 캐시에서 삭제할지 결정하기 위해 n에 비례하는 비교나 연산이 필요하다는 의미\nproxy cache의 경우, 통상적으로 cache 내에 수백만 개의 객체가 존재하기 때문에 이들을 다 조사하는 시간 복잡도의 방법은 부담이 크기 때문에, 웹 환경에서는 이 알고리즘으로 사용하기 어렵다.\nLRU\n가장 최근에 참조된 시각을 기준으로 객체들의 가치를 일렬로 세워놓고 새롭게 참조된 객체만 가치가 가장 높은 위치로 옮기면 되므로, O(1)의 시간 복잡도 구현이 가능하다. O(1): 캐시 내에 존재하는 객체의 수 n이 커지더라도, 이에 관계없이 캐시에서 이루어지는 비교나 연산이 정해진 적은 횟수로 충분하다는 의미 나머지 알고리즘\n힙(heap) 자료구조를 이용해 O(log n)의 시간 복잡도에 각종 캐시 연산을 구현하게 된다. 하지만, 최근 참조 시각을 이용하는 알고리즘에서는 객체의 가치가 시간과 비례하여 다르게 평가되기 때문에, 가치의 대소 관계가 변할 수 있다. 그래서, O(n)의 시간 복잡도가 필요하다. 3. 웹캐시의 일관성 유지 기법 cache에 보관된 웹 객체는 근원지 서버에서 변경될 수 있으므로 일관성 유지를 위한 기법으로, 특히 웹캐시의 일관성은 컴퓨터 시스템에서의 캐시와 달리 큰 문제를 야기하지 않으므로, 적응적 TTL(adaptive Time-To-Live) 기법과 같은 약한 일관성 유지 기법을 사용한다.\n약한 일관성 유지 기법\n사용자의 요청이 있을 때마다 서버에서 일일이 확인하는 게 아닌, 변경될 가능성이 높은 경우에만 확인하는 기법 예) adaptive TTL 강한 일관성 유지 기법\n최신 정보가 사용자에게 전달되는 것을 보장하는 기법 예) polling-every-time, invalidation 웹서버와 네트워크의 부담이 커서 득보다 실이 많아 일반적으로 약한 일관성 유지 기법을 사용한다.\n4. 웹캐시의 공유 및 협력 기법 웹캐싱 효과를 극대화 하기 위해 웹캐시 간의 공유 및 협력 기법이 필요하다.\n4.1 ICP (Internet Cache Protocal, 인터넷 캐시 프로토콜) 동료 proxy cache 사이에서 웹 객체의 검색 및 전송을 지원하기 위한 protocol\n사용자가 프락시서버에 웹 객체를 요구했는데, 프락시서버가 그 객체를 캐싱하고 있지 않은 경우, ICP에서 모든 동료 프락시들에게 ICP 질의를 멀티캐스트(multicast)해서 누가 요청된 웹 객체를 가지고 있는지 확인한다.\n웹 객체를 가지고 있는 동료 프락시가 답신을 보낸다.\n프락시 서버(Proxy server) : 클라이언트와 서버 사이에서 data를 중계하는 역할을 하는 서버 ICP 질의를 보냈던 프락시는 답신을 준 프락시에 HTTP 요청을 보내서 해당 객체를 받아온 후 사용자에게 전달한다.\nHTTP와 ICP의 차이\nHTTP는 웹 객체의 전송을 위한 프로토콜인 반면, ICP는 공유 웹캐시들 간의 객체 위치를 확인하기 위한 프로토콜 HTTP에 비해 매우 부담이 적은 프로토콜 4.2 CARP (Cache Array Routing Protocol, 캐시 배열 간 경로지정 프로토콜) 공유 웹캐시들에 동일한 웹 객체들이 중복 저장되는 것을 막기 위해 URL 공간을 분할해, 각각의 캐시는 자신에게 배정되는 객체들만을 캐싱는 기법\n5. 웹캐시의 사전인출 기법 웹 서비스의 응답 지연시간을 줄이기 위해, 사용자에 의해 아직 요청되지 않은 객체를 미리 받아오는 기법으로 2가지로 나눠진다.\n5.1 예측 사전인출 기법(predictive prefetching) 웹페이지들 간의 관계 그래프 등을 구성해 하나의 웹 페이지가 참조되었을 때, 과거 참조 기록을 통해 새로운 웹페이지가 참조될 된 것을 기반으로 사전인출을 수행하는 방법 5.2 대화식 사전인출 기법(interactive prefetching) 사용자가 HTML 문서를 요청했을 때, 웹캐시는 캐싱하고 있던 HTML 문서를 미리 파싱(parsing)한다. 그래서 그 문서에 포함되거나 연결된 웹 객체를 미리 받아와서 사용자의 후속 요청에 곧바로 전달하는 기법 6. 동적 웹 객체의 캐싱 기법 6.1 정적 웹 페이지와 동적 웹 페이지의 차이 정적 웹 페이지\n실시간으로 변하지 않고 서버에 저장되어 있는 HTML+CSS file 그대로 보여주는 방식 동적 웹 페이지\n상황에 따라 서버에 저장되어 있는 HTML에 데이터 추가/가공하여 보여주는 방법으로, 실시간성 을 요구하는 콘텐츠를 처리하는 웹 페이지를 말한다. 6.2 동적 웹 객체의 캐싱 기법 동적 웹 페이지의 콘텐츠는 실시간성이 있어서, 결과물이 이전과 정확히 일치하지 않지만, 상당 부분 유사하다.\n그래서 부분적으로 캐싱하여 추후 그 결과를 활용할 수 있다.\nReference kocw 이화여자대학교 운영체제 - 반효경 교수 - 운영체제와 정보기술의 원리 - 반효경 지음 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_13_%EC%9B%B9%EC%BA%90%EC%8B%B1/","summary":"캐싱이란 무엇이고, 웹에서 사용되는 캐싱은 무엇을 목적으로 하는지, 웹캐싱이 전통적인 캐싱 기법과 무엇이 다른지, ICP는 무엇인지, 정적 웹과 동적 웹이란 무엇인지 등을 알아본다.","title":"[TIL] Chapter 13: 웹캐싱 기법"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 6. Allocation of File data in disk disk에 균일하지 않은 크기의 file을 저장할 때는 disk를 균일한 크기로 쪼갠 sector 단위로 저장한다.\ndisk에 file을 저장하는 방식 3가지 (paging 기법과 유사)\nContiguous Allocation (연속 할당) Linked Allocation (연결 할당) Indexed Allocation (인덱스를 이용한 할당) sector와 block의 차이\nsector: disk에서 물리적으로 저장하는 단위 block: file system에서 file이 저장되는 단위 6.1 Contiguous Allocation 하나의 file을 sector들에 Array 구조로 저장하여, 나누어진 각 블록들이 연속된 번호를 부여받아 저장된다.\ndirectory를 설명하자면\n\u0026lsquo;count\u0026rsquo; file은 0부터 시작해서 총 2개의 sector를 차지한다. \u0026rsquo;tr\u0026rsquo; file은 14부터 시작해서 총 3개의 sector를 차지한다. 장점\nFast I/O (시간 효율성 증가) file이 모두 연속해서 붙어 있으므로 한 번의 seek / rotation으로 많은 양의 데이터를 받을 수 있다. 대부분의 접근 시간은 header가 움직이면서 읽어들이는 시간이기 때문에, 시간 효율성이 증가한다. Realtime file 용 또는 이미 run 중이던 process의 swapping 용도로 사용된다. Direct access (= random access) 가능 몇 번 sector부터 시작하는지 directory가 알기 때문에 가능하다. 단점\nExternal fragmentation (hole 발생) File grow가 어렵다. file grow를 해도 낭비 발생 (internal fragmentation) file이 커져서 sector를 늘려 저장하려할 때, 다른 file이 옆 sector를 차지하고 있다면 늘릴 수 없다. 그래서 file이 커질 것을 대비하여 미리 할당했을지라도, 할당된 만큼만 커질 수 있다는 단점이 있다. 그리고 미리 할당된거면서 사용하지 않는 조각이기 때문에, 내부 조각이 발생된다. 6.2 Linked Allocation sector들이 각각 node되어 linked list 구조로 파일을 저장한다.\n장점\n외부 단편화가 발생하지 않는다. 단점\n첫 요소부터 차례대로 읽어야하므로, 직접 접근이 불가능하다. 또한, 각 sector로 header가 이동해야하므로, 시간이 더 걸린다. 신뢰성 문제 한 sector가 고장나 pointer가 유실되면 그 이후 모든 sector로 접근할 수 없다. pointer란 block 주소를 의미한다고 생각하자. 포인터를 위한 공간이 필요하므로 공간 효율성을 떨어뜨린다. 512 bytes/sector, 4 bytes/pointer 변형\nFile-Allocation Table (FAT) 파일 시스템 pointer를 별도의 sector에 보관하여 신뢰성 문제와 공간 효율성 문제를 해결한다. 6.3 Indexed Allocation directory에 file의 index block을 표시하여 이 index block을 통해서 직접 접근이 가능한 방식\nindex block이란??\nfile이 어디에 나눠져 있는지 index를 적어 두는 block 하나 장점\nExternal fragmentation(외부 조각 hole) 발생 X 직접 접근 (= 임의 접근)이 가능하다. 단점\n작은 파일의 경우, 공간 낭비가 심하며 실제로 많은 파일들이 사이즈가 작다. index block을 위한 sector와 실제 file 저장을 위한 sector가 필요하기 때문에 공간 낭비가 심하다. 매우 큰 파일의 경우, 하나의 index block으로 커버할 수 없다. 해결 방안: linked scheme, multi-level index 전자는 index block을 여러 개 두는 것이고, 후자는 block의 마지막에 다음 index block을 가리키는 값을 설정하여 서로 연결하는 것이다. 이번 소챕터에서는 이론적으로 disk에 file을 어떻게 할당하는 지를 알아봤으니, 다음 소챕터에서는 실제로 어떠한지 알아보자.\n7. UNIX 파일 시스템의 구조 Partition(= Logical Disk) 은 Boot block, Super block, Inode list, Data block으로 구성된다.\n7.1 Boot block Booting에 필요한 정보를 담고 있는 block\n0번 block이며, bootstrap loader라고도 한다. 모든 file system에 존재하는 블록 7.2 Super block file system에 관한 총체적인 정보를 담고 있는 블록\n어느 부분이 비어 있는 블록인지, 어느 부분이 사용 중인 블록인지, 어디부터가 Inode 블록인지, data 블록인지 등을 알려주는 정보를 가지고 있다. 7.3 Inode list 파일 이름을 제외한 파일의 모든 \u0026lsquo;메타 데이터\u0026rsquo; 를 따로 저장하고 있는 list\n파일 하나당 Inode가 하나씩 할당된다. 해당 Inode는 파일의 meta data를 가지고 있는데, 파일의 이름과 Inode 번호는 directory가 가지고 있다. direct blocks 파일이 존재하는 인덱스를 저장하는 index block 파일의 크기가 크지 않다면 이 블록을 이용하여 파일을 접근할 수 있다. direct blocks로 커버할 수 있는 크기보다 저장 용량이 큰 파일은 single indirect를 통해서 하나의 level을 두어 저장하는 방식을 취하고, 그보다 더 큰 파일은 double indirect, 더 큰 파일은 triple indirect 방식을 취한다. 7.4 Data block 파일의 실제 내용을 보관하는 블록\n이 중 directory file은 자신의 directory에 속한 file의 이름과 inode 번호를 가지고 있다. file의 이름은 실제로 data block이 가지고 있고, 나머지는 Inode 번호로 가진다. 8. FAT 파일 시스템 window 계열에서 주로 사용되는 file system 방식으로, Partition(= Logical Disk)은 Boot block, FAT, Root directory, Data block으로 구성된다.\n구조: Boot block + FAT + Root directory + Data block\nfile의 metadata의 일부(위치 정보)를 FAT에 저장하고, 나머지 정보는 root directory가 가지고 있다. (file name, 접근 권한, 소유주, 파일의 첫 번째 위치 등)\n위 사진에서 217번이 첫 번째 블록인데, 다음 블록의 위치를 FAT에 별도로 관리한다. 그래서 FAT을 통해서 직접 접근이 가능하다. FAT table 전체를 메모리에 올려 놓았으므로 연결 할당(linked allocation)의 단점을 전부 극복하였다.\nFAT는 중요한 정보이므로 복제본을 만들어 두어야 한다.\n9. Free-space management Sector가 할당되고 나서 발생하는 hole을 관리하는 디스크 자유 공간 관리방법으로, 아래 4가지가 있다.\n9.1 Bit map or Bit vector 각 block 마다 bit를 둬서 bit가 0이면 free block이고, 1이면 sector에 저장된 block이다.\n연속된 n개의 free block(빈 공간)을 찾기 효과적이지만, 0 또는 1을 저장할 부가적인 공간을 필요로 한다.\nUNIX file system의 경우, super block에 정보를 저장한다.\n9.2 Linked list 모든 free block을 link로 연결 (free list)한 방식\n회색이 비어있는 공간\n연속적인 가용 공간을 찾기 어렵지만, 공간의 낭비가 없다.\n9.3 Grouping Linked list의 변형으로, 첫 번째 자유 블록(free block)이 n개의 블록 주소(pointer)를 저장하는 방법\nn개의 블록 주소 중, (n-1)개는 실제로 비어있는 블록의 주소다. 그러나 마지막 1개는 첫 번째와 마찬가지로, (n-1)개의 빈 블록 주소를 가지고 있는 또 다른 자유 블록을 가리킨다. linked list와 달리 비어있는 block을 한 번에 찾기에는 효율적이지만, 연속적인 free block을 찾기에는 효과적이지 않다. 9.4 Counting free block의 위치를 가리키고, 거기서부터 몇 개가 비어 있는지 알려주는 방식\n프로그램들이 종종 여러 개의 연속적인 block을 할당하고 반납한다는 사실에 착안했다. 모든 블록을 일일이 추적할 필요 없이, 자유 블록의 첫 번째와 연속된 계수만 유지하면 보다 효율적이다. 10. Directory Implementation Linear list\n\u0026lt;file name, file의 메타 데이터\u0026gt;의 list 구현이 간단하다. 하지만, directory 내에 파일이 있는지 찾기 위해서는 선형 탐색이 필요하다. 해시 테이블\n선형 리스트 + 해싱 hashing: 더 짧은 길이의 값이나 키로 변환하는 것 Hash table은 file name을 선형 리스트의 위치로 hashing한다. 탐색 시간이 O(1)이다. 해시 충돌이 발생할 수 있다. -\u0026gt; 자료 구조 관련 내용 파일의 메타 데이터 보관 위치\nDirectory 내에 직접 보관 Directory 에는 포인터를 두고 다른 곳에 보관 UNIX에서는 대부분 Inode에서 저장, FAT file system에서는 다음 block 위치를 가지고 있었다. Long file name의 지원\n\u0026lt;file name, file의 metadata\u0026gt;의 list에서 각 entry는 일반적으로 고정 크기다. 하지만 file name이 엔트리의 고정 길이보다 길어지는 경우, entry의 마지막 부분에 file name의 뒷 부분이 위치한 곳의 pointer를 둔다. file 이름의 나머지 부분은 동일한 directory file의 일부에 존재한다. 11. VFS와 NFS Virtual File System (VFS)\n서로 다른 다양한 파일 시스템에 대한 동일한 시스템 콜 인터페이스(API)를 통해 접근할 수 있게 해주는 OS의 layer Network file System (NFS)\n분산 환경에서 네트워크를 통해 파일이 공유되는 대표적인 공유 방법 어떤 파일 시스템을 쓰든 상관 없이 VFS interface를 사용한다.\nclient 입장에서 VFS interface를 거쳐서 file system이 없으면 NFS를 사용한다.\n분산 시스템에서는 네트워크를 통해 파일을 공유하기 위해 NFS client와 NFS server가 이용된다.\nclient와 server 모두에 NFS module이 있어서, 같은 약속으로 접근이 가능하다. 12. Page cache and buffer cache 12.1 Page cache Virtual memory의 paging system에서 사용하는 page frame을 page cache라 부르는 것으로, cache의 관점에서 설명하는 용어다. 이 관점에서는 프로세스의 주소 공간을 구성하는 페이지가 swap area에 내려가 있는가, page cache에 올라와 있는가로 바라본다.\nMemory-Mapped I/O 를 쓰는 경우, 파일의 I/O에서도 page cache를 사용한다. page cache는 운영체제에게 주어진 정보가 극히 제한적이라, clock 알고리즘을 사용한다. 12.2 Memory-Mapped I/O 디스크 파일의 일부를 가상 메모리에 매핑하여 사용하는 것으로, 매핑 후에는 system call을 하지 않고 메모리에서 사용자가 직접 읽고 쓴다.\n매핑한 영역에 대한 메모리 접근 연산은 파일의 입출력을 수행하게 한다. 12.3 Buffer cache: File system 관점 프로그램이 I/O 시, disk의 file system에서 system call에 의해 OS가 대신 read() 작업을 수행하여, 읽어온 data를 kernel의 memmory 영역에 copy 하여 놓은 data를 buffer cache라 한다. 즉 이 관점에서는 disk에 있는냐 아니면 kernel의 memory 영역에 copy되어 있느냐로 바라본다.\n파일 시스템을 통한 I/O 연산은 메모리의 특정 영역인 buffer cache를 사용한다. 한 번 읽어 온 블록에 대한 후속 요청 시, buffer cache에서 즉시 전달 모든 process가 공용으로 사용 교체 알고리즘 필요 (LRU, LFU 등) 12.4 Unified(통합) buffer cache 최근의 OS에서 기존의 buffer cache가 page cahce에 통합되어 사용되는 방식\n별도의 구분 없이 필요할 때만 할당해서 사용하는 방식이다. 12.5 통합 buffer cache로 인한 차이점 13. 프로그램의 실행 프로그램이 실행되면 실행 파일이 프로세스가 되며, 프로세스만의 독자적인 주소 공간이 만들어진다.\n이 공간은 code, data, stack으로 구분되며 Address translation을 통해서 당장 사용될 부분은 물리적 메모리에 올라가고, 당장 사용되지 않는 부분은 swap area로 내려간다.\n이 때, 코드 부분은 이미 파일 시스템에 있고, 프로세스의 주소에 이미 mapping된 경우이기 때문에, swap area에 내리지 않고 필요 없으면 물리적 메모리에서 지운다. 나중에 필요하면 file system에서 가져오면 된다. 즉, 이 code 부분은 memory mapping된 대표적인 예다.\n13.1 Memory Mapped I/O 수행 프로세스가 일반 데이터 파일을 I/O하고 싶을 수 있다.\n이때 mmap()을 호출하면 Memory Mapped I/O 방식으로 파일을 I/O할 수 있고, mmap()은 시스템 콜이므로 운영 체제에게 CPU의 제어권이 넘어간다.\n운영 체제는 데이터 파일의 일부를 프로세스 주소 공간에 매핑한다.\n만약 데이터 파일이 매핑된 영역을 접근했을 때, 실제 물리적인 메모리에 페이지가 올라와 있지 않다면 페이지 부재가 발생한다. 그렇지 않으면 가상 메모리의 mapping된 영역은 물리적 메모리의 페이지 프레임과 일치가 되므로, 프로세스가 데이터 파일에 대해 I/O를 하고 싶을 때, 운영 체제의 도움 없이 독자적으로 I/O를 수행할 수 있다.\n물리적 메모리에 올라간 데이터 파일과 매핑된 페이지 프레임을 쫓아내야 할 때는 swap area로 내리는 것이 아니라, 수정된 사항을 file system에 적용하고 물리적 메모리에서 지운다.\n현재 process B가 데이터 파일에 대해 Memory Mapped I/O를 수행하여, 물리적 메모리에 페이지 프레임을 올려 두었는데도, 프로세스 A도 이 page frame을 공유하여 사용할 수 있다.\n13.2 read() 수행 프로세스가 일반 데이터 파일을 I/O를 하는 방법으로, read() system call을 호출할 수도 있다.\nread() system call을 호출하면 memory의 buffer cache를 확인해야 하는데, 통합 buffer cache 환경에서는 페이지 캐시가 buffer cache 역할을 동시에 수행한다. 그래서 Memory Mapped I/O 로 올라간 페이지 cache를 buffer cache로 사용할 수 있다.\n운영 체제는 buffer cache에 있던 내용을 복사하여 process의 주소 공간에 할당한다. 13.3 Memory Mapped I/O vs read() Memory Mapped I/O\n가상 메모리에 올라 온 영역이 곧 파일이므로, system call 없이 I/O 작업을 할 수 있다. page cache에 있는 내용을 복사할 필요가 없다. 여러 프로세스가 mmap()를 사용하여 같은 영역을 공유하여 사용하면 일관성 문제가 발생할 수 있다. read()\n매번 운영체제의 중재를 받는다. page cache에 있는 내용을 복사해야 한다. 여러 프로세스가 read()를 사용해도 일관성 문제가 발생하지 않는다. Reference kocw 이화여자대학교 운영체제 - 반효경 교수 - 운영체제와 정보기술의 원리 - 반효경 지음 - 느리더라도 꾸준하게: [반효경 운영체제] File System Implementations 1\u0026amp;2 연결 리스트(Linked list) ","permalink":"http://jeha00.github.io/post/os/os_chapter_12_%ED%8C%8C%EC%9D%BC%EC%8B%9C%EC%8A%A4%ED%85%9C_2/","summary":"Disk의 할당방식 3가지, FAT file system이란 무엇인지, disk의 빈 공간을 어떻게 관리하는지, page cache와 buffer cache와의 차이점과 마지막으로 통합 buffer cache에서의 Memory mapped 방식에 대해 알아본다.","title":"[TIL] Chapter 12: 파일 시스템 2"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 1. File and File System File\nA named collection of related information\n저장 장소: 일반적으로 비휘발성의 보조기억장치(disk)에 저장 메모리는 주소를 통해서 접근하는 장치지만, disk에 일반적으로 저장되는 file은 이름을 통해서 접근한다. 운영체제는 다양한 저장 장치를 file이라는 동일한 논리적 단위로 볼 수 있고 관리한다. 운영체제의 관리 방법으로 사용되는 file을 \u0026lsquo;device special file\u0026rsquo; 이라 한다. file 관련 Operation(연산): create, delete,read, write, reposition(파일 내부의 위치 저장), open, close 등 File attribute(or metadata of file)\n파일 자체의 내용이 아니라 파일을 관리하기 위한 각종 정보들\n파일 이름, 유형, 저장된 위치, 파일 사이즈 접근 권한(읽기 / 쓰기 / 실행), 시간(생성 / 변경 / 사용), 소유자 등 File system\n운영체제에서 파일을 관리하는 체계\n파일 및 파일의 메타 데이터, 디렉토리 정보 등을 관리 파일의 저장 방법 결정 파일 보호 등 Directory\n파일의 metadata 중 일부를 보관하고 있는 일종의 특별한 파일 그 디렉토리에 속한 파일 이름 및 파일 attribute들을 가지고 있다. directory로 정의되는 연산 file 찾기, 만들기, 지우기 list a directory, rename a file, traverse(탐색) the file system Partition (= Logical Disk)\n하나의 물리적 디스크 안에 여러 파티션을 두는 게 일반적이다. 쪼개진 파티션을 C drive, D drive라 불린다. 반대로 여러 개의 물리적인 디스크를 하나의 파티션으로 구성하기도 한다. (물리적) 디스크를 파티션으로 구성한 뒤 각각의 파티션에 file system을 설치하거나, 가상 메모리의 swapping 등 다른 용도로 크게 2가지로 나눠 사용할 수 있다. 2. open() 연산 system call을 통해서 OS가 물리적 디스크에 있는 file의 metadata를 memory로 올리는 연산으로, read와 write 같은 연산들 모두 system call을 통해서 수행한다.\n2.1 open() 연산의 구체적인 과정 왼쪽: memory, 오른쪽: disk\nopen(\u0026rsquo;/a/b/\u0026rsquo;): Process A가 \u0026lsquo;/a/b/\u0026rsquo; 경로에 있는 file을 open하겠다.\nsystem call 이므로, CPU 제어권이 OS에게 넘어간다.\ndisk로부터 파일 c의 metadata를 메모리로 가져오기 위해, directroy path를 search.\nopen 작업: 그 안에 있는 metadata를 memory에 올리는 것\nread 작업: open 후, memory에 올린 metadata 안의 disk 상의 실제 위치를 얻는 것\nroot directory \u0026lsquo;/\u0026lsquo;의 metadata는 미리 알고 있다.\nroot directory \u0026lsquo;/\u0026lsquo;를 open하고, read하여 그 안(= disk 상의 실제 위치 안)에서 \u0026lsquo;a\u0026rsquo;의 metadata를 획득.\n파일 \u0026lsquo;a\u0026rsquo;의 metadata를 open한 후, read하여 그 안에서 파일 \u0026lsquo;b\u0026rsquo;의 metadata를 획득.\n파일 \u0026lsquo;b\u0026rsquo;의 metadata를 open한 후, read하여 그 안에서 원하는 data를 가져온다.\n이런 tree 구조의 directory는 search에 너무 많은 시간을 소요한다.\n한 번 open한 파일은 kernel의 메모리 영역 일부에 copy하여 두고 나서 동일한 경로의 파일에 관한 read / wrtie 시, kernel의 메모리 영역에 둔 file을 다시 copy해서 사용하기 때문에 directory search를 하지 않아도 된다. kernel memory 일부 영역에 copy하여 별도로 저장된 file을 buffer cache 라 한다. 그래서 LRU와 LFU 알고리즘을 자연스럽게 사용할 수 있다. 2.2 file system 연산의 두 종류 table File descriptor table(fd) (file handle, file control block)\n프로세스마다 존재하여 프로세스 별 open file table에 대한 위치 정보를 나타낸다. 위 이미지에서는 b file의 index 정보를 가지고 있다. Open file table\n현재 open된 file들의 metadata 보관소 (in memory)\n디스크의 metadata보다 몇 가지 정보가 추가된다.\nOpen한 process의 수 File offset: 파일 어느 위치 접근 중인지 표시 (별도 테이블 필요) 3. File Protection 각 파일에 대해 누구에게 어떤 유형의 접근(read / wrtie / execution)을 허락할 것인가?? Access Control 방법: 3가지 Access control Matrix, Grouping, Password Access control Matrix로 하는 건 overhead가 커서 일반적인 OS에서는 Grouping 방법을 사용한다. Grouping 방식은 단 9 비트만 있으면 된다. 4. File System의 Mounting Mounting 연산이란 A partition의 root file system에 있는 특정 directory 이름에다가 또 다른 파티션 B의 file system을 mounting 하여, A parition이지만 B partition과 연결하는 연산\n5. Access Methods 시스템이 제공하는 파일 정보의 접근 방식\n순차 접근 (sequential access)\n카세트 테이프를 사용하는 방식처럼 접근 읽거나 쓰면 offset은 자동적으로 증가 직접 접근 (direct access, random access)\nLP 레코드 판과 같이 접근하도록 한다. 파일을 구성하는 레코드를 임의의 순서로 접근할 수 있다. Reference kocw 이화여자대학교 운영체제 - 반효경 교수 - 운영체제와 정보기술의 원리 - 반효경 지음 - metadata ","permalink":"http://jeha00.github.io/post/os/os_chapter_12_%ED%8C%8C%EC%9D%BC%EC%8B%9C%EC%8A%A4%ED%85%9C_1/","summary":"file이란 무엇이고, 이 file 관리하는 system은 무엇인지, operation은 memory와 disk 사이에서 어떤 순서로 이뤄지는지,  file protection은 어떻게 이뤄지는지, 순차 접근과 직접 접근이 무엇인지 알아본다.","title":"[TIL] Chapter 12: 파일 시스템 1"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 1. 디스크의 구조 디스크(disk): 컴퓨터 시스템의 대표적인 2차 저장장치 memory는 volatile(휘발성) 저장장치이지만, disk는 영구 보관할 수 있는 2차 저장장치 디스크의 효율적인 관리를 위해 디스크 스케쥴링 기법 과 저전력 디스크 관리 기법 에 대해 알아보자. 또한, 엘리베이터 scheduling 문제를 통해 쉽게 이해해보자. 1.1 논리 블록(logical block) 단위 디스크 외부(=컴퓨터 host의 내부)에서 보는 디스크의 단위 정보 저장 공간들을 말한다. 내부에서는 sector로 바라본다.\n주소를 가진 1차원 배열처럼 취급\nhost에서 disk의 정보를 읽을 때, sector 몇 번지가 아니라 1차원 배열에서 몇 번째 있는 정보를 달라고 요청한다. 정보를 전송하는 최소 단위\ndisk에 데이터 저장과 disk 외부로의 입출력은 논리 블록 단위로 저장 및 전송이 이뤄진다. 어떻게 논리 블록의 저장된 데이터에 접근하는가??\n해당 블록의 index 번호를 disk controller에 전달 → disk controller가 대응되는 sector를 찾아 요청 데이터에 대한 입출력 작업을 수행 1.2 디스크의 물리적 구조 디스크의 물리적인 구조: 마그네틱의 원판 으로 구성\n원판 = 트랙(track) 으로 구성\n트랙(track) = 섹터(sector) 로 구성 논리블록 단위의 disk 내에 물리적인 위치 = 섹터(Sector)\n논리 블록 하나가 섹터 하나와 1대1 매핑되어 저장되기 때문 sector 0: 최외곽 실린더의 첫 트랙에 있는 첫 번째 섹터 실린더(Cylinder)\n상대적 위치가 동일한 트랙들의 집합 track과 거의 유사하게 사용 암(Arm) = disk의 data를 읽고 쓰기 위해서, 해당 섹터가 위치한 실린더로 이동하는 장치\n헤드(head) = 암에 붙어있는 data를 읽고 쓰는 장치\nPartitioning\ndisk를 하나 이상의 실린더 그룹으로 나누는 과정 OS는 이것을 독립적인 disk 로 취급(logical disk) 1.3 Booting Logical formatting\n파일 시스템을 만드는 것 컴퓨터 전원을 키면 이 파일 시스템에 있는 운영체제가 메모리에 올라와서 booting FAT, inode, free space 등의 구조 포함 Booting 의 간결한 절차 순서\ndisk에 CPU가 직접 접근하지 못 하는데 어떻게 접근하는가???\n전원 on -\u0026gt; CPU가 ROM의 small bootstrap loader가 실행 -\u0026gt; ROM: 전원이 나가도 기억하는 소량의 memory small bootstrap loader: booting을 위한 loader small bootstrp loader의 지시에 의해 sector 0 (boot block)을 memory에 load하여 실행-\u0026gt; 이 sector 0은 어떤 파일 시스템이든 공통이기 때문에, 이 sector 0에 있는 boot block을 메모리에 올려서 실행한다. OS를 disk에서 load하여 실행 boot block이 file system에서 OS의 kernel 위치를 찾아서 memory에 올려서 실행하라고 지시한다. 2. 디스크 스케쥴링 2.1 접근시간(Access time)의 구성 탐색시간(seek time), 회전지연시간(rotational latency), 전송시간(transfer time)으로 구분\n탐색시간(seek time)\ndisk head를 해당 실린더 위치로 이동시키는데 걸리는 시간 회전지연시간(rotational latency)\n디스크가 회전해서 읽고 쓰려는 섹터가 헤드 위치에 도달하기까지 걸리는 시간 전송시간(transfer time)\n해당 sector가 head 위치에 도달한 후, data를 실제로 sector에 읽고 쓰는 데 소요되는 시간 disk I/O에 소요되는 접근시간 최소화 ⇒ disk I/O 효율 상승\n회전지연시간, 전송시간은 OS가 통제하기 힘들다. 그래서, 탐색시간 을 줄이기 위해 헤드의 움직임을 최소화하는 스케쥴링 작업을 실행한다. 2.2 Disk scheduling 작업 효율적인 disk I/O를 위해 여러 sector들에 대한 I/O 요청이 들어왔을 때, 이들을 어떤 순서로 처리할지 결정하는 mechanism\n목표: disk head의 이동거리를 줄이는 것 seek time을 최소화하는 것과 유사 2.2.1 FCFS(First Come First Served) scheduling 디스크에 먼저 들어온 요청을 먼저 처리하는 방식\n은행창구처럼 고정된 장소에서 이뤄지는 게 아니라, 데스크 헤드가 움직이면서 서비스를 하기 때문에, 비효율적 그룹화를 하지 않고 진행하기 때문. 2.2.2 SSTF(Shortest Seek Time First) scheduling head의 현재 위치로부터 가장 가까운 위치에 있는 요청을 제일 먼저 처리하는 방식\n문제점: 기아 현상(starvation)\n헤드 위치에서 멀리 떨어진 곳의 요청은 무한히 기다려야 하는 문제가 발생 이동거리 측면에서 가장 우수한 알고리즘은 아니다.\n2.2.3 SCAN algorithum head가 disk 원판의 안쪽 끝과 바깥쪽 끝을 오가며, 그 경로에 존재하는 모든 요청을 처리\n엘리베이터에서 사용하는 스케쥴링 알고리즘과 유사\nelevator scheduling algorithum 이라 불리기도 한다. 효율성과 형평성을 모두 만족하는 알고리즘\nFCFS처럼 불필요한 헤드의 이동 발생 X SSTF처럼 starvation 현상 발생 X 문제점\n이동 거리 측면에서 효율적이나, 모든 실린더 위치의 기다리는 시간이 공평한 것 X 제일 안쪽과 바깥쪽 위치보다 가운데 위치가 기다리는 평균시간이 더 짧기 때문 2.2.4 C-SCAN algorithum 출발점에서 다른 쪽 끝으로 이동하며 가는 길목에 있는 모든 요청을 처리하는 것까지 SCAN과 동일하나, 다른 쪽 끝에 도달해 원래 출발점 방향으로 이동할 때, 요청을 처리하지 않고, 바로 이동만 한다.\nSCAN algorithum을 개선한 것으로, circular-SCAN의 줄임말이다. 장점: 이동거리는 조금 길어지지만, 균일한 탐색시간을 제공 2.2.5 LOOK and C-LOOK algorithum head가 한쪽 방향으로 이동하다가 그 방향에 더 이상 대기 중인 요청이 없으면 head의 이동 방향을 즉시 반대로 바꾸는 scheduling 방식\nSCAN과 C-SCAN을 개선한 방식 진행 방향에 요청이 있는지 살핀 후, 이동하기 때문에 LOOK 이라 한다. 지금까지 살펴본 디스크 스케쥴링 기법들 중 LOOK 과 C-LOOK 등의 알고리즘이 많은 시스템에서 FCFS 와 SSTF에 비해 더 효율적인 것으로 알려져있다. 3. Swap-space management Disk를 사용하는 두 가지 이유\nMemory의 volatile 특성 -\u0026gt; file system 프로그램 실행을 위한 memory 공간 부족 -\u0026gt; swap space (swap area) Swap space\nVirtual memory system에서는 디스크를 memory의 연장 공간으로서 사용 파일 시스템 내부에 둘 수도 있으나, 별도 partion 사용이 일반적 공간 효율성보다는 속도 효율성이 우선 process가 끝나면 다 사라져버리는 내용이기 때문에, 공간효율성보다는 속도 효율성이 중요하다. 일반 파일보다 훨씬 짧은 시간만 존재하고 자주 참조된다. 따라서, block의 크기 및 저장 방식이 일반 파일 시스템과 다름 4. 다중 디스크 환경에서의 스케쥴링(RAID) RAID(Redundant Array of Independent Disks)\n여러 개의 disk를 묶어서 사용 어디서 다중 디스크를 사용하는가???\n동시 사용자가 많은 서버에서는 다수의 disk를 함께 사용한다. RAID의 사용 목적과 장점\n디스크 처리 속도 향상\n여러 disk에 block의 내용을 분산 저장 병렬적으로 읽어온다. 신뢰성(Reliability) 향상\n동일 정보를 여러 디스크에 중복 저장 -\u0026gt; 동시 서비스 가능 하나의 디스크가 고장 시, 다른 디스크에서 읽어온다. 단순한 중복 저장이 아니라, 일부 디스크에 parity를 저장하여 공간의 효율성을 높일 수 있다. 다중 디스크의 문제와 스케쥴링 목적\n다중 디스크 환경에서는 어느 디스크에서 요청을 처리할지 결정하는 스케쥴링 문제까지 포함 다중 디스크 환경에서의 스케쥴링 목적: 부하 균형(load balancing)을 이루면서 확장성 있는 서비스가 목표 일부 디스크가 과부하에 걸리지 않도록, 모든 디스크에 골고루 분배하도록 스케쥴링 다중 디스크 스케쥴링의 또 다른 목표: 전력 소모 감소\n하나의 디스크로부터 요청을 충분히 감당할 수 있을 때, 다른 디스크들의 회전은 정지하는 게 효율적 유사한 예시: 그룹 엘리베이터 이웃한 여러 대의 엘리베이터가 독립적으로 운영되는 게 아니라, 동일한 제어 시스템에 의해서 공동으로 운영된다. 목표: 다수의 승객이 오래 기다리지 않고, 빠른 서비스를 받는 시스템의 확장성 사용자가 적을 경우, 한 대의 엘리베이터로 운행하는 게 효율적 5. 디스크의 저전력 관리 5.1 비활성화 기법 디스크의 상태는 전력소모를 기준으로 4가지 상태로 나뉜다.\n활동(active) 상태: 현재 head가 data를 읽거나 쓰고 있는 상태 공회전(idle) 상태: disk가 회전 중이지만, data를 읽거나 쓰지 않는 상태 준비(standby) : disk 회전하지 않지만, interface가 활성화된 상태 휴면(sleep) 상태: disk 회전 X, interface 비활성화 활성 상태와 비활성 상태\n활성 상태 = active + idle 비활성 상태 = standby + sleep 전력 소모 관점에서의 상태\n전력 소모가 비활성 상태일 때, 더 적다.\n각 상태로 전환 시, 부가적인 전력 및 시간 소모된다.\n후속 요청까지의 시간 간격이 일정 시간 이상이어야만, 디스크의 회전을 정지시키는 것이 전력 소모 절감에 효과적\n비활성화 시점을 결정하는 게 중요하다는 것\n디스크 비활성화 시점 결정 방법\n시간기반(timeout based): 일정 시간 동안 디스크가 공회전 상태이면 장치를 정지 → 요청이 들어오면 디스크 활성화 예측기반(prediction based): 과거 요청을 관찰하여, 다음 공회전 구간의 길이를 예측 후, 비활성화 시점 결정 확률기반(stochastic based): 확률분포를 사용 5.2 회전속도 조절 기법 디스크의 회전속도(RPM)를 가변적으로 조절하는 기법 OS는 시스템 자원과 부하를 포괄적으로 볼 수 있기 때문에, 하드웨어 혼자보다 더 많은 전력 절감 효과 얻음 멀티미디어 환경에서는 미래의 참조 예측이 비교적 정확해서 전력 소모를 줄일 수 있다. 5.3 디스크의 데이터 배치 기법 데이터의 복제본을 많이 만들어, 헤드 위치에서 가까운 복제본에 접근하여 빠른 응답시간과 전력 소모량 절감을 얻는 FS2 file 시스템(free space file system) 5.4 버퍼캐싱 및 사전인출 기법 전제:미래에 요청할 데이터를 미리 알거나, 어느 정도 예측할 수 있다면 활성 상태일 때 헤드 위치로부터 가까운 데이터를 사전 인출하여, 디스크의 비활성화 가능성을 높여 전력 소모를 줄임 5.5 쓰기전략을 통한 저전력 디스크 기법 디스크가 비활성화 상태일 때는 기다리다가, 활성 상태일 때 쓰는 방식으로 전력 소모를 줄이는 방안 Reference kocw 이화여자대학교 운영체제 - 반효경 교수 - 운영체제와 정보기술의 원리 - 반효경 지음 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_11_%EB%94%94%EC%8A%A4%ED%81%AC%EA%B4%80%EB%A6%AC/","summary":"디스크의 물리적인 구조는 어떻고, 이 디스크 스케쥴링이 왜 필요하고 어떤 알고리즘들로 스케쥴링되는지, disk의 역할 2가지는 무엇인지, 다중 디스크 상황의 장점은 무엇인지 알아본다.","title":"[TIL] Chapter 11: 디스크 관리"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 운영체제는 보통 모든 프로그램들에 공평하게 같은 크기의 메모리를 할당하기보다는 몇몇 프로그램들에게 집중적으로 메모리를 할당한 후, 시간이 흐르면 이들로부터 메모리를 회수해서 다른 프로그램들에게 다시 집중적으로 메모리를 할당하는 방식을 채택한다.\n왜냐하면 프로세스의 빠른 수행을 위해 프로그램마다 최소한 확보해야하는 메모리 크기가 존재 하기 때문이다.\n하지만 그렇다고 프로세스의 주소 공간 전체가 메모리에 올라와 있어야 하는 것은 아니다. 운영체제는 CPU에서 당장 수행할 부분만을 메모리에 올려놓고, 그렇지 않은 부분은 disk의 swap area에 내려놓았다가 다시 필요해지면 메모리에 올라가 있는 부분과 교체하는 방식을 사용한다.\n또한, 프로그램은 0번지부터 시작하는 자기 자신만의 메모리 공간을 가정한다. 이러한 공간을 Virtual memory(가상 메모리) 이라 한다. 이 가상 공간 중 일부가 swap area에존재하고, 일부는 물리적 메모리에 존재하는 것이다.\n이 가상 메모리를 적재하는 단위에 따라 요구 페이징 또는 요구 세그먼테이션 방식으로 나눠진다. 전자는 대부분의 경우에 사용되며, 세부적인 구현에 특히 사용된다. 후자는 paged segmentation 기법을 사용하는 경우를 말한다.\n그러면 요구 페이징에 대해 먼저 알아보자.\n1. 요구 페이징 프로그램 실행 시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 게 아닌, 당장 사용될 페이지만을 올리는 방식\n특정 페이지에 대한 CPU 요청이 들어온 후에야 해당 페이지를 메모리에 적재한다.\n비유: 매 끼니마다 필요한 분량만큼 재료를 구입해서 보관하는 방식\n냉장고: 물리적 메모리 식재료: 프로세스를구성하는 페이지 보관 행위: 페이지를 메모리에 적재 장점\n필요한 부분만을 적재하기 때문에, 메모리 사용량 감소, I/O 양 감소 -\u0026gt; 응답시간 단축 프로세스 전체를 메모리에 올리는데 소요되는 입출력 오버헤드 감소 더 많은 프로세스 수용 물리적 메모리 용량 제약에서 벗어남 Problem\n가상 메모리 중 어떤 페이지가 메모리에 존재하는지 유무를 구별하기 위한 방안 필요 Solution\n유효-무효(Valid - Invalid bit)를 두어 page가 각 memory에 존재하는지 표시 모든 page에 대해 존재해야 하므로, page table의각 항목별로 저장 Valid - Invalid bit\n기본 bit 값: invalid bit\n특정 페이지가 참조되어 메모리에 적재 → Valid bit → 적재된 page가 swap area로 쫓겨남 → Invalid bit\nInvalid bit 는 언제일 때를 말하는가?\n해당 페이지가 물리적 메모리에 없는 경우 페이지가 속한 주소 영역을 프로세스가 사용하지 않은 경우 물리적 메모리에 A,C,G가 올라가 있기 때문에, 이에 해당하는 page table의 0, 2, 6이 valid라는 걸 확인할 수 있다. Page fault CPU가 한 페이지를 참조하려는데, 요청한 페이지가 메모리에 없어서 invalid bit인 경우를 말한다. 1.1 요구 페이징의 페이지 부재 처리 CPU가 무효 페이지에 접근 → 주소 변환 담당 MMU가 페이지 부재 트랩(page fault trap) 발생 → kernel mode로 전환 → OS의 페이지 부재 처리루틴(page fault handler)이 호출\nOS의 처리 과정\nOS는 프로세스의 해당 페이지에 대한 접근이 적법한지 먼저 체크 (reference)\n사용되지 않는 주소 영역에 속한 페이지에 접근하려거나, 해당 페이지에 대한 접근 권한 위반(protection violation)을 했을 경우, 해당 프로세스를 종료 protection violtaion: read-only file에 write 시도를 한 경우 → 적법 판정 → 물리적 메모리의 빈 frame을 할당받아 이 공간에 해당 페이지를 적재.\n빈 frame이 없다면, 물리적 메모리에 적재된 페이지 중 하나를 swap out → 요청한 페이지를 디스크로부터 물리적 메모리에 적재하기(disk I/O 작업을 의미)까지 오랜 시간이 걸리므로, CPU를 빼앗기고 봉쇄 상태(block state)가 됨\n현재까지 수행되던 프로세스는 CPU register state 및 PC value를 PCB에 저장하여, 나중에 이 프로세스를 재할당 시, 정확히 같은 상태에서 다음 instruction을 수행. → I/O 작업이 완료되어 interrupt가 발생하면 page table에서 해당 page의 valid-invalid bit를 valid bit로 설정 (reset page table)\n→ 봉쇄된 process를 ready queue로 이동\n→ 다시 CPU를 잡고 running 하며 아까 중단되었던 instruction을 재개한다.\n1.2요구 페이징의 성능 페이지 부재의 발생 빈도 페이지 부재로 인해 페이지 교체가 이뤄지는 과정에서 요청된 페이지를 디스크에서 메모리로 읽어오는 disk input/output 과 각종 overhead가 포함되어 시간이 오래 걸린다. 그래서 유효 접근 시간 이 짧을 수록 성능 향상 2. 페이지 교체 페이지 교체(page replacement)란?\n페이지 부재가 발생 시, 요청 페이지를 디스크에서 메모리로 불러오기 위에 메모리에 적재된 여러 페이지 중 하나를 swap out하여 요청된 페이지를 메모리에 적재하는 것 교체 알고리즘(replacement algoritum)\n페이지 교체 시, 어떤 프레임에 있는 페이지를 쫓아 낼지 결정하는 알고리즘 페이지 부재 발생비율(page-fault rate)을 최소화하는 것이 목표 평가 기준: 주어진 페이지 참조열에 대해 페이지 부재를 얼마나 내는지 조사 가까운 미래에 참조될 가능성이 적은 페이지를 내쫓는 것이 성능 향상 방안 페이지 참조열(page reference string)\n참조되는 페이지들의 번호를 시간 순서에 따라 나열한 것 예) 1,2,3,4,1,2,5,1,2,3,4,5 2.1 최적 페이지(Optimal Algorithum) 교체 Belady’s optimal algorithum (빌레디의 최적 알고리즘) = MIN, OPT\n페이지 부재율을 최소화하기 위해, 메모리에 존재하는 페이지 중 가까운 미래에 참조될 페이지를 쫓아내는 것 다른 알고리즘의 Upper bound\n어떠한 알고리즘보다도 가장 적은 페이지 부재율을 보장 하므로 다른 알고리즘 성능에 대한 상한선(Upper bound) 를 제공한다. 그래서 어떤 교체 알고리즘이 이 알고리즘과 유사하다면 더 이상의 알고리즘 연구가 필요하지 않음을 시사한다. 예시\n4 frames example 처음 페이지 참조 시에는 4회까지 페이지 부재가 불가피하다. 5, 6회는 이미 페이지가 존재하기 때문에 발생하지 않는다. 7회에서 페이지 5를 참조 시, 페이지 부재가 발생하여 디스크에서 메모리로 가져오는 작업이 필요하다. 이 때 페이지 교체를 해야 하는데, 가장 먼 미래에 참조될 페이지인 4번 페이지와 교체된다. 그래서 총 6번의 페이지 부재가 발생한다. Offline algorithum\n미래에 어떤 페이지가 참조될지 미리 알고 있다는 전제 이므로, 온라인에서 사용할 수 없어서 offline algorithum 이라 한다. 이 이후에 알고리즘은 미래를 모르는 알고리즘들이다.\n2.2 선입선출(FIFO:First In First Out) 알고리즘 물리적 메모리에 먼저 올라온 페이지를 우선적으로 내쫓는 알고리즘 향후 참조 가능성 고려 X 물리적 메모리에 들어온 순서대로 대상 선정 페이지 프레임을 늘린다고, page fault가 줄어드는 게 아니다.\n페이지 프레임 3개\n9번의 페이지 부재 페이지 프레임 4개\n10번의 페이지 부재 2.3 LRU(Least Recently Used) 알고리즘 교체 알고리즘으로 가장 많이 사용된다. 시간지역성(Temporal locality)이 낮은 페이지를 쫓아내는 알고리즘 시간 지역성: 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질 가장 오래 전에 참조된 것을 지워서, 참조 횟수는 고려하지 않는다. 2.4 LFU(Least Frequently used) 알고리즘 물리적 메모리 내에 존재하는 페이지 중 과거에 참조 횟수(reference count)가 가장 적은 페이지로 교체 페이지를 결정하는 알고리즘\n최저 참조 횟수를 가진 페이지가 여러 개일 경우, 상대적으로 더 오래전에 참조된 페이지를 쫓아낸다. 참조 횟수를 계산하는 방식에 따라 Incache-LFU 와 Perfect-LFU 로 나눠진다.\nIncache-LFU\npage가 물리적 메모리에 올라온 후부터의 참조 횟수를 카운트하는 방식 그래서 메모리에서 내려갔다가 다시 적재되면 참조 횟수는 초기화된다. Perfect-LFU\n메모리에 적재여부와 상관없이 그 페이지의 과거 총 참조 횟수를 카운트하는 방식 장점: 페이지의 참조 횟수를 정확히 반영 단점: 메모리에서 쫓겨난 페이지의 참조 기록까지 모두 보관하고 있어야 하므로, 오버헤드가 상대적으로 더 크다. 장단점\n장점: LFU 알고리즘은 LRU알고리즘보다 오랜 시간 참조 기록을 보기 때문에, 더 정확히 반영 가능 단점: 참조 시점의 최근성을 반영 X, LRU보다 구현 복잡 2.5 클럭(Clock) 알고리즘 하드웨어적 지원을 통해 알고리즘의 운영 오버헤드를 줄인 방식\n그래서 LRU 비해 페이지의 관리가 훨씬 빠르고 효율적으로 이뤄지기 때문에, 일반적으로 페이지 교체 알고리즘으로 클럭 알고리즘을 선택한다. LRU의 근사 알고리즘으로서, 다음과 같이 불린다. Second chance algorithum NUR(Not Used Recently) NRU(Not Recently Used) LRU는 가장 오래 전에 참조된 페이지를 교체하는 것에 비해 클럭 알고리즘은 오랫동안 참조되지 않은 페이지 중 하나를 교체하기 때문에, 가장 오래되었다는 건 보장하지 못한다. 그림 설명\n직사각형= 물리적 메모리 안에 있는 페이지(= 페이지 프레임)를 의미 교체할 페이지 선정을 위해 HW가 세팅한 페이지 프레임들의 참조 비트(reference bit) 를 순차적으로 OS가 조사한다.\npointer 이동 중에 reference bit 1은 모두 0으로 바꾼다. reference bit가 0인 것을 찾으면 그 페이지를 교체한다. 한 바퀴 되돌아와서도 (=second chance) 0 이면 그 때 교체된다. 자주 사용되는 페이지라면 second chance가 올 때 1 Clock algorithum의 개선\nHW가 bit를 setting reference bit = 0: 한 바퀴 도는 동안 이 페이지에 대한 참조가 없었다는 의미 reference bit = 1: 한 바퀴 도는 동안 적어도 한 번 참조된 페이지 modified bit = 1: 최근에 변경된 페이지(I/O를 동반하는 페이지) 3. 페이지 프레임의 할당(allocation) 프로세스 여러 개가 동시에 수행되는 상황에서 각 프로세스에 얼마만큼의 메모리 공간을 할당할 것인지 결정해야 한다. 이를 위한 알고리즘을 3가지로 나눌 수 있다.\n첫 번째, 균등할당(equal algorithum)\n모든 프로세스에게 페이지 프레임을 균일하게 할당하는 방식 두 번째, 비례할당(proportional allocation)\n프로세스의 크기에 비례해서 페이지 프레임을 할당하는 방식 세 번째, 우선순위 할당(priority allocation)\n프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당하는 방식 당장 CPU에서 실행될 프로세스와 아닌 프로세스를 구분하여 전자 쪽에 더 많은 페이지 프레임을 할당하는 방식 할당 알고리즘만으로는 process의 페이지 아래의 참조 특성을 제대로 반영하지 못한다.\n첫 번째, 명령어 수행을 위해 최소한 할당되어야 하는 frame의 수가 존재 두 번째, Loop(반복문)를 구성하는 page들은 한꺼번에 할당되는게 유리하다. 최소한의 allocation이 없으면 매 loop마다 page fault 발생 세 번째, 프로세스에게 최소한으로 필요한 메모리의 양은 시간에 따라 다르다. 그래서, 종합적인 상황을 고려해서 각 프로세스에 할당되는 페이지 프레임의 수를 결정해야 한다.\n경우에 따라서는, 최소한의 메모리 요구량을 충족시키기 위해 일부 프로세스에게 메모리를 할당하지 않아야 한다.\n4. 전역교체와 지역교체 (Global vs. Local replacement) 교체할 페이지를 선정할 때, 교체 대상이 될 프레임의 범위에 따라 다음 2가지로 구분된다.\n전역 교체(global replacement)\n프로세스마다 미리 메모리를 할당하는 게 아닌, 전체 메모리를 공유해서 사용하고 교체 알고리즘에 근거해서 할당되는 메모리 양이 가변적으로 변하는 방법\n그래서 replace 시, 다른 process에게 할당된 frame도 빼앗아 올 수 있다. (경쟁)\n= 모든 페이지 프레임이 교체 대상 = Process 별 프레임 할당량을 조절하는 또 다른 방법 FIFO, LRU, LFU 등의 알고리즘을 사용하다보면 전체 시스템 차원에서 특정 페이지가 알아서 메모리에 올라가기 때문에 frame 할당량이 알아서 조절된다.\n다음 절의 working set, PFF 알고리즘의 경우, 프로그램이 최소한 필요로 하는 할당 효과가 있는 알고리즘이기 때문에, 전역교체 방법으로 사용될 수 있다.\n지역 교체(local replacement)\n프로세스마다 페이지 프레임을 미리 할당하는 것 현재 수행 중인 프로세스에게 할당된 frame 내에서만 빼앗아올 수 있는 방법 frame 할당 알고리즘은 균등할당, 비례할당, 우선순위 할당으로 프로세스에게 미리 할당한다. 프로세스가 FIFO, LRU, LFU 등의 알고리즘을 독자적으로 운영할 때, 사용되는 방법 5. 스레싱(thrashing) 프로세스가 원활히 수행되기 위한 일정 수준 이상의 페이지 프레임을 할당받지 못하여 page fault가 지나치게 발생하는 상황\nThrashinig의 자세한 발생 과정 프로세스에게 일정 수준 이상의 페이지 프레임 할당 X → 페이지 부재율이 크게 상승 → CPU 이용률이 급격히 하락\n→ 낮은 CPU 이용률 -\u0026gt; OS가 메모리에 올라가는 프로세스의 수 증가 = 다중 프로그래밍의 정도(Multi-Programming Degree: MPD) 증가 →\nMPD를 OS가 높이는 이유는 OS에게 CPU 이용률이 낮다는 건, 프로세스의 수가 너무 적고, 프로세스가 모두 I/O 작업을 하여 ready queue가 비는 경우를 의미한다.\n→ 과도한 MPD 상승 -\u0026gt; 프로세스 당 할당되는 메모리 양이 지나치게 감소 -\u0026gt; 빈번한 페이지 부재 발생 → 페이지 교체하며 swap in \u0026amp; swap out이 지속적으로 발생 -\u0026gt; CPU 이용률 다시 감소 → 2번 과정 다시 수행\nswap in \u0026amp; swap out 작업 과정\nI/O 작업을 수반 → 문맥교환을 통해 다른 프로세스에게 CPU 이양 → 다른 프로세스에게도 할당받은 메모리 양이 적으면 페이지 부재 발생 그래서 ready queue에 있는 모든 프로세스에게 CPU가 한 차례씩 할당되었는데도 모든 프로세스가 다 페이지 부재가 발생. 결국 낮은 처리량(low throughput)을 가진다.\n이렇게 1번에서 5번 과정이 계속 반복되는 것을 스레싱이라 한다.\nThrashing graph 위 과정을 그래프로 나타낸 것이 다음과 같다. 프로그램이 1개일 때는 메모리를 쓰다가 I/O 하는 동안 CPU가 쉰다.\n그래서 프로그램이 I/O 작업 시, 다른 프로세스에게 CPU 이양하여 CPU 이용률을 높인다.\n하지만, 프로세스의 수를 증가시키면 오히려 CPU 이용률이 뚝 떨어진다.\n왜냐하면 thrashing이 발생했기 때문이다.\n그래서 CPU 이용률을 최대한 높이면서 MPD를 조절하는 게 중요하다.\n이를 조절하는 알고리즘이 워킹셋(working-set algorithum) 과 페이지 부재 빈도 알고리즘(page-fault frequency scheme) 이 있다.\n5.1 워킹셋(working-set) 알고리즘 지역성 집합이 메모리에 동시 올라갈 수 있도록 보장하는 메모리 관리 알고리즘\nLocality of reference\n프로세스는 특정 시간 동안 일정 장소만을 집중적으로 참조하는 현상 Locality set(지역성 집합)\n집중적으로 참조되는 해당 page들의 집합 Working-set 이란?\n프로세스가 일정 시간 동안 원활히 수행되기 위해, 한꺼번에 메모리에 올라와 있어야 하는 페이지들의 집합 working-set에서의 locality set MPD 조절 방법\n프로세스의 워킹셋을 구성하는 페이지들이 한꺼번에 메모리에 올라갈 수 있는 경우에만, 그 프로세스에게 메모리를 할당 그렇지 않으면 프로세스에게 할당된 페이지 프레임들을 모두 반납한 후, 프로세스의 주소 공간 전체를 disk로 swap out한다. 5.1.1 Working-set algorithum 구현 Working Set(WS) 결정하기\nworking-set window를 사용한다. window의 크기: Δ time interval 사이에 참조된 서로 다른 페이지들의 집합 WS 크기는 변한다. working set 크기와 frame 수에 따른 MPD 제어\n워킹셋 크기 합 \u0026gt; frame 수 → 일부 프로세스를 스왑 아웃 → 남은 프로세스의 워킹셋이 메모리에 모두 올라가는 것을 보장 ⇒ MPD 감소 효과 워킹셋 크기 합 \u0026lt; frame 수 → swap out한 프로세스를 다시 메모리에 적재 → working set을 할당 → MPD를 증가 위 두 가지 방식으로 thrasing을 방지 window의 크기가 너무 작으면, 지역성 집합을 모두 수용 X window의 크기가 너무 크면, 여러 규모의 지역성 집합 수용 가능하지만, MPD가 감소 → CPU 이용률 감소 5.2 페이지 부재 빈도(page fault frequency: PFF) 알고리즘 프로세스의 페이지 부재율을 주기적으로 조사하고, 이 값에 근거해서 각 프로세스에 할당할 메모리 양을 조절하여 MPD를 조절하면서 CPU 이용률을 높이는 알고리즘\npage-fault rate의 상한값과 하한값을 둔다\nPage fault rate이 상한값을 넘으면 frame을 더 할당한다. Page fault rate이 하한값 이하이면 할당 frame 수를 줄인다. 빈 frame이 없으면 일부 프로세스를 swap out한다.\n모든 프로세스에게 프레임을 다 할당한 후에도 프레임이 남는 경우, 위의 swap out된 process에게 frame을 할당하여 MPD를 높인다.\nReference kocw 이화여자대학교 운영체제 - 반효경 교수 - 운영체제와 정보기술의 원리 - 반효경 지음 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_10_%EA%B0%80%EC%83%81%EB%A9%94%EB%AA%A8%EB%A6%AC/","summary":"가상 메모리를 관리하기 위한 방법으로 demanding paging에 대해 알아본다. 그리고, 페이지 교체는 어떠한 순서로 이뤄지는지, 프로세스에 프레임은 어떤 알고리즘을 통해서 할당되는지, 전역 교체와 지역교체는 무엇인지 마지막으로 thrashing 상황과 MPD 개념에 대해 알아본다.","title":"[TIL] Chapter 10: 가상 메모리"},{"categories":["Python"],"content":"0. Introduction Meta class에 대한 의견 “Metaclasses are deeper magic than 99% of users should ever worry about. If you wonder whether you need them, you don’t (the people who actually need them know with certainty that they need them, and don’t need an explanation about why).”\n\u0026ndash; Tim Peters \u0026ndash;\nMeta class를 배우는 이유\nTim Peters가 언급한 것처럼 아직은 필요성을 못 느끼지만, 여러 오픈 소스들에서는 이 meteaclass를 활용하여 작성된 경우가 매우 많으므로, class의 형성 원리를 이해한 후 오픈 소스를 보다 잘 이해하기 위해 학습한다. 파이썬에서는 클래스도 포함하여 모든 것들이 객체다.\n공식 레퍼런스에서도 클래스와 객체를 혼용해서 사용한다. 이번 chapter에서의 목표는 최종적으로 Custom Meta class를 만들기 위함이다.\n1. Type: function and metaclass 첫 번째: type() 함수를 통해서 해당 인스턴스 및 클래스의 상위 클래스가 무엇인지 확인할 수 있다. 두 번째: type class는 class of class로, 클래스를 만들어내는 meta class다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 ## Foo class 만들기 # class Foo(object): 로 해도 동일 \u0026gt; class Foo(): \u0026gt; pass ## instance 만들기 \u0026gt; x = Foo() ## 해당 객체의 상위 클래스가 무엇인지 알려준다. \u0026gt; print(x.__class__) \u0026gt; print(type(x)) \u0026lt;class \u0026#39;__main__.Foo\u0026#39;\u0026gt; ## 그렇다면 Foo class의 상위 class는 무엇일까?? \u0026gt; print(x.__class__.__class__) \u0026gt; print(type(Foo)) \u0026gt; print(type(x).__class__) \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; \u0026gt; print(x.__class__ is type(x)) \u0026gt; print(x.__class__.__class__ is type(x).__class__) True ## type class의 상위 class는 무엇일까??? \u0026gt; print(Foo.__class__.__class__) \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; type의 상위 클래스도 type이 출력되었다. 그러면 다른 자료형들의 상위 클래스도 알아보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # integer \u0026gt; n = 10 # dictionary \u0026gt; d = {\u0026#39;a\u0026#39; : 10, \u0026#39;b\u0026#39;: 20} \u0026gt; for o in (n, d): \u0026gt; print(\u0026#39;{} {} {}\u0026#39;.format(type(o), type(o) is o.__class__, o.__class__.__class__)) \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; True \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; True \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; \u0026gt; for t in int, float, list, tuple: \u0026gt; print(type(t)) \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; 여러 자료형들의 상위 클래스가 type class임을 확인했다.\n그러면 다음과 같은 사실들을 알 수 있다.\n여러 자료형들은 class를 기반으로 만들어졌다. 각 class들의 상위 클래스는(원형은) type class다. type class의 상위 클래스는(원형은) type class다. 이 type class를 metaclass라 한다.\n모든 클래스들은 이 type metaclass의 인스턴스들이다. 즉, 모든 클래스들은 type metaclass로부터 만들어졌다. 모든 클래스의 원형은 type metaclass다. 2. Metaclass의 이점 1. type function을 통해서 동적으로 생성한 metaclass를 통해서 custom metaclass를 생성할 수 있다.\n- meta class를 통해 클래스 구현 레벨에 직접 관여할 수 있기 때문에, - 의도하는 방향으로 클래스를 커스텀할 수 있다. - 단 `type class` 이상으로는 관여할 수 없다. 2. framework 작성 시 필수다.\n- 1번의 이유처럼 의도하는 방향대로 직접 클래스 생성에 관여할 수 있기 때문에, - 범용적인 프레임워크 개발, 패키지 개발에 사용된다. - Django의 내부를 보면 이 metaclass를 사용하여 구현할 것을 알 수 있다. - 많은 세계적인 파이썬 user들은 meta class를 바탕으로 선언한 후, 원하는 대로 구현한다. 3. type 함수를 통해서 클래스를 동적으로 생성 가능하기 때문에, custom metaclass 생성이 가능하다.\n4. meta class를 바탕으로 엄격한 class 사용 그리고, method override를 요구한다.\n- Django는 metaclass를 기반으로 만든 ORM framework로, - DB와 클래스를 일대일로 맵핑하기 때문에 엄격하다. 3. Make a class statically and dynamically 3.1 정적으로 클래스 만들기 class를 입력하여 만드는 일반적인 방식\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026gt; class Ex: \u0026gt; pass \u0026gt; class foo(Ex): \u0026gt; attr1 = 100 \u0026gt; attr2 = \u0026#39;hi\u0026#39; \u0026gt; def add(self, m, n): \u0026gt; return m + n \u0026gt; def mul(self, m, n): \u0026gt; return m * n \u0026gt; ex = foo() 3.2 동적으로 클래스 만들기 동적으로 클래스를 만든다는 건 type() 에 3가지 인자를 입력하여 만드는 방식으로, 필요할 때마다 바로 바로 클래스를 만들어낼 수 있다는 걸 의미한다.\ntype([name], [bases], [dct])\n[name] : 만들려는 클래스의 이름 을 명시한다. 그리고, 만들어진 클래스의 __name__ 속성이 된다.\n[bases] : 만들려는 클래스에게 상속할 클래스 이름 을 명시한다. 이 때, tuple type으로 입력한다. 이는 클래스의 __base__ 속성이 된다.\n[dct] : class body에 있는 속성, method 들을 포함하는 namespace dictionary를 명시한다. 이는 클래스의 __dict__ 속성이 된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 \u0026gt; Ex = type(\u0026#39;eX\u0026#39;, (), {}) ## 위에 처럼 Ex로 인스턴스를 만들거나, Ex라는 클래스를 정적으로 만들어야 상속할 수 있다. \u0026gt; class Ex: \u0026gt; pass ## 동적 정의 type 외부에 method를 정의할 수도 있으나, 한 번만 사용할거면 람다 함수를 사용하는 게 낫다. \u0026gt; ex = type(\u0026#39;foo\u0026#39;, \u0026gt; (Ex, ), \u0026gt; dict(attr1 = 100, attr2 = \u0026#39;hi\u0026#39;, add = lambda x,y : x + y, mul = lambda x, y: x * y) \u0026gt; ) ## 위에 동적으로 정의한 class를 정적으로 정의하면 다음과 같은 형식이다. \u0026gt; class foo(Ex): \u0026gt; attr1 = 100 \u0026gt; attr2 = \u0026#39;hi\u0026#39; \u0026gt; def add(x,y): \u0026gt; return x + y \u0026gt; def mul(x, y): \u0026gt; return x * y ## 그러면 동적으로 정의한 ex를 출력해보자. \u0026gt; print(ex) \u0026lt;__main__.foo object at 0x000002A86E3A7D90\u0026gt; \u0026gt; print(type(ex)) \u0026lt;class \u0026#39;__main__.foo\u0026#39;\u0026gt; \u0026gt; print(ex.__name__) foo \u0026gt; print(ex.__base__) \u0026lt;class \u0026#39;__main__.Ex\u0026#39;\u0026gt; \u0026gt; print(ex.__dict__) {\u0026#39;attr1\u0026#39;: 100, \u0026#39;attr2\u0026#39;: \u0026#39;hi\u0026#39;, \u0026#39;__module__\u0026#39;: \u0026#39;__main__\u0026#39;, \u0026#39;__doc__\u0026#39;: None} \u0026gt; print(ex.attr1, ex.attr2) 100 hi \u0026gt; print(ex.add(100,200)) 300 \u0026gt; print(ex.mul(100,200)) 2000 4. Custom metaclass 만들기 Metaclass를 상속한다는 것의 의미\ntype class를 상속받는다. metaclass 속성을 사용한다. custom metaclass 생성하면 다음 일들이 쉬워진다. 클래서 생성 가로채기(intercept) = 후킹(hooking) 잡아채서 원하는 기능을 보충하고 수정하는 것 클래스 수정하기 (modifiy) 클래스 개선(기능 추가) 수정된 클래스 반환 4.1 Custom metaclass란? type meta class에서 파생되어 사용자가 의도한 대로 작동하도록 만든 metaclass\nCustom Metaclass가 필요한 이유 를 다음 코드를 통해서 알아보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # cls란 class에 사용되는 변수를 의미한다. # self는 instance에 사용되는 변수를 의미한다. \u0026gt; def new(cls): \u0026gt; x = object.__new__(cls) \u0026gt; x.attr = 100 \u0026gt; return x \u0026gt; class Foo: \u0026gt; pass \u0026gt; Foo.__new__ = new \u0026gt; f = Foo() \u0026gt; print(f.attr) 100 # Foo의 __new__를 customizing 했다. # Foo는 type metaclass의 instance이므로, type의 __new__ method도 커스터마이징을 할려고 한다. # 하지만 다음과 같이 error가 떴다. \u0026gt; type.__new__ = new TypeError: can\u0026#39;t set attributes of built-in/extension type \u0026#39;type\u0026#39; 위와 같은 Error가 발생된 이유는 파이썬이 이를 허용하지 않기 때문이다.\nWhy?? type은 모든 클래스들이 만들어지는 기본 토대인 meta class이기 때문에, 사용자가 만질 수 없다. 그래서 type으로부터 만들어지는 custom metaclass를 만드는 것이다.\nCustom Metaclass 만드는 단계: type metaclass로부터 파생된 metaclass를 정의하기\ndefinition head를 class \u0026lt;custom metaclass name\u0026gt;(type): 로 작성하자. 새롭게 정의한 __new__ method 역할 상위 metaclass의 __new__ method를 super() function을 통해서 새로 만들어지는 클래스에게 할당한다. 1 2 3 4 5 6 7 8 9 10 11 \u0026gt; class MetaClass(type): \u0026gt; def __new__(cls, name, bases, dct or namespace): \u0026gt; x = super().__new__(cls, name, bases, dct or namespace) \u0026gt; x.attr = 100 \u0026gt; return x \u0026gt; class Foo(MetaClass) \u0026gt; pass \u0026gt; print(Foo.attr) \u0026gt; 100 4.2 Ex1 with Type 상속 X 그러면 custom metacalss를 생성해보자. 다음 것들에 유의해서 보자. class가 아니어도 self를 사용하는 것 class 내부가 아닌 외부에 function을 정의하여, component 식으로 필요할 때마다 꺼내서 custom metaclass에 사용할 수 있다. open source에서 이런 방식을 많이 사용한다. 동적으로 class 만들 때, 상속할 class로 list를 입력함에 따라 어떻게 흘러가는지. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 ## class 외부에 function 만들기 \u0026gt; def cus_mul(self, d): \u0026gt; for i in range(len(self)): \u0026gt; self[i] = self[i] * d \u0026gt; def cus_replace(self, old, new): \u0026gt; while old in self: \u0026gt; self[self.index(old)] = new ## 동적으로 class 만들기 \u0026gt; CustomList = type( \u0026gt; \u0026#39;CustomList\u0026#39;, \u0026gt; (list, ), \u0026gt; { \u0026gt; \u0026#39;desc\u0026#39; : \u0026#39;커스텀 리스트 1\u0026#39;, \u0026gt; # 위에서 만든 함수를 넣는다. \u0026gt; \u0026#39;cus_mul\u0026#39; : cus_mul, \u0026gt; \u0026#39;cus_replace\u0026#39; : cus_replace \u0026gt; } \u0026gt; ) ## 인스턴스 만들기 # 위 method의 self가 list가 자체가 된다. \u0026gt; c = CustomList([x for x in range(10)]) \u0026gt; c.cus_mul(1000) \u0026gt; print(c) [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000] \u0026gt; c.cus_replace(1000,1) \u0026gt; print(c) [1, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000] \u0026gt; c.cus_replace(1,\u0026#39;hahaha\u0026#39;) \u0026gt; print(c) [\u0026#39;hahaha\u0026#39;, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000] \u0026gt; print(c.desc) 커스텀 리스트1 \u0026gt; print(dir(c)) [\u0026#39;__add__\u0026#39;, \u0026#39;__class__\u0026#39;, \u0026#39;__class_getitem__\u0026#39;, \u0026#39;__contains__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__delitem__\u0026#39;, \u0026#39;__dict__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;, .... \u0026#39;append\u0026#39;, \u0026#39;clear\u0026#39;, \u0026#39;copy\u0026#39;, \u0026#39;count\u0026#39;, \u0026#39;cus_mul\u0026#39;, \u0026#39;cus_replace\u0026#39;, \u0026#39;desc\u0026#39;, \u0026#39;extend\u0026#39;, \u0026#39;index\u0026#39;, \u0026#39;insert\u0026#39;, \u0026#39;pop\u0026#39;, \u0026#39;remove\u0026#39;, \u0026#39;reverse\u0026#39;, \u0026#39;sort\u0026#39;] base에 list를 입력하여, list class를 상속받았기 때문에, list object를 class롤 받을 수 있다. list만의 모든 method를 사용할 수 있으면서, 추가한 method까지 사용할 수 있다. dir()로 확인한 속성을 보면 list에 사용되는 method들이 있는 것을 확인할 수 있다. 4.3 Ex2 with Type 상속 O Ex1 에 대한 내부 작동 원리를 보여주는 예제\n__new__: class의 new instance를 만들기 위해 호출되는 static method\n사용자 정의 메타 클래스에서 클래스 생성을 customizing 하기 위해 사용된다. 실행 순서: __new__ -\u0026gt; __init__ -\u0026gt; __call__\n__new__ 가 class의 instance를 return하지 않으면, 새 instance의 __init__은 호출되지 않는다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 \u0026gt; class CustomListMeta(type): ## __new__에 의해 생성된 인스턴스 초기화 # type function의 3가지 인수가 포함된 걸 확인할 수 있다. \u0026gt; def __init__(self, object_or_name, bases, dict): # method overriding \u0026gt; print(\u0026#39;__init__ -\u0026gt;\u0026#39;, self, object_or_name, bases, dict) \u0026gt; super().__init__(object_or_name, bases, dict) ## instance 실행을 위한 호출 \u0026gt; def __call__(self, *args, **kwargs) # method overriding \u0026gt; print(\u0026#39;__call__ -\u0026gt;\u0026#39;, self, args, kwargs) \u0026gt; return super().__call__(*args, **kwargs) ## class instance 생성하기: 이 때 메모리 초기화 \u0026gt; def __new__(metacls, name, bases, namespace): # method overriding \u0026gt; print(\u0026#39;__new__ -\u0026gt;\u0026#39;, metacls, name, bases, namespace) \u0026gt; namespace[\u0026#39;desc\u0026#39;] = \u0026#39;커스텀 리스트 2\u0026#39; \u0026gt; namespace[\u0026#39;cus_mul\u0026#39;] = cus_mul \u0026gt; namespace[\u0026#39;cus_replace\u0026#39;] = cus_replace \u0026gt; return type.__new__(metacls, name, bases, namespace) ## 클래스 동적 생성 \u0026gt; CustomList2 = CustomListMeta( \u0026gt; \u0026#39;CustomList2\u0026#39;, \u0026gt; (list, ), \u0026gt; {} \u0026gt; ) \u0026gt; c = CustomList2([x for x in range(10)]) __new__ -\u0026gt; \u0026lt;class \u0026#39;__main__.CustomListMeta\u0026#39;\u0026gt; CustomList2 (\u0026lt;class \u0026#39;list\u0026#39;\u0026gt;,) {} __init__ -\u0026gt; \u0026lt;class \u0026#39;__main__.CustomList2\u0026#39;\u0026gt; CustomList2 (\u0026lt;class \u0026#39;list\u0026#39;\u0026gt;,) {\u0026#39;desc\u0026#39;: \u0026#39;커스텀 리스트2\u0026#39;, \u0026#39;cus_mul\u0026#39;: \u0026lt;function cus_mul at 0x0000017A20387F70\u0026gt;, \u0026#39;cus_replace\u0026#39;: \u0026lt;function cus_replace at 0x0000017A2051FB80\u0026gt;} __call__ -\u0026gt; \u0026lt;class \u0026#39;__main__.CustomList2\u0026#39;\u0026gt; ([1, 2, 3, 4, 5, 6, 7, 8, 9],) {} \u0026gt; c.cus_mul(100) \u0026gt; c.cus_replace(100, 777) \u0026gt; print(c) [777, 200, 300, 400, 500, 600, 700, 800, 900] Reference 모두를 위한 파이썬 : 필수 문법 배우기 Feat. 오픈소스 패키지 배포 (Inflearn Original) Read Python - Python Metaclasses ","permalink":"http://jeha00.github.io/post/python/python_basic_46_metaclass/","summary":"첫 번째,Type fuction을 통해서 Metaclass가 무엇인지, 그리고 class를 동적으로 만들어본다. 두 번째, Metaclass의 장점은 무엇이고, metaclass를 통해서 custom metaclass를 만들어본다.","title":"[TIL] Python basic 46: Metaclass"},{"categories":["Python"],"content":"1. Method overriding 상위 클래스에서 정의한 method의 기능을 하위 클래스에서 가져와 자신에게(하위 클래스에) 맞게 customizing 하는 것\nMethod overriding 장점\nsub class에서 super class를 호출 후 사용한다.\nmethod 재정의 후, 사용 가능하다.\nSuper class의 method 추상화 후 사용 가능\n구조적 접근이 가능하다. 확장 가능, 다형성\n다형성: 상위 클래스에서 하나로 만들었지만, 하위 클래스의 성질에 따라 다양하게 적용되기 때문에 다형성을 띈다. 가독성 증가, 오류 가능성 감소, 유지 보수성 증가\nMethod 이름이 절약되기 때문이다. 아래 코드들을 보면서 위 장점들에 대해 느껴보자\n1.1 Ex1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 ## Super class \u0026gt; class ParentEx1(): \u0026gt; def __init__(self): \u0026gt; self.value = 5 # 지난 번에 배운 property를 사용할 수도 있다. \u0026gt; def get_vaue(self): \u0026gt; return self.value ## Sub class \u0026gt; class ChildEx1(ParentEx1): \u0026gt; pass ## Instance \u0026gt; c1 = ChildEx1() \u0026gt; p1 = ParentEx1() ## 상위 클래스의 method를 호출한다. \u0026gt; print(c1.get_value()) 5 # c1의 모든 속성 출력 \u0026gt; print(dir(c1)) [\u0026#39;__class__\u0026#39;, \u0026#39;__dict__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;,... , \u0026#39;get_value\u0026#39;, \u0026#39;value\u0026#39;] ## 상위, 하위 클래스의 모든 속성 비교하기 # 동일하다. \u0026gt; print(dir(ParentEx1)) \u0026gt; print(dir(ChildEx1)) [\u0026#39;__class__\u0026#39;, ..., \u0026#39;get_value\u0026#39;] dir과 __dict__를 각각 호출해보자. 1 2 3 4 5 \u0026gt; print(ParentEx1.__dict__) Ex1 \u0026gt; {\u0026#39;__module__\u0026#39;: \u0026#39;__main__\u0026#39;, \u0026#39;__init__\u0026#39;: \u0026lt;function ParentEx1.__init__ at 0x0000025A8A4AFA60\u0026gt;, \u0026#39;get_value\u0026#39;: \u0026lt;function ParentEx1.get_value at 0x0000025A8A4AFB80\u0026gt;, \u0026#39;__dict__\u0026#39;: \u0026lt;attribute \u0026#39;__dict__\u0026#39; of \u0026#39;ParentEx1\u0026#39; objects\u0026gt;, \u0026#39;__weakref__\u0026#39;: \u0026lt;attribute \u0026#39;__weakref__\u0026#39; of \u0026#39;ParentEx1\u0026#39; objects\u0026gt;, \u0026#39;__doc__\u0026#39;: None} \u0026gt; print(ChildEx1.__dict__) {\u0026#39;__module__\u0026#39;: \u0026#39;__main__\u0026#39;, \u0026#39;__doc__\u0026#39;: None} 그 결과, 차이가 있다는 걸 알 수 있다. Ex 1.2 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 \u0026gt; class ParentEx2(): \u0026gt; def __init__(self): \u0026gt; self.value = 5 \u0026gt; def get_value(self): \u0026gt; return self.value \u0026gt; class ChildEx2(ParentEx2): # 상위 클래스의 method를 가져와서 하위 클래스에서 customizing 한다. \u0026gt; def get_value(self): \u0026gt; return self.value * 10 \u0026gt; p2 = ParentEx2() \u0026gt; c2 = ChildEx2() \u0026gt; print(p2.get_value()) 5 \u0026gt; print(c2.get_value()) 10 # 출력값이 동일하다. \u0026gt; print(dir(ParentEx2)) \u0026gt; print(dir(ChiledEx2)) [\u0026#39;__class__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__dict__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__eq__\u0026#39;, \u0026#39;__format__\u0026#39;, \u0026#39;__ge__\u0026#39;, \u0026#39;__getattribute__\u0026#39;, \u0026#39;__gt__\u0026#39;, \u0026#39;__hash__\u0026#39;, \u0026#39;__init__\u0026#39;, \u0026#39;__init_subclass__\u0026#39;, \u0026#39;__le__\u0026#39;, \u0026#39;__lt__\u0026#39;, \u0026#39;__module__\u0026#39;, \u0026#39;__ne__\u0026#39;, \u0026#39;__new__\u0026#39;, \u0026#39;__reduce__\u0026#39;, \u0026#39;__reduce_ex__\u0026#39;, \u0026#39;__repr__\u0026#39;, \u0026#39;__setattr__\u0026#39;, \u0026#39;__sizeof__\u0026#39;, \u0026#39;__str__\u0026#39;, \u0026#39;__subclasshook__\u0026#39;, \u0026#39;__weakref__\u0026#39;, \u0026#39;get_value\u0026#39;] \u0026gt; print(ParentEx2.__dict__) {\u0026#39;__module__\u0026#39;: \u0026#39;__main__\u0026#39;, \u0026#39;__init__\u0026#39;: \u0026lt;function ParentEx2.__init__ at 0x000002919386FC10\u0026gt;, \u0026#39;get_value\u0026#39;: \u0026lt;function ParentEx2.get_value at 0x000002919386FCA0\u0026gt;, \u0026#39;__dict__\u0026#39;: \u0026lt;attribute \u0026#39;__dict__\u0026#39; of \u0026#39;ParentEx2\u0026#39; objects\u0026gt;, \u0026#39;__weakref__\u0026#39;: \u0026lt;attribute \u0026#39;__weakref__\u0026#39; of \u0026#39;ParentEx2\u0026#39; objects\u0026gt;, \u0026#39;__doc__\u0026#39;: None} \u0026gt; print(ChildEx2.__dict__) {\u0026#39;__module__\u0026#39;: \u0026#39;__main__\u0026#39;, \u0026#39;get_value\u0026#39;: \u0026lt;function ChildEx2.get_value at 0x000002919386FD30\u0026gt;, \u0026#39;__doc__\u0026#39;: None} Ex 1.3 Method overriding을 통해서 log class를 구현하기\n이번 예제를 통해서 구조적 설계에서의 장점을 보인다. 운영에 있어서 필요한 log class를 구현해보자. 실무적으로 좋은 예제다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 \u0026gt; import datetime \u0026gt; class Logger(object): \u0026gt; def log(self, msg): \u0026gt; print(msg) ## 다형성으로 하위 클래스 2개를 만든다. # 1. 시분초까지 표시되는 하위 클래스 \u0026gt; class TimestampLogger(Logger): \u0026gt; def log(self, msg): \u0026gt; message = \u0026#39;{ts} {msg}\u0026#39;.format(ts = datetime.datetime.now(), msg = msg) \u0026gt; super(TimestampLogger, self).log(message) # 2. 날짜만 출력되는 하위 클래스 # strftime은 현장에서 많이 사용된다. \u0026gt; class DateLogger(Logger): \u0026gt; def log(self, msg): \u0026gt; message = \u0026#39;{ts} {msg}\u0026#39;.format(ts = datetime.datetime.now().strtime(\u0026#39;%y-%m-%d\u0026#39;), msg = msg) \u0026gt; super(DateLogger, self).log(message) \u0026gt; l = Logger() \u0026gt; t = TimestampLogger() \u0026gt; d = DateLogger() \u0026gt; l.log(\u0026#39;test1\u0026#39;) test1 \u0026gt; t.log(\u0026#39;test2\u0026#39;) 2022-05-15 20:23:45.956916 test2 \u0026gt; d.log(\u0026#39;test3\u0026#39;) 22-05-15 test3 super(TimestampLogger, self)는 super(파생클래스, self)로 기반 클래스의 method 호출에 사용한다. 2. Method overloading 동일한 class 내에서 method 이름은 동일하지만, parameter의 number와 type이 다른 여러 method를 정의하는 것\nMethod overloading 장점\n동일 method 재정의 Naming으로 기능 예측 코드 절약, 가독성 향상 Method parameter 기반 호출 방식 아래 코드들을 보면서 위 장점들에 대해 느껴보자\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; class SampleA(): \u0026gt; def add(self, x, y): \u0026gt; return x + y \u0026gt; def add(self, x, y, z): \u0026gt; return x+ y + z \u0026gt; a = SampleA() \u0026gt; print(a.add(4,5)) TypeError: add() missing 1 required positional argument: \u0026#39;z\u0026#39; 분명 인자가 2개인 method를 만들었지만, z가 부족하다는 Error가 떴다.\n동일한 method name으로 작성했을 때, 맨 마지막 method로 인식한다는 것이다.\n이 문제에 대해 해결책은 2가지 방법이 있다.\nunpacking 사용하기 외부 모듈인 multipledispatch 사용하기 1 2 3 4 5 6 7 8 9 10 11 12 13 # unpacking 사용하기 \u0026gt; class SampleA(): \u0026gt; def add(self, *args): \u0026gt; return sum(args) \u0026gt; a = SampleA() \u0026gt; print(a.add(2,3)) 5 \u0026gt; print(a.add(2,3,6)) 11 다음으로 unpacking에 자료형에 따른 분기 처리 를 추가해보자. single method로 여러 기능들을 구현할 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026gt; class SampleB(): \u0026gt; def add(self, datatype, *args): \u0026gt; if datatype == \u0026#39;int\u0026#39;: \u0026gt; return sum(args) \u0026gt; if datatype == \u0026#39;str\u0026#39;: \u0026gt; return \u0026#39; \u0026#39;.join([x for x in args]) \u0026gt; b = SampleB() # 정수형 연산 \u0026gt; print(b.add(\u0026#39;int\u0026#39;, 5, 6)) 11 # 문자열 연산 \u0026gt; print(b.add(\u0026#39;str\u0026#39;, \u0026#39;Hi\u0026#39;, \u0026#39;Guys\u0026#39;)) Hi Guys 이렇게 단일 method 내에서 조건 분기화를 통해서 구현했지만, 이는 method overriding이 아니다.\n파이썬은 클래스 내에서 method overloading을 지원하지 않는다.\n그래서 multipledispatch를 사용하여 method overloading을 구현한다. 3. Overloading: multipledispatch 외부 module인 multipledispatch를 사용하여 overriding을 구현해보기\n3.1 To install Multipledispatch 이를 위해서 먼저 외부 module을 설치해보자. 외부 모듈이기 때문에, 가상환경에 입력한다. pip install multipledispatch 로는 설치되지 않는다. 1 2 3 4 5 6 7 8 9 # 다음 명령어를 입력하여 설치한다. \u0026gt; py -m pip install multipledispath # 설치가 잘 되었는지 확인한다. # 설치된 module을 확인할 수 있다. \u0026gt; pip list # 설치된 multipledispatch의 version을 탐색한다. \u0026gt; pip search multipledispatch 3.2 Multipledispatch로 구현하기 설치한 package를 통해서 method overloading을 보다 편하게 구현할 수 있다. 또한, 최근 overloading을 구현하는 방식이다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; from multipledispatch import dispatch \u0026gt; class SampleC(): \u0026gt; @dispatch(int, int) \u0026gt; def product(x, y): \u0026gt; return x * y \u0026gt; @dispatch(int, int, int) \u0026gt; def prodcut(x, y, z): \u0026gt; return x * y * z \u0026gt; @dispatch(float, float, float) \u0026gt; def product(x, y, z): \u0026gt; return x * y * z 동일한 이름을 사용해서 훨씬 깔끔하고, 이름을 아낄 수 있다. 그럼 인스턴스를 만들어서 각 method를 실행해보자. 1 2 3 4 5 6 7 8 9 10 \u0026gt; c = SampleC() \u0026gt; print(c.product(5, 6)) 30 \u0026gt; print(c.product(5, 6, 7)) 210 \u0026gt; print(c.product(10.0, 15.0, 25.0)) 3750.0 동일한 method 명이지만, 변수의 타입과 갯수에 맞게 적절한 method가 적용된다는 걸 확인했다. 동일한 name을 사용하여 훨씬 깔끔하고, name을 아낄 수 있다. Reference 모두를 위한 파이썬 : 필수 문법 배우기 Feat. 오픈소스 패키지 배포 (Inflearn Original) 외부 모듈 설치하기 ","permalink":"http://jeha00.github.io/post/python/python_basic_45_overriding_overloading/","summary":"OOP에서 사용하는 overriding과 overloading에 대해 알아본다. 그리고, multipledispatch module을 사용하여 overloading을 구현한다.","title":"[TIL] Python basic 45: Overriding vs Overloading"},{"categories":["Python"],"content":"0. Introduction 지난 Chapter Python basic 43: Underscore 의 access modifier에 대한 개념을 먼저 이해해야 한다. class 내의 attribute를 관리하기 위해서 2가지 방법을 가진다.\n첫 번째: 이 attribute data에 직접 접근하여 변경하기: Python basic 43: Underscore 두 번째: method를 통해 접근하여 변경하기: Method 활용하여 Getter, Setter 작성 이번 Chapter에서는 두 번째 방법에 대해 알아본 후, property로 이를 구현해본다.\n1. Method 활용하여 Getter, Setter 작성 Method를 활용하여 data에 접근하는 이유\naccess modifier로 구분한 data에 직접 접근하기보다는 class 내의 method를 통해서 접근하는 것이 side effect를 고려했을 때 현명한 방법이다.\n그래서 data에 접근하기 위한 method인 Getter (=accessor) 와 Setter(= mutator)에 대해 작성해보겠다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026gt; class Sample: \u0026gt; def __init__(self): \u0026gt; self.x = 0 \u0026gt; self.__y = 0 # Getter \u0026gt; def get_y(self): \u0026gt; return self.__y # Setter \u0026gt; def set_y(self, value): \u0026gt; self.__y = value \u0026gt; A = Sample() \u0026gt; A.set_y(2) \u0026gt; print(\u0026#39;Ex \u0026gt; x: {}\u0026#39;.format(b.x)) Ex \u0026gt; x : 0 \u0026gt; print(\u0026#39;Ex \u0026gt; y: {}\u0026#39;.format(b.get_y())) Ex \u0026gt; y : 2 \u0026gt; print(dir(A)) [\u0026#39;_SampleB__y\u0026#39;, \u0026#39;__class__\u0026#39;, ..., \u0026#39;get_y\u0026#39;, \u0026#39;set_y\u0026#39;, \u0026#39;x\u0026#39;] dir()를 통해서 private variable은 naming mangling이 일어난 걸 알 수 있다. method get_y 와 set_y를 확인할 수 있다. 2. Property 2.1 Property란?? 공개적으로 노출된 API를 변경하지 않고도 class 내부의 attribute의 기본 구현을 변경할 수 있는 도구\n위 방식의 문제점 위 방식은 접근하려는 변수의 수가 만약 10개라면 각 변수에 대해 method를 작성해야한다. 객체 지향 설계의 캡슐화를 깨뜨린다. 그래서 Python에서는 위 방식보다 간편하고 안전한 도구를 제공하는데, 바로 property 다. property는 속성 같이 행동하는 method를 만든다. getter와 setter method를 피하는 pythonic way로, 내부 method를 외부에 노출시키는 것 없이 구현(Implementation)할 수 있다. 2.2 Property의 구현 방식 2가지 function으로서 Property( ) 와 decorator로서 @property\nfunction으로 property 방법은 Real Python - Python\u0026rsquo;s property(): Add Managed Attributes to Your Classes - Getting Started With Python’s property()를 참고한다.\n전자보다 후자인 decorator 로서의 property 를 사용하는 방식이 보다 Pythonic way 이며, Python open source community에서 가장 유명한 방법 이다.\n@property 는 Python 2.4 부터 가능해진 방식이다.\n2.3 @property 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # circle.py \u0026gt; class Circle: \u0026gt; def __init__(self, radius): \u0026gt; self.__radius = radius \u0026gt; @property \u0026gt; def radius(self): \u0026gt; \u0026#34;\u0026#34;\u0026#34;The radius property.\u0026#34;\u0026#34;\u0026#34; \u0026gt; print(\u0026#34;Get radius\u0026#34;) \u0026gt; return self.__radius \u0026gt; @radius.setter \u0026gt; def radius(self, value): \u0026gt; print(\u0026#34;Set radius\u0026#34;) \u0026gt; self.__radius = value \u0026gt; @radius.deleter \u0026gt; def radius(self): \u0026gt; print(\u0026#34;Delete radius\u0026#34;) \u0026gt; del self.__radius 그러면 위 파일을 import하여 실행해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 \u0026gt; from circle import Circle \u0026gt; circle = Circle(100) \u0026gt; circle.radius Get radius \u0026gt; print(circle.radius) Get radius 100 \u0026gt; circle.radius = 50 Set radius \u0026gt; print(circle.radius) Get radius 50 \u0026gt; print(dir(circle)) [\u0026#39;_Circle__radius\u0026#39;, \u0026#39;__class__\u0026#39;, ... \u0026#39;radius\u0026#39;] \u0026gt; del circle.radius Delete radius # `del`을 실행한 후, `dir`로 확인하면 `_Circle_radius`가 사라진 걸 확인할 수 있다. \u0026gt; print(dir(circle)) [ \u0026#39;__class__\u0026#39;, ... \u0026#39;radius\u0026#39;] \u0026gt; circle.radius AttributeError: \u0026#39;Circle\u0026#39; object has no attribute \u0026#39;_radius\u0026#39; 또한 property 내의 docstring을 출력할 수 있다. 출력되는 내용은 @property 가 붙은 method 안에 docstring이다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; help(circle) Help on Circle in module circle object: class Circle(builtins.object) | Circle(radius) | | Methods defined here: | | __init__(self, radius) | Initialize self. See help(type(self)) for accurate | --------------- | Data descriptors defined here: | ...... | radius | The radius property docsting으로 property에 대해 달고 싶으면 @property decorator가 붙는 method에 작성해야 한다는 걸 확인했다.\n그러면 마지막으로 제약조건을 추가하여 사용해보자.\n@radius.setter 에 제약조건을 추가한다. 1 2 3 4 5 6 \u0026gt; @radius.setter \u0026gt; def radius(value): \u0026gt; print(\u0026#39;Set radius\u0026#39;) \u0026gt; if value \u0026lt;= 0: \u0026gt; raise ValueError(\u0026#39;0보다 큰 값을 입력하세요\u0026#39;) \u0026gt; self.__radius = value 똑같이 import하여 실행해보자. 의도한대로 ValueError가 뜨는 걸 확인할 수 있다. 1 2 3 4 \u0026gt; circle = Circle(100) \u0026gt; circle.radius = -20 ValueError: 0보다 큰 값을 입력하세요. 2.4 Summary @property는 getter method를 decorate 한다. docstring의 위치는 @property 안에 입력해야 한다. setter 와 deleter method는 getter method name에 .setter 그리고, .deleter 로 추가하여 decorate 된다. Reference 모두를 위한 파이썬 : 필수 문법 배우기 Feat. 오픈소스 패키지 배포 (Inflearn Original) Real Python - Python\u0026rsquo;s property(): Add Managed Attributes to Your Classes ","permalink":"http://jeha00.github.io/post/python/python_basic_44_property/","summary":"첫 번째, method를 사용하여 getter와 setter를 구현한다. 두 번째, 첫 번째보다 pythonic way인 property를 사용하여 구현해보는데, property 방법 2가지 중 decorator를 사용하여 getter, setter, deleter를 구현해본다.","title":"[TIL] Python basic 44: Property"},{"categories":["Python"],"content":"1. Python underscore 활용 Interpreter 내에서의 마지막 값 1 2 3 4 5 \u0026gt; 2 + 3 5 \u0026gt; _ + 5 10 특정값을 무시하는 용도 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; x, _, y = (1, 2, 3) # Unpacking에 사용 \u0026gt; a, *_, b = (1, 2, 3, 4, 5) \u0026gt; print(x, y, a, b) 1 3 1 5 # Error가 뜨지 않는다. \u0026gt; for _ in range(10): \u0026gt; pass # 각 index에 대응하는 value만 출력 \u0026gt; for _, val in enumerate(range(10)): \u0026gt; print(val, end = \u0026#39;\u0026#39;) 0123456789 magic method 사용 시, double underscore를 사용한다.\nmagic method는 special method, Dunder(Double underscore) method와 동의어다. [TIL] Python basic 27: Special Method Access modifier 접근 지정자로 사용된다.\n이 접근 지정자 private에서 Naming Mangling 이 발생된다. 2. Access modifier 접근 지정자라 하며, 정보 은익(Information Hiding)을 위해 사용된다. 즉, class의 attribute, method에 대해 접근을 제어할 수 있는 기능이다.\nPublic -\u0026gt; Protected -\u0026gt; Private 단계로 접근할 수 있는 대상이 좁아진다.\nunderscore를 통해 각 대상의 범위를 지정한다.\nname: public _name: protected __name: private Python에서는 약속된 규약에 따라 자유도와 책임감을 가지고 코딩하는 것을 장려한다.\n그러면 Public, Protected, Private에 대해 각각 알아보자.\n2.1 Public public으로 선언된 attribute, method는 어떤 클래스라도 접근 가능하며, Python에서 모든 attribute, method는 기본적으로 public 이다.\n클래스 외부에서 attribute, method가 접근 가능하기 때문에 사용 가능하다. underscore는 없다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026gt; class kim: # constructor \u0026gt; def __init__(self, name, age): \u0026gt; self.kimname = name \u0026gt; self.kimage = age \u0026gt; # public member function \u0026gt; def display_age(self): \u0026gt; # accessing public data member \u0026gt; print(\u0026#34;Age: \u0026#34;, self.kimage) # creating instance of the class \u0026gt; inst = kim(\u0026#39;king\u0026#39;, 30) # accessing public data member \u0026gt; print(\u0026#34;Name: \u0026#34;, inst.kimname) \u0026gt; inst.display_age() Name: king Age: 30 public이어도 다음과 같이 접근하여 직접 수정하는 건 권장하지 않는다. 수정하고 출력하는 별도의 method를 사용하는 걸 권장한다. 1 2 3 4 # 권장하지 않는 방법 \u0026gt; inst.kimname = \u0026#39;Wang\u0026#39; \u0026gt; print(\u0026#34;Name: \u0026#34;, inst.kimname) Name: Wang 2.2 Protected 정의한 해당 class 또는 해당 class를 상속 받은 클래스에서만 접근이 가능하다는 의미지만, 실제로는 public 처럼 접근 가능하다.\n상속받은 자식 class에서 사용하자는 의미다. 하나의 underscore를 name 앞에 붙여서 표시만 한다. 즉, 실제로 제약되지는 않고, 일종의 경고 표시로 사용 된다. 단지 경고 표시일 지라도 접근하여 수정하지 않는 걸 권고한다. 1 2 3 4 5 6 7 8 9 10 11 \u0026gt; class Sample: \u0026gt; def __init__(self): \u0026gt; self.x = 0 \u0026gt; self._y = 0 \u0026gt; a = Sample() # 출력 가능하다. # 이렇게 직접 출력하는 걸 권장하지 않는다. \u0026gt; print(\u0026#39;y = \u0026#39;, a._y) y = 0 상속받은 클래스에서 사용하기 아래 code처럼 출력 method를 통해서 접근하는 걸 권장한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 ## super class \u0026gt; class Student: # protected data members \u0026gt; _name = None \u0026gt; _roll = None \u0026gt; _branch = None \u0026gt; # constructor \u0026gt; def __init__(self, name, roll, branch): \u0026gt; self._name = name \u0026gt; self._roll = roll \u0026gt; self._branch = branch \u0026gt; # protected member function \u0026gt; def _displayRollAndBranch(self): \u0026gt; # accessing protected data memebers \u0026gt; print(\u0026#34;Roll: \u0026#34;, self._roll) \u0026gt; print(\u0026#34;branch: \u0026#34;, self._branch) ## Subclass \u0026gt; class Geek(Student): \u0026gt; # constructor \u0026gt; def __init__(self, name, roll, branch): \u0026gt; Student.__init__(self, name, roll, branch) \u0026gt; # public function \u0026gt; def displayDetails(self): \u0026gt; # accessing protected data of super class \u0026gt; print(\u0026#34;Name: \u0026#34;, self._name) \u0026gt; # accessing protected function of super class \u0026gt; self._displayRollAndBranch() \u0026gt; inst = Geek(\u0026#34;Wang\u0026#34;,130205, \u0026#34;Information Technology\u0026#34;) \u0026gt; inst.displayDetails() Name: Wang Roll: 130205 branch: Information Technology 2.3 Private: Naming Mangling 정의한 해당 class에서만 직접 접근이 가능하다. 만약 상속받은 클래스에서 접근하고자 한다면 상위 클래스에서의 private 변수에 접근할 수 있는 method를 만들어야 가능하다. 두 개의 underscore를 name 앞에 붙여서 사용하여 지정한다. OOP의 캡슐화를 의미한다.\npython에서는 double underscore를 name 앞에 붙이면 해당 이름으로 접근이 허용되지 않는다.\n왜냐하면 Naming Mangling이 일어나기 때문이다.\ndouble underscore를 붙이면 해당 이름이 _\u0026lt;해당 class name\u0026gt;_name 으로 mangling이 일어난다.\n__name -\u0026gt; _\u0026lt;해당 class name\u0026gt;_name 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ## 정의한 class에서만 접근이 가능하다. \u0026gt; class Student: # private members \u0026gt; __name = None \u0026gt; __roll = None \u0026gt; __branch = None \u0026gt; # constructor \u0026gt; def __init__(self, name, roll, branch): \u0026gt; self.__name = name \u0026gt; self.__roll = roll \u0026gt; self.__branch = branch \u0026gt; # private function \u0026gt; def __displayRollAndBranch(self): \u0026gt; # accessing private memebers \u0026gt; print(\u0026#34;Roll: \u0026#34;, self.__roll) \u0026gt; print(\u0026#34;branch: \u0026#34;, self.__branch) \u0026gt; # public function \u0026gt; def accessPrivateFunction(self): \u0026gt; # accessing private function \u0026gt; self.__displayRollAndBranch() \u0026gt; inst = Student(\u0026#34;Wang\u0026#34;,130205, \u0026#34;Information Technology\u0026#34;) \u0026gt; inst.acessPrivateFunction() Name: Wang Roll: 130205 branch: Information Technology 만약 Protected chapter에서 다뤘던 code에서 protected data로 지정한 _name = None 을 private로 바꿔서 상속된 class를 통해서 실행한다면 어떻게 될까??? _name = None -\u0026gt; __name = None 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 ## Super class \u0026gt; class Student: \u0026gt; # private data \u0026gt; __name = None \u0026gt; # protected data members \u0026gt; _roll = None \u0026gt; _branch = None \u0026gt; # constructor \u0026gt; def __init__(self, name, roll, branch): \u0026gt; # private data \u0026gt; self.__name = name \u0026gt; # protected data \u0026gt; self._roll = roll \u0026gt; self._branch = branch \u0026gt; def _displayRollAndBranch(self): \u0026gt; # accessing protected data memebers \u0026gt; print(\u0026#34;Roll: \u0026#34;, self._roll) \u0026gt; print(\u0026#34;branch: \u0026#34;, self._branch) ## Subclass \u0026gt; class Geek(Student): \u0026gt; # constructor \u0026gt; def __init__(self, name, roll, branch): \u0026gt; Student.__init__(self, name, roll, branch) \u0026gt; # public function \u0026gt; def displayDetails(self): # accessing protected data of super class \u0026gt; self._displayRollAndBranch() \u0026gt; # accessing private data of super class \u0026gt; print(\u0026#34;Name: \u0026#34;, self.__name) \u0026gt; inst = Geek(\u0026#34;Wang\u0026#34;,130205, \u0026#34;Information Technology\u0026#34;) # super class의 private 변수에 직접 접근을 불허한다. \u0026gt; inst.displayDetails() AttributeError: \u0026#39;Geek\u0026#39; object has no attribute \u0026#39;_Geek__name\u0026#39; 위의 경우처럼 Error가 뜬다. private data는 상속된 class에서 출력할 수 없다는 걸 확인했다. Naming Mangling 확인하기 그러면 Naming Mangling을 확인해보자. 위의 AttributeError 에서도 확인할 수 있듯이 _Geek__name으로 private data인 __name이 변경된 걸 확인했다. 1 2 3 4 5 # 위 코드에서 실행했다. \u0026gt; print(dir(inst)) # 결과는 다음과 같다. [\u0026#39;_Student__name\u0026#39;, \u0026#39;__class__\u0026#39;, ... \u0026#39;_branch\u0026#39;, \u0026#39;_displayRollAndBranch\u0026#39;, \u0026#39;_roll\u0026#39;, \u0026#39;displayDetails\u0026#39;] 맨 처음 private data를 선언된 class의 이름이 붙여져서 _Student__name으로 naming Mangling 된 걸 확인했다. mangling의 의미처럼 기존의 설정한 name은 훼손되어 사용할 수 없다. 다른 언어와의 차이점 타 클래스의 private attribute, method에 접근하지 않는 것이 원칙이지만, 파이썬은 사실 접근이 가능하다.\n하지만, 원칙에 맞게 Python 오픈 소스 프로젝트들은 이를 준수하고 있다.\n2.4 Summary 그러면 마지막으로 3가지 access modifier에 대해 코드로 정리한 후, 마무리하겠다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 ## Super class \u0026gt; class Super: \u0026gt; # public \u0026gt; var1 = None \u0026gt; # protected data \u0026gt; _var2 = None \u0026gt; # private data \u0026gt; __var3 = None \u0026gt; # Constructor \u0026gt; def __init__(self, var1, var2, var3): \u0026gt; self.var1 = var1 \u0026gt; self._var2 = var2 \u0026gt; self.__var3 = var3 \u0026gt; # public function \u0026gt; def displayPublicMembers(self): \u0026gt; print(\u0026#34;Public data: \u0026#34;, self.var1) \u0026gt; # protected function \u0026gt; def _displayProtectedMembers(self): \u0026gt; print(\u0026#34;Protected data: \u0026#34;, self._var2) \u0026gt; # private function \u0026gt; def __displayPrivateMembers(self): \u0026gt; print(\u0026#34;private data: \u0026#34;, self.__var3) \u0026gt; # public function \u0026gt; def accessPrivateMembers(self): \u0026gt; # accessing private member function \u0026gt; self.__displayPrivateMembers() ## derived class \u0026gt; class Sub(Super): # constructor \u0026gt; def __init__(self, var1, var2, var3): \u0026gt; Super.__init__(self, var1, var2, var3) \u0026gt; # public fucntion \u0026gt; def accessProtectedMembers(self): \u0026gt; self._displayProtectedMembers() \u0026gt; inst = Sub(\u0026#34;Wang\u0026#34;,4, \u0026#34;!\u0026#34;) \u0026gt; inst.displayPublicMembers() \u0026gt; inst.accessProtectedMembers() \u0026gt; inst.accessPrivateMembers() Public data: Wang Protected data: 4 private data: ! Reference 모두를 위한 파이썬 : 필수 문법 배우기 Feat. 오픈소스 패키지 배포 (Inflearn Original) The Python Standard library - Python 3.10.2 document 파이썬과 객체지향 (public, private, protected) 프로그래밍 Access Modifiers in Python: Public, Private and Protected ","permalink":"http://jeha00.github.io/post/python/python_basic_43_underscore/","summary":"Python에서 underscore(_)가 어떻게 쓰이는지 알아보고, 그 중에서 Access modifier 접근 지정자 Public, Protected, private 각각에 대해 알아본다. 그리고, Private의 경우, naming mangling와 연결하여 알아본다.","title":"[TIL] Python basic 43: Underscore"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 책에는 있지 않고, kocw 이화여자대학교 운영체제 -반효경 교수- 강의만 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 1. The Deadlock Problem deadlock이 현실 사례 비유 누군가가 희생하지 않으면 교착 상태는 발생하지 않는다. 즉, 각자 일부 자원을 가지고 있으면서, 상대방이 가지고 있는 걸 요구하는 상황 1.1 Deadlock이란?? 일련의 프로세스들이 서로가 가진 자원을 기다리며 block된 상태\n1.2 Resource (자원)이란?? 하드웨어, 소프트웨어 등을 포함하는 개념 (예) I/O device, CPU cycle, memory space, semaphore 등 프로세스가 자원을 사용하는 절차\nRequest(요청) → Allocate(할당) → Use(사용) → Release(반납) Deadlock Example 1\n시스템에 2개의 tape drive가 있다. 프로세스 P1과 P2 각각이 하나의 tape drive를 보유한 채 다른 하나를 기다리고 있다. Deadlock Example 2\nBinary semaphore A and B Po: P(A) → P(B) P1: P(B) → P(A) Po는 A를 획득한 후, B를 얻고 싶어한다. P1은 반대다. 서로 반대 것을 가지고 있기 때문에, Deadlock 상황이다. 2. Deadlock 발생의 4가지 조건 아래 4가지 조건을 다 만족해야 deadlock이 발생한다.\n첫 번째: Mutal exclusion (상호 배제)\n매 순간 하나의 프로세스만이 자원을 사용할 수 있다. (독점적 사용) 두 번째: No preemption (비선점)\n프로세스는 자원을 스스로 내어놓을 뿐 강제로 빼앗기지 않는다. 세 번째: Hold and wait\n자원을 가진 프로세스가 다른 자원을 기다릴 때, 보유 자원을 놓지 않고 계속 가지고 있는다. 네 번째: Circular wait\n자원을 기다리는 프로세스 간에 사이클이 형성되어야 한다. 프로세스 Po, P1, \u0026hellip;. ,Pn이 있을 때 Po는 P1이 가진 자원을 기다린다. P1은 P2가 가진 자원을 기다린다. Pn-1은 Pn이 가진 자원을 기다린다. Pn은 Po이 가진 자원을 기다린다. 3. Resource - Allocation Graph Deadlock 발생하는지 확인하기 위해, resource - allocation graph (자원 할당 그래프)를 그려본다.\n3.1 Graph 설명 Vertex (= 꼭지점, 정점)\nProcess P = {P1. P2, \u0026hellip;., Pn} Resource R = {R1, R2,\u0026hellip;,Rm} Edge (= 화살표 )\nPi → Rj: request edge = Pi가 Rj 자원을 요청한다. Rj → Pi: assignment edge = Rj 자원을 Pi 자원이 가지고 있다. 자원의 점은 instance를 의미한다\n3.2 deadlock 확인하기 그래프에 deadlock이 있는지 어떻게 알 수 있을까?\ngraph에 cycle 유무에 따라 deadlock을 판단할 수 있다.\n1번, Cycle 無 in graph -\u0026gt; deadlock X\n2번 Cycle 有 in graph -\u0026gt;\n2-1번 one instance per resource -\u0026gt; deadlock O 2-2번 multiple intsnace per resource -\u0026gt; deadlock X \u0026amp; 가능성 O 오른쪽 graph: 2-2번 case\nP4가 resource를 다 사용 후, 반납하면 P3는 이용가능해진다. P2 또한 resource를 다 사용하고 반납하면 P1이 사용가능하다. 한 resource에 여러 개의 instance가 존재하기 때문에 deadlock이 아니다. 왼쪽 graph: 2-1번 case\nR2 자원을 P1과 P2가 가지고 있으면서, P3가 이 자원을 요청하는 상황이기 때문에, deadlock 이다. 4. Deadlock 처리 방법 위로 올라갈수록 강한 방법이다. 하지만, 맨 마지막 방법을 대부분의 OS가 채택하는 이유는 deadlock을 탐색하는 것과 deadlock에 대처하는 것 모든 것이 overhead이기 때문이다.\n첫 번째, Deadlock Prevention\n자원 할당 시, deadlock의 4가지 필요 조건 중 어느 하나가 만족되지 않도록 하는 것 두 번째, Deadlock Avoidance\n자원 요청에 대한 부가적인 정보를 이용해서 deadlock의 가능성이 없는 경우에만 자원을 할당 시스템 state가 원래 state로 돌아올 수 있는 경우에만 자원 할당 세 번째, Deadlock Detection and recovery\nDeadlock 발생은 허용하되, 그에 대한 detection routine을 두어 deadlock 발견시 recover 네 번째, Deadlock Ignorance\nDeadlock을 시스템이 책임지지 않는다. Unix를 포함한 대부분의 OS가 채택 Deadlock은 빈번히 발생하는 문제가 아니기 때문에, 이를 방지하기 위해 오히려 많은 overhead가 발생하기 때문에, 이 방식을 택한다. 4.1 Deadlock 처리 방법 첫 번째: deadlock prevention Process가 resource를 요구하는 방식에 제한을 두는 방식으로, deadlock이 발생하는 4가지 필요 조건 중 어느 하나가 만족되지 않도록 하는 것\nMutual Exclusion\n공유해서는 안되는 자원의 경우, 반드시 성립해야 한다. 따라서, 이 조건의 발생을 막아 deadlock을 해결하는 건 불가능하다. Hold and wait 조건에 대한 방법\n프로세스가 자원을 요청할 때, 다른 어떤 자원도 가지고 있지 않기\n방법 1: 프로세스 시작 시, 모든 필요한 자원을 할당받는 방법\n다 사용하고 나서 자원을 반납한다. 방법 2: 자원이 필요할 경우, 보유 자원을 모두 놓고 다시 요청\nhold한 자원을 다 뱉는다. 하지만, 한 번에 한 프로세스만 자원을 소유할 수 있어서 효율적이지 않다.\nstarvation이 발생할 수 있고, throughput이 낮다.\nNo Preemption 조건에 대한 방법\nPreemption을 허락하기 Process가 어떤 자원을 기다려야 하는 경우, 이미 보유한 자원이 선점된다. 모든 필요한 자원을 얻을 수 있을 때, 그 프로세스는 다시 시작된다. 이 때, starvation이 발생할 수 있다. state를 쉽게 save하고, restore할 수 있는 자원에서 주로 사용(CPU, memory) Circular wait 막기\n모든 자원 유형에 할당 순서를 정하여 정해진 순서대로만 자원을 할당하기 예를 들어 순서가 3인 자원 Ri를 보유 중인 프로세스가 순서가 1인 자원 Rj를 할당받기 위해서는 우선 Rj를 release해야 한다. 하지만, 생기지도 않을 수 있는 이런 제약들로 인해서 다음과 같은 문제점을 낳기 때문에, 이 방법은 잘 사용하지 않는다.\n⇒ Utilization 저하, throughout 감소, starvation 문제\n4.2 Deadlock 처리 방법 두 번째: deadlock avoidance 자원에 대한 사전 정보를 이용해서 deadlock의 발생 가능성을 계속 검사하여, resource-allocation state가 safe state인 경우에만 자원을 할당하는 방식\n자원에 대한 사전 정보\n가장 단순하고 일반적인 예: 프로세스들이 필요로 하는 각 자원별 최대 사용량을 미리 선언 safe state란??\n시스템 내의 프로세스들에 대한 safe sequence 가 존재하는 상태 순서가 어떻든 safe sequence가 존재하면 safe state다. 시스템이 safe state이면 no deadlock unsafe state이면 possibility of deadlock 존재 safe sequence란??\nn개의 프로세스 중 하나인 Pi(1≤ i ≤ n)의 자원요청이 가용 자원 + 모든 P_j(j \u0026lt; i)의 보유자원 에 의해 충족되는 순서 safe sequence가 존재하면 cycle을 형성하지 않는다. 조건을 만족하면 다음 방법으로 모든 프로세스의 수행을 보장한다. Pi의 자원 요청이 즉시 충족될 수 없으면 모든 Pj(j \u0026lt;p i) 가 종료될 때까지 기다린다. P(i-1)이 종료되면 Pi의 자원 요청을 만족시켜 수행한다. Deadlock Avoidance\n시스템이 unsafe state에 들어가지 않는 것을 보장한다. 2가지 경우의 avoidance algorithum single instance per resource types Resource Allocation Graph algorithum 사용 Multiple instances per resource types Banker’s Algorithum (은행원 알고리즘) 사용 4.2.1 Resource Allocation Graph algorithum: single instance per resource types 위의 resource allocation graph algorithum에 claim edge 를 추가한다. Claim edge (점선): Pi → Rj 프로세스 Pi가 자원 Rj를 미래에 요청할 수 있음을 뜻한다. 프로세스가 해당 자원 요청 시 request edge로 바뀐다. (실선: 소유하고 있다) Rj가 release되면 assignment edge는 다시 claim edge로 바뀐다. request edge의 assignment edge 변경 시(점선을 포함하여), cycle이 생기지 않는 경우에만 요청 자원을 할당. Cycle 생성 여부 조사 시, 프로세스의 수가 n일 때 O(n^2)의 Time Complexity 를 가진다. 4.2.2 Banker’s Algorithum: multiple instances per resource types 위의 single instance일 때를 넘어서 일반화하는 algorithum 이용 가능한 자원으로 요청 양을 만족할 수 있는지 판단한다. 충족할 수 있으면 이 프로세스의 요청은 다 받아들이고, 충족되지 않으면 다 받아들여지지 않는다. 가정\n모든 프로세스는 자원의 최대 사용량을 미리 명시 avoidance 설명대로 각 자원 별 최대 사용량을 미리 선언한 것 프로세스가 요청 자원을 모두 할당받은 경우, 유한 시간 안에 이들 자원을 다시 반납 이 알고리즘은 최악의 상황을 가정한다. 방법\n기본 개념: 자원 요청 시, safe 상태를 유지할 경우에만 할당한다. 충분히 할당할 수 있는 자원의 수가 있어도, safe 상태를 유지하지 못하면 할당하지 않는다는 의미 총 요청 자원의 수가 가용 자원의 수보다 적은 프로세스를 선택 그런 프로세스가 없으면 unsafe 상태 그런 프로세스가 있으면 그 프로세스에게 자원을 할당 할당(allocation)받은 프로세스가 종료되면 모든 자원을 반납 (available이 된다.) 모든 프로세스가 종료될 때까지 이러한 과정 반복 사전 정보\nAllocation: 각 프로세스에 할당된 각 자원의 양 Max: 각 프로세스의 자원별로 최대 요구하는 자원의 양 Available: 각 자원 별로 현재 남아있는 자원의 양 Need: 각 프로세스의 추가로 요청 가능한 자원의 양 Resource\n총 자원: A 10개,B 5개, C 7개 A = 2 + 3 + 2 = 7 이고, 가용자원으로 A가 3개임을 확인할 수 있다. P0의 할당된 자원 B를 반납하면 이용가능한 B 자원의 수는 늘어난다. safe sequence\nP0: P0에 추가로 할당할 수 있는 자원이 존재하지만, Need한 만큼 요청하면 가용자원만으로는 불가능하기 때문에, 요청을 받아들이지 않고, 기다린다.\nP1: 최대 필요 요청은 가용 자원으로 충분히 가능하기 때문에, P0와 달리 받아들인다.\nP1이 가용자원을 가져가서 다 사용 후, 자원을 반납하면 available resource에 추가되고 P3가 그걸로 가능하다.\n이런 순서가 나타나는게 P1,P3,P4,P2,P0다. 이런 순서가 존재하면 절대 dead lock이 발생하지 않는 safe state다. 뱅커스 알고리즘 이렇게 최대요청을 해도 deadlock이 발생하지 않는 상황에서만 요청을 받아들여 deadlock을 피해간다.\n하지만, 이는 혹시 모를 상황을 대비하기 때문에 비효율적이다. 4.3 Deadlock Detection and Recovery 알고리즘을 통해 현재 시스템에 deadlock이 있는지 찾고, 알고리즘을 통해 deadlock을 복구하는 것\n4.3.1 Single instance per resource type wait-for graph algorithum을 사용하며, deadlock detection을 하기 위해서는 wait-for graph에서 cycle이 있는지를 판단한다.\nwait-for graph\ncycle이 곧 deadlock을 의미한다.\n자원 할당 그래프의 변형\n프로세스만으로 node 구성\nEdge 의미\nPk → Pj: Pj가 가지고 있는 자원을 Pk가 기다리는 경우 R(resource) → P: 이 자원을 P가 소유하고 있다. P -\u0026gt; R(resource): P가 이 자원을 요청한다. 자원의 최대 사용량을 미리 알릴 필요가 없기 때문에, 그래프에 점선이 없다. algorithum\nwait-for grpah에 cycle이 존재하는지를 주기적으로 조사 O(n^(2)) Resource-allocation graph에서 자원을 빼면 coreesponding wait-for graph가 된다.\n4.3.1 Multiple instance per resource type deadlock 찾는 방법은 banker’s algorithum과 유사한 방법 활용\nDeadlock 존재 유무를 판단하기 위해서는 deadlock avoidance와 반대로 매우 보수적인 판단이 아닌, 긍정적인 판단을 해야 한다.\n긍정적으로 바라보기 때문에, 각 프로세스는 가지고 있는 자원을 반납할 것이라 본다. Deadlock 확인하기\n가용자원(Avaoilable)이 몇 개 있는지 확인한다. 요청하지 않은 프로세스의 자원도 가용자원으로 합친다. 합친 가용자원으로 처리 가능한지 확인한다. 처리 후 처리된 프로세스의 자원도 합쳐서, 모든 프로세스가 끝낼 수 있는지 확인한다. Deadlock detection과 recovery도 overhead가 크다.\n4.3.2 Recovery Process termination\nabort all deadlocked processes abort one process at a time until the deadlock cycle is eliminated Resource Preemption\n비용을 최소화할 victim으로 선정 safe state로 rollback하여 process를 restart starvation 문제 동일한 프로세스가 계속해서 victim으로 선정되는 경우 cost factor에 rollback 횟수도 같이 고려 4.4 Deadlock Ignorance Deadlock이 일어나지 않는다고 생각하고, 아무런 조치도 취하지 않는 방식\nDeadlock이 매우 드물게 발생하므로, deadlock에 대한 조치 자체가 더 큰 overhead일 수 있다. 만약 시스템에 deadlock이 발생한 경우, 직접 process를 죽이는 등의 방법으로 대처한다. 만약 한 번에 deadlock의 원인이 되는 process를 죽이면 효율적이지만, 원인이 되는 process가 죽을 수도 있다. UNIX, Windows 등 대부분의 범용 OS가 채택하는 방식이다. Reference kocw 이화여자대학교 운영체제 - 반효경 교수 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_09_%EA%B5%90%EC%B0%A9%EC%83%81%ED%83%9C/","summary":"교착 상태(deadlock)이란 무엇이고, deadlock 발생 조건 4가지는 무엇이며, 이에 따라 deadlock 처리 방법에 대해 알아본다.","title":"[TIL] Chapter 09: 교착 상태"},{"categories":"OS","content":"0. Introduction 해당 내용은 kocw 이화여자대학교 운영체제 - 반효경 교수 - 강의만 보고 정리한 내용이다. 운영체제와 정보기술의 원리 -반효경 지음- 책에는 있지 않은 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 6. 프로세스 동기화의 첫 번째 문제 **Bounded-buffer problem (producer-consumber problem)**으로서, 생산자와 소비자가 공유 buffer에 도착했을 경우, 동기화되지 않는 문제\nbuffer: 임시로 데이터를 저장하는 공간\n두 종류의 process\nProducer: 생산자 process로서, 공유 buffer에다가 데이터를 만들어서 집어넣는 역할 Consumer: 소비자 process로서, 공유 buffer에서 데이터를 꺼내는 역할 Bounded-buffer로 인한 문제점\nTo producer buffer가 가득 차고, 소비자가 안오는 상황이라면 data를 더 이상 생산할 수 없다는 문제가 발생된다. To consumer 소비자 process는 소비할 수 있는 buffer가 없으면 문제가 발생된다. 생산자 process가 내용을 넣어줄 때까지 계속 기다린다. Synchronization variable\nmutual exclusion: 공유 데이터의 상호 배제를 위해서 binary semaphore를 사용 resource count: 가용 buffer 수를 표시하기 위해서 counting semaphore를 사용 6.1 Semaphore로 문제 해결하기 Synchronization variable (= semaphore variable) semaphore full = 0, empty = n, mutex = 1 Producer\nP(empty): 빈 buffer를 확인하고, 있으면 획득한다. 빈 buffer가 없으면 이 단계에서 대기한다. 소비자가 소비한 buffer는 producer에게는 자원이다. P(mutex): buffer에 data를 넣기 위해 lock을 건다. V(mutex): buffer에 건 lock을 푼다. V(full): 내용이 들어가 있는 buffer의 갯수를 1 증가시키는 연산 내용이 들어가 있는 buffer는 소비자에게는 자원이다. 그리고, 소비자가 내용 있는 buffer가 없어서 대기하고 있으면 소비자를 wake up 해주는 연산 Consumer\nP(full): 내용이 있는 buffer 획득 P(mutex): 획득한 buffer에 lock을 건다. V(mutex): lock을 푼다. V(empty): 비어있는 buffer의 수를 1 증가시킨다. 그리고, 비어진 buffer는 생산자에게 자원이 된다. 7. 프로세스 동기화의 두 번째 문제 Readers and writers problem\nSolution\nWriter가 DB에 접근 허가를 아직 얻지 못한 상태에서는 모든 대기 중인 Reader들을 다 DB에 접근하게 한다. Writer는 대기 중인 Reader가 하나도 없을 때, DB 접근이 허용된다. 일단 Writer가 DB에 접근 중이면 Reader들은 접근이 금지된다. Writer가 DB에 빠져나가야만 Reader의 접근이 허용된다. read는 동시에 여러 개가 접근해도 된다. shared data\nDB 자체 readcount: 현대 DB에 접근 중인 reader의 수 Synchronization variables\nmutex: 공유 변수 readcount를 접근하는 코드(critical section)의 mutual exclusion 보장을 위해 사용 DB: reader와 writer가 공유 DB 자체를 올바르게 접근하는 역할 Writer\nP(db)가 DB에 lock을 걸고 쓰는 작업을 수행 이 작업이 끝나면 V(db)를 통해서 lock을 푼다. starvation 문제 발생 write가 reader들이 다 작업을 완료할 때까지 기다리는 중에, 또 다른 reader들이 들어오면 더 오래 기다려야 한다. 위 코드에서는 starvation에 대한 대책 코드는 나와있지 않는다. Reader\nreadcount는 공유 변수이기 때문에, race condition을 방지하기 위해서 mutex 변수를 사용한다. 그래서 P(mutex)에서 readcount 변수에 lock을 건다. readcount == 1: 자신이 최초의 reader라는 의미이고, DB에 lock을 건다. if readcount \u0026gt; 1: 이미 최초의 reader가 DB에 lock을 걸었기 때문에, 추가로 DB에 lock을 걸지 않고 읽기만 한다. readcount - -: process가 다 읽고 빠져나가기 때문에, 1 감소된다. if readcount == 0: writer가 작성할 수 있다. 8. 프로세스 동기화의 세 번째 문제 Dinning-philosophers problem (식사하는 철학자 문제)\nDeadlock 발생지점\n모든 철학자가 동시에 배가 고파서 왼쪽 젓가락을 집어버린 경우 Solution\n4명의 철학자만이 테이블에 동시에 앉을 수 있도록 한다. 젓가락을 두 개 모두 집을 수 있을 때에만 젓가락을 집을 수 있게 한다. 비대칭 짝수(홀수) 철학자는 왼쪽(오른쪽) 젓가락부터 집도록한다. Semaphore code Synchronization variables\nenum {thinking, hungry, eating} state [5]\nsemaphore self[5] = 0 or 1\ni 번째 철학자가 젓가락을 소유할 수 있는 권한 유무 0 -\u0026gt; 권한 X 1 -\u0026gt; 권한 O semaphore mutex = 1\n본인의 상태를 본인 뿐만 아니라, 다른 철학자가 바꿀 수 있음을 나타내는 것 Philosopher i: 5명의 철학자가 하는 일을 의미\nputdown: 젓가락 내려놓기 pickup: 젓가락 집기 test 밑 단원 monitor 개념을 이용한 식사하는 철학자 문제\n- semaphore code와 비교하기 9. Monitor 9.1 Semaphore의 문제점 코딩하기 어렵다. 정확성 입증이 어렵다. 자발적 협력이 필요하다. 한 번의 실수가 모든 시스템에 치명적인 영향을 준다. 1 2 3 4 5 6 7 8 9 # Deadlock 발생 경우 P(mutex) Critical section P(mutex) # Deadlock 발생하지 않는 경우 V(mutex) Critical section P(mutex) 9.2 Monitor 동시 수행 중인 프로세스 사이에서 abstract data type의 안전한 공유를 보장하기 위한 고수준의 동기화 구조체\nSemaphore와의 차이점\nlock을 걸 필요가 없다. Monitor: 동시 접근 막는 것을 지원 semaphore: 자원을 얻기 위해서 프로그래머가 작성 monitor는 공유 데이터에 접근하기 위해서 monitor 라고 정의된 내부 procedure를 통해서만 접근이 가능하다.\n이 monitor를 어떻게 지원할지는 프로그래밍 언어마다 다르다. 9.2.1 Monitor 내부 구조 shared data + shared data에 접근하는 operations + initialization code\nProcess\nshared data에 접근하고 싶으면 밑에 operations (process) 들을 통해서만 가능하다. process들은 동시에 실행되지 않고, 한 번에 한 process만 실행되도록 설정하므로, lock이 불필요하다. 그래서 개발자가 별도로 lock을 구현할 필요가 없다. (semaphore와의 차이점 이유) monitor 안에 하나의 process만 활성화되기 때문에, 나머지 process는 이에 entry queue에 줄서서 기다린다. monitor 안에 공유자원의 갯수가 없어서 기다려야 하면, 내용 있는 process를 기다리는 queue는 x이고, 내용 없는 process를 기다리는 queue는 y다. semaphore에서는 resource의 갯수를 세는 개 필요하듯이 monitor도 그러하다.\n자원이 있으면 접근 허용, 자원이 없으면 대기한다. Condition variable\nmonitor 안에서 process가 기다릴 수 있도록 하기 위해 condition variable을 사용한다. semaphore 변수와 동일한 역할을 한다. condition variable은 wait과 signal 연산에 의해서만 접근 가능하다. x.wait(): x.wait()을 invoke한 process는 다른 프로세스가 x.signal을 invoke하기 전까지는 suspend 된다. x.signal(): x.signal을 정확하게 하나의 suspend된 프로세스를 resume 한다. suspend된 프로세스가 없으면 아무 일도 일어나지 않는다. monitor가 lock이 필요없는 이유\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026gt; monitor bounded_buffer \u0026gt; { int buffer[n]; \u0026gt; condition full, empty; \u0026gt; void produce(int x) \u0026gt; { if there is no empty buffer \u0026gt; empty.wait(); \u0026gt; add x to an empty buffer \u0026gt; full.signal (); \u0026gt; } \u0026gt; void consume(int *x) \u0026gt; { if there is no full buffer \u0026gt; full.wait(); \u0026gt; remove an item from buffer and store it to *x \u0026gt; empty.signal(); \u0026gt; } \u0026gt; } full, empty 같은 condition var.을 가지지 않고, 자신의 queue에 process를 매달아서, sleep시키거나, queue에서 process를 깨우는 역할만 한다. full: 내용이 들어 있는 buffer를 기다리면서 잠들게 하는 역할 empty: 내용이 없는 buffer를 기다리면서 잠들게 하는 역할 작업을 하기 위해서는 모니터 내부 코드를 실행해야 한다. 생산자 소비자 모두 하나의 프로세스 안에서 활성화되기 때문에, 락을 걸지 않아도 race condition 문제를 고려하지 않아도 된다. empty.wait() 생산자 입장에서는 빈 buffer가 필요한데, 그런 경우 empty wait을 통해서 빈 buffer에 줄 서서 기다린다. full.signal() 내용이 들어 있는 buffer가 있으면 생산자를 깨운다. Reference kocw 이화여자대학교 운영체제 - 반효경 교수 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_08_%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4_%EB%8F%99%EA%B8%B0%ED%99%94_2/","summary":"프로세스 동기화의 전통적인 문제 3가지와 semaphore를 개선한 방법인 monitor에 대해 알아본다.","title":"[TIL] Chapter 08: 프로세스 동기화 2"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 책에는 있지 않고, kocw 이화여자대학교 운영체제 - 반효경 교수 - 강의만 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 1. 데이터 저장과 연산 순서 storage로부터 data를 가져와 연산한 후, 다시 storage에 저장한다. 각 box 예시 E-box S-box CPU Memory 컴퓨터 내부 디ㅃ스크 프로세스 그 프로세스의 주소 공간 2. Race condition 2.1 Race condition이란?? 여러 프로세스/스레드가 동시에 shared data를 조작할 때, 한 연산자가 stroage에서 가져와 작업 중인데, 작업 중인 data를 다른 연산자가 가져가서 작업하여 동기화되지 않는 현상\n2.2 Race condition 발생 배경과 원인 공유 데이터(shared data)의 동시 접근(concurrent access) -\u0026gt; 데이터의 불일치(inconsistency) 발생\n그래서 concurrent process는 동기화가 필요하다.\n일관성(consistency) 유지를 위해 협력 프로세스(cooperating process) 간의 실행 순서(oderly execution)을 정해주는 메커니즘이 필요하다. 데이터 불일치가 발생하는 상황들\nMultiprocessor system (Memory ~ CPU) shared memory를 사용하는 process들 (address space ~ process) kernel 내부 data를 접근하는 routine들 간 발생 3. OS에서의 race condition 3가지 원인: kernel address space를 공유할 때, race condition이 발생한다.\n3.1 Interrupt handler vs kernel 연산 과정\n첫 번째: load 메모리에 있는 값을 CPU 내의 register로 불러들인다. 두 번째: Increase 불러들인 값을 증가시킨다. 세 번째: Store memory에 저장시킨다. Race condition 발생\nLoad 후, interrupt가 들어왔을 경우 -\u0026gt; Count++ 작업을 중단한 후, interrupt service routine으로 넘어간다. -\u0026gt; interrupt handler 이기 때문에, kernel address space를 공유한다. -\u0026gt; 이 상황에서 Count --를 실행하여, 완료하면 interrupt 당한 작업으로 돌아온다. -\u0026gt; 돌아와서 interrupt handler 작업을 완료한 context 부터 작업을 실행해야 하지만, interrupt 당하기 전 load 한 context부터 실행된다. 즉, count--는 실행이 안된 것과 동일하다. Solution: 먼저 하던 작업을 끝낸 후, 넘긴다.\n중요한 변수값을 건드리는 동안에는 인터럽트가 들어와도 인터럽트 처리 루틴으로 바로 넘어가지 않는다. 인터럽트를 disable 시켰다가, 작업이 다 끝난 다음에 interrupt service routine으로 넘긴다. 3.2 Preempt a process running in kernel 한 프로세스의 system call을 통한 mode 전환 이미지 kernel mode로 실행 중 system call로 인한 CPU 선점 두 프로세스의 address space 간에는 data sharing이 없다. 그러나 \u0026lsquo;Pa의 CPU 할당시간 만료\u0026rsquo;로, Pa는 kernel mode로 실행 중 Pb에게 \u0026lsquo;CPU를 선점\u0026rsquo;당한다. system call을 하는 동안, kernel address space의 data에 접근한다. 이로 인해 race condition이 발생한다. Solution 첫 번째: kernel mode에서 수행 중일 때는 CPU를 빼앗지 않는다. 두 번째: kernel mode에서 user mode로 돌아갈 때 CPU를 빼앗는다. 3.3 Multi-processor Problem\nmulti-processor인 경우, interrupt enable 과 disable로 해결되지 않는다. CPU 한 쪽의 interrupt를 막았어도, 다른 CPU가 남아있기 때문이다. Solution\n해결책 1: 한 번에 하나의 CPU만이 kernel에 들어갈 수 있도록 하는 방법 해결책 2: shared data in kernel에 접근할 때마다 이 데이터에 대해 lock 과 unlcok을 하는 방법 kernel 전체를 하나의 lock으로 막고, kernel에서 나올 때는 unlock 한다. 4. Critical section problem 4.1 Critical section(임계구역)이란?? 각 process가 shared data에 접근하기 위해 가지고 있는 code\n4.2 Critical section problem이란 무엇인가?? Problem 2개 이상의 process가 shard data를 동시에 사용하기를 원하는 경우, 각 프로세스의 critical section을 통해서 접근해야 한다. A process가 critical section에 있을 때 = 공유 데이터에 접근하는 코드를 실행하고 있을 때, A process의 CPU 할당 시간이 끝나서 다른 process에게 CPU를 넘겼다. 하지만, A process가 critical section에 있기 때문에, 다른 process가 CPU를 받아도 critical section에 들어갈 수 없고, 대기해야 한다. 이를 Critical section problem 이라 한다. 4.3 SW 해결법의 충족 조건 3가지(requirements) 가정(Assumption)\n모든 process의 수행 속도는 0보다 크다. process들 간의 상대적인 수행 속도는 가정하지 않는다. 첫 번째 requirement: Mutual Exclusion\nprocess P_i가 critical section 부분을 수행 중이면 다른 모든 process들은 그들의 critical section에 들어가면 안된다. 두 번째 requirement: Progress\n아무도 critical section에 있지 않은 상태에서 critical section에 들어가고자 하는 process가 있으면 critical section에 들어가도록 해야한다. 첫 번째 requirement의 부작용으로 critical section에 어떤 process도 들어가지 않은 상황이 발생한다. 세 번째 requirement: Bounded waiting\nProcess가 critical section에 들어가려고 요청한 순간부터 그 요청이 허용될 때까지 다른 process들이 critical section에 들어가는 횟수에 한계가 있어야 한다. 횟수 한계가 없으면 starvation 문제가 발생한다. 4.4 위 조건을 해결하기 위한 SW solution: Peterson\u0026rsquo;s Algorithum SW 방법으로 해결하기 위한 code의 일반적인 구조 1 2 3 4 5 6 do { entry section # 다른 process는 못 들어오게 shared data를 lock 하는 code critical section # shared data에 접근하려는 코드 exit section # 다 처리 후, 다른 process가 들어오도록 unlock하는 코드 remainder section # 못 들어온 process를 의미하는 코드 } while(1) process들은 수행의 동기화(synchronization)을 위해 몇 몇 변수를 공유할 수 있다.\nsynchronization varible Algorithum이 필요한 이유\n고급 언어는 단일 instruction이 아니기 때문에, instruction 수행 중 CPU를 빼앗길 수 있기 때문이다. 그래서 이를 방지하고자 알고리즘으로 구현한다. Synchronization variables(동기화 변수)\n1 2 boolean flag [2] # process 0과 1의 flag initially flag [모두] = false; # no one is in Critical Section Process Pi가 CPU를 잡고 있는 상황 1 2 3 4 5 6 7 8 9 10 11 do { flag [i] = true; # critical section에 들어가겠다는 의미 turn = j; # turn을 상대방 turn을 바꾼다. # 상대방이 깃발을 들고 있고, 이번이 상대방 차례인 조건을 만족하면 기다린다. while (flag [j] \u0026amp;\u0026amp; turn == j) critical section flag [i] = false; # 깃발을 내린다. remainder section } while (1) 모든 요구 조건들을 만족하지만, 그래도 문제점이 존재한다. busy waiting (= spin lock): 계속 CPU와 memory의 할당 시간을 쓰면서 기다리는 현상 while 문을 돌면서( spin ) 계속 lock 을 걸어서 상대방이 못 들어온다. A process가 critical section에 들어가 있는 상태에서 B process가 CPU를 받아서 작동할 때, B process의 CPU 할당 시간 동안 while문이 만족되는지 체크한다. 하지만, A process가 CPU를 잡아서 조건을 바꿔줘야 B process가 들어올 수 있다. 그래서 이를 busy waiting이라 한다. 4.5 위 조건을 해결하기 위한 HW solution Synchronization HW\nHW 적으로 Test \u0026amp; modify 를 atomic 하게 수행할 수 있도록 지원하는 경우, 앞의 문제는 간단히 해결된다.\nHW 적으로 lock을 읽고 setting하는 작업을 말한다. atomic instruction이란??\n실행 중간에 간섭받거나 중단되지 않는다. 같은 메모리 영역에 대해 동시에 실행되지 않는다. Test_and_set (a)\na라는 데이터를 읽은 후, 1로 쓰는 Instruction 읽는 작업과 쓰는 작업을 동시에 지원하는 HW가 있다면 쉽게 해결할 수 있다. Mutual exclusion with Test \u0026amp; Set\n1 2 3 4 5 6 7 8 9 10 Synchronization variable: boolean lock = false; # 다른 process가 lock이 걸려 있는지 확인 Process Pi do { while(Test_and_Set(lock)); critical section lock = false; # lock에 0 할당 remainder section } lock = false : critical section에 아무도 안들어간 상태 들어가고 나서, Test_and_Set에 의해 lock = True로 바뀌면서 lock 이 걸린다. lock = true: critical section에 프로세스가 들어간 상태 들어가지 못 하고, 계속 while문을 돈다. critical section에서 나오면서 lock = false로 재설정하여 while문에서 돌고 있는 process가 들어오게 한다. 5. Semaphores 5.1 Semaphores 란?? 공유자원을 얻고 반납하는 작업을 위해서 lock \u0026amp; unlock 작업을 도와주는 추상 자료형\n추상화\n세부 구현으로부터 분리하여 개념을 일반화시키는 것 what은 정의하지만, 언어를 사용하여 어떻게 구현할지 How는 정의하지 않는다. 추상 자료형\n추상화를 통해 얻어낸 자료형 구성: object + operation operation의 구현은 system 마다 다르다. atomic instruction이란??\n실행 중간에 간섭받거나 중단되지 않는다. 같은 메모리 영역에 대해 동시에 실행되지 않는다. Semaphores S\n위 SW와 HW 알고리즘들 방식을 추상화시켜, 보다 효율적으로 관리한다.\ninteger variable (=Semaphore variable)\nsemaphore variable = 자원의 갯수 ex) semaphore variable = 5: 자원의 갯수가 5개라는 의미 자원을 획득하는 연산을 사용하면 자원의 갯수는 감소 자원을 반납하는 연산을 사용하면 자원의 갯수는 증가 정의된 2가지 atomic operation: P, V\nSemaphore variable을 가지고 수행하는 연산\nP(S) operation: 공유 데이터 자원을 획득하고 lock을 거는 연산\n1 2 3 4 5 6 // S가 음수라는 건 자원이 없다는 걸 의미한다. // 자원이 없기 때문에, while문에서 계속 반복하며 기다린다. while(S \u0026lt;= 0) do no-op; // 자원을 획득하여 P 연산을 시작하므로, S 값을 1 감소시킨다. S--; V(S) operation: 공유 데이터 자원을 다 사용하고 나서 반납하고, unlock하는 연산\n1 2 3 // operation 사용이 끝나면 V 연산을 하여 S 값을 1 증가시킨다. S++ Semaphore의 문제점\nwhile문에서 계속 기다리기 때문에 busy \u0026amp; wait 문제가 존재한다. 5.2 Criticall section of n process critical section에 semaphore 사용하기\nmutex = mutual exclusion 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Synchronization variable semaphore mutex: # initally 1 Process Pi: do { # 진입할 때 사용하는 연산. 이 조건에 만족하면 critical section에 진입하고 semaphore 감소, 그렇지 않으면 대기. P(mutex): critical section V(mutex): # 빠져나올 때 사용하는 연산으로, semaphore 증가 remainder section } while(1) busy-wait(spin lock) 방식은 CPU를 할당받았지만, while문에서 대기하는 걸로 할당시간을 낭비하기 때문에 효율적이지 못하다. 그래서 block \u0026amp; wake up (=sleep lock) 방식으로 구현한다. shared data를 쓰고 있는 process가 criticial section 실행을 완료할 때까지, 대기 중인 process는 block 상태에 있어서 CPU를 얻지 못하고, 사용 중이던 process가 데이터를 내놓으면 block 상태에 있는 process는 wake up 하여 ready queue에 들어와서 대기하는 방식 5.3 Block \u0026amp; Wakeup implementation Semaphore 정의 1 2 3 4 typeef struct { int value; # semaphore를 의미 struct process *L; # queue for process wait } semaphore; Block \u0026amp; Wakeup\nBlock kernel은 block을 호출한 process를 suspend 시킨다. 이 process의 PCB를 semaphore에 대한 wait queue에 넣는다. Wake up block state인 process P를 wake up 이 process의 PCB를 ready queue로 옮긴다. 정의된 Semaphore 연산\nS: semaphore variable\nP(S): resource 획득 연산\n1 2 3 4 5 6 7 S.value --; # 자원을 획득하기 때문에 감소 if (S.value \u0026lt; 0 ) # 음수이면 들어가지 못 한다. { # 음수면 이 프로세스를 queue에서 대기하도록 추가한다. 그 후, block로 둔다. add this process to S.L; block } V(S): resource 반납 연산과 이 자원을 기다리면 잠든 프로세스를 깨우는 연산 1 2 3 4 5 6 7 8 S.value ++; # 자원을 내놓았는데도 0이거나 음수라는 건, 어떤 프로세스가 P 연산에 의해 block 상태임을 의미 if (S.value \u0026lt;= 0 ) { # queue에서 제거한다. remove this process to S.L; wake(P); } 5.4 Busy-wait VS Block \u0026amp; wake-up critical section의 길이에 따라 달라진다.\ncritical section의 길이가 긴 경우\nblock / wakeup이 필수 오랫 동안 풀지 않은 lock을 풀기 위해 CPU를 얻어도 계속 while문에서 대기하는 게 길기 때문이다. critical section의 길이가 짧은 경우\nblock/wakeup overhead가 busy-wait overhead보다 더 커질 수 있다. 일반적으로는 block/wakeup 방식이 더 좋다. 5.5 Two types of semaphores Counting semaphores and Binary semaphores (=mutext)\nAttribute Counting semaphore Binary semaphore resource resource \u0026gt;= 0 resource = 1 purpose resource counting mutext(lock / unlock) 5.5 Semaphore 주의사항: Deadlock and Starvation 5.5.1 Deadlock 둘 이상의 process가 서로 상대방에 의해 충족될 수 있는 event를 무한히 기다리는 현상\n어떤 일을 하기 위해서, S와 Q를 모두 획득해야지만 일할 수 있고, S, Q를 모두 반환한다. S와 Q: 서로 배타적으로 사용할 수 있는, 1로 초기화된 semaphore - Process 모두 하나씩 차지한 상황 - P0가 S를 먼저 작업하다가 CPU를 빼앗겨 P1이 CPU와 Q semaphore 를 얻어 작업한다. - 그런데, 상대방의 것을 서로 요구한다. - 하지만, 서로 가지고 있기 때문에, 영원히 기다려야 한다. - 왜냐하면 다 사용하고 나서 반환하기 때문이다. - 이 문제를 `Deadlock` 이라 한다. Solution - 서로 다른 프로세스여도 같은 순서로 정한다. - Q를 획득하려면 S를 먼저 획득하라는 의미 5.5.2 Starvation infinite blocking이라 하며, process가 suspend된 이유에 해당하는 semaphore queue에서 빠져나갈 수 없는 현상\n특정 process 자원을 독점하여 나머지 프로세스가 자원을 얻지 못하고 무한히 기다리는 현상으로 Deadlock과 유사하지만, 다르다. Reference kocw 이화여자대학교 운영체제 - 반효경 교수 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_08_%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4_%EB%8F%99%EA%B8%B0%ED%99%94_1/","summary":"Race condition이란 무엇이고, 이 race condition은 OS에서 언제 발생되며, 이를 해결하기 위한 방법으로 SW 방법과 SW 방법에는 무엇이 있는지를 배운다. 또한, Semaphore가 무엇인지 알아본다.","title":"[TIL] Chapter 08: 프로세스 동기화 1"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 이번 chapter 내용인 메모리 관리는 물리적인 메모리 관리로, 주요 내용은 address binding이다. address binding에서의 OS의 역할은 없고, 다 HW가 해야한다. address binding을 할 때마다 OS에게 CPU 제어권을 양도해도, 결국 물리적 메모리에 instruction을 실행하는 건 CPU다. 그래서 HW가 해야한다. 4. 페이징 기법 프로세스의 주소 공간을 동일한 크기의 페이지 단위로 나누어, 물리적 메모리의 서로 다른 위치에 불연속적으로 페이지들을 저장하는 방식\n각 프로세스의 주소 공간 전체를 물리적 메모리에 한꺼번에 올릴 필요 없이, 스와핑을 사용하여 일부만 메모리에 올릴 수 있다.\n또한, 이 메모리는 페이지와 동일한 크기의 프레임(frame) 으로 미리 나누어둔다.\n그래서 빈 프레임이 있으면 메모리의 어떤 위치이든 사용될 수 있다. 이 특징으로 연속할당에서의 동적 메모리 할당 문제와 외부조각 문제가 발생하지 않는다. (외부 단편화 x) 그러나, 프로그램의 크기가 항상 페이지 크기의 배수라는 보장이 없기 때문에 내부조각이 발생할 가능성은 있다. (내부 단편화 o) Problem 01\n물리적 메모리의 불연속적인 위치에 각 페이지를 올리기 때문에, 논리적 주소에서 물리적 주소로 변환하는 작업이 복잡하다. Solution 01\n위 문제에 대한 해결책으로 페이지 테이블(page table) 을 가진다. page table이 사용하는 주소 변환기법에 대해 알아보자. 4.1 주소 변환(address translation) 기법 page table에는 각 page마다 frame 주소가 mapping되어 있다.\nlogical address에서 physical address로 변환하는 구체적인 과정은 다음과 같다.\np = 페이지 번호: page table 접근 시 인덱스(index)로 사용 d = 페이지 offset\n-\u0026gt; 각 index의 항목(entry)에는 그 페이지의 물리적 메모리상의 기준 주소(base address)인 시작위치가 저장되어 있다.\n-\u0026gt; page table에서 위에서 p 번째를 찾으면 frame 번호(f)가 나온다.\n-\u0026gt; 이렇게 해서 logical address에서 physical address로 바뀐다. 4.2 페이지 테이블의 구현 page table이란? paging 기법에서 주소 변환을 하기 위한 자료 구조로, 물리적 메모리에 위치한다. page table에 접근하기 위해 2개의 레지스터를 사용한다. page table에 접근하기 위한 2개의 레지스터는 다음과 같다.\n페이지 테이블 기준 레지스터(page-table base register, PTBR): 물리적 메모리 내에서의 페이지 테이블의 시작 위치 페이지 테이블 길이 레지스터(page-table length register, PTLR): 페이지 테이블의 크기를 보관 Problem\n페이징 기법에서 메모리 접근 연산은 총 두 번 이뤄진다. 첫 번째: 주소 변환을 위해 메모리에 있는 페이지 테이블에 접근하기 두 번째: 변환된 주소로 실제 데이터에 접근하기 즉, 두 번 접근해야 하는 오버헤드가 뒤따른다. Solution: TLB\nTLB란? Translation Look-aside Buffer 의 약어로, 테이블 접근 오버헤드를 줄이고, 메모리 접근 속도를 높이기 위한, 고속 주소 변환용 하드웨어 캐시 page table에서 빈번히 찾는 일부 entry를 저장하고 있다. TLB mechanism CPU가 논리적인 주소를 주면 page table보다 먼저 TLB를 검색한다. TLB 저장된 정보를 통해서 주소 변환이 가능한지 확인한다. TLB에 저장되어 있다면 TLB를 통해서 바로 주소 변환을 한다. 이 경우, 메모리에 한 번만 접근한다. 저장되어 있지 않다면 page table을 통해서 일반적인 주소 변환을 실행한다. TLB의 문제점\npage table의 경우 page 번호만큼 떨어진 항목에 곧바로 접근해 대응되는 프레임 번호를 얻는다. 하지만, TLB의 경우 해당 페이지에 대한 주소 변환 정보가 TLB에 있는지 확인하기 위해 TLB의 모든 항목을 다 찾아봐야 하는 오버헤드가 발생한다. Associative register(연관 레지스터)\n위의 언급한 오버헤드를 줄이기 위해 병렬 탐색(parallel search)이 가능한 연관 레지스터(associative register)를 사용한다. Parallel search: TLB 내의 모든 항목을 동시에 탐색할 수 있는 기능 page table은 각 process마다 논리적인 주소 체계가 달라서, 각 프로세스마다 존재한다.\n그래서, TLB도 각 process마다 다르게 존재한다. 4.3 계층적 페이징 2개 이상의 page table을 통해서 물리적 메모리에 접근하는 기법으로, 각 페이지를 다시 페이지화시키는 기법\n4.3.1 Twp-level page table이란??? 2단계 페이징 기법(Two-level page table)은 outer-page table과 inner-page table을 통해서 Physical memory에 접근한다. 4.3.2 Two-level page table을 사용하는 이유 현대의 컴퓨터는 address space가 매우 큰 프로그램을 지원한다.\n컴퓨터 시스템에서의 K, M, G\nK = 2^(10) = Kilo M = 2^(20) = Mega G = 2^(30) = Giga 32 bit address 사용 시: 2^(32) byte (= 4G byte)의 주소 공간\n페이지의 크기가 4KB일 때, 4GB / 4KB = 1M 개의 page table entry(항목)이 필요\n페이지의 항목이 4 byte 라면 한 프로세스 당 페이지 테이블을 위해 1M x 4byte = 4MB 크기의 메모리 공간이 필요하다.\n이런 상황에서 왜 2단계 페이징 기법을 사용하는가??\npage table이 2개라서 공간 낭비일 것 같지만, 다음과 같은 이유로 효과가 더 크기 때문에 사용한다. 프로그램의 대부분은 방어용 코드로 주로 사용하는 페이지 수는 적다. 그래서, 사용되지 않는 주소 공간에 대해서는 outer page table의 항목을 NULL로 설정하며, 여기에 대응하는 inner page table을 생성하지 않는다. 그 결과, page table의 공간을 줄일 수 있기 때문에, 속도가 느려도 사용한다. 사용하지 않는 주소 공간에 대해서 outer page table에 생성하는 이유는 page table의 자료구조 특성상 index로 작용하기 때문이다. 4.3.3 Two-level page table의 구성과 갯수, 크기 계산 logical address의 구성\ntwo level 이므로, 두 종류의 페이지 번호(P1,P2) 페이지 오프셋(d) P1: outer page table의 index P2: inner page table의 index outer page table의 entry 하나 당 inner page table이 하나 만들어진다.\ninner page table 하나의 크기가 page 크기와 동일하다.\npage table entry 하나의 크기가 4 byte 라고 했는데, 그러면 entry 갯수는 1K 개다.\npage 크기가 4KB 이고, 32bit 주소체계라고할 때, page number와 page offset의 크기는 다음과 같다.\npage 크기가 4K = 2^(12) 이므로, 한 페이지를 구분하기 위해서는 page offset은 12bit 가 필요하다. page table entry가 4byte이므로, 내부 페이지 테이블은 1KB = 2^(10) 개의 항목을 가진다. 2^(10)개를 구분하기 위해서는 P2는 10bit 가 필요하다. 그러면 총 32bit 주소체계에서 22bit를 사용했으므로, P1에는 10bit 가 할당된다. P1 P2 Page offset 10bit 10bit 12bit 다음과 같은 순서로 찾는다.\n첫 번째 outer page table로부터 P1만큼 떨어진 위치에서 inner page table의 주소 를 얻는다. inner page table은 여러개가 있다. outer page table의 한 entry당 하나의 inner page table이 만들어진다. 두 번째 innter page table로부터 P2만큼 떨어진 위치에서 요청된 페이지가 존재하는 프레임의 위치 를 얻는다. 세 번째 해당 프레임으로부터 d 만큼 떨어진 곳에서 원하는 정보에 접근한다. 4.3.4 multi-level page의 문제점과 해결책 Problem\nprocess의 address space가 커질수록 page table의 크기도 커지므로, 주소 변환을 위한 메모리 공간 낭비 점점 심각해지기 때문에, 다단계 페이지 테이블이 필요.\n이에 따라 공간은 절약할 수 있지만 메모리 접근시간이 크게 늘어나는 문제가 발생.\nSolution: TLB\nTLB 와 함께 사용하여 메모리 접근 시간을 줄일 수 있고, 다단계 page table을 사용하여 메모리 공간의 효율적 사용 효과는 매우 크다. 4.4 메모리 보호(Memory Protection) 메모리 보호를 위해 page table의 각 entry마다 보호 비트(protection bit)와 유효-무효 비트(valid-invalid bit)를 둔다.\n보호 비트(Protection bit): 각 page에 대한 연산 접근 권한을 설정하는데 사용\nread / write / read-only 유효-무효 비트(Valid-Invalid bit): 해당 페이지의 내용에 접근을 허용하는지 결정\nvalid 로 세팅: 해당 메모리 프레임에 그 페이지가 존재 -\u0026gt; 접근 허용 invalid 로 세팅 -\u0026gt; 유효한 접근 권한 X 첫 번재 경우, 프로세스가 그 주소 부분을 사용 X 두 번째 경우, 해당 페이지가 물리적 메모리에 올라있지 않고, 백킹스토어에 존재 4.5 역페이지 테이블(Inverted page table) page table이 매우 큰 이유\n모든 process 별로 그 logical address에 대응하는 모든 page에 대해 page table entry를 다 구성해야 하기 때문이다. 대응하는 page가 메모리에 존재하든 안하든 page table에는 entry로 존재 Inverted page table\nlogical address에 대해 page table을 만드는 것이 아닌, physical address에 대해 page table을 만드는 것\n시스템 전체에(system-wide) page table을 하나만 두는 방법\nphysical address는 1개이기 때문에, physical address에 대해 page table을 만든다는 건 하나만 만드는 걸 의미한다. 각 프로세스마다 page table을 두는 게 아니다. page table entry 수 = Physical memory의 page frame 수\nPhysical memory의 page frame 하나당 page table에 하나의 entry를 둔 것 page table entry 수 =! process의 page 갯수 각 page table entry는 각각의 물리적 메모리의 page frame이 담고 있는 내용 표시\nprocess의 id(pid), logical address(p) 어떤 process의 p번째 페이지인지를 확인하기 위해 pid를 저장해야 한다. 단점: 테이블 전체를 탐색해야 한다.\n역페이지 테이블에 주소 변환 요청이 들어오면, 그 주소를 담은 페이지가 물리적 메모리에 존재하는지 여부를 판단하기 위해, 페이지 테이블 전체를 다 탐색해야한다. physical address를 보고 logical address로 바꾸는 것이기 때문에, 목적에 맞지 않다.\n그러면 이 table을 통해서 어떻게 전환할 것인가??\n논리주소에 해당되는 P가 물리적 메모리 어디에 올라가는지를 찾을라면 이 entry를 다 찾아서 해당되는 P가 F 번째에 나오면, f번째에 있는 물리적 프레임에 있다는 걸로 파악한다. table의 장점인 index를 통해서 찾을 수 있는 장점이 없다. 그래서 시간이 아닌 단지 공간을 줄이기 위해서 사용되는 것이다.\n해결책: associative register 사용한다.\n연관 레지스터를 사용하여 병렬탐색을 하여 시간적 효율성을 높인다. 단, 비용이 비싸다. 4.6 공유 페이지(Shared page) shared code(공유 코드)를 담고 있는 페이지\nshared code란??\n메모리 공간의 효율적인 사용을 위해, 여러 프로세스에서 공통으로 사용되도록 작성된 코드 재진입 가능코드 (re-entrant code) 또는 순수 코드(pure code)라 한다. read-only 특성을 가진다. -shared memory 기법에서는 read - write다. 프로세스 간 공유 페이지이므로 물리적 메모리에 하나만 적재하여 효율적으로 사용한다.\n하지만, 이 특성으로 모든 프로세스의 logical address space 의 동일한 위치에 존재해야하는 제약점이 있다.\n왜냐하면 logical address에서 실행 시작하여 physical address에 올라갈 때, logical address에 연결되기 때문이다. Address binding 내용에서 이미지를 참고하자. private page(사유 페이지)\n공유 페이지와 대비되는 개념으로, 프로세스끼리 공유하지 않고 독자적으로 사용하는 페이지 사유 페이지는 해당 프로세스의 논리적 주소 공간 중 어더한 위치에 있어도 무방하다. 5. 세그먼테이션 프로세스 가상 메모리를 의미 단위인 segment로 나눠서 물리적 메모리에 올리는 기법\n프로세스의 주소 공간을 크기 단위가 아닌 의미 단위(logical unit)로 나눈 것이기 때문에, 크기가 균일하지 않다.\nmain (), function, global variables, stack\u0026hellip; 그래서 부가적인 관리 오버헤드가 뒤따른다.\nsegment 크기 기준\n프로그램은 의미 단위인 여러 개의 segment로 구성한다. 작게는 프로그램을 구성하는 함수 하나 하나를 segment로 정의한다. 크게는 프로그램 전체를 하나의 세그먼트로 정의한다. 일반적으로는 code, data, stack 부분이 하나씩의 segment로 정의된다. 5.1 Segmentation Architecture 5.1.1 Logical address 두 가지 [s: segment-number, d: offset]로 구성\n5.1.2 Segment table Segmentation에서 주소 변환을 위해 사용하는 table\n이 table은 기준점(base) 와 한계점(limit) 을 가진다.\n기준점: 물리적 메모리에서 각 세그먼트의 시작위치를 의미. 한계점: 각 세그먼트의 길이를 의미. 페이징 기법과는 달리 각 segment의 길이가 균일하지 않기 때문이다. segment의 갯수에 따라 table entry 수가 결정된다.\nCPU 안에 주소 변환을 위한 2개의 레지스터\nSegment Table Base Register(STBR) : 물리적 메모리에서의 segment table의 시작위치\nSegment Table Length Register(STLR) : 프로세스의 segment의 길이와 갯수\nLogical address를 physical address로 변환하기 위한 두 가지 사항\n첫 번째: segment number(s)가 STLR에 저장된 값보다 작은 값인지 확인 아니라면 trap 발생시키기 두 번째: 논리적 주소의 오프셋 값(d)이 세그먼트의 길이보다 작은 값인지 확인 세그먼트 테이블의 한계점과 요청된 논리적 주소의 오프셋값을 비교해 확인한다. d가 더 크다면 trap 발생시키기 균일하지 않은 segment로 인한 paging과의 차이점들\n첫 번째 차이 paging 기법에서는 크기가 균일하기 때문에, offset의 크기가 page 크기에 의해서 결정된다. segment 기법에서는 offset 크기가 segment 크기를 제한하는 요소다. 두 번째 차이 paging 기법에서는 크기가 균일하기 때문에, 시작 주소가 frame 번호다. segment 기법에서는 크기가 다르기 때문에, 이 segment가 어디서 시작되는지 정확한 byte 단위 주소로 알려줘야 한다. 장점: paging과 달리 의미 단위라서 segment의 갯수가 상대적으로 많이 적다.\n그래서 table로 인한 메모리 낭비를 비교하자면 일반적인 시스템에서는 적다. 5.2 세그먼테이션에서의 보호비트와 유효비트 보호 비트(protection bit): 각 세그먼트 별로 가지고 있어서 각각에 대해 읽기/쓰기/실행 등의 권한이 있는지 나타낸다. 유효 비트(valid bit): 각 세그먼트의 주소 변환 정보가 유효한지, 즉 해당 세그먼트가 현재 물리적 메모리에 적재되어 있는지 나타낸다. valid bit = 0 : illegal segment 5.3 공유 세그먼트(shared segment) 공유 세그먼트(shared segment)\n여러 프로세스가 특정 세그먼트를 공유해 사용한다. 이 세그먼트를 공유하는 모든 프로세스의 주소 공간에서 동일한 논리적 주소에 위치 해야 한다. 장점: 공유(sharing)와 보안(protection) 측면에서 세그먼테이션\n의미 단위로 나눠져 있어서 페이징 기법보다 훨씬 효과적이다. -\u0026gt; 5.2 와 연결하기 왜냐하면 크기 단위로 나누다 보면 공유 코드와 사유 데이터 영역이 동일 페이지에 공존하는 경우가 발생할 수 있기 때문이다. 그래서 어떤 권한을 줘야할지 결정하기가 어렵다. 5.4 세그먼트 할당 방식 세그먼트를 가용 공간에 할당하는 방식 세그먼트 크기가 균일하지 않기 때문에, 외부 단편화는 존재하지만 내부 단편화는 존재하지 않는다. 그래서 동적 메모리 할당 문제가 존재한다. 이 문제에 대해서는 first-fit 방식과 best-fit 방식을 사용한다. 6. 페이지드 세그먼테이션 segmentation을 기반으로, 각 segmentation을 크기가 동일한 page로 구성\n6.1 pure segmentaton과의 차이점 segment-table entry 가 segment의 base address 를 가지고 있는 것이 아닌, segment를 구성하는 page table 의 base address 를 가지고 있다. 6.2 Paged segmentation의 logical address 두 가지 [s: segment-number, d: offset]로 구성 6.3 Paged segmentation의 특징과 장점 물리적 메모리에 적재하는 단위: page\naddress binding을 위해 외부의 segment table과 내부의 page table을 이용한다.\n장점: segmentation에서의 외부조각 문제와 paging 기법의 접근 권한 보호 문제를 해결\n6.4 address binding 과정 설명 첫 번째\n논리적 주소의 상위 비트인 segment number(s)로 segment table의 해당 항목에 접근 두 번째\n이 segment table entry = segment 길이 + segment의 page table 시작 주소 세 번째\n세그먼트 길이를 넘어서는 메모리 접근 시도인지 여부를 체크하기 위해, segment length와 logical address의 하위 비트 offset(d) 값과 비교.\nIf segment lenth \u0026lt; offset: 유효 X -\u0026gt; trap 발생.\nIf segment lenth \u0026gt; offset: offset 값을 다시 상위 하위 비트로 나눔.\n나눠진 상위비트(p): 그 segment 내에서 page number를 의미. 나눠진 하위비트(d\u0026rsquo;): page 내에서의 변위를 의미. 네 번째\nsegment table entry에 있는 segment의 page-table base를 기준으로, p만큼 떨어진 page table entry로부터 물리적 메모리의 page frame 위치(f)를 얻음. 다섯 번째\n이 얻어진 위치에서 d\u0026rsquo;만큼 떨어진 곳 = 물리적 메모리 주소. page table for segment s 의 entry 갯수는 segment table의 segment 길이를 보면 알 수 있다.\nReference 운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_07_%EB%A9%94%EB%AA%A8%EB%A6%AC%EA%B4%80%EB%A6%AC_2/","summary":"불연속 할당 방법인 pagin 기법, segmentation 기법, paged segmentation 기법에 대해 알아본다.","title":"[TIL] Chapter 07: 메모리 관리 2"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 이번 chapter 내용인 메모리 관리는 물리적인 메모리 관리로, 주요 내용은 address binding이다. address binding에서의 OS의 역할은 없고, 다 HW가 해야한다. address binding을 할 때마다 OS에게 CPU 제어권을 양도해도, 결국 물리적 메모리에 instruction을 실행하는 건 CPU다. 그래서 HW가 해야한다. 1. 주소(address) 바인딩 1.1 주소란?? 서로 다른 위치를 구분하기 위해 사용하는 일련의 숫자 크게 논리적 주소와 물리적 주소로 나뉠 수 있다. Memory는 주소를 통해 접근하는 저장장치다. 컴퓨터 시스템은 32bit 혹은 64bit의 주소체계를 사용하는데, 32bit는 2^(32) 가지, 64bit는 2^(64) 가지의 서로 다른 메모리 위치를 구분할 수 있다. byte 단위로 메모리 주소를 부여한다. 1.2 논리적 주소, 물리적 주소 논리적 주소(logical address, virtual address)란?\n프로세스마다 독립적으로 가지는 주소 공간 각 프로세스마다 0번지부터 시작 CPU가 보는 주소는 logical address Why? 물리적 메모리에 올라오는 위치는 달라도 코드 상의 내용은 compile 시 내용. 물리적 주소(physical address)란?\n메모리에 실제로 올라가는 위치 물리적 주소의 낮은 주소 영역에는 kernel이 올라간다. 물리적 주소의 높은 주소 영역에는 user process들이 올라간다. 프로세스가 실행되기 위해서\n해당 프로그램이 물리적 메모리에 올라가 있어야 한다. 해당 논리적 주소가 물리적 메모리의 어느 위치에 매핑되는지 확인해야 한다. 1.3 주소 바인딩(address binding) logical address를 physical address로 연결시켜서, physical address를 결정하는 작업\nSymbolic address \u0026ndash;(compile)\u0026ndash;\u0026gt; Logical address \u0026ndash;(address binding)\u0026ndash;\u0026gt; Physical address 주소 바인딩 방식 3가지: 물리적 메모리 주소가 결정되는 시기에 따라 분류된다.\n컴파일 타임 바인딩(compile time binding) 로드 타임 바인딩(load time binding) 실행시간 바인딩(execution time binding or run time binding) 방식 이름 compile time binding load time binding run time binding 시기 컴파일 시 프로그램 실행이 시작 시 (변경 가능 X) 프로그램 실행이 시작 시, (변경 가능 O) swapping 효과 좋지 않음 좋지 않음 좋음 Compile time binding\n컴파일 시, 논리적인 주소와 물리적인 주소 다 생성된다. compiler는 절대 코드 를 생성한다. 그래서 program이 올라가 있는 물리적 메모리의 시작위치를 변경할려면 컴파일을 다시 해야 한다. 물리적 주소의 0번지부터 시작한다. 현대의 시분할 컴퓨터 환경에서는 잘 사용하지 않는 기법 Load time binding\n컴파일 시에는 논리적인 주소만 결정된다. 이를 실행하고 나서, 메모리가 비어있는 곳부터 올린다. 로더(loader)의 책임 하에 물리적 메모리 주소 부여 Loader: user program을 memory에 적재시키는 프로그램 compiler가 재배치 가능 코드 를 생성한 경우 가능 Run time binding\nLoad time binding 처럼 실행 시, physical address가 생성된다. 실행을 시작한 후에도 물리적 메모리상의 위치(물리적 주소)를 옮길 수 있는 방식 CPU가 주소 참조 시, address mapping table을 이용해 원하는 데이터가 물리적 메모리의 어느 위치에 존재하는지 확인한다. MMU(Memory Management Unit) 라는 하드웨어적 지원이 필요 1.4 MMU 기법(MMU scheme) 기준 레지스터를 사용하여 logical에서 physical address로 mapping해주는 HW device\n가정\n프로그램의 주소 공간이 메모리의 한 장소에 연속적으로 적재되는 걸 가정한다. MMU scheme\n사용자 프로세스가 CPU에서 수행되여 생성해내는 모든 논리적 주소값에 대해 base register(= relocation register) 의 값을 더하여 물리적 주소값을 얻어낸다. base register = CPU가 사용하려는 프로세스의 물리적 메모리 시작 주소 user program\nlogical address 만을 다룬다. 실제 physical address 를 볼 수 없으며, 알 필요가 없다. 예시\nCPU가 논리적 주소: 123번지 정보를 요청 기준 레지스터(=재배치 레지스터): 23000 물리적 주소 = 123 + 23000 = 23123 물리적 주소 23123번지에서 CPU가 요청한 정보를 찾는다. 논리적 주소란 기준 레지스터로부터 얼마나 떨어져 있는지를 나타내는 것 동일한 논리적 주소\n프로세스는 각 자신만의 고유한 주소 공간을 가진다. 그래서 동일한 논리적 주소라고 할 지라도, 서로 다른 내용을 담는다. MMU 기법에서 프로세스가 바뀔 때마다 기준 레지스터의 값을 바뀌는 프로세스에 해당되는 값으로 재설정한다. 메모리 보안\nProblem 가상 메모리에 기준 레지스터를 더했을 때, 해당 프로세스의 주소 공간을 벗어나는 경우, 다른 프로세스 영역에 침범하거나, kernel 영역을 변경해 치명적인 결과를 초래할 수 있다. Solution 한계 레지스터(limit register) 를 사용하여, 프로세스 자신의 주소 공간을 넘어서는 메모리 참조를 하는지 확인한다. 한계 레지스터(limit register): 논리적 주소의 범위 벗어날 경우, trap을 발생시켜 해당 프로세스를 강제종료시킨다. 2. 메모리 관리와 관련된 용어 2.1 동적 로딩(Dynamic loading) 다중 프로그래밍 환경에서 메모리를 효율적으로 사용하기 위한 기법 프로세스의 주소 공간 전체를 메모리에 다 올려놓는 게 아닌, 해당 부분이 불릴 때에마다 그 부분만 메모리에 적재하는 방식: 연속 할당에 해당되지 않는다. loading: 물리적 메모리로 올리는 것 부분적으로만 올리는 이유 실제 프로그램의 코드 중 상당 부분 = 가끔씩 사용하는 방어용 코드 -\u0026gt; 주소 공간 전체 loading -\u0026gt; 메모리 낭비 초래 동적 로딩 -\u0026gt; 더 많은 프로그램 로딩 가능 -\u0026gt; 메모리 이용 효율성 향상 운영체제 지원 없이 개발자가 코드로 구현 가능하고, OS는 라이브러리를 통해 지원 가능 2.2 중첩(overlays) 메모리보다 큰 프로세스를 실행하기 위해서, 프로세스의 주소 공간을 분할해 실제 필요한 부분만을 메모리에 적재하는 기법\n중첩과 동적 로딩의 차이점: 목적 동적 로딩의 목적: 메모리에 multi-process를 실행하기 위한 용도 중첩의 목적: single-process를 실행하기 위한 환경에서 메모리 용량보다 큰 프로세스를 실행하기 위한 용도 운영체제의 지원 없이 프로그래머가 직접 구현해야 한다. 2.3 스와핑(Swapping) 프로세스의 주소 공간 전체를 메모리에서 backing store로 쫓아내는 것\n스왑 영역(Swap area)란??\n다른 말로 백킹 스토어(backing store) 라고 한다. 디스크 내의 파일 시스템과는 별도로 존재하는 일정 영역으로, 파일 시스템 은 전원이 나가도 유지되어야 하는 비휘발성 저장공간이지만, 스왑 영역 은 프로세스가 수행 중인 동안에만 디스크에 일시적으로 저장하는 휘발성 영역이다. 프로세스 실행이 종료되면 메모리에서 디스크로 내려놓는다. (swap out) 그리고, 다음과 같은 특징을 가져야 한다. 다수의 사용자 프로세스를 담을 수 있을 만큼 충분히 큰 저장 공간이다. 어느 정도의 접근 속도가 보장되야 한다. Swap in \u0026amp; out\nSwap in: disk -\u0026gt; memory 올리는 작업 Swap out: memory -\u0026gt; disk 내리는 작업 스와핑이 일어나는 과정\n첫 번째: Swapper라 불리는 중기 스케쥴러 에 의해 swap out할 process를 선정.\n선정 기준: priority priority가 낮은 프로세스를 swap out priority가 높은 프로세스를 swap in 두 번째: 선정된 process를 메모리에 올라간 주소 공간 전체 내용을 disk swap area로 아웃시켜서 메모리의 프로세스 수를 조절한다.\n즉, Swapper로 멀티 프로그래밍 정도(degree of multi-programming)를 조절한다.\n메모리에 많은 프로그램이 올라오면 할당되는 메모리 양이 지나치게 적어져, 시스템 전체 성능이 감소되기 때문이다.\nSwap time\nSwap time: swapping에 소요되는 시간 Transfer time: 데이터를 읽고 쓰는 전송 시간 Swap time은 디스크를 탐색하는 것보다 disk sector에서 transfer time이 대부분을 차지한다. 즉, transfer time 은 swap 되는 양에 비례 address binding에 따른 swapping\ncompile time binding \u0026amp; load time binding: 다시 swap in 시, 원래 존재하던 메모리 위치로 다시 올라가야 해서 swapping의 효과가 좋지 않다. runtime binding은 추후 빈 메모리 영역 아무 곳에나 프로세스를 올리기 때문에, swapping으로 인한 효과가 좋다. 2.4 동적 연결(Dynamic linking) 연결(linking)이란??\n목적 파일(object file)과 이미 컴파일된 라이브러리 파일을 묶어서 하나의 실행파일을 생성하는 과정 Object file: 프로그래머가 작성한 source code를 컴파일하여 생성된 파일 정적 연결(static linking)과 동적 연결(dynamic linking)의 차이: 첫 번째\n정적 연결: 프로그래머가 작성한 코드와 라이브러리가 모두 합쳐진 상태에서 실행파일이 생성되는 방식으로, 연결된 상태에서 실행파일을 생성하는 방식\n라이브러리가 프로그램의 실행 파일 코드에 포함되어, 실행파일의 크기가 상대적으로 크다. 동적 연결 : 라이브러리를 포함하지 않는 생성된 실행 파일이 라이브버리 호출 시 , 연결이 이뤄지는 방식\n그래서 라이브러리의 위치를 찾기 위해 라이브러리 호출 부분에 stub 이라는 작은 코드를 둔다. 이 stub을 통해 해당 라이브러리 루틴이 메모리에 이미 존재하는지 먼저 살펴본다. 메모리에 이미 존재 -\u0026gt; 그 메모리 위치에서 직접 참조 메모리에 없음 -\u0026gt; 디스크에서 읽어옴 정적 연결(static linking)과 동적 연결(dynamic linking)의 차이: 두 번째\n정적 연결: 첫 번째 차이점으로 인해 동일한 라이브러리를 각 프로세스가 개별적으로 메모리에 적재해야 하므로, 물리적 메모리가 낭비된다.\n동일한 라이브러리 코드여도 각 프로세스의 주소 공간에 독자적으로 존재하는 코드이므로 별도의 적재가 필요하다. 그 결과, 메모리 낭비가 심하다. 동적 연결: 라이브러리를 호출하면 되므로 메모리에 한 번만 적재하여 낭비 X\n공용으로 쓰는 라이브러리를 shared library 라 한다. Summary\n특징 정적 연결 동적 연결 연결 시기 실행 파일 생성 전 실행 파일 생성 후, 호출 적재 횟수 각 프로세스 개별적으로 메모리에 한 번만 실행 파일에 라이브러리 포함 유무 O X 메모리 낭비 발생 O X 3. 물리적 메모리의 할당 방식 물리적 메모리 할당 방식과 사용자 영역 관리 방식은 다음과 같다. 3.1 연속할당(Contiguous allocation) 방식 프로세스를 메모리에 올릴 때, 주소 공간을 여러 개로 분할하지 않고, 메모리의 한 곳에 연속적으로 적재하는 방식\n이에 해당하는 자료구조의 예에는 배열(array) 가 존재한다. 고정분할 방식 과 가변분할 방식 으로 나눠진다. 연속적으로 할당하기 때문에 물리적 메모리 주소로 mapping 하는 게 쉽다. 연속 할당 기법에서는 프로세스의 주소 공간 전체를 담을 수 있는 가용공간을 찾아야 한다. 가용 공간(hole) : 사용되지 않은 메모리 공간으로, 메모리 내의 여러 곳에서 산발적으로 존재할 수 있다. 이 가용공간(hole)은 물리적 메모리 내부에 산발적으로 존재하기 때문에, 효율적으로 관리하기 위해서 운영체제는 사용 중인 공간과 가용 공간에 대한 정보를 각각 유지한다. 3.1.1 고정분할(Fixed partition) 방식 물리적 메모리를 영구적인 분할(partition)로 미리 나누어두고, 각 분할에 오직 하나의 프로세스만을 적재해 실행하는 방식\n이에 따라 다음과 같은 특징을 가진다.\n미리 나누는 분할의 크기는 다 동일할 수도 있고, 다르게 할 수도 있다. 동시에 메모리에 올릴 수 있는 프로그램의 수가 고정되었다. 수행 가능한 프로그램의 최대 크기 또한 제한된다. 외부 조각(external fragmentation)과 내부 조각(internal fragmentation)이 발생한다. 외부 조각과 내부 조각에 대해 알아보자.\n조각 종류 외부 조각 내부 조각 When 프로그램 크기 \u0026gt; 분할 크기 프로그램 크기 \u0026lt; 분할 크기 할당 유무 할당하지 않은 조각 할당된 조각 외부 조각: 프로그램의 크기가 분할 크기보다 커서 프로그램을 적재하지 못하여 발생하는 메모리 공간 하지만, 분할 크기보다 작은 프로그램이 도착하면 이 외부조각에 적재할 수 있다. 내부 조각: 하나의 분할에 프로그램을 적재한 후, 남아서 사용되지 않는 메모리 공간 남은 공간에 충분히 적재할 수 있는 프로그램이 있을지라도, 이미 할당된 조각이므로 다른 프로그램에 할당할 수 없다. 3.1.2 가변분할(Variable partition) 방식 미리 분할시키는 것이 아닌 프로그램이 실행될 때마다 메모리에 순서대로 차곡차곡 쌓는 방식 그래서, 분할의 크기, 개수가 동적으로 변한다. 현대의 컴퓨터가 사용하는 방식 분할의 크기를 프로그램 크기보다 일부러 크게 할당하지 않기 때문에, 내부조각이 발생하지 않는다.\nProblem 1:외부조각\n메모리에 존재하는 프로그램이 종료될 경우, 중간에 빈 공간이 발생하는데, 이 공간이 새로 시작하는 프로그램보다 작을 경우 외부조각이 발생할 가능성이 있다. Solution 1: Compaction (윈도우에서 디스크 조각 모음이 이에 해당되는 방법)\n외부조각 같은 hole을 해결하는 방법으로 컴팩션(compaction) 을 사용한다. Compaction이란??? 물리적 메모리 중에서 프로세스에 의해 사용 중인 메모리 영역을 한 쪽으로 몰고, 가용 공간들을 다른 한쪽으로 모아서 하나의 큰 가용공간을 만드는 방법 메모리 위치를 상당 부분 이동해야 해서 비용이 매우 많이 들기 때문에, 최소한의 메모리 이동으로 얻을려고 한다. 또한, 수행 중인 프로세스의 물리적 메모리 위치를 옮겨야 하므로, 실행 도중 프로세스 주소를 동적으로 바꿀 수 있는 run time binding 방식을 지원하는 환경에서만 수행할 수 있다. Problem 2: 동적 메모리 할당 문제(Dynamic storage-allocation problem)\nsize가 n인 프로세스를 메모리 내 가용 공간 중 어떤 위치에 올릴 지 결정하는 문제 Solution 2: 3가지\n아래 3가지 방법들 중 첫 번째와 두 번째가 속도와 공간 이용률 측면에서 효과적이다. 최초적합(first-fit) 방법 size가 n 이상인 것 중 가장 먼저 찾아지는 hole에 프로세스를 할당하는 방법으로, 시간적인 측면에서 효율적이다. 최적적합(best-fit) 방법 size가 n 이상인 가장 작은 hole을 찾아 새로운 프로그램을 할당하는 방법으로, 모든 hole의 리스트를 탐색하므로 시간적 오버헤드가 발생하지만, 공간적인 측면에서는 효율적이다. 최악적합(Worst-fit) 방법 가장 크기가 큰 hole을 찾아 새로운 프로그램을 할당하는 방법으로, 시간적 오버헤드가 발생하고, 가용 공간을 빨리 소진한다. 3.2 불연속할당(Noncontiguous allocation) 기법 물리적 메모리의 여러 위치에 분산되어 올라가는 메모리 할당 기법\n이를 사용하는 자료구조의 예시로는 연결 리스트 가 있다.\n프로그램을 분할하는 기준에 따라 여러 방법으로 나눠진다.\n페이징(paging) 기법: 동일한 크기로 나누어 메모리에 올리는 기법 세그먼테이션(segmentation) 기법: 크기는 일정하지 않지만, 의미 단위로 나누어 메모리에 올리는 기법 페이지드 세그먼테이션(paged segmentation) 기법: segmentation을 기본으로 한 후, paging 기법으로 나누어 메모리에 올리는 기법 그러면 다음 챕터에서 위 3가지 기법들에 대해 알아보자.\nReference 운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_07_%EB%A9%94%EB%AA%A8%EB%A6%AC%EA%B4%80%EB%A6%AC_1/","summary":"logical address와 physical address를 어떻게 mapping하는지, 메모리 관리와 관련된 용어 4가지에 대해 알아보고, 물리적 메모리의 할당 방식 연속할당과 불연속할당 방식 중 연속할당에 대해 알아본다.","title":"[TIL] Chapter 07: 메모리 관리 1"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 1. Bound process 1.1 CPU란?? CPU(Central Processing Unit): PC(Program Counter)가 가리키는 주소의 기계어 명령을 실제로 수행하는 컴퓨터 내의 중앙처리장치 PC: Program Counter로, 레지스터의 한 종류로서 현재 CPU에서 수행할 프로세스의 코드의 메모리 주소값을 가지고 있다. 1.2 기계어 명령의 종류 CPU에서 수행하는 기계어 명령어의 종류를 알아보자.\n1. CPU 내에서 수행되는 명령어\nAdd 명령어: CPU 내의 레지스터에 있는 두 값을 더해 레지스터에 저장하는 명령어 CPU 내에서만 수행되므로 명령의 수행 속도가 매우 빠르다. 2. 메모리 접근을 필요로 하는 명령어\nLoad 명령어: 메모리에 있는 데이터를 CPU로 읽어들이는 명령어 Store 명령어: CPU에서 계산된 결과값을 메모리에 저장하는 명령어 1번보다 느리지만, 비교적 짧은 시간에 수행 가능하다. 3. 입출력 동반 명령어\n입출력 작업(I/O 작업)이 필요한 경우, 사용하는 명령어 ex) 키보드로부터 입력을 받기, 화면에 출력하기 입출력 수반 명령은 1번과 2번에 비해 대단히 오랜 시간이 걸린다. 입출력 작업은 특권 명령으로 규정해서 user program이 직접 수행할 수 없고, OS를 통해서 서비스를 대행하도록 한다. 각 명령어 수행 속도 비교: 3번 \u0026lt; 2번 \u0026lt; 1번\n특권 명령과 일반 명령으로 분류\n특권 명령: 3번 일반 명령: 1번과 2번 1.3 CPU burst와 I/O burst user program이 실행되는 과정은 CPU 작업 과 I/O 작업의 반복이다.\n즉, CPU burst 와 I/O burst가 번갈아 실행된다.\nCPU burst(버스트): user program이 CPU만 연속적으로 사용하여 instruction만 실행하는 일련의 단계 -\u0026gt; user mode I/O burst(버스트): I/O 요청이 발생해 kernel에 의해 입출력 작업을 진행하는 비교적 느린 단계 -\u0026gt; kernel mode 위 2가지를 I/O 작업을 기준으로 분류해보자.\nCPU burst: program이 I/O를 한 번 완료한 후, 다음 번 I/O를 수행하기까지 직접 CPU를 가지고 명령을 수행하는 일련의 작업\nI/O burst: I/O 작업이 요청된 후, 다시 CPU burst로 돌아가기까지 일어나는 일련의 작업\n1.4 Bound process: CPU \u0026amp; I/O 각 program마다 CPU burst와 I/O burst의 비율이 균일하지 않다.\n그래서 CPU bound process와 I/O bound process로 나눠볼 수 있다.\nCPU bound process: 계산 위주의 jb\nfew very long CPU bursts 입출력 작업 없이 CPU 작업에 소모하는 계산 위주의 프로그램이 해당된다. I/O bound process: CPU를 잡고 계산하는 시간보다 I/O에 많은 시간이 필요한 job\nMany short CPU bursts 대화형 프로그램(interactive prgram)에 해당 즉, 사용자에게 입력을 받아 CPU 연산을 수행하여 그 결과를 다시 출력하는 작업에 해당 1.5 CPU sheduling이 필요한 이유 여러 종류의 process(=job)이 동일한 시스템 내부에서 섞여 있기 때문에, CPU scheduling이 필요하다.\nI/O는 interactive job으로서 적절한 response 필요하다.\nCPU와 I/O 장치 등 시스템 자원을 골고루 효율적으로 사용\n특히, 이 CPU는 한 시스템 내에 하나 밖에 없으므로, 시분할 시스템에서 매우 효율적으로 관리해야 한다.\n대부분의 짧은 CPU burst + 극히 일부분의 긴 CPU burst\n= 대부분 CPU를 오래 사용하기보다는 잠깐 사용하고, I/O 작업을 수행하는 process들이 많다.\n= CPU busrt가 짧은 process는 대부분 대화형 작업이다. = CPU 스케쥴링을 할 때, CPU burst가 짧은 process에게 우선적으로 CPU를 사용할 수 있도록 하는 스케쥴링이 필요\n그래서, I/O bound process의 우선순위를 높이는 것이 바람직한다.\nI/O bound process에게 늦게 주면 사용자는 답답함을 느낀다. 2. CPU 스케쥴러 CPU 스케쥴러란?? ready state에 있는 procese 중에서 이번에 CPU를 줄 프로세스를 결정하는 OS의 code\nHW가 아닌, os의 code 중 이 기능을 하는 부분을 CPU 스케쥴러라 부르는 것이다. CPU 스케쥴링이 필요한 경우\nI/O 요청 system call에 의해 running에서 blocked로 바뀐 경우 Timer interrupt에 의해 running에서 ready로 바뀐 경우 I/O 작업 요청으로 blocked 상태였던 process가 I/O 작업 완료에 의해 device controller가 interrupt 발생하여 ready 상태로 바뀐 경우 running 상태에 있는 프로세스가 종료(terminate)되는 경우 CPU 스케쥴링 방식 2가지: 비선점형(non-preemptive) 과 선점형(preemptive)\n비선점형(preemptive): process가 작업완료 후, 자발적으로 CPU를 반납하는 방식 -\u0026gt; 1번과 4번 선점형(preemptive): CPU를 계속 사용하기 원해도, 강제로 빼앗는 방법 -\u0026gt; 2번과 3번 ex) timer interrupt 3. Dispatcher Dispatcher란?? CPU scheduler에 의해 새롭게 선택된 프로세스가 CPU를 할당받아 작업을 수행하도록 환경설정을 하는 OS의 code\nHW가 아닌, os의 code 중 이 기능을 하는 부분을 CPU 스케쥴러라 부르는 것이다. Dispatcher 과정\n현재 수행 중이던 process context를 이 process의 PCB에 저장한다.\n-\u0026gt; 새로운 process의 PCB를 복원\n-\u0026gt; user mode로 전환하여 CPU를 넘긴다.\n-\u0026gt; 복원된 context의 program counter로 현재 수행할 주소를 찾는다. Dispatch latency (디스패치 지연시간): 디스패치가 하나의 프로세스를 정지시키고 다른 프로세스에게 CPU를 전달하기까지 걸리는 시간\nDispatcher 과정에서 1번부터 3번까지 걸린 시간 context switching의 overhead에 해당 4. 스케쥴링의 성능 척도 스케쥴링의 성능을 평가하기 위해 여러 지표들이 사용된다.\n시스템 관점의 지표: CPU 이용률, 처리량(throughput) 사용자 관점의 지표: 소요시간, 대기시간, 응답시간 시스템 관점의 지표\nCPU 이용률(CPU utilization): 전체 시간 중 CPU가 일을 한 시간\n휴면 상태(idle)에 머무르는 시간을 최대한 줄이는 것이 CPU 스케쥴링의 중요한 목표 처리량(throughput): 주어진 시간 동안 ready queue에서 CPU burst를 완료한 프로세스의 개수\nCPU burst가 짧은 process에게 할당할수록 증가한다. 사용자 관점의 지표\n소요시간(turnaround time): process가 CPU를 요청한 시점부터 자신이 원하는 만큼 CPU를 다 쓰고, CPU burst가 끝날 때까지 걸린 시간\n대기시간(waiting time) + 실제로 CPU를 이용한 시간의 합 대기시간(waiting time): CPU burst 기간 중 process가 ready queue에서 CPU를 얻기 위해 기다린 시간의 합\nCPU burst 동안, CPU를 얻기 잃는 걸 반복한다. 응답시간(response time): process가 ready queue에 들어온 후, 첫 번째 CPU를 획득하기까지 기다린 시간\n사용자 응답하는 대화형 시스템에서 적합한 성능 척도 사용자 관점 지표에서 가장 중요 timer interrupt가 빈번할수록 응답시간 감소 생활 속의 비유: 중국집\n이용률과 처리량 -\u0026gt; 중국집 입장에서의 척도 이용률: 전체 시간 중 주방장이 일한 시간의 비율 처리량: 주방장이 주어진 시간 동안 몇 명의 손님에게 요리를 만들어주었는지 중국집 입장에서는 주방장을 고용해서 가능한 많은 일을 시키는 것이 좋으므로, 이용률이 높은 것을 선호한다. 소요시간, 대기시간, 응답시간 -\u0026gt; 손님 입장에서의 척도 소요시간: 손님이 중국집에 들어와서 주문한 음식을 다 먹고 나가기까지 소요된 총 시간 대기시간: 각각의 음식이 나오기까지 기다린 시간을 합한 것 응답시간: 최초의 음식이 나오기까지 기다린 시간 5. 스케쥴링 알고리즘 5.1 선입선출 스케쥴링(FCFS: First-Come First-Served) process가 ready queue에 도착한 순서대로 CPU를 할당하는 방식. 비선점형이다. FCFS 스케쥴링은 먼저 도착한 프로세스의 성격에 따라 평균 대기시간이 크게 달라진다.\nCPU burst가 긴 프로세스가 먼저 도착할 경우: 평균 대기시간이 길어진다. (Conboy effect) CPU burst가 짧은 프로세스가 먼저 도착할 경우: 평균 대기시간이 짧아진다. 단점\n콘보이 현상(Convoy effect): CPU burst가 긴 process가 짧은 process보다 먼저 도착하여 오랜 시간을 기다려야하는 현상으로, 평균 대기시간이 길어진다. FCFS의 대표적인 단점 예시\n프로세스 CPU burst 시간 P1 24 P2 3 P3 3 들어온 순서가 P1,P2,P3 일 때\n대기시간: P1 = 0, P2 = 24, P3 = 27 평균 대기시간: (0 + 24 + 27 ) / 3 = 17 들어온 순서가 P2, P3, P1 일 때\n대기시간: P1 = 6, P2 = 0, P3 = 3 평균 대기시간: (6+0+3)/3 = 3 5.2 최단작업 우선 스케쥴링(Shortest-Job First: SJF) CPU burst가 가장 짧은 process에게 제일 먼저 CPU를 할당하는 방식 평균 대기시간을 가장 짧게 하는 최적 알고리즘(optimal algorithum)이지만 최고의 알고리즘은 아니다. SJF algorithum의 방식: 비선점형(non-preemptive) 과 선점형(preemptive)\n효율적이지만, 형평성을 간과한 스케쥴링\n비선점형(preemptive): 프로세스가 CPU를 자진 반납하기 전까지는 CPU를 빼앗지 않는 방식 선점형(preemptive): ready queue에서 CPU burst가 가장 짧은 process에게 CPU를 할당했어도, 더 짧은 process가 도착할 경우, CPU를 빼앗아 더 짧은 process에게 부여하는 방식 SRTF(Shortest Remaining Time First)라고도 한다. process들이 ready queue에 도착시간이 불규칙한 환경에서는 선점형이 평균 대기시간을 최소화하는 최적의 알고리즘이 된다. SJF의 선점형 첫 번째 문제점: 기아 현상(starvation)\n기아 현상(starvation): CPU burst가 짧은 process가 계속 도착할 경우, 한 process는 영원히 CPU를 할당받지 못하는 현상 SJF의 두 번째 문제점: 현실적으로 미리 알 수 없는 CPU burst 시간\n하지만 과거의 data를 통해서 예측할 수 있다. 예시\n비선점형\n선점형\n5.3 우선순위 스케쥴링(Priority scheduling) ready queue에서 기다리는 process 중 우선선위가 가장 높은 process에게 제일 먼저 CPU를 할당하는 방식 우선순위는 우선순위값(priority number)을 통해 표시하며, 작을수록 높은 우선순위를 가지는 것으로 가정한다. 우선순위 스케쥴링도 비선점형 방식과 선점형 방식으로 각각 구현할 수 있다.\nSJF도 우선순위 스케쥴링의 한 종류다.\n왜냐하면, CPU burst 시간을 우선순위값으로 정의하며 우선순위 스케쥴링은 SJF 알고리즘과 동일하다. Problem: 우선순위 스케쥴링도 기아 현상(starvation) 문제점이 있다.\nSolution: 노화 기법(aging) 을 사용한다.\n기다리는 시간이 비례하여 우선순위를 높이는 것을 말한다.\nex) 버스나 지하철에서 나이 드신 분께 자리를 양보하는 것과 동일. 5.4 라운드 로빈 스케쥴링(Round Robin Scheduling) 시분할 시스템의 성질을 가장 잘 활용한 스케쥴링 방식 각 프로세스가 연속적으로 CPU를 사용할 수 있는 시간이 제한되며, 이 시간이 경과하면 CPU를 회수해 ready queue에 줄 슨다. 현대 CPU 스케쥴링의 기반 + CPU 설명의 기반 스케쥴링: 라운드 로빈 스케쥴링\n각 프로세스가 연속적으로 CPU를 사용할 수 있는 시간: 할당 시간(time quantum)\n규모: 수십 밀리초 정도의 규모 할당시간이 지나면 timer interrupt가 발생 CPU 사용 시간이 할당 시간보다 짧으면 스스로 반납한다. 할당 시간이 너무 짧으면 문맥교환의 오버헤드가 증가하여, 전체 시스템 성능이 저하된다. 대화형 프로세스의 빠른 응답 시간(response time)을 보장할 수 있다.\n라운드 로빈 스케쥴링의 기본적인 목적: 공정성\nCPU burst 시간이 짧은 프로세스가 빨리 CPU를 얻고, 동시에 CPU burst 시간이 긴 프로세스가 불이익 X CPU를 사용하고자 하는 양에 비례하여 소요시간이 증가하므로 공정하다. Round robine과 다른 scheduling 비교\nSJF와의 비교: SJF보다 평균 turnaround time이 길지만, response time은 더 짧다는 것이 중요한 장점이다.\nFCFS와의 비교: 할당시간을 크게 하면 FCFS와 동일\nCPU 버스트 시간이 동일한 프로세스들일 경우,\nFCFS: CPU를 먼저 쓰고 나가는 프로세스의 소요시간 및 대기시간이 짧아진다. Round robine: CPU를 조금씩 같이 쓰고, 거의 동시에 끝나게 되어 소요시간 및 대기시간이 가장 오래 기다린 프로세스에 맞춰진다. 따라서 Round robine 스케쥴링은 FCFS의 평균 대기시간 및 평균 소요시간이 FCFS보다 거의 두 배로 더 길어진다. 하지만, CPU burst 시간이 균일하지 않은 경우가 대부분이기 때문에, Round robine은 FCFS보다 합리적\n5.5 멀티레벨 큐(Multi-level queue) ready queue를 여러 개로 분할해 관리하는 스케쥴링 기법 공정하지 않은 알고리즘이지만, 우선순위가 높은 프로세스가 더 빨리 CPU를 얻어야 하기 때문이다. 이 기법의 경우, 다음과 같은 문제점이 발생한다.\n이 기법의 경우, 어떤 줄에 서 있는 프로세스를 우선적으로 스케쥴링할 것인가?? 프로세스가 도착했을 때, 어느 줄에 세워야할지 결정하는 메커니즘 필요 첫 번째 문제에 대한 해결책: 프로세스의 성격에 맞는 스케쥴링을 사용한다.\n전위 큐(foreground queue): 대화형 작업(interactive job)을 담기 위한 전위 -\u0026gt; 응답시간을 짧게 하기 위해 Round robin scheduling 사용 후위 큐(background queue): 계산 위주의 작업을 담기 위한 후위 -\u0026gt; 응답 시간이 큰 의미를 가지지 않기 때문에, 그리고 context switching overhead를 줄이기 위해 FCFS 사용 두 번째 문제에 대한 해결책: 고정 우선순위 방식(fixed priority scheduling)\nFixed priority scheduling(고정 우선순위 방식) Queue에 고정적인 우선순위를 부여하는 방식 우선순위가 높은 큐를 먼저 서비스 -\u0026gt; 낮은 큐는 우선순위가 높은 큐가 비어있을 때만 서비스 실행. 즉, 전위 큐에 있는 프로세스에게 우선적으로 CPU를 부여하고, 전위 큐가 비어 있는 경우에만 후위 큐에 있는 프로세스에게 CPU를 할당한다. 하지만, starvation 이 발생할 수 있다. 두 번재 문제에 대한 또 다른 해결책: time slice\n각 queue에 CPU 시간을 적절한 비율로 할당 ex) RR인 전위 큐: 80% , FCFS인 후위 큐: 20% 5.6 멀티레벨 피드백 큐(Multi-level Feedback Queue) 멀티레벨 큐와 거의 다 동일하나, 차이점은 process가 하나의 queue에서 다른 큐로 이동이 가능하다. 즉, 프로세스의 우선순위가 바뀔 수 있다.\n우선순위 스케쥴링의 aging 기법을 멀티레벨 피드백 큐 방식으로 구현하면,\n기다렸으면 우선순위가 낮은 큐에서 높은 큐로 승격시키는 방식이다. 차근 차근 시간을 늘려 때문에, CPU 사용 시간을 예측할 필요가 없다. 멀티레벨 피드백 큐를 정의하는 요소들\n큐의 수 각 큐의 스케쥴링 알고리즘 프로세스를 상위 큐로 승격시키는 기준 프로세스를 하위 큐로 강등시키는 기준 프로세스가 도착했을 때, 들어갈 큐를 결정하는 기준 등등 멀티레벨 피드백 큐의 동작 예\n프로세스가 준비 큐에 도착하면 우선순위가 가장 높은 큐(Round robine, 할당시간 8)에 줄을 선다.\n-\u0026gt; CPU 사용시간이 짧은 대화형 프로세스라면 빨리 서비스 박고 작업완료할 수 있다.\n-\u0026gt; CPU burst가 긴 process라면 하위 큐(Round robine, 할당시간 16)로 강등시킨다. -\u0026gt; 그럼에도 완료하지 못하면 계산위주의 프로세스로 간주하여 최하위 큐인 FCFS scheduling을 적용 5.7 다중처리기 스케쥴링(Multi-processor system) multi-processor 상황에서의 scheduling 기법\n은행창구에서 번호표를 뽑아 기다리는 것처럼 CPU가 알아서 다음 프로세스를 꺼내가도록 할 수 있다.\n하지만, 반드시 특정 CPU가 실행해야 한다든가 ex) 미용실에서 특정 미용사로 예약한 경우\nLoad sharing\n각 CPU 별 부하가 적절히 분산되도록 하는 매커니즘이 필요하다. 다중처리기 스케쥴링의 방식\n대칭형 다중처리(SMP, Symetric Multi-Processing): 모든 CPU가 대등해서 각자 알아서 스케줄링을 결정하는 방식 비대칭형 다중처리(asymmetric multiprogramming): 하나의 CPU가 다른 모든 CPU의 스케줄링 및 데이터 접근을 책임지고, CPU는 거기에 따라 움직이는 방식 5.8 실시간 스케쥴링(real-time system) 정해진 시간(dead line) 이내에 처리해야만 하는 스케줄링\n경성 실시간 시스템(Hard real-time system)과 연성 실시간 시스템(soft real-time system)으로 나눠진다. 전자는 원자로 제어, 미사일 발사 등 시간을 정확히 지켜야하는 시스템 후자는 데드라인이 존재하지만, 지키지 못했다고 하여 위험한 상황이 발생하지 않는다. 5.9 Thread scheduling Thread를 구현하는 방식 2가지 Local Scheduling (by user process) User level thread의 경우, process가 thread를 직접 관리하고 OS는 thread의 존재를 모른다. 그래서 OS는 이 thread에게 CPU를 줄지 결정한다. 그리고, process 내부에서 어떤 thread에게 줄지를 결정한다. Global Scheduling (by OS) Kernel level thread의 경우, 일반 프로세스와 마찬가지로 커널의 단기 스케쥴러가 어떤 thread를 스케줄할지 결정 즉, OS가 thread의 존재를 인지한다. 6. 스케쥴링 알고리즘의 평가 스케쥴링 알고리즘의 성능을 평가하는 방법에는 큐잉모델(Queuing model), 구현 및 실측(Implementation \u0026amp; measrrement), 시뮬레이션(Simulation)가 있다. Queueing model: 이론가들이 수행하는 방식 수학적 계산을 통해 performance index(CPU 처리량, Process 평균 대기시간 등)를 구한다. 밑에 방식이 훨씬 많이 사용된다. Implementation \u0026amp; measurement: 이론가가 아닌 구현가들이 수행하는 방식 동일한 program을 원래 kernel과 CPU scheduler code를 수정한 kernel에서 수행한 후, 실행시간을 측정하여 알고리즘을 평가한다. 이 방법이 어려우면 밑에 방법을 사용한다. Simulation: 가상으로 CPU scheduling program을 작성하는 방식 가상으로 CPU scheduling program을 작성한 후, 프로그램의 CPU 요청을 입력값으로 넣어 어떠한 결과가 나오는지 확인하는 방법 그래서 가상으로 생성된 값과 실제 system에서 추출한 입력값(이를 trace라 한다.)을 비교한다. Reference 운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_06_cpu_scheduling/","summary":"Bound process를 중심으로 CPU 스케쥴러가 왜 필요한지, 스케쥴링의 성능 척도는 무엇인지, CPU sheduling 알고리즘의 종류에는 무엇이 있고, 이 알고리즘 평가는 어떻게 이뤄지는지 알아보자.","title":"[TIL] Chapter 06: CPU scheduling"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 1. 프로세스의 개념 1.1 Process (프로세스) is a prgram in execution 프로세스 = 실행 중인 프로그램 디스크에 실행파일 형태로 존재하는 상태(프로그램) → 메모리에 올라감 → 실행 이 실행 중일 때를 process라 한다. 1.2 Process context (프로세스 문맥 ) process의 수행 상태를 정확히 아는데 필요한 모든 요소\nprocess conetxt를 알아야 하는 이유???\nCPU는 시분할 시스템으로, timer interrupt에 의해서 여러 process가 돌아가면서 CPU를 사용한다. 이런 상황에서, 한 process가 CPU를 다른 process에게 이양했다가 다시 획득했을 때, 직전 수행 시점의 정확한 상태 를 재현하기 위해서 필요하다. Process context의 분류\nHardware context\nProgram counter 각종 register 이 register에 저장된 값들 Process의 address space\ncode, data, stack process만의 독자적인 주소 공간 process 관련 kernel 상의 문맥\nPCB (Process Control Block) Kernel stack OS가 process를 관리하기 위해 유지하는 자료구조들: PCB, kernel stack 2. 프로세스의 상태 2.1 Process의 상태도 Process는 다음 상태 중 어느 한 상태에 머무르며, 시간의 흐름에 따라 변한다.\nProcess의 상태를 나누는 이유는 컴퓨터의 자원을 효율적으로 관리하기 위함\nProcess의 상태도\nRunning: CPU를 잡고 instruction을 수행 중인 상태 Ready: 다른 조건은 다 만족하고, 메모리에는 올라와 CPU만 기다리는 상태 Blocked( wait, sleep ): CPU를 할당받아도 당장 instruction을 수행할 수 없는 상태 process 자신이 요청한 event가 즉시 만족되지 않아 이를 기다리는 상태 ex) disk에서 file을 읽어와야 하는 경우 (I/O 작업) New: process가 시작되어 자료구조는 생성되었지만, 메모리 획득을 승인받지 못한 상태 Terminated: execution(실행)이 끝났지만, 자료 구조 정리는 완료하지 못한 상태 Dispatch:\nCPU를 할당받을 process를 선택한 후, 실제로 CPU의 제어권을 넘겨받는 과정 2.2 Process 상태 변화 예시 입출력을 요청한 프로세스의 상태 변화\nRunning state\nA process가 CPU를 할당 받아 기계어 명령을 하나씩 수행 → I/O 요청\n파일의 내용을 disk에서 읽어와야 명령이 진행될 수 있으므로, 입출력 요청을 한다. → Blocked state\n입출력 요청이 완료될 때까지 CPU를 반환한 다음, disk 입출력 서비스를 기다리며 봉쇄 상태로 바뀐다. 그리고, 해당 process는 device I/O queue 뒤에 줄슨다. → Ready state의 process 중 선정\nCPU를 할당받을 process를 선택하기 위해, ready 상태의 process 들 중에서 CPU scheduler가 적절한 process를 하나 선정하여 CPU를 할당한다. → Running state\nB process가 CPU를 받아 자신의 code를 실행한다. → device controller 가 interrupt 발생\nI/O 작업을 하던 controller가 interrupt를 발생하여 CPU에게 I/O 작업 완료를 알림 → B process를 user mode에서 kernel mode 진입\ninterrupt의 발생 원인이 B process와 상관없어도, CPU가 현재 사용하고 있던 process가 kernel mode로 진입했다고 판단. → Ready state\nHW interrupt에 의해서 A process를 blocked state에서 ready state로 바꾼 후, CPU의 ready queue에 줄을 세운다. 그리고, device의 local buffer에 있는 내용을 memory로 이동한다. 3. 프로세스 제어블록 3.1 PCB란 ?? 운영체제가 각 process를 관리하기 위해, process 마다 유지하는 정보들을 담는, 커널 내의 자료구조 3.2 PCB의 구성 요소 1) OS가 관리를 위해 사용하는 정보 Process state, process ID process state: CPU를 할당해도 되는지 여부를 결정하기 위해 process ID: 효율적인 관리를 위해 process 마다 매긴 고유 번호 scheduling information, priority 2) CPU 수행 관련 HW 값 program counter: 다음에 수행할 명령의 위치를 가리킨다. registers 3) 메모리 관련 code, data, stack 4) 파일 관련 open file descriptors: 입출력 관련 상태 정보 4. 문맥교환 (Context switch) Context switch란?? CPU를 한 프로세스에서 다른 프로세스로 넘겨주는 과정\n문맥 교환 중, OS가 실행하는 것들\nCPU를 내어주는 process의 state를 이 process의 PCB에 저장\nCPU를 새롭에 얻는 process의 state를 PCB에서 읽어온다.\ncontext switch가 일어나는 경우와 그렇지 않은 경우\nSystem call이나 interrupt 발생 시, 반드시 문맥교환이 일어나는 게 아니다.\n첫 번째 경우, 단지 같은 process의 mode가 바뀌는 경우 두 번째 경우가 context switch다. 첫 번째 경우도 CPU 수행 정보 등 context의 일부를 PCB에 저장해야 하지만, context switch를 하는 경우, 오버헤드가 훨씬 크다. (eg. cache memory flush) A process의 address space의 code를 실행하다가, kernel address space의 code를 실행하는 것이기 때문에, PCB에 저장해야 한다. 문맥교환에 소요되는 시간은 일종의 오버헤드다.\n그래서, timer로 CPU 할당시간을 아주 작게 세팅하면 문맥교환이 빈번히 발생하기 때문에, 오버헤드가 상당히 커진다. 하지만, CPU 할당 시간을 너무 크게 설정하면 시분할 시스템의 의미가 퇴색된다. 그러므로, 적절한 CPU 할당시간을 정해야 한다. 5. 프로세스를 스케쥴링 하기 위한 큐 5.1 kernel의 process 상태 관리 process 상태 관리는 kernel의 주소 공간의 data 영역 에 다양한 queue를 두어 수행한다. process들은 각 queue들을 오가며 수행한다. 5.2 다양한 queue 종류 Job queue 현재 시스템 내에 있는 모든 프로세스를 관리하기 위한 큐 모든 process가 속한다. ready queue와 device queue가 다 포함된다. ready 큐에 포함하면 device 큐에는 포함되지 않는다. Ready queue 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합 Device queues (장치 큐) = HW queue 각 I/O device의 service를 기다리는 process의 집합 각 deivce마다 있기 때문에, 다양하다. 예) device controller가 줄 서 있는 순서대로 I/O 작업 수행 → 작업 완료하면 controller가 interrupt 발생 → interrupt service routine에 의해서 입출력 작업이 완료된 process는 I/O queue에서 나와 CPU대기 queue 슨다. resource queue = SW resource SW queue가 필요한 이유?? SW resource인 공유 데이터에 여러 process가 접근할 경우, 데이터의 일관성 훼손 이 발생할 수 있다. 그래서, 공유 데이터에는 매 시점 하나의 프로세스만이 접근하도록 한다. SW resource에 접근 중인 process가 다 사용하고 반납할 때까지, 다른 process가 CPU를 할당받았어도 접근하지 말고 공유 데이터 queue에서 기다려야 한다. 5.3 Process scheduling queue의 모습 위 image는 OS가 queue를 어떻게 자료구조로 구현하는지 보여준다. queue는 각 process의 PCB를 연결 list 형태로 관리하여 순서를 정한다. Queue header 큐의 가장 앞부분 PCB의 pointer 부분이 이어진다. queue 흐름 설명 process가 CPU 할당받고 수행 중 I/O 요청이 발생하면 해당 device queue에 줄을 슨다. device queue에 속한 process는 blocked state였다가, 해당 장치의 서비스를 받으면, device controller가 인터럽트를 발생시켜 준비 상태로 바껴 ready queue로 이동한다. ready queue에는 PCB 7 다음에, PCV 2가 대기하고 있다. magnetic tape에는 아무것도 대기하지 않는다. disk queue에는 PCB 3 ← PCB 14 ← PCB 6 순서로 대기하고 있다. terminal queue에는 PCB 5 만 대기하고 있다. 6. 스케쥴러 (Scheduler) 6.1 Long-term scheduler (장기 스케쥴러 or job scheduler) 시작 프로세스 중 어떤 것들을 ready queue 로 보낼지 결정 process에 memory (및 각종 자원) 을 주는 문제 메모리를 어느 것에 줄지를 결정 현대의 컴퓨터는 메모리를 기본적으로 바로 준다. degree of Multiprogramming 제어 multi-programming: 메모리에 여러 프로그램이 동시에 올라가는 것을 의미 이 메모리에 올라가는 수를 제어하는 것 → 컴퓨터 성능에 영향을 줌 현 컴퓨터에는 장기 스케쥴러는 없고, 프로그램이 시작하면 다 ready 상태로 들어간다. time sharing system에는 보통 장기 scheduler가 없다. (무조건 ready) 6.2 Short-term schduler (단기 scheduler or CPU scheduler) 어떤 프로세스를 다음 번에 running 시킬지 결정 프로세스에 CPU 를주는문제 충분히 빨라야 함 (milli-second 단위) 6.3 Medium-Term Scheduler (중기 스케쥴러 or Swapper) 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아낸다. 프로세스에게서 memory 를 뺏는 문제 메모리에 프로그램이 너무 많이 올라가면, 쫓아내어 전체적인 컴퓨터 성능을 개선. 시스템 입장에서는 장기 스케쥴러보다 중기 스케쥴러를 주는 게 더 이득 degree of multiprogramming 을 제어 현재 multi-programming을 제어하는 scheduler 이 중기 스케쥴러가 들어가 있기 때문에, 프로세스의 상태 3가지에 추가된 게 suspended다. 6.4 추가된 프로세스 상태도 중기 스케쥴러에 의해 suspended state가 추가되었다. Running CPU를 잡고 instruction을 수행 중인 상태 Ready CPU를 기다리는 상태( 메모리 등 다른 조건을 모두 만족하고) Blocked (wait, sleep) I/O 등의 event를 스스로 기다리는 상태 예) 디스크에서 file을 읽어와야 하는 경우 Suspended (stopped) 외부적인 이유로 강제로 프로세스의 수행이 정지된 상태 중기 스케쥴러에 의해 강제로 뺏긴 상태 이 상태의 프로세스는 통째로 디스크에 swap out 된다. 예) 사용자가 프로그램을 일시 정지시킨 경우 (break key). 이 경우에는 사람이 재개시켜야 위의 상태가 된다. 시스템이 여러 이유로 프로세스를 잠시 중단시킴 → 중기 스케쥴러 (메모리에 너무 많은 프로세스가 올라와 있을 때) blocked와 suspended 구분하기 Blocekd: 자신이 요청한 event가 만족되면(자신이 요청한 작업이 완료되면) Ready Suspended: 외부에서 정지된 상태이기 대문에, 외부에서 resume 해 주어야 Active 7. 프로세스의 생성 7.1 Process creation (프로세스 생성) : COW(Copy-On-Write) OS가 process를 전부 생성하는 게 아닌, 부팅 후 최초의 process는 운영체제가 직접 생성한다. 그 다음부터는 이미 존재하는 process가 다른 process를 복제 생성한다.\n부모 프로세스와 자식 프로세스의 정의 및 관계\nprocess를 생성하는 process: 부모 프로세스 부모 프로세스에 의해 생성된 process: 자식 프로세스 부모 프로세스 1개가 자식 프로세스 최소 1개를 복제 생성 한다. 또한, 자식 프로세스가 process를 생성할 수 있다. 그래서 프로세스의 트리(계층 구조) 형성 작업 수행을 위한 자원\n부모 프로세스는 OS로부터 받는다. 자식 프로세스는 부모 프로세스와 공유 한다. 부모와 자식 프로세스가 서로 모든 자원을 공유 하는 모델 일부를 공유 하는 모델 전혀 공유하지 않는 모델 주소 공간 (Address space)\nprocess 생성의 첫 번째: 부모 공간을 복사 → 두 번째: 복사한 공간에 새로운 프로그램의 주소 공간을 덮어씌운다. Process 와 관련한 system call (특권 명령 )\nfork() : create a child (copy) exec() : overlay new image = 새로운 프로그램으로서 덮어씌운다. wait() : sleep until child is done exit() : frees all the resources, notify parent UNIX의 예\nos에게 fork() system call 요청하여, 새로운 process를 생성 부모를 그대로 복사하고, 주고 공간을 할당 복사할 때, 부모 프로세스의 process ID는 제외한다. fork () 다음에 이어지는 exec () system cal을 통해 새로운 프로그램을 메모리에 올린다. fork () 와 exec () 둘 다 system call을 통해서 실행되므로, 운영체제가 생성한다. 7.2 Process Termination (프로세스 종료) 프로세스가 마지막 명령을 수행한 후, 운영체제에게 이를 알려준다. (’exit’ system call) 자식이 부모에게 output data를 보낸다. (via ‘wait’ system call) 프로세스의 각종 자원들이 운영체제에게 반납된다. 자식 프로세스가 먼저 종료 후 부모 프로세스가 종료되야 한다. 부모 프로세스에게 자식의 수행을 종료시킨다. (abort) 자식이 할당 자원의 한계치를 넘어설 때 자식에게 할당된 task가 더 이상 필요하지 않을 때 (자식 프로세스를 만든 이유가 일을 시키기 위함이기 때문) 부모가 종료(exit)할 때 운영체제는 부모프로세스가 종료하는 경우, 자식이 더 수행되도록 두지 않는다. 단계적인 종료( 손자 → 자식 → 부모 )가 지켜져야 한다. 7.3 fork () system call creats a new address space that is a duplicate of the caller 자식 process를 만들 때, 부모 process의 program counter까지 복사된다. 부모 process와 자식 process의 차이는 식별자 다. 그래서, program counter는 fork () 실행 후, 다음 코드를 가리키기 때문에, 자식 process는 fork ()한 이후부터 코드를 실행한다. 자식 process라 부르지만, 복제인간이라 생각하는 게 정확한다. 또한, 복제된 process는 자신을 원본이라 생각한다. 복제된 process인지 아닌지 구분하는 방법 fork 함수의 결과값으로 자식 process 는 0을, 부모 process에게는 양수를 준다. 7.4 exec () system call fork () 한 후, exec () system call을 통해서 자식 프로세스를 새로운 program으로 대체한다. (overwrite) 한 번 만들어지면 다시 되돌아갈 수 없다. 7.5 wait () system call wait () system call은 자식 process가 종료될 때까지 process A를 blocked state로 만든다. 자식 프로세스가 종료되면 kernel은 프로세스 A를 준비 상태로 변경하여 준비 큐에 진입. 7.6 exit() system call process의 종료 자발적 종료 마지막 statement 수행 후, OS에게 exit () system call로 자신이 종료됨을 알린다. 명시적으로 exit ()을 호출하지 않아도, main () 함수가 반환되는 위치에 compiler가 자동으로 삽입해 프로세스 종료 직전에 항상 호출한다. 비자발적 종료 (자식 프로세스 밖에서 종료시키는 경우) 부모 프로세스가 자식 프로세스를 강제 종료시킨다. When?? 자식 프로세스가 한계치를 넘어서는 할당 자원 요청을 할 때 자식에게 할당된 task가 더 이상 필요하지 않을 때 프로그램 종료 버튼을 누르는 경우나, 키보드로 kill, break 등을 친 경우 부모가 종료하는 경우 부모 프로세스가 종료하기 전에 자식들이 먼저 종료된다. 프로그램을 강제 종료시킨 후, 계속 수행시켜야하는 경우에는 종료되지 않는 다른 자식 프로세스로 이양시켜서, 기존 부모 프로세스가 종료된 후에도 다른 프로세스 아래에서 계속 수행한다. 부모가 죽기 전에 자식이 먼저 죽는다는 원칙은 여전히 지켜진다. 8. 프로세스 간의 협력 8.1 Process 간 협력하는 이유 독립적 프로세스 (Independent process)\n프로세스는 각자의 주소 공간을 가지고 수행되므로, 원칙적으로 하나의 프로세스는 다른 프로세스의 수행에 영향을 미치지 못한다. 하지만, process 간 협력한다면 왜 하고 어떻게 하는 것일까??\n협력 프로세스( Cooperating process)\nWhy? 업무의 효율성 증대: 부분적인 처리 결과, 정보를 공유할 수 있고, 처리 속도가 향상. How? IPC(Inter-Process Communication): process 간 통신과 동기화를 이루기 위한 mechanism 8.2 IPC의 대표적인 방법: 2가지 Message passing: 메시지 전달 방식\nMessage passing의 특징\n프로세스 사이에 공유 변수(shared variable)을 일체 사용하지 않고 통신하는 시스템. 중간에 kernel을 통해서 하는데, 명시적으로 process의 이름을 표시하냐 안하냐의 차이. kernel에 의해 send(message)와 receive(message)라는 두 가지 연산을 제공받는다. 즉, 이 두 가지 연산은 특권명령이다. Message passing 방식 2가지\n직접 통신 (direct communication): Web socket 간접 통신 (Indirect communication): Message queue, file 형식 Shared memory: 공유 메모리 방식\n8.3 Message passing 방식: 2가지 Message passing 방식에는 직접통신(direct communication)과 간접통신(indirect communication) 으로 나뉜다.\nDirect communication 통신하려는 프로세스의 이름을 명시적으로 표시한다. Send (Q, message): process Q에게 메시지를 전송하는 것을 의미 Receive (P, message): process P로부터 메시지를 전달받는 것을 의미 link는 자동적으로 생성되며, 하나의 link는 정확히 한 쌍의 process에게 할당된다. 각 쌍의 process에게는 오직 하나의 link만이 존재한다. Indirect communication 통신하려는 프로세스의 이름을 명시적으로 표시하지 않는다. mailbox ( or port)를 통해 메시지를 간접 전달한다. mailbox에는 고유의 ID가 있다. 이 mailbox를 공유하는 process 들끼리만 서로 통신할 수 있다. Send(M, message): M이라는 mailbox에 message를 전달하는 것 Receive(M, message): M이라는 mailbox로부터 메시지를 전달받는 것 mailbox를 3개 이상의 process가 공유할 경우, 각각의 프로세스에게 링크를 따로 생성가능. 8.4 Shared memory 서로 다른 process 간에도 일부 주소 공간을 공유하게 하는 mechanism 두 process가 서로 신뢰할 수 있는 process여야 한다. kernel에게 system call 후, memory가 공유된다. 물리적인 공간에 mapping 할 때, 공유된 상태로 진행한다. 이 방법에서 동기화 문제는 kernel 책임지지 않고, 공유되는 process 들이 책임져야 한다. 9. Thread 9.1 Thread란?? A Thread (or lightweight process) is a basic unit of CPU utilization\nCPU의 기본 실행 단위를 Thread 라 한다. Thread의 구성\nProgram counter register set stack space stack space에서 여러 thread로 나눠진다. process 내부에서 thread가 동료 thread와 공유하는 부분 = task\ncode section data section OS resources heavyweight process 는 하나의 thread를 가지고 있는 task 다.\nCPU가 명령 수행을 위해서는 코드의 실행될 부분을 가리키는 program counter가 있어야 한다. 또한, memory에 register 값 을 세팅해야 한다. OS는 process를 관리하기 위해 process마다 1개의 PCB를 둔다. 이 PCB를 보면 여러 thread로 구성된 걸 확인할 수 있다. 9.2 Thread의 장점 Responsiveness: 응답성 eg) multi-thread: 하나의 thread가 blocked state 인 동안에도, 동일한 task 내의 다른 thread가 계속 실행되어 빠른 처리를 할 수 있다. Resource sharing: 자원의 효율적인 관리 여러 thread가 process의 code, data, resource를 공유하기 때문에, 자원 관리가 효율적. Economy: 경제성 process를 새로 생성하는 것보다 thread를 새로 생성하는 게 오버헤드가 훨씬 적다. process 간의 switching보다, thread 간의 switching이 오버헤드가 훨씬 적다. Utilization of MP Architectures 병렬로 thread가 실행될 수 있다. 다중 thread가 협력하여 높은 처리율과 성능 향상을 얻는다. 9.3 Implementation of threads Some are supported by kernel ⇒ Kernel threads thread가 여러 개인 것을 운영체제가 알고 있음 예) Windows 95, 98 / NT Solaris Digital UNIX, Mach Others are supported by library ⇒ User Threads 운영체제가 프로세스 안에 thread가 여러개인 걸 모른다. 즉, User program이 thread를 관리한다. 예) POSIX Pthreads MAch C-threads Solaris threads Some are real time threads real time을 지원하는 thread Reference 운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_05_%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4_%EA%B4%80%EB%A6%AC/","summary":"프로세스란 무엇인지, 프로세스의 상태는 어떻게 흘러가는지, 문맥 교환이란 무엇인지, 프로세스가 어떻게 생성되고 종료되는지, 프로세스끼리 협력은 어떻게 하는지, thread는 무엇인지 알아보겠다.","title":"[TIL] Chapter 05: 프로세스 관리"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 1. 프로그램의 구조와 인터럽트 프로그램이 CPU에서 명령을 수행하기 위해서는 명령을 담은 프로그램의 주소 영역이 메모리에 올라가 있어야 한다. 왜냐하면 CPU는 메모리에 있는 instruction만을 보고 실행하기 때문이다. 1.1 프로그램의 주소 영역 프로그램의 주소영역 = Code + Data + Stack 영역 Code 영역 작성한 함수의 코드가 CPU에서 수행하는 기계어 형태로 변환되어 저장 되는 공간 Data 영역 전역 변수(global variable) 등 프로그램이 사용하는 데이터를 저장 하는 공간 Stack 영역 프로그램 내의 함수 호출 시의 복귀 주소 및 데이터를 저장 하는 공간 예) 프로그램 내의 X 함수 수행 → 프로그램 내의 Y 함수 호출 → 이 때 X 함수에서 Y 함수를 호출하는 지점을 stack 영역에 저장 → Y 함수가 호출되어 실행할 명령의 메모리 위치가 바뀜 → Y 함수 수행 완료 → stack에 저장된 X 함수의 주소 위치로 돌아와 코드를 계속 수행 1.2 PCB: 프로그램 수행의 복귀 위치 인터럽트가 발생할 경우 복귀 위치: PCB(Process Control block)에 저장한다. interrupt가 발생한 시점에서 프로그램의 어느 부분까지 수행했는지를 PCB에 저장 과정 A 프로그램이 CPU를 할당받아 명령을 수행 → interrupt 발생 → 현재 수행 중인 명령 위치를 PCB에 저장 → CPU 제어권을 OS에게 양도 → 인터럽트 처리 완료 후, PCB에 저장된 작업 지점으로 돌아와 계속 수행 2. 컴퓨터 시스템의 작동 개요 컴퓨터 시스템의 작동 CPU에서 명령을 수행하는 부분 + 컴퓨터 외부장치와 입출력이 이루어지는 부분 2.1 프로그램 카운터(Program Counter(PC)) PC = Program Counter = CPU가 수행해야할 메모리 주소를 담고 있는 레지스터 CPU는 빠른 속도의 연산 능력은 가지고 있지만, 결정 능력을 가지고 있지 않다. 단지 매번 프로그램 카운터가 가리키는 메모리 위치의 명령을 처리한다. 통상 프로그램 카운터가 다음 명령어를 가리키어 CPU 명령은 순차적으로 수행된다. 반복문이나 함수 호출 등으로 바로 다음 주소가 아닌 명령을 수행할 수도 있다. Program Counter 가 OS가 존재하는 메모리 위치 를 가리키면 CPU가 \u0026lsquo;kernel mode\u0026rsquo; 에서 수행 중 사용자 프로그램의 메모리 위치 를 가리키면 CPU가 \u0026lsquo;user mode\u0026rsquo; 에서 수행 중 2.2 일반 명령과 특권 명령 일반 명령 메모리에서 자료를 읽어와 CPU에서 연산을 하고, 그 결과를 메모리에 쓰는 명령 모든 프로그램이 수행 가능 mode bit가 1일 때 특권 명령 보안이 필요한 명령 각종 장치에 접근하는 명령 운영체제만이 수행 mode bite가 0일 때 운영체제를 향한 사용자 프로그램의 대행 요청: system call 사용자 프로그램이 특권 명령을 사용하고자 할 때, 사용자 프로그램이 특권 명령을 수행할 수 없으므로 운영체제에게 대행 요청 system call 을 한다. 그러면 CPU의 제어권이 운영체제에게 넘어가서 특권 명령을 수행한다. 2.3 인터럽트 라인을 세팅하는 이유 Problem CPU는 프로그램 카운터가 가리키는 메모리 위치의 명령만 계속 수행하여, 주변장치의 상태를 지속적으로 파악할 수 없다. Solution 주변 장치들이 CPU의 도움이 필요할 때 인터럽트 라인(interrupt line)을 세팅한다. CPU는 매번 명령을 수행한 후, 인터럽트 라인을 체크하여 요청 유무를 확인한다. 또한, 인터럽트의 원인이 다양하기 때문에, 인터럽트 라인을 다르게 해서 구분한다. 3. 프로그램의 실행 “프로그램이 실행(program execution)되고 있다” = disk에 존재하던 실행 파일이 메모리에 적재된다 = program이 CPU를 할당받고 instruction을 수행하고 있는 상태 “프로그램이 동시에 실행된다” = 여러 프로그램이 짧은 시간 단위로 CPU를 나누어 사용한다. = 프로그램이 메모리에 동시에 적재되어 있을 수 있으므로 3.1 가상 메모리(Virtual Memory) 프로그램은 실행 파일 형태로 하드 디스크에 저장한다.\n이 때는 프로그램은 주소 영역을 가지고 있다고 한다. 하지만, 실행되는 순간 프로세스가 되며 프로그램의 주소 영역은 프로세스의 주소 공간이 되는 것이다. 파일 실행 → 가상 메모리(Virtual Memory) 생성 → Address transition → 물리적 메모리(Physical Memory) 에 올라감\n가상 메모리(address space, logical memory) : 프로세스마다 가지는 독자적인 주소 공간 물리적 메모리(Physical Memory) : 0번지부터 시작 Address transition : 가상 메모리 주소를 물리적 메모리 주소로 변환하는 것으로, 하드웨어 장치가 수행 Virtual memory = 주소 공간 = Address space = code + data + stack\nOS의 주소 공간\nkernel의 code 자원 관리를 위한 부분 사용자에게 편리한 인터페이스를 제공하기 위한 부분 system call 및 interrup를 처리하기 위한 부분 kernel의 data 하드웨어와 소프트웨어(ex: 사용자 프로그램)를 포함하는 시스템 내의 모든 자원을 관리하기 위한 자료구조를 유지 ex) PCB kernel의 stack 현재 수행 중인 프로세스마다 별도의 스택을 두어 관리. Reason 1: system call로 특권 명령 대행을 요청한 후, 운영체제가 system call 내부의 다른 함수를 호출할 경우 복귀 주소는 커널 내의 주소가 되기 때문에 Reason 2: kernel은 일종의 공유 코드로서, 모든 프로세스가 system call을 통해 kernel 함수를 접근할 수 있으므로, 각 프로세스마다 커널 내에 별도의 스택을 둔다. 함수 호출 복귀 시 저장 장소\n'____' 코드 수행 중 이루어지는 함수 호출로 인한 복귀 주소 유지는 '____' 을 사용 process → 자신의 address space 내의 stack kernel → kernel stack 여기서 유의사항은 CPU 수행 주체가 OS로 바뀔 때 직전 수행 프로그램의 복귀 정보는 stack이 아닌 PCB에 저장한다는 사실이다. 3.2 Swap area Problem 프로그램이 프로세스 되었을 때 생성되는 address space를 물리적 메모리에 다 올리지 않는다. Why?? 다 올리면 메모리 낭비가 심하기 때문 Solution 바로 필요한 코드 부분만 memory에 올린다. 그 외 부분은 보조기억장치에 놔두는데, 이 영역을 swap area라 한다. swap area는 메모리 용량 한계로 메모리 연장 용도로 사용한다. 하지만, 프로그램이 파일 형태로 저장되는 보조기억장치의 disk 영역은 비휘발성 용도로 저장한다. 4. 사용자 프로그램이 사용하는 함수 프로그램이 사용하는 함수의 종류 사용자 정의 함수: 프로그래머 본인이 직접 작성한 함수 라이브러리 함수: 자신의 프로그램에서 정의하지 않고 가져다 쓴 함수로, 자신의 프로그램의 실행 파일에 포함되어 있다. 커널 함수: kernel의 코드에 정의된 함수 = system call 함수 + interrupt 처리 함수 system call 함수: 사용자 프로그램이 운영체제의 서비스를 요청하기 위해 호출함수 interrupt 처리 함수: 각종 HW 및 SW가 CPU의 서비스를 요청하기 위한 함수 kernel의 address space에 code가 정의되기 때문에, system call로 kernel mode로 바꿔야 실행 가능하다. 사용자 정의 함수와 라이브러리 함수 는 프로그램의 코드 영역에 기계어 명령 형태로 존재 → 프로그램 실행 시, 해당 프로세스의 address space에 포함 프로세스 내의 함수 호출 시에도, 프로세스의 address space에 있는 stack 영역을 사용 프로세스의 address space의 code 영역 안에서 메모리 상의 점프를 한다. user mode에서 실행된다. 5. 인터럽트 5.1 Interrupt 작동 순서 복습 CPU는 프로그램 카운터가 가리키는 명령만 쉬지 않고 수행하기 때문에, 다른 명령을 수행하기 위해서는 interrupt를 걸어야 한다. CPU는 program counter가 가리키는 명령을 하나씩 수행한 후, interrupt line이 세팅되었는지 확인한다. interrupt line setting을 통해 interrupt가 발생했으면 현재 수행하던 process를 멈추고, 운영체제의 인터럽트 처리 루틴으로 이동하여, 인터럽트 처리를 수행한다. 인터럽트 처리를 마치면 인터럽트 발생 직전의 프로세스에게 CPU 제어권이 넘어간다. 5.2 Interrupt의 서로 다른 중요도 인터럽트 처리 중, 또 다른 인터럽트가 발생한 경우에는 어떻게 처리되는가??? 중요도를 비교한다. 현재 처리 중인 인터럽트의 중요도가 상대적으로 낮으면, 처리 중인 인터럽트 코드의 수행 지점을 저장한다. 그 다음, 중요도가 더 높은 인터럽트를 처리한다. 인터럽트 처리가 끝나면 저장 주소로 복귀해 이전에 수행하던 인터럽트 처리 코드를 마저 수행한다. 6. 시스템 콜 system call 사용의 예\nprocess가 CPU에서 명령을 수행하던 중 I/O 작업이 필요한 경우, sw interrupt인 system call을 통해 kernel 함수를 호출한다.\n→ kernel 함수는 사용자 프로그램이 수행할 수 없으므로, CPU 제어권을 OS에게 넘겨야 하는데,\n→ OS에게 넘기기 위해서 인터럽트 라인을 세팅하는 명령을 실행하여, CPU에게 interrupt가 발생했다는 걸 알린다.\n→ CPU는 program counter가 가리키는 명령을 하나씩 실행한 후, interrupt line을 체크하여 interrupt 발생을 확인한다.\n→ interrupt를 확인한 CPU는 현재 실행 중인 process를 멈춘 후, process의 실행 상태를 PCB에 저장한다.\n→ OS는 interrupt line을 통해서 어느 종류의 interrupt인지 확인한 후, interrupt vector가 가리키는 interrut service routine을 찾아 실행하여, 요청한 I/O에 해당하는 device controller에게 I/O 명령을 한다.\n→ I/O 요청이 수행되는 동안, 해당 process는 데이터가 없어서 다음 명령을 수행할 수 없으므로, CPU를 다른 process에게 이양한다.\n→ 다른 process의 작업을 CPU가 작업하는 도중에, I/O 작업이 완료되면 device controller가 CPU에게 interrupt를 발생시켜 I/O 작업 완료를 알린다. 이 때 발생한 interrupt는 HW interrupt다.\n→ interrupt 처리 내용으로 device controller가 device로부터 읽어와서 local buffer에 저장한 내용을 메모리로 복사해온다.\n→ 복사 후, I/O 작업을 요청했던 process에게 다시 CPU를 얻을 수 있는 권한을 준다.\n→ 그러면 I/O 작업을 이제 완료한 process는 CPU를 기다리는 큐에 삽입되고, CPU의 제어권은 interrupt를 당한 process에게 넘어가서 하던 작업을 계속 수행한다. process가 CPU를 빼앗기는 경우: 2가지\nTimer의 CPU 할당 시간이 만료된 경우, interrupt가 발생 time sharing system의 필수적인 요소 한 process가 CPU를 독점하는 걸 방지 process가 I/O 작업 같은 kernel code 수행이 필요한 경우 sw interrupt인 system call 하는 경우 시간이 오래 걸리는 I/O 작업이 수행하는 동안, CPU를 다른 process에게 할당한다. 그 이유는??? 입출력 작업을 요청한 process에게 CPU를 할당해도 파일 데이터가 있어야 당장 다음 명령을 수행할 수 있는데, I/O 연산 속도는 CPU 연산 속도보다 매우 느리기 때문에, 긴 기다리는 시간 동안 CPU가 일을 할 수 없어 비효율적이기 때문이다. 7. 프로세스의 두 가지 실행 상태 프로세스의 실행 상태 두 가지: user mode running(사용자 모드에서의 실행 상태) 와 kernel mode running(커널 모드에서의 실행 상태) 프로그램 자신의 주소 공간에서 정의된 코드를 실행 ↔ user mode running ex) 사용자 정의 함수 와 라이브러리 함수를 호출 kernel의 system call 함수 (kernel 주소 공간에 정의된 함수) 를 실행 ↔ kernel mode running system call 실행이 끝나면 다시 user mode로 복귀 또한, 프로그램 실행이 끝날 때에는 kernel mode로 진입해 프로그램을 종료한다. process 가 kernel mode에서 실행 중이란 의미는??? process A가 system call 을 통해 OS에게 대행 요청을 하여 kernel code를 실행 중이다 = process A가 kernel mode에서 실행 중 os가 kernel code를 수행하고 있을 지라도, os는 process A를 대신하여 수행 중이기 때문에, process A가 실행 상태인 걸로 간주한다. Reference 운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_04_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8%EC%9D%98%EA%B5%AC%EC%A1%B0%EC%99%80%EC%8B%A4%ED%96%89/","summary":"프로그램의 구조와 실행에 대해 설명한다. 예를 들어 프로그램의 주소영역, PCB, Program counter, 일반 명령과 특권 명령, Virtual memory, kernel mode와 user mode 등등을 알아본다.","title":"[TIL] Chapter 04: 프로그램의 구조와 실행"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 5. 입출력 구조 CPU의 명령 수행 속도는 빠르지만, 입출력 연산은 매우 느리다. 이 입출력 방식에는 동기식 입출력 과 비동기식 입출력 이 있다. 5.1 동기식 입출력(Synchronous I/O) 일반적으로 사용하는 방식으로 어떤 프로그램이 입출력했을 때, 입출력 작업이 완료된 후에야 그 프로그램이 후속 작업을 수행할 수 있는 방식이다.\n예) 프로그램이 CPU를 점유한 상태에서 디스크에 정보를 읽어오라는 요청을 했다. 디스크 입출력이 완료되기까지 어느 정도의 시간이 소요된다. 이 때 동기식은 입출력 작업이 완료될 때까지 다음 명령을 수행하지 않고 기다린다. 그러다가 입출력이 완료되면 인터럽트를 통해 이 사실을 대기하고 있던 CPU에게 전달하고, CPU의 제어권이 프로그램에게 넘어가서 다음 명령을 수행할 수 있다. 동기식 입출력 과정\nA process가 code 실행 중에 I/O 요청이 필요한 명령을 만나서 I/O 요청을 한다\n→ A는 CPU에게 system call이라는 SW interrupt를 발생\n→ CPU는 프로그램 A의 코드를 실행하던 일을 멈추고, 현재 상태를 프로그램의 PCB에 저장한다\n→ CPU의 제어권이 운영체제에게 넘어간다\n→ A가 입출력 연산을 요청했으므로, 운영체제가 프로세스 A를 봉쇄상태로 표시 그리고, 운영체제는 인터럽트 처리루틴 수행\n→ CPU는 컨트롤러에게 입출력 연산을 요청\n→ 컨트롤러는 A가 요청한 데이터를 디스크로부터 자신의 로컬 버퍼로 읽어온다.\nA가 직접 입출력 작업을 하는 건 아니지만, A의 요청에 의해서 하는 것이므로, 이 과정을 프로세스 A가 입출력 작업을 수행 중이라 언급한다.\n→ 컨트롤러가 읽어오는 동안 CPU를 다른 프로그램 B에 할당해 계속 CPU가 일을 할 수 있도록 한다\n→ 원하는 정보가 로컬버퍼로 다 들어오면 컨트롤러는 CPU에게 입출력이 완료되었다는 사실을 인터럽트를 발생시켜 알린다. 이 때 발생시킨 인터럽트는 하드웨어 인터럽트다\n프로세스 A가 입출력 작업을 완료했다고 언급한다.\n→ 프로그램 B를 수행 중이던 CPU는 수행하던 지점 및 상태를 process B의 PCB에 저장하고, 인터럽트를 처리\n→ 인터럽트 처리 루틴은 로컬 버퍼에 있는 A가 요청한 데이터를 A의 메모리 영역으로 읽어오고 A의 봉쇄 상태를 해제시킨다.\n→ A는 CPU를 기다리는 줄에 다시 선다\n→ 다시 B로 돌아와 업무를 중단한 지점부터 계속 진행\n→ A는 CPU를 큐에서 기다리다가 자신의 차례가 되면 CPU를 할당받고 입출력 연산 이후의 작업을 수행\n5.1.1 입출력 연산 동안 CPU를 다른 process에게 할당하는 이유 기본지식\n입출력 연산 속도는 CPU 연산 속도보다 매우 느리다. 매 시점 시스템 내에서는 하나의 입출력만 수행할 수 있다. 하지만, 동기화는 자동적으로 이뤄진다. 이유: CPU 낭비 방지를 위해서\n입출력 연산 속도는 매우 느려서 이를 수행하고 있는 프로그램이 CPU를 계속 점유하면, 프로그램의 입출력 연산이 끝날 때까지 CPU는 인터럽트를 기다리며 아무런 일을 하지 못한다. 그래서 일반적으로 프로그램이 입출력을 수행 중인 경우, CPU를 다른 프로그램에게 이양해 CPU가 쉬지 않고 일하도록 관리한다. 입출력 작업을 수행 중인 프로세스에게 CPU를 할당해도 명령을 수행하지 못하는 이유\n입출력 중인 프로그램의 상태를 봉쇄 상태(Bblocked state) 로 전환하기 때문 봉쇄 상태의 프로그램에게는 CPU를 할당하지 않고, CPU 할당 시 곧바로 명령을 수행할 수 있는 프로그램에만 CPU를 할당한다. 인터럽트를 보내면 프로그램의 상태를 봉쇄 상태로부터 해제시킨다. 5.1.2 봉쇄 해제 후, ready 상태로 큐에서 기다리는 이유 이유: 동기성 보장 = 동기화를 위해서\n입출력 수행 중일 때 다른 프로그램에게 CPU를 양도하면, 다수의 입출력 연산이 동시에 요청되거나 처리되어 동기화에 문제가 발생할 수 있다. 그래서 입출력 요청의 동기화를 위해 장치별로 큐(queue)를 두어 요청한 순서대로 처리할 수 있도록 한다. 예시\n프로그램 A가 먼저 요청했으면 이를 먼저 큐에 넣고, 그 후에 발생한 B의 요청을 A 요청 뒤에 삽입한다. 디스크 차원에서는 큐에 있는 순서대로 처리하여 동기화 문제를 해결할 수 있다. 5.1.3 Summary 동기식 입출력을 요청한 프로그램은 입출력이 완료될 때까지 다음 명령을 수행할 수 없어 CPU가 낭비된다. 그러나, CPU의 효율적인 사용을 위해 입출력이 수행하는 동안 다른 프로그램에게 CPU를 양도하면 동시에 다수의 입출력 연산이 일어날 수 있다. 그래서 다수의 프로그램이 동시에 입출력 연산을 요청하는 경우 동기성(synchronization)을 보장하기 위해 장치마다 큐를 두어 요청된 순서대로 처리할 수 있도록 한다. 5.2 비동기식 입출력(Asynchronous I/O) I/O가 시작된 후, 입출력 작업이 끝나기를 기다리지 않고 즉시 제어가 사용자 프로그램에 넘어간다. 그래서 입출력 연산과 무관한 처리 가능한 작업부터 처리한다. 6. DMA Direct Memory Access의 약어로, CPU의 중재 없이 device controller가 device의 buffer storage에 읽어오면 CPU를 대신하여 읽어온 내용을 메모리에 block 단위로 직접 복사한 후, CPU에게 interrupt를 발생시키는 장치\n왜 DMA가 필요한가??? 문제점: CPU가 interrupt로 많은 방해를 받아 효율이 많이 떨어진다. Interrupt가 발생하면 CPU는 controller의 local buffer와 memory 사이에서 데이터를 옮기는 일을 수행하는데, 만약 사용자 프로그램이 CPU를 사용하는 중에 I/O 장치가 interrupt를 많이 걸면, CPU가 많은 방해를 받아 CPU 효율이 많이 떨어진다. 해결책: DMA가 CPU를 대신하여 local buffer에서 메모리로 읽어오는 작업을 수행한다. CPU는 바이트(byte) 단위로 읽어오지만, DMA는 byte가 아닌 block이라는 큰 단위로 정보를 메모리로 읽어온 후에 CPU에게 인터럽트를 발생시켜 해당 작업의 완료를 알리기 때문에, 인터럽트의 빈도를 줄인다. 결과: DMA를 통해 CPU를 효율적으로 관리하고, 입출력 연산을 빠르게 수행 가능 메모리에는 CPU 뿐만 아니라 DMA도 접근할 수 있다는 걸 알 수 있다.\n7. 저장장치의 구조 저장장치 = 주기억장치 + 보조기억장치 주기억장치 = 메모리 = RAM with 휘발성(volatile) 보조기억장치 = 마그네틱 디스크 with 비휘발성(non-volatile) ex) 마그네틱 디스크(하드디스크), 플래시 메모리, CD, 마그네틱 테이프 보조기억장치의 용도 = file system용 + swap area용 file system용: 비휘발성 성질을 이용하여 전원이 나가도 유지해야할 정보를 파일형태로 저장하는 용도 swap area용: 메모리 한계로 메모리 연장 용도로 사용. 프로그램 수행에 필요한 부분만 메모리에 올려놓고(process), 그렇지 않은 부분은 swap area에 내려놓는다. swap area에 내려놓는 일을 swap out(스왑 아웃) 이라 한다. 비휘발성으로 사용되는 file system용과 구분 하드디스크의 물리적 구조 여러 개의 마그네틱 원판들이 회전축에 붙어있고, 원판의 표면은 track으로 나눠지고, 각 track은 sector로 나눠지며, 이 sector에 최소한의 단위 정보가 저장된다. Arm assembly에 연결된 arm이 움직이면서 head가 저장된 데이터를 읽고 쓴다. 8. 저장장치의 계층 구조 컴퓨터 시스템의 저장장치 계층 구조는 다음과 같다. 위로 올라갈수록 속도는 빨라지고, 가격은 비싸지고, 용량은 적어진다. 저장장치 = Primary(주기억장치) + Secondary(보조기억장치) Primary 적은 용량, 빠른 속도, 비싼 가격 CPU는 한 clock 당 한 instruction이 걸리지만, Main memory는 10 clock 당 한 instruction이 걸린다. 그래서 그 중간의 완충으로 cache memory를 둔다. 당장 필요한 정보를 저장 구성: 휘발성 저장장치로 구성되어, 전원이 나가면 그 내용이 사라진다. 최상위 CPU 내부에 존재하는 register부터 cache memory, main memory 등 regsiter: CPU 내부에 존재하는 작은 저장 장소 cache memory: CPU 내부에 있는 메모리로써, CPU와 main memory 간 속도 차이를 줄이기 위해 사용 Secondary 많은 용량, 느린 속도, 저렴한 가격 당장 필요하지 않은 정보 구성: 비휘발성 저장장치로 구성되어, 전원이 나가도 지워지지 않는다. Caching: copying information into faster storage system 상대적으로 용량이 적은 빠른 저장장치를 이용해 느린 저장장치의 성능을 향상하는 총체적인 기법 상대적으로 ‘느린 저장장치’ 에 있는 내용 중 당장 필요한 것만 ‘빠른 저장장치’ 에 선별적으로 복사 저장 하여 두 저장장치의 속도를 완충시킨다. 프로그램을 구성하는 모든 부분이 균일하게 사용되는 게 아니라, 일부분만 집중적으로 사용되기 때문에 적은 용량으로도 효과를 거둔다. 9. 하드웨어의 보안 하드웨어의 보안이 필요한 이유?? OS는 multi-programming 환경에서 동작하기 때문에, 프로그램 간에 충돌이나, 다른 프로그램의 실행을 방해할 수 있기 때문. Solution: 보조 장치 Mode bit 사용 Mode bit 을 통해 하드웨어적으로 두 가지 모드의 operation 지원 Mode bit == 0: kernel mode 운영체제가 CPU를 수행하는 mode 모든 종류의 명령 실행 가능 보안을 해칠 수 있는 중요 명령어는 특권명령 으로 규정 모든 I/O 명령은 특권명령이므로, kernel mode에서 실행 interrupt가 들어오면 mode bit는 0으로 setting Mode bit == 1: user mode 사용자 프로그램이 CPU를 수행하는 mode 자신의 메모리 영역 주소만 보고 수행하여, 모든 기계어 실행을 막는다. 사용자가 무한 루프로 CPU를 사용할 경우에도 timer가 있기 때문에 CPU 독점 사용 방지가능 운영체제가 CPU 제어권을 사용자 프로그램에게 넘길 때 mode bit를 1로 세팅하여 넘긴다. 전환 mechanism CPU는 보안 관련 명령을 수행하기 전에는 항상 mode bit가 0인지 확인한다. 입출력도 보안 관련 명령이므로, 사용자 프로그램이 입출력을 직접 할 수 없고, 운영체제가 한다. 그래서, 사용자 프로그램이 입출력을 하고 싶으면 sw interrupt인 system call을 CPU에 걸어서 운영체제가 CPU를 할당 받고, interrupt vector가 가리키는 위치를 통해 interrupt service routine으로 이동한다. sw interrupt를 거는 순간 mode bit 는 1에서 0으로 세팅되어 입출력 명령을 수행할 수 있다. 10. 메모리 보안 메모리 보안이 필요한 이유?? 메모리에 여러 프로그램들이 동시에 올라와 실행되기 때문에, 한 사용자 프로그램이 다른 사용자 프로그램이나 운영체제가 위치한 메모리 영역을 침범할 수 있기 때문이다. 그래서 프로세스가 합법적인 메모리 범위에 있는지 체크하는 방법을 사용한다. Solution: 기준 레지스터(base register) + 한계 레지스터(limit register) 기준 레지스터(base register) 어떤 프로그램이 수행하는 동안 그 프로그램이 합법적으로 접근할 수 있는 메모리 상의 가장 작은 주소를 보관한다. 한계 레지스터(limit register) 프로그램이 기준 레지스터값부터 접근할 수 있는 메모리의 범위를 보관 이 Solution을 어떻게 사용하는가??? 사용자 프로그램이 base register + limit register 값을 벗어나는 주소에 접근하면 불법적인 메모리 접근이므로, SW interrupt인 exception을 발생시킨다. 그래서 CPU의 제어권을 해당 프로그램으로부터 운영체제로 이양시키고, 예외상황을 발생시킨 프로그램을 강제로 종료시킨다. 메모리 보안에서 특권명령 기준 레지스터와 한계 레지스터의 값을 세팅하는 연산은 특권명령으로 규정. 메모리 접근 연산은 사용자 프로그램이 CPU를 가지고 있는 동안 수행되므로 특권명령이 아니다. kernel mode와 user mode의 메모리 접근 차이 kernel mode: 메모리에 무제한 접근 가능 user mode: base register와 limit register를 사용해서 메모리를 보호 11. CPU 보호 CPU의 독점 사용을 방지하기 위해 Timer(타이머) 라는 하드웨어를 사용한다. 사용자 프로그램이 CPU를 보유하고 있다가 정해진 시간이 흐른 뒤, 운영체제에게 제어권이 넘어가도록 interrupt를 발생시키는 하드웨어 매 clock tick 때마다 1씩 감소하다가, 0이 되면 interrupt가 발생한다. timer의 값을 setting하는 명령을 load timer 라 하며, 특권 명령 이다. timer는 시분할 시스템을 구현하기 위해서도 사용된다. 12. 시스템 콜을 이용한 입출력 수행 모든 입출력(I/O) 명령은 특권 명령(kernel 영역)에 해당한다. 그러면 사용자 프로그램은 어떻게 I/O를 하는가?? system call이라는 SW interrupt를 통하여 운영체제에게 I/O 서비스 대행 요청을 한다. 그러면 제어권이 사용자 프로그램에서 운영체제로 넘어간다. 그리고, 운영체제는 인터럽트 처리 루틴을 실행한다. 입출력 완료 시, 제어권을 사용자 프로그램에게 넘긴다. Reference 운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_03_%EC%BB%B4%ED%93%A8%ED%84%B0%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%EB%8F%99%EC%9E%91%EC%9B%90%EB%A6%AC_2/","summary":"입출력 구조, DMA, 저장장치의 구조 그리고 계층구조에 대해 알아본다. 또한, 하드웨어, 메모리, CPU의 각 보안 방법에 대해 알아본다.","title":"[TIL] Chapter 03: 컴퓨터 시스템의 동작원리 2"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 1. 컴퓨터 시스템의 구조 1.1 컴퓨터의 구조: 내부장치와 외부장치 컴퓨터 시스템의 구조 = 컴퓨터 내부장치 + 컴퓨터 외부장치 컴퓨터 내부장치 : CPU, Memory 컴퓨터 외부장치 : Disk, keyboard, mouse, monitor, network device 등 1.2 컴퓨터의 업무 처리 방식 컴퓨터 외부장치에서 내부장치로 데이터를 읽어와 각종 연산을 수행한 후, 연산 결과를 외부장치로 다시 내보내는 방식으로 업무를 처리한다. 이때, 업무의 각 부분을 다음과 같이 정의한다. 입력(input): 컴퓨터 내부로 데이터가 들어오는 것 출력(output): 컴퓨터 외부장치로 데이터가 나가는 것 입출력(Input-output: I/O): 컴퓨터 시스템이 컴퓨터 외부 입출력 장치들과 데이터를 주고 받는 것 예시) 키보드로부터 입력을 받아 컴퓨터가 연산을 한 후, 그 결과를 모니터에 출력 컴퓨터 외부장치인 디스크에서 내용을 읽어 컴퓨터 내부에 연산을 한 후, 디스크에 데이터를 저장. 1.3 Controller: 각 하드웨어 장치의 작은 CPU 컴퓨터 전체에 CPU(Cetnral Processing Unit)라는 중앙처리장치가 있듯이, 컴퓨터의 각 하드웨어 장치에는 이들을 제어하는 일종의 작은 CPU인 컨트롤러 가 있다. 예) 메모리를 제어하는 컨트롤러는 메모리 컨트롤러 디스크를 제어하는 컨트롤러는 디스크 컨트롤러 2. CPU 연산과 I/O 연산 2.1 연산 = CPU가 무언가를 한다 컴퓨터에서 연산을 한다 = CPU가 무언가 일을 한다 컴퓨터의 구성장치 관점에서 연산을 나눠 보자면 다음과 같이 담당한다. 입출력 장치들의 I/O 연산 → 입출력 컨트롤러가 담당 컴퓨터 내에서 수행되는 연산 → main CPU 이 때 입출력 장치와 main CPU는 일이 다른 곳에서 발생하므로 동시 수행이 가능하다. 2.2 Local Buffer(로컬 버퍼) 각 장치 컨트롤러는 장치로부터 오고 나가는 데이터를 임시 저장 하기 위한 작은 메모리인 로컬 버퍼(local buffer) 가 존재한다. 입력 장치로부터 데이터를 읽어오는 경우, 각 입력장치의 컨트롤러가 장치에서 로컬버퍼로 데이터를 읽어와서 저장 후, 컴퓨터 내부의 메모리에 전달한다. 2.3 CPU와 I/O 장치의 연산과정 프로그램에서 데이터를 읽어오라는 명령을 내린다 → 각 장치의 컨트롤러가 장치로부터 내용을 읽어 로컬버퍼에 저장한다 → 데이터를 읽는 작업을 완료했기 때문에, 메인 CPU에서 I/O 작업을 요청한 프로그램의 다음 일을 수행할 수 있다. HW 또는 SW는 CPU 옆에 인터룹트 라인(interrup line) 을 세팅하는 명령을 실행하여, 컨트롤러가 인터룹트(interrupt) 를 발생시켜 메인 CPU에게 I/O작업이 완료됨을 알린다 → 인터럽트란 컨트롤러들이 CPU의 서비스가 필요할 때 이를 통보하는 방법 CPU는 명령 하나를 수행할 때마다 인터룹트가 발생했는지 확인하는데, 인터럽트가 발생하면 자신이 하던 일을 멈추고, 인터럽트 처리를 먼저 한 후 멈춘 명령을 다시 수행한다. 3. 인터럽트의 일반적 기능 3.1 Interrupt(인터럽트)란?? 인터럽트(Interrupt)란 CPU의 제어권을 양도하라는 신호\n사용자 프로그램에게 CPU 제어권이 있어서, CPU를 사용하고 있다가 interrupt를 발생시키면 kernel에게 CPU가 이양된다.\n오늘날 운영체제가 CPU를 점유하는 건 인터럽트에 의하지 않고는 발생하지 않는다.\n운영체제는 단지 인터럽트가 발생할 때에만 CPU의 제어권을 획득할 수 있는데, 인터럽트가 발생하지 않으면 사용자 프로그램이 계속 CPU를 점유한다. 3.2 인터럽트 처리루틴이란??? 인터럽트를 당한 시점의 레지스터와 program counter를 저장한 후, CPU 제어를 인터럽트 처리 루틴에 넘긴다. 인터럽트 처리루틴(Interrupt Service Routine) 이란? 해당 인터럽트를 처리하는 커널 함수 인터럽트 핸들러(interrupt handler) 라고도 한다. 다양한 controller가 있는 만큼 interrupt의 종류도 다양하다. 그러므로 인터럽트 처리루틴의 종류도 다양하다. 인터럽트 벡터(interrupt vector) 해당 인터럽트의 처리 루틴 주소를 가리킨다. 인터럽트 처리루틴까지의 과정 컨트롤러가 인터럽트를 발생시키면 CPU는 인터럽트 라인을 통해 인터럽트 발생을 확인하고, 자신이 하던 일을 멈춘다.\n-\u0026gt; 프로그램의 실행 상태를 PCB에 저장한 후, CPU의 제어권은 프로세스에서 운영체제로 넘어간다.\n-\u0026gt; 그리고, 운영체제는 interrupt vector가 가리키는 곳으로 가서 인터럽트 처리루틴을 찾는다.\n-\u0026gt; 인터럽트 처리루틴을 통해 해당하는 인터럽트 처리를 완료하고 나면, CPU는 PCB로부터 CPU 상에 복원하여 인터럽트 당하기 직전의 위치부터 계속 수행. 3.3 Interrupt line 특정 프로그램이 CPU를 독점하는 걸 방지하기 위해서 timer 라는 HW를 사용하여, timer의 시간이 다 되면 interrupt line 을 통해 interrupt를 건다. 또한, controller가 I/O 작업을 완료하면 interrupt line을 통해 interrupt를 건다. 3.4 인터럽트의 종류: HW interrupt 와 SW interrupt Interrupt = HW interrupt + SW interrupt HW interrupt HW가 발생시킨 인터럽트 HW 일꾼들이 CPU와 정보 교신을 위해서 거는 것 하드웨어 장치가 CPU의 interrupt line을 세팅한다. ex) Timer Interrupt, device controller가 발생시키는 interrupt 통상적으로 불리는 interrupt의 의미가 HW interrupt다. SW interrupt (= 트랩(trap)) 사용자 프로그램이 운영체제에게 대행해달라고 요청하는 것 소프트웨어가 CPU의 interrupt line을 세팅한다. Trap의 종류: 예외 상황(exception) 과 시스템 콜(system call) HW interrupt와 SW interrupt의 공통점 CPU 옆 인터럽트 라인에 신호를 보내 인터럽트 발생유무를 알리는 방식은 동일하다. 3.5 Trap: exception 과 system call 3.5.1 예외 상황(exception) 비정상적인 작업 또는, 권한이 없는 작업을 시도할 때, 이에 대한 처리를 위해 발생시키는 인터럽트\n비정상적인 작업의 예: 사용자 프로그램이 0으로 나누는 연산을 실행 권한이 없는 작업의 예: 사용자 프로그램이 자신의 메모리 영역 바깥에 접근하려는 시도 3.5.2 시스템 콜(system call) 사용자 프로그램이 운영체제 내부에 정의된 코드를 실행할 때, 운영체제에게 서비스를 요청하는 trap\n사용자 프로그램의 코드는 사용자 프로그램이 CPU에 대한 제어권을 가지고 실행한다. 하지만, 커널 내부에 있는 코드를 사용자 프로그램이 실행하고자 할 때는 사용자 프로그램이 직접 접근할 수 있는 게 아니라, system call을 통해서 대행 요청 을 한다. system call 요청을 interrupt line 을 통해 CPU 제어권을 운영체제로 넘겨 커널 내부 코드를 실행한다. 4. 인터럽트 핸들링(Interrupt handling) 4.1 Interrupt handling 이란?? 인터럽트가 발생한 경우에 처리해야할 일의 절차\n프로그램 A가 실행되고 있을 때, 인터럽트가 발생하면 프로그램 A의 현재 상태를 먼저 저장 한다.\n현재 상태란? 현재 CPU에서 실행 중인 명령의 메모리 주소를 포함해 몇 가지 부가적인 정보들을 의미한다. 현재 상태를 먼저 저장하는 이유는??\nCPU에서 명령이 실행될 때 CPU 내부에 있는 임시 기억장치인 레지스터(register)에 데이터를 읽거나 쓰면서 작업을 한다. 그런데, 인터럽트가 발생해 새로운 명령을 실행하면 기존의 레지스터 값들이 지워지므로 , CPU 내의 이러한 상태를 저장해둬야 한다. 4.2 PCB(Process Control Block)이란?? OS가 현재 시스템 내에서 실행되는 프로그램들을 관리하기 위해 둔 자료구조로 PCB(Process Control Block, 프로세스 제어 블록)라 한다.\nPCB 는 각각의 프로그램마다 하나씩 존재 한다. 해당 프로그램의 어느 부분이 실행 중이었는지를 저장 한다. ex) 코드의 메모리 주소, 레지스터값, 하드웨어 상태 등 PCB 사용절차 Interrupt 발생 → CPU의 제어권을 넘기기 전에 프로그램의 실행 상태를 PCB에 저장 → CPU의 제어권이 OS로 넘어간다 → 운영체제는 인터럽트 벡터가 가리키는 곳으로 가서 인터럽트 처리루틴에 따라 인터럽트 처리를 수행→ 인터럽트 처리 완료 → 저장된 상태를 PCB로부터 CPU 상에 복원 → 인터럽트 당하기 직전 위치부터 재실행 Reference 운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 - ","permalink":"http://jeha00.github.io/post/os/os_chapter_03_%EC%BB%B4%ED%93%A8%ED%84%B0%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%EB%8F%99%EC%9E%91%EC%9B%90%EB%A6%AC_1/","summary":"I/O 연산이 무엇이고, controller와 local buffer가 무엇이고, 입출력 연산이 Interrupt를 중심으로 어떻게 진행되는지를 알아본다.","title":"[TIL] Chapter 03: 컴퓨터 시스템의 동작원리 1"},{"categories":["Python"],"content":"1. Context Manager란? 원하는 타이밍에 정확하게 resource를 할당 및 제공하며, 반환하는 역할을 한다.\n그래서, special method .__enter__ 와 .__exit__을 가지고 있는 객체를 말한다.\n1.1 Context Manager가 필요한 이유??? 외부와 connection될 때, 한정된 H/W resource를 사용하기 때문에, resource가 제 때 반환되지 않으면 system이 느려지거나 특정 상황에서 error가 발생할 수 있다. 즉, 문을 열고 들어갔으면 문을 닫아야 하고, 도서관에서 책을 빌리면 책을 반납해야 하듯이 memory resource 또한 사용되면 반환되야 한다. 그래서 원하는 시점에 resource 할당 및 회수를 위해서 context manager가 중요하다. 이러한 특징으로 외부 resource를 처리하는 작업을 할 때, 안전하게 할 수 있는 기능을 만들 수 있다. 1.2 Context Manager의 magic method What is a \u0026ldquo;runtime context?\u0026rdquo; stackoverflow 내용을 덧붙인다.\nwith statement 아래의 code block에 들어가기 위해서 .__enter__ special method가 호출된다. with statement 아래의 code block에서 나가기 위해서 .__exit__ special method가 호출된다. Python docs: Context Manager Types의 내용을 추가한다.\ncontext manager는 context manager 자체를 반환하는데 이것의 example 중 하나는 file object다.\nfile obejct는 open() function이 with statement 에서 사용되기 위해 __enter__ 로부터 file object 자신들을 반환한다.\n.__enter__() magic method에 의해 반환된 값은 with statement의 as 절의 식별자(identifier)에 연결된다.\n.__exit__(exc_type, exc_val, exc_tb) 은 runtime context를 빠져나오고, 발생한 exception을 무시해야하는지를 가리키는 boolean flag를 반환한다.\nwith 문의 body를 실행하는 동안 예외가 발생하면 예외 타입, 값, 추적정보가 포함된다. 이 method에서 True를 반환하면, with문이 예외를 막고 계속해서 실행한다. Context manager의 대표적인 구문인 with를 이해해야한다.\nwith문에 관한 내용은 [TIL] Python basic 20: with open as 와 [TIL] Python basic 21: csv.read, write을 참고한다. 2. Context manager: no use \u0026lsquo;with\u0026rsquo; 1 2 3 4 5 6 7 8 9 \u0026gt; file = open(\u0026#39;./testfile1.txt\u0026#39;, \u0026#39;w\u0026#39;) # 파일을 열고 \u0026gt; try: \u0026gt; file.write(\u0026#39;Context Manager Test1.\\nContextlib Test1.\u0026#39;) # 파일을 닫는다. \u0026gt; finally: \u0026gt; file.close() python이 업데이트 되어 나온게 with문이다. 3. Context manager: use \u0026lsquo;with\u0026rsquo; 위에 no use \u0026lsquo;with\u0026rsquo; 에서의 코드가 with를 사용해서 다음 code로 바뀐다. close를 입력하지 않아도, 자동으로 반환한다. 그래서 이 with문으로 Internet connection을 맺고 끊는 것으로 사용할 수 있다. 1 2 \u0026gt; with open(\u0026#39;testfile1.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: \u0026gt; f.write(\u0026#39;Context Manager Test1.\\nContextlib Test1.\u0026#39;) 위 코드의 결과로 testfile2.txt 가 생성되고, 그 안에는 Context Manager Test2. \\nContextlib Test2. 가 작성되어 있다. 4. Context manager: use \u0026lsquo;class\u0026rsquo; magic method를 사용하여 class로 customizing 한 후, with문을 실행해보자. with문을 실행하면 magic method는 이와 같은 순서로 실행된다. __init__ -\u0026gt; __enter__가 실행된다. 실행된 결과로 어느 값이 반환되고, 이 반환 값으로 write 작업을 실행한다. write 작업이 완료 후, 빠져나갈 때 error가 발생되면 __exit__의 print에서 처리되고, close()가 실행된다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026gt; class FileWriter(): \u0026gt; def __init__(self, file_name, method): \u0026gt; print(\u0026#39;FileWriter started : __init__\u0026#39;) \u0026gt; self.file_obj = open(file_name, method) \u0026gt; def __enter__(self): \u0026gt; print(\u0026#39;MyfilerWriter started : __enter__\u0026#39;) \u0026gt; return self.file_obj \u0026gt; def __exit__(self, exc_type, value, trace_back): \u0026gt; print(\u0026#39;FileWriter started : __exit__\u0026#39;) \u0026gt; if exc_type: \u0026gt; print(\u0026#39;Logging exception {}\u0026#39;.format(exc_type, value, trace_back)) \u0026gt; self.file_obj.close() \u0026gt; with FileWriter(\u0026#39;testfile1.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: \u0026gt; f.write(\u0026#39;Context Manager Text1.\\nContextlib Test1\u0026#39;) FileWriter started : __init__ FileWriter started : __enter__ FileWriter started : __exit__ # 그리고 testfile3.txt가 생성된다. 5. Context manager: Measure execution Github에서 많이들 제작하는 timer다. 이 timer로 with문이 걸린 시간을 알 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026gt; class Timer(object): \u0026gt; def __init__(self,msg): \u0026gt; delf._msg = msg \u0026gt; def __enter__(self): # 시간을 숫자형태로 가져와서, self의 start 변수에 저장한다. \u0026gt; self._start = time.monotonic() \u0026gt; return self._start \u0026gt; def __exit__(self, exc_type, exc_value, exc_traceback): \u0026gt; if exc_type: \u0026gt; print(\u0026#34;Logging exception {}\u0026#34;.format(exc_type, exc_value, exc_traceback)) \u0026gt; else: \u0026gt; print(\u0026#39;{} : {}s\u0026#39;.format(self._msg, time.monotonic() - self._start)) # with문을 잘 빠져나왔다는 의미 \u0026gt; return True \u0026gt; with Timer(\u0026#34;Start!\u0026#34;) as j: \u0026gt; print(\u0026#39;Received start monotonic1 : {}\u0026#39;.format(v)) # self._start가 v에 연결된 걸 확인했다. Received start monotonic1 : 590914.968 # else문이 실행된 결과 Start! job: 0.35999999998603016 s 6. Context manager: use \u0026lsquo;decorator\u0026rsquo; contextlibary를 annotation을 사용하여 class 형태가 아닌 함수 형태로 구현해본다. 코드의 line을 줄일 수 있고, 직관적으로 코드를 작성할 수 있다. class로 context manager를 구현하는 것보다 확실히 간결하다. 하지만, \u0026lsquo;예외 처리\u0026rsquo;를 꼼꼼히 정석대로 할려면 class로 구현하는 게 낫다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; import contextlib \u0026gt; import time # annotation \u0026gt; @contextlib.contextmanger \u0026gt; def writer(file_name, method): \u0026gt; f = open(file_name, method) # __enter__ \u0026gt; yield f # __exit__ \u0026gt; f.close() # yield된 f가 with문의 alias f와 연결된다. \u0026gt; with writer(\u0026#39;testfile1.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: \u0026gt; f.write(\u0026#39;Context manager Test4.\\nContextlib test4\u0026#39;) 마지막 예제로 decorator를 사용하여 timer를 만들어보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026gt; @contextlib.contextmanager \u0026gt; def Timer(msg): \u0026gt; start = time.monotonic() # __enter__ \u0026gt; try: \u0026gt; yield start \u0026gt; except BaseException as e: \u0026gt; print(\u0026#39;Logging exception {} : {}\u0026#39;.format(msg, e)) \u0026gt; raise # __exit__ \u0026gt; else: \u0026gt; print(\u0026#39;{} : {} s\u0026#39;.format(msg, time.monotonic() - start)) \u0026gt; with Timer(\u0026#34;Start!\u0026#34;) as v: \u0026gt; print(\u0026#39;Received start monotonic2 : {}\u0026#39;.format(v)) Received start monotonic2 : 594934.0 Start! : 0.42099999997299165 s Reference 모두를 위한 파이썬 : 필수 문법 배우기 Feat. 오픈소스 패키지 배포 (Inflearn Original) [TIL] Python basic 20: with open as [TIL] Python basic 21: csv.read, write What is a \u0026ldquo;runtime context?\u0026rdquo; Python docs: Context Manager Types ","permalink":"http://jeha00.github.io/post/python/python_basic_42_contextmanager/","summary":"context manager가 무엇이고, 이를 with, class, decorator를 사용하여 여러 방법으로 구현해본다.","title":"[TIL] Python basic 42: Context manager"},{"categories":["Python"],"content":"Intro [TIL] Python basic 29: Data Model에서 간단히 다뤘던 shallow copy와 deep copy에 대해 깊이 알아보자.\n또한, 이번에 학습하는 개념은 Pointer의 개념과 연결되는 것으로 아래 링크들과 연결된다.\n[TIL] Python basic 40: Call by object reference shallow copy와 deep copy는 모든 분야에 통틀어 알고 있어야 하는 지식이다. Python은 모든 걸 객체취급하는데, 이 객체의 복사를 수행하는 명령어가 copy 명령어다. 어느 수준까지 복사가 되는 지에 따라 copy, shallow 그리고 deep copy로 나눠진다. 각 copy에 대해 정확히 이해한 후, 프로그램 개발에 사용해야 문제가 발생하지 않고, 디버깅의 방해 요소가 되지 않는다. 또한, 구현하려는 목적에 맞게 이 3가지 copy 방식을 구분해서 사용해야 한다. 1. Copy 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # mutable data type \u0026gt; a_list = [1, 2, 3, [4, 5, 6], [7, 8, 9]] # call by reference \u0026gt; b_list = a_list # 동일한 id가 출력된다. \u0026gt; print(id(a_list), id(b_list)) 2230595359488 2230595359488 \u0026gt; print(id(a_list) == id(b_list)) True # b_list를 수정해보자. \u0026gt; b_list[2] = 100 # b_list만 수정했지만, 어째서인지 a_list까지 수정되었다. \u0026gt; print(a_list) [1, 2, 100, [4, 5, 6], [7, 8, 9]] \u0026gt; print(b_list) [1, 2, 100, [4, 5, 6], [7, 8, 9]] # b_list를 다시 수정해보자. \u0026gt; b_list[3][2] = 100 \u0026gt; print(a_list, b_list) [1, 2, 100, [4, 5, 100], [7, 8, 9]] \u0026gt; print(a_list, b_list) [1, 2, 100, [4, 5, 100], [7, 8, 9]] 일반적인 copy 방식으로 call by reference 방식이다. 동일한 reference를 참조하기 때문에, b_list의 성분만을 수정했지만 a_list 까지 수정되었다. 2. Shallow Copy 중첩 data는 수정된다.\nshallow copy는 위에 일반 copy와 달리 copy module을 import 해야 한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; c_list = [1, 2, 3, [4, 5, 6], [7, 8, 9]] \u0026gt; d_list = copy.copy(c_list) # 위에 call by reference로 복사한 것과 달리 id 값이 다른 걸 확인할 수 있다. \u0026gt; print(id(c_list), id(d_list)) 1892474493824 1892474493568 # d_list 수정 \u0026gt; d_list[1] = 100 # c_list는 수정되지 않았다. \u0026gt; print(\u0026#39;c_list \u0026gt; \u0026#39;, c_list) c_list \u0026gt; [1, 2, 3, [4, 5, 6], [7, 8, 9]] # d_list만 수정되었다. \u0026gt; print(\u0026#39;d_list \u0026gt; \u0026#39;, d_list) d_list \u0026gt; [1, 100, 3, [4, 5, 6], [7, 8, 9]] 여기까지만 보면 왜 shallow copy인지 이해가 안갈 것이다.\n왜냐하면 d_list를 수정해도 c_list가 수정되지 않기 때문이다.\n그러면 list 안에 list 성분을 수정해보자.\n1 2 3 4 5 6 7 8 9 \u0026gt; d_list[3].append(1000) \u0026gt; d_list[4][1] = 10000 # d_list만 시도했지만, c_list까지 중첩 data가 수정되었다. \u0026gt; print(\u0026#39;c_list \u0026gt; \u0026#39;, c_list) [1, 2, 3, [4, 5, 6, 1000], [7, 10000, 9]] \u0026gt; print(\u0026#39;d_list \u0026gt; \u0026#39;, d_list) [1, 100, 3, [4, 5, 6, 1000], [7, 10000, 9]] mutable 안에 중첩 data는 동일한 reference를 참조한다는 걸 알 수 있다.\n이를 id function으로 확인해보자.\n1 2 3 4 5 6 7 8 \u0026gt; print(\u0026#39;nested data - \u0026#39;,id(c_list[3]), id(d_list[3])) nested data - 2343545032000 2343545032000 \u0026gt; print(\u0026#39;c_list \u0026gt; \u0026#39;, id(c_list)) c_list \u0026gt; 2636124593152 \u0026gt; print(\u0026#39;d_list \u0026gt; \u0026#39;, id(d_list)) d_list \u0026gt; 2636124592896 중첩된 data 까지는 독립된 reference를 가지지 않는 걸 확인했다.\n3. Deep Copy 중첩된 data까지 독립된 id를 가진다.\nDeep copy도 copy module을 import 하는 것부터 시작한다.\nshallow copy는 중첩 성분을 포함하는 객체만 복사하는 방식이면, deep copy는 중첩 성분까지 복사한다.\n그래서 deep copy를 깊은 복사 말고, 전체 복사라고도 한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; c_list = [1, 2, 3, [4, 5, 6], [7, 8, 9]] \u0026gt; d_list = copy.deepcopy(c_list) # 다른 id 값을 확인할 수 있다. \u0026gt; print(\u0026#39;Ex3 \u0026gt; \u0026#39;, id(c_list)) Ex3 \u0026gt; 2636124592960 \u0026gt; print(\u0026#39;Ex3 \u0026gt; \u0026#39;, id(d_list)) Ex3 \u0026gt; 2636124593408 # 내장된 data도 독립된 id값을 가진 걸 확인할 수 있다. \u0026gt; print(\u0026#39;nested data \u0026gt; \u0026#39;, id(c_list[3])) nested data \u0026gt; 1329303493056 \u0026gt; print(\u0026#39;nested data \u0026gt; \u0026#39;, id(d_list[3])) nested data \u0026gt; 1329303494272 4. list comprehension에서를 통한 깊은 복사 list comprehension의 주의사항 글을 보면 리스트를 곱셈 연산을 사용하여 늘리는 것과 list comprehension으로 늘리는 것은 다르다는 걸 알 수 있는데, 곱셈 연산은 똑같은 참조값을 참조하는 값을 늘리는 것으로 얕은 복사(shallow copy)다. 하지만 list comprehension으로 늘리는 것은 동일한 값이지만 다른 참조값을 가지는 걸 통해 \u0026lsquo;객체를 새로 생성하는 것\u0026rsquo;으로 늘리므로 깊은 복사(deep copy)임을 알 수 있다.\n5. Summary 다음 image로 shallow copy와 deep copy 복사 정도를 비교하면 쉽게 알 수 있다.\n같은 색상의 block이 동일한 id를 가지고 있다.\nshallow copy는 객체만을 복사하고, 객체의 성분은 복사하지 않는다.\n객체는 call by value, 객체의 성분은 call by reference 하지만, deep copy는 객체와 객체의 성분까지 복사한다.\n객체와 객체의 성분도 call by value shallow copy deep copy\nReference 모두를 위한 파이썬 : 필수 문법 배우기 Feat. 오픈소스 패키지 배포 (Inflearn Original) [TIL] Python basic 29: Data Model ","permalink":"http://jeha00.github.io/post/python/python_basic_41_shallowdeepcopy/","summary":"Shallow copy 와 Deep copy가 각각 무엇이고, 무슨 차이인지 알아본다.","title":"[TIL] Python basic 41: Shallow copy \u0026 Deep copy"},{"categories":["Python"],"content":"0. Introduction python의 변수를 만드는 원리와 호출 방식에 대해 알아보자.\n또한, 이번에 학습하는 개념은 Pointer의 개념과 연결되는 것으로 아래 링크들과 연결된다.\n[TIL] Python basic 41: Shallow copy \u0026amp; Deep copy [TIL] Python basic 29: Data Model 1. Object reference 파이썬의 변수들은 객체에 대한 참조들이다.\n컴퓨터 프로그램에서 사용되는 한 물리적인 메모리 위치를 나타내는 상징적으로 나타내는 이름이 변수 다.\n이 변수에는 여러 가지 data type들이 담겨질 수 있으니, container 로 생각하자. program이 실행되는 동안, 이 변수에 접근할 수 있고, 변경할 수도 있다. 하지만, 변수를 만드는 원리가 C,C++, JAVA 와 Python에는 차이가 있다.\nC,C++, JAVA 의 예\n먼저 변수 이름을 아래와 같이 선언한다. 1 2 \u0026gt; int x \u0026gt; int y 위 코드를 그림으로 표현하면 다음과 같다.\n그리고 나서 변수들에 값을 할당한다. 할당하는 건 =을 사용한다. 1 2 \u0026gt; x = 42 \u0026gt; y = 78 위 코드를 그림으로 표현하면 다음과 같다.\n변수를 할당할 때는 처음에 int로 정했기 때문에, integer type만 할당할 수 있다.\n다음으로 Python에서의 variable을 알아보자. 파이썬에서는 선언하는 게 필요 없고, 바로 변수의 이름과 이 변수에 할당할 data type과 value만 정하면 된다. C, C++, JAVA의 경우에는 변수가 선언되고 그 변수 안에 값이 담겨지지만 파이썬은 그렇지 않다. 파이썬의 변수들은 객체들을 가리키고, 객체들은 임의의 data type을 가질 수 있다. 그리고 실제 데이터는 객체들 안에 포함되어 있다.\n1 \u0026gt; x = 42 아래 이미지는 파이썬에서 x = 42를 그림으로 구현할 것이다.\n1 \u0026gt; y = x 아래 이미지는 파이썬에서 y = x를 그림으로 구현할 것이다.\n2. Call by object reference python은 공식문서에 따르면 call by object reference 방식으로 호출한다.\n인수의 데이터 타입에 따라 call by value 와 call by reference 인지 결정하는 방식이다.\n값에 의한 호출(call by value): immutable object 참조에 의한 호출(call by reference): mutable object 각 방식에 대해 code로 구현해보자.\ndata type에 따라 id 값이 변하는 것과 변하지 않는 것에 대한 설명은 [TIL] Python basic 29: Data Model를 참조한다.\n2.1 Call by value 실제 인수의 값을 매개변수에 복사하는 방식이다. 값에 의한 호출 이라 한다. 변수에 할당된 값만을 복사해서 함수의 인자로 넘긴다. 파이썬은 immutable object일 때 이 방식을 사용한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026gt; def foo(s): \u0026gt; print(id(s), s) \u0026gt; s += \u0026#34; is Best\u0026#34; \u0026gt; print(id(s),s) \u0026gt; return s \u0026gt; msg = \u0026#34;Python\u0026#34; \u0026gt; print(\u0026#39;msg = \u0026#39;, msg, id(msg)) msg = Python 2072884335536 \u0026gt; foo(msg) 2072884335536 Python 2072889254896 Python is Best \u0026gt; print(\u0026#39;msg = \u0026#39;, msg, id(msg)) msg = Python 2072884335536 순서는 다음과 같다. \u0026ldquo;Python\u0026quot;이라는 문자열 인스턴스를 msg 라는 변수가 가리키고 있다. foo의 매개변수 s 에 msg가 입력되면서 매개변수 s 또한 \u0026ldquo;Python\u0026quot;이라는 문자열 인스턴스를 가리키고 있다. s += 연산을 통해 \u0026ldquo;Python is Best\u0026rdquo; 라는 문자열 인스턴스를 생성되어 참조 객체가 달라지기 때문에 메모리 주소가 다르다. 그리고 달라진 참조 객체를 변수 s가 가리킨다. 2.2 Call by reference 실제 인수의 참조를 매개변수에 복사하여, 매개변수가 실제 인수와 같아지는 방식이다. 참조에 의한 호출 이라 한다. 함수의 인자로 넘어간 값이 함수 내부에서 변경되면, 실제로 값이 변경된다. 파이썬은 mutable object일 때 이 방식을 사용한다. mutable object가 넘어갈 때, object reference가 넘어가기 때문에 값을 바꿀 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; def foo(s): \u0026gt; print(s, id(s)) \u0026gt; s.append(10) \u0026gt; print(s, id(s)) \u0026gt; msg = [s for s in range(1,6)] \u0026gt; print(\u0026#39;msg = \u0026#39;, msg, id(msg)) msg = [1, 2, 3, 4, 5] 4310824192 \u0026gt; foo(msg) [1, 2, 3, 4, 5] 4310824192 [1, 2, 3, 4, 5, 10] 4310824192 \u0026gt; print(\u0026#39;msg = \u0026#39;, msg, id(msg)) msg = [1, 2, 3, 4, 5, 10] 4310824192 foo function에서 수정했지만, 그것이 global scope에서 출력 시에도 영향을 준다. 즉, 참조값이 수정된 걸 의미한다. 하지만, list의 성분인 integer가 값이 바뀌면 id 값은 바뀐다. Reference 모두를 위한 파이썬 : 필수 문법 배우기 Feat. 오픈소스 패키지 배포 (Inflearn Original) [TIL] Python basic 29: Data Model Python tutorials Data type call-by-value, call-by-reference ","permalink":"http://jeha00.github.io/post/python/python_basic_40_callbyobjectreference/","summary":"python의 변수를 만드는 원리인 object reference에 대해 알아보고, 파이썬의 호출 방식인 call by object reference에 대해 알아본다.","title":"[TIL] Python basic 40: Call by object reference"},{"categories":["Python"],"content":"0. Introduction [TIL] Python basic 31: First-class에서 학습한 고위 함수(High-Order Function)의 대표적인 예인 map, filter, reduce function에 대해 집중적으로 학습하기 위해 작성한다. 그래서 고위 함수(High-Order Function)란 무엇인지 간단히 알아보고, 각 fuction에 대해 기존에 했던 예제에 추가하여 더 알아보자. High - Order Function (고위 함수)란??\n함수들 중 인수로 전달 가능하고, 결과값으로서 반환 가능한 함수 일급 함수(first - class)의 특징이기도 한다. 이번 예에서 lambda function을 사용할 것이다.\n[TIL] Python basic 12: Method 에서 학습했으므로, 이를 참조한다. 1. Map map(func, iterable)\niterable에 있는 모든 요소에 지정한 function을 적용하여 결과를 iterator로 반환한다. return 된 객체는 map oject 다. map의 인자로 넘어가는 function은 3가지 방식으로 구현해본다.\nlambda (Ex1-1) def (Ex1-2) closure (Ex1-3) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 \u0026gt; digist1 = [x * 10 for x in range(1, 6)] \u0026gt; print(\u0026#39;Ex1 \u0026gt; \u0026#39;, digist1) Ex1 \u0026gt; [10, 20, 30, 40, 50] \u0026gt; result = map(lambda x: x ** 2, digist1) \u0026gt; print(\u0026#39;Ex1-1 lambda \u0026gt; \u0026#39;result) Ex1-1 lambda \u0026gt; \u0026lt;map object at 0x000002786FE62D90\u0026gt; # map object로 뜨기 때문에 type conversion을 한 후, result에 할당한다. # lambda를 사용했기 때문에, 메모리에 저장되지 않고 garbage collector에 의해서 제거된다. \u0026gt; result = list(map(lambda x: x ** 2, digist1)) \u0026gt; print(\u0026#39;Ex1-1 lambda \u0026gt; \u0026#39;result) Ex1-1 lambda \u0026gt; [100, 400, 900, 1600, 2500] # lambda로 구현한 함수를 선언형으로 해보자. \u0026gt; def ex2_func(x): \u0026gt; return x ** 2 \u0026gt; result = list(map(ex2_func, digist1)) \u0026gt; print(\u0026#39;Ex1-2 function \u0026gt; \u0026#39;, result) Ex1-2 function \u0026gt; [100, 400, 900, 1600, 2500] # closure를 통해서 선언해보자. \u0026gt; def also_square(nums): \u0026gt; def double(x): \u0026gt; return x * 2 \u0026gt; return map(double, nums) \u0026gt; print(\u0026#39;Ex1-3 Closure\u0026#39;, list(also_square(digist1))) Ex1-3 Closure \u0026gt; [20, 40, 60, 80, 100] 2. Filter filter(func, iterable)\niterable 중에서 function 조건에 True인 요소만 뽑아 새로운 시퀀스형으로 만드는 함수 return된 객체는 filter object 다. filter의 인자로 넘어가는 function은 2가지 방식으로 구현해본다.\nlambda (Ex1-1) closure (Ex1-3) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # list comprehension으로 iterator를 만든다. \u0026gt; digist2 = [x for x in range(1, 6)] # 홀수만 출력한다. # lambda 사용 \u0026gt; result = list(filter(lambda x: x % 2, digist2)) \u0026gt; print(\u0026#39;Ex2-1 lambda \u0026gt; \u0026#39;, result) Ex2-1 lambda \u0026gt; [1, 3, 5] # closure 사용 \u0026gt; def odd(nums): \u0026gt; def is_oven(x): \u0026gt; return x % 2 \u0026gt; return filter(is_oven, nums) \u0026gt; print(\u0026#39;Ex2-2 closure\u0026#39;, odd(digist2)) Ex2-2 closure \u0026gt; [1, 3, 5] 3. Reduce reduce(func, iterable)\niterable의 요소를 왼쪽부터 오른쪽 방향으로 함수를 적용하여 하나의 값으로 합친다. reduce는 built-in fuction이 아니기 때문에, 별도로 import를 해야 한다.\nfrom functools import reduce reduce의 인자로 넘어가는 function은 2가지 방식으로 구현해본다.\nlambda (Ex1-1) closure (Ex1-3) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; from functools import reduce \u0026gt; digit3 = [x for x in range(1, 101)] # lambda 사용 \u0026gt; reduce = reduce(lambda x,y: x + y, digit3) \u0026gt; print(\u0026#39;Ex3 lambda \u0026gt; \u0026#39;, reduce) 5050 # closure 사용 \u0026gt; def also_add(nums): \u0026gt; def add_plus(x,y): \u0026gt; return x + y \u0026gt; return reduce(add_plus, nums) \u0026gt; print(\u0026#39;Ex3 Closure \u0026gt; \u0026#39;, also_add(digit3)) 5050 Reference 모두를 위한 파이썬 : 필수 문법 배우기 Feat. 오픈소스 패키지 배포 (Inflearn Original) [TIL] Python basic 31: First-class ","permalink":"http://jeha00.github.io/post/python/python_basic_39_mapfilterreduce/","summary":"High-order function의 대표적인 예인 map, filter, reduce에 대해 lambda, def, closure로 구현해본다.","title":"[TIL] Python basic 39: Map, Filter, Reduce"},{"categories":"OS","content":"0. Introduction 해당 내용은 운영체제와 정보기술의 원리을 보고 혼자 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다. 1. 운영체제의 정의 운영체제란? 운영체제(operating system) 란??\n컴퓨터 하드웨어의 바로 윗단에 설치되는 소프트웨어로, 사용자 및 다른 소프트웨어와 하드웨어를 연결하는 소프트웨어 계층이다.\n왜 system이라 하는가??? system은 흔히들 하드웨어를 지칭할 때 주로 사용되는 단어인데, 이 system을 사용한 이유는 운영체제 없이 하드웨어만 있다면 컴퓨터 역할을 할 수 없고, OS와 하드웨어가 같이 있어야 진정한 컴퓨터이기 때문이다.\nkernel이란?? 소프트웨어가 실행되기 위해서는 메모리에 그 프로그램이 올라가야 한다. 운영체제도 하나의 SW이기 때문에, 컴퓨터 하드웨어의 전원이 켜지는 동시에, 메모리에 올라간다. 이 운영체제 SW는 규모가 큰 프로그램이기 때문에, 운영체제 전부를 메모리에 올린다면 메모리 공간 낭비가 심해진다.\n그래서 운영체제 중 항상 필요한 부분만 을 전원이 켜짐과 동시에 메모리에 올려놓고, 그렇지 않은 부분은 필요할 때 메모리로 올려서 사용한다. 메모리에 항상 상주하는 운영체제 부분 을 커널(kernel) 이라 한다. 이 커널을 좁은 의미의 운영체제 라고도 불리며, 넓은 의미의 운영체제 는 utility들(ex: copy)을 광범위하게 포함하는 개념이다.\n2. 운영체제의 기능 하드웨어 그리고 사용자를 위한 운영체제의 역할 운영체제는 사용자 및 다른 소프트웨어와 하드웨어를 연결하는 소프트웨어 계층이라는 관점에서 운영체제의 기능을 생각해보면, 하드웨어를 위한 역할 과 사용자를 위한 역할 로 나눠진다.\n전자 는 사용자를 대신하여 운영체제가 하드웨어인 컴퓨터 시스템 내의 resource를 효율적으로 관리하는 역할 을 말한다.\n후자 는 사용자가 컴퓨터 시스템을 편리하게 사용하도록, 사용자에게 편리한 인터페이스를 제공하는 역할 을 말한다. 하드웨어를 직접 다루는 부분은 운영체제가 대행하여, 사용자 및 프로그램이 이에 대한 내용은 알지 못해도 프로그램을 실행해주는 기능을 말한다.\n❗운영체제의 핵심 역할: 효율적, 균형있게, 안전하게 자원 관리하기 운영체제의 기능은 전자와 후자 중 중요한 핵심기능은 바로 전자 다.\n그래서 운영체제를 자원 관리자(resource manager) 라고도 부른다. 여기서 자원이란 하드웨어 자원(ex: CPU, memory, HDD) 과 소프트웨어 자원을 모두 총칭하는 말이다. 운영체제는 이 자원들을 효율적으로 관리 하여 가장 좋은 성능 을 내도록 만든다.\n하지만, 전체적인 성능을 향상시켜려다보면 일부 프로그램 또는 사용자가 불이익을 당할 수 있다. 그래서 운영체제는 사용자 및 프로그램들 간에 자원이 형평성 있게 분배 되도록 하는 균형자 역할도 함께 수행해야 한다.\n또한, 더 중요한게 사용자와 운영체제 자신을 보호하는 보안 역할을 담당한다. 악의성 프로그램으로 다른 사용자 프로그램에 접근하지 않도록 보안 및 보호 기능을 수행해야 한다.\n3. 운영체제의 분류 운영체제의 분류 중 하나는 multi-processing system 과 single-processing system 이다. CPU가 2개 이상 설치되면 전자, 1개만 설치되면 후자를 말한다. 여기서 분류는 후자를 가정으로 진행된다.\n운영체제의 분류에는 동시 작업을 지원하는지, 다중 사용자를 지원하는지, 실시간(real time)을 지원하는지에 따라 분류된다. 앞에서부터 차근 차근 알아보자.\n첫 번째 분류: 동시 작업의 지원 유무 동시 작업을 지원하는지의 여부에 따라 단일작업(single tasking)용 운영체제와 다중작업(multi tasking)용 운영체제로 나누어볼 수 있다. 각 설명은 다음 표와 같다.\n운영체제 분류 동시 작업 지원 유무 예시 single tasking X (한 번에 하나) 초창기 운영체제, DOS multi-tasking O (동시에 창 여러개) MS window, Unix Multi-tasking: 시분할, 다중 프로그래밍, 대화형 system 다중 작업 시에는 여러 프로그램이 CPU와 memory를 공유한다.\nCPU의 경우, 처리 속도가 워낙 빨라서 여러 프로그램이 CPU의 작업시간을 조금씩 나누어 번갈아 쓰지만, 사용자 입장에서는 동시 실행처럼 보인다. 이를 시분할 시스템(time sharing system) 이라 한다.\n또한, 메모리의 경우 메모리 공간을 분할해 여러 프로그램들을 동시에 메모리에 올려놓고 처리하는 시스템을 사용한다. 이를 다중 프로그래밍 시스템(multi-programming system) 이라 한다.\n다중 작업의 경우, 여러 프로그램을 같이 실행하지만, 사용자 개개인의 관점에서는 각 프로그램에 대한 입력 결과를 곧바로 화면에 보여준다. 이를 대화형 시스템(interactive system) 이라 한다. 여러 사용자가 동시 접속 하는 서버의 경우에도, 각 사용자 입장에서는 혼자 사용하는 것처럼 느끼게 해주므로 대화형 시스템에 해당된다.\n두 번째 분류: 다중 사용자 동시지원 유무 운영체제 분류 다중 사용자 지원 추가 설명 예시 단일 사용자용 X 한 번에 한 사용자만 DOS, MS window 다중 사용자용 O 여러 사용자 동시 접속 가능 server(서버) 세 번째 분류: 작업 처리 방식(일괄처리 와 시분할 방식) 작업 처리 방식 의미 추가 설명 예 일괄 처리 (batch processing) 일정량씩 모아 한꺼번에 처리하는 방식 응답 시간이 길다. 초창기 컴퓨터에 사용하는 punch card 시분할 방식 (time sharing system) 여러 작업을 수행 시, 일정 시간 단위로 분할해 CPU를 사용하는 방식 짧은 응답시간을 갖는다. 유닉스 운영체제 하의 서버 컴퓨터 다섯 번째 분류: 실시간(real time) 운영체제 real time system은 정해진 시간 안에 처리를 보장하는 시스템에서 사용된다.\n분류 설명 예 Hard realtime system 주어진 시간을 지키지 못할 경우, 매우 위험한 결과를 초래할 가능성 O 원자로, 공장 제어 시스템, 미사일 제어 시스템 Soft realtime system 데이터가 정해진 시간 단위로 되어야 올바른 기능을 수행할 수 있는 시스템. 위험한 결과 X 멀티 미디어 스트링 4. 운영체제의 예 MS Window와 Unix의 예를 통해 간단히 살펴보자.\nMS Window는 마이크로소프트에서 이전에 개발한 MS-DOS와 WINDOW 3.1을 발전시킨, 개인용 컴퓨터를 위한 운영체제다.\n마이크로소프트가 기존에 발표한 MS-DOS는 초보자가 사용하기 어려운 명령어 입력 방식을 지녔기 때문에, 좀 더 쉬운 사용을 위해 윈도우를 개발했다.\n그리고, WINDOW 3.1은 grapic interface와 mouse 기능을 지원하는 점에서 사용자에게 편리한 환경을 제공했지만, 독자적인 운영체제가 되지 못하고 MS-DOS 위에 수행된다는 점에서 여러 한계점을 가지고 있었다. 예를 들어 컴퓨터 시스템을 완전히 제어할 수 없는 것, 불안정하다는 것 그리고, WINDOW를 사용하면서도 DOS를 함께 사용해야 하는 부가적인 어려움이 있었다.\n그 이후 온전한 운영체제가 된 것이 윈도우 95다. 윈도우 XP부터는 인터페이스측면에서 그래픽 환경과 아이콘 방식을 기본적으로 채택하면서, 다양한 방식으로 지원해 자신에게 편한 방법으로 다룰 수 있게 했다.\nMS Window의 또 다른 큰 특징은 plug and play다. 시스템에 새로운 하드웨어를 장착하면 OS가 자동으로 감지하여, 새로운 하드웨어에 맞게 설정된다는 점이다.\n그러면 MS Window와 Unix를 비교해보겠다.\n이식성(protability) 이란?\n해당 소프트웨어를 다른 기종의 기계로 옮기는 것이 얼마나 용이한가를 나타내는 지표\nMS Window Unix 대상 누구든지 손쉽게 사용(개인용 컴퓨터) 프로그램 개발 환경을 위해 설계된 OS, 오랜 전통, 대형 컴퓨터,전문적인 목적 특징 1 편리한 인터페이스 이식성(protability)이 좋음 특징 2 안정성 낮음 안정성이 좋음 특징 3 kernel의 크기가 작음 특징 4 souce code 공개됨 → 실제 연구에 이바지 특징 5 스스로 꾸밀 수 있음 특징 6 후에 GUI 제공됨 5. 운영체제의 자원 관리 기능 자원이란 하드웨어 자원과 소프트웨어 자원을 포함한다고 했다. 이번 소단원에서는 하드웨어 자원을 어떻게 관리하는지 알아보자.\n하드웨어 자원에는 CPU, 메모리, 그리고 입출력 장치들로 구성된다.\n5.1 CPU 관리 기법: 3가지 CPU 란 Central Processing Unit의 약자로, 명령어를 실행하는 연산 장치를 말한다. 이 CPU 는 통상적으로 컴퓨터 한 대에 하나가 장착되기 때문에, 여러 프로세스들이 CPU를 효율적으로 나누어 사용할 수 있도록 관리되어야 한다. 이 CPU의 대표적인 관리 방법 에는 선입선출(First Come First Served: FCFS), 라운드 로빈(Round Robin), 우선순위(Priority) 기법이 있다.\n5.1.1 CPU 관리 기법 첫 번째: 선입선출(FCFS) CPU를 사용하기 위해 먼저 온 process를 먼저 처리하는 방식이 선입선출 이다. 일상생활에서 줄을 서서 기다리는 것과 동일하다. 이 방법의 단점은 CPU를 필요로 하는 process가 여러 개 있을 때, CPU를 먼저 얻은 process가 원하는 작업을 완료할 때까지 다른 프로세스들은 CPU를 사용하지 못한다는 점이다. CPU 자체의 효율적인 측면에서는 문제 없지만, 전체 시스템의 관점에서는 비효율적인 결과를 초래할 수 있다. 장시간 이용해야 하는 프로세스가 먼저 오고, 그 뒤에 단시간 이용해야하는 프로세스가 올 경우 단시간 이용하면 되지만, 먼저 온 프로세스로 인해 계속 대기해야하는 상황이 발생된다.\n5.1.2 CPU 관리 기법 두 번째: 라운드 로빈(Round Robin) 위 선입선출의 단점을 보완하여 나온 방법이 라운드 로빈(Round Robin) 이다. 이 방법은 CPU를 한 번 할당 받아 사용할 수 있는 시간을 일정하게 고정된 시간으로 제한 한다. 각 프로세스는 이 정해진 시간 동안에만 CPU를 할당받는다. 작업이 완료되지 않았어도, 시간이 끝나면 CPU를 내려놓고, CPU 대기열의 제일 뒤에 가서 줄을 서야 한다. 먼저 온 프로세스의 작업 완료 시간이 길어도, 계속해서 기다릴 문제가 발생되지 않는다. 각 process마다 이 정해진 시간만큼 보장받을 수 있다.\n5.1.3 CPU 관리 기법 세 번째: 우선순위(Priority) 대기 중인 프로세스들에게 우선순위를 부여하고, 우선순위가 높은 process들에게 먼저 CPU를 할당 한다. 먼저 와서 CPU를 기다릴지라도, 우선순위에 따라 융통성 있게 process들에게 CPU를 할당할 수 있다. 또한, 지나치게 오래 기다리는 프로세스가 발생하지 않도록, 기다리는 시간에 비례하여 우선순위를 점차 높여주는 방안도 활용된다.\n5.2 Memory란?? 다른 중요 관리 대상으로 Memory가 있다.\n메모리는 CPU가 직접 접근할 수 있는 컴퓨터 내부 기억장치다. 프로그램이 CPU에서 실행될라면 해당 부분이 메모리에 올라 있어야 한다.\n메모리 역시 CPU처럼 한정된 용량만 존재하기 때문에, 서로 다른 다수의 프로세스들이 나누어 쓸 수 있도록 해야 한다. 이 한정된 용량을 효율적인 관리하기 위해 운영체제는 메모리의 어느 부분이 어떤 프로그램에 의해 사용되고 있는지를 주소(address) 를 통해 관리한다.\n5.2.1 운영체제가 Memory 관리가 필요한 이유 프로세스와 메모리의 관계는 다음과 같다.\n추가적으로 할당하여 프로세스가 빨리 수행될 수 있지만, 메모리 자원을 낭비하는 경우도 발생한다. 운영체제는 프로그램에 메모리가 필요할 때 할당하고, 필요하지 않으면 메모리를 회수한다.\n따라서 운영체제는 전체 메모리 공간이 효율적으로 사용될 수 있도록 잘 판단해야 한다.\n또한, 각 프로세스가 자신의 메모리 영역에만 접근할 수 있도록 보안 관리를 잘 해야 한다.\n5.2.2 Memory 관리 방식 3가지 memory 관리 방식에는 고정 분할(fixed partition) 방식, 가변 분할(variable partition) 방식, 가상 메모리(virtual memory) 방식이 있다. 각 방식에 대해 알아보자.\nMemory 관리 방식 첫 번째: 고정 분할 방식 고정 분할 방식은 명칭 그대로 물리적 메모리를 미리 고정된 크기로 나누어 관리한다. 여기에는 몇 가지 단점이 있다.\n첫 번째, 프로그램 크기에 맞게 융통성 있게 할당할 수가 없다\n두 번째, 고정된 크기이기 때문에 최대 할당할 수 있는 프로그램의 수가 정해져 있다.\n세 번째, 나눠진 메모리 크기보다 큰 프로그램은 적재가 불가능 하다.\n네 번째, 나눠진 크기보다 작은 프로그램에 할당하면 분할 내에 남는 영역 이 발생한다. 이 영역을 내부 조각(internal fragmentation) 이라 한다. 이 영역은 올라온 프로그램에 의해서도 사용될 수 없고, 다른 프로그램에 할당할 수 없어서 비효율적으로 낭비되는 공간 이다.\nMemory 관리 방식 두 번째: 가변 분할 방식 가변 분할 방식은 매 시점 프로그램의 크기에 맞게 메모리를 분할해서 사용하는 방식이다.\n이 방식 또한 전체 물리적 메모리 크기보다 큰 프로그램에는 여전히 할당할 수 없다. 그리고, 고정 분할 방식의 내부 조각은 발생되지 않지만, 외부 조각(external fragmentation) 이 발생할 수 있다.\n외부조각이란 프로그램에 할당되지는 않았지만, 그 크기가 작아 프로그램을 올리지 못하는 메모리 영역을 말한다.\n그래서 비효율적으로 낭비되는 공간이다.\nMemory 관리 방식 세 번째: 가상 메모리(Virtual Memory) 기법 현대 컴퓨터 환경에서 가장 널리 사용되는 메모리 관리 기법이다. 이 기법에서 실행될 수 있는 프로그램의 크기는 물리적 메모리가 아닌 가상 메모리 크기에 의해 결정된다. 그래서 물리적 메모리보다 큰 프로그램도 지원할 수 있다.\n모든 프로그램은 물리적 메모리와 독립적으로 가상 메모리를 가지고 있다. 운영체제는 이 가상 메모리의 주소를 물리적 메모리의 주소로 mapping(전환, 연결)하는 기술을 사용하여 전환 후, 물리적 메모리에 올린다.\n예를 들어보자.\n가상 메모리 기법을 사용하여 현재 물리적 메모리보다 더 큰 메모리를 요구하는 프로그램을 실행한다고 하자. 각 프로그램은 전체가 동시에 사용되는 게 아니다. 그러므로 사용되고 있는 부분만 물리적 메모리에 올리고, 나머지는 보조기억장치(disk)에 저장해두었다가 필요할 때 적재하는 방식으로 큰 프로그램을 사용할 수 있다. 이 때, 사용되는 보조기억장치의 영역을 스왑 영역(swap area) 라고 부른다. 프로그램을 구성하는 가상 메모리 공간은 페이징(paging) 기법을 사용하여 저장된다.\n5.3 입출력 장치 관리 기법 이 CPU와 메모리는 휘발성으로 전원이 꺼지면 처리 중이던 정보가 모두 지워지기 때문에, 비휘발성인 보조기억장치 에 파일 형태로 저장한다.\n이 보조기억장치의 예로는 하드디스크가 있으며, 그 외에는 키보드, 마우스, 모니터 등이 입출력 장치 로 OS 관리 대상에 포함된다.\n입출력 장치 관리는 인터룹트(interrupt) 를 통해 이뤄진다.\nInterrupt mechanism CPU는 CPU scheduling에 따라 주어진 작업을 수행하다가, 주변 입출력 장치로의 controller가 CPU에게 인터룹트를 발생시키면 CPU는 자신이 하던 작업을 중단한다. 그리고 현재 자신이 하던 작업 상태를 저장한다. 왜냐하면 다시 중단된 작업을 나중에 이어서 해야하기 때문이다.\nController란 입출력 장치가 가지고 있는 sub CPU라 생각하자.\n이 인터룹트가 발생된 순간, CPU의 사용권은 프로그램에서 운영체제로 넘어온다. 그러면, 운영체제는 발생된 인터룹트의 종류에 맞는 인터룹트 처리루틴을 kernel에서 찾아서 처리루틴에 기록된 코드에 따라 일을 처리한다. 그 후, 다시 중단되 업무에 CPU는 복귀한다.\nReference 운영체제와 정보기술의 원리 ","permalink":"http://jeha00.github.io/post/os/os_chapter_02_%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C_%EA%B0%9C%EC%9A%94/","summary":"운영체제란 무엇이고, 무슨 역할을 하는지, 어떻게 분류되는지, 그리고 CPU, 메모리, 입출력 장치의 대략적인 관리 mechanism에 대해 알아본다.","title":"[TIL] Introduction to Operating System"},{"categories":["Python"],"content":"0. Introduction 병행성을 위한 방법으로 generator와 coroutine을 알아보고자 한다. 이번 포스팅에서는 generator를 알아본다. 그리고, 병행성과 병렬성이 개념적으로 무엇인지 학습한다. 두 번째로, Generator를 본격적으로 알아본다. 1. 병행성과 병렬성이란?? 병행성(Concurrency): 한 컴퓨터가 여러 일을 동시에 수행하여, 단일 프로그램 안에서 여러 일을 쉽게 해결 목적\n병렬성(parallelism): 여러 컴퓨터가 여러 작업을 동시에 수행하여, 속도 향상 목적\n병행성 : thread는 하나지만, 마치 동시에 일을 하고 있는 것처럼 수행한다. 예) 공부 중에 강의 멈춰놓고, 밥 먹고 와서 강의를 중단한 부분부터 다시 시작하는 것 파이썬에서는 병행성 과 병렬성 을 모두 지원한다. 그리고, 파이썬 실력을 결정하는 중요한 내용이다. 2 Generator란? 모든 값을 메모리에 올려두고 이용하는 게 아닌, 필요할 때마다 한 번에 한 개의 항목을 생성해서 메모리에 올려두고 반환하는 객체. 그래서 메모리를 유지하지 않기 때문에, 효율적으로 사용할 수 있다. Generator는 iterator의 한 종류로, 위와 같은 이유로 매우 강력한 iterator다.\n연산을 필요한 순간까지 미루는 걸 Lazy evaluation이라 한다.\niterator이므로 출력하기 위해 next() 를 사용한다.\nGenerator function이 일반 function과의 차이는 yield statement다.\nGenerator = iterator + yield\n공통점:\nyield 또한 return 처럼 값을 반환한다. 차이점:\nreturn을 사용할 경우 지역 변수가 사라지지만, yield는 local을 나가도 사라지지 않는다. 위치 인자를 계속해서 유지한다. next처럼 \u0026lsquo;위치 인자\u0026rsquo;를 계속해서 유지하는 게 \u0026lsquo;병행성\u0026rsquo;의 핵심 그리고, yield는 제네레이터를 반환한다. Generator의 장점\nlist comprehension, dictionary comprehension 등 데이터 양이 증가하면 메모리 사용량이 증가하는데, 이 때 제네레이터를 사용하여 메모리 사용량을 줄이고, 수행시간도 절약해준다. 단위 실행 가능한 코루틴(Coroutine) 구현과 연동이 가능하다. 작은 메모리 조각으로 사용 가능하다. Generator 주의사항\ngenerator는 실행 시, 함수의 몸체를 실행하는 게 아니라, generator 함수가 가진 객체를 반환하는 일을 한다. 한 번 생성해서 반환한 객체를 보관하지 않기 때문에, 이전 코드를 실행한 후, 추가 코드를 실행하면 아무런 객체도 출력되지 않는다. 3. Generator 예제 3.1 예제 1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # Generator Ex1 \u0026gt; def generator_ex1(): \u0026gt; print(\u0026#39;Start\u0026#39;) # yield 뒤에 값을 return하고 멈춘다. \u0026gt; yield \u0026#39;A Point.\u0026#39; \u0026gt; print(\u0026#39;continue\u0026#39;) # 멈춘 후, 다음 yield value를 return할 때까지 진행된다. \u0026gt; yield \u0026#39;B Point.\u0026#39; \u0026gt; print(\u0026#39;End\u0026#39;) \u0026gt; temp = iter(generator_ex1()) \u0026gt; print(temp) \u0026lt;generator object generator_ex1 at 0x000001E8B2549510\u0026gt; \u0026gt; print(next(temp)) Start A Point. \u0026gt; print(next(temp)) Continue B point. \u0026gt; print(next(temp)) End StopIteration yield 까지 출력한 후, 다음 출력은 다음 yield까지 한다. 이처럼 위의 next처럼 \u0026lsquo;위치 인자\u0026rsquo;를 계속해서 유지하는 게 \u0026lsquo;병행성\u0026rsquo;의 핵심 이다. 위치 인자를 계속해서 기억하는 것 즉, 다음 할 일을 계속해서 기억하는 걸 의미한다. 3.2 예제 2 이 예제가 단순히 동일한 일을 하는 것처럼 보이지만, 생성된 값을 미리 메모리에 만들어 두는 게 아닌, for 문에서 필요한 때마다 generator로부터 받아온다. 즉, 메모리에서 보관하지 않는다. list comprehension 과 유사해보이지만, 소괄호()를 사용하여 generator expression을 만들 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # list comprehension \u0026gt; temp2 = [x * 3 for x in generator_ex1()] # Generator \u0026gt; temp3 = (x * 3 for x in generator_ex1()) \u0026gt; print(type(temp2)) \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; \u0026gt; print(type(temp3)) \u0026lt;class \u0026#39;generator\u0026#39;\u0026gt; # yield로 반환되는 값만 list로 만들어진 걸 확인했다. \u0026gt; print(\u0026#39;temp2 - \u0026#39;, temp2) temp2 - [\u0026#39;A Point.A Point.A Point.\u0026#39;, \u0026#39;B Point.B Point.B Point.\u0026#39;] # 아래와 같이 출력되기 때문에, for문에서 출력하자. \u0026gt; print(\u0026#39;temp3 - \u0026#39;,temp3) temp3 - \u0026lt;generator object \u0026lt;genexpr\u0026gt; at 0x000002895A5AE9E0\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # list comprehension # yield로 반환된 것들만 출력된다. \u0026gt; for i in temp2: \u0026gt; print(i) A Point.A Point.A Point. B Point.B Point.B Point. # Generator # Generator이기 때문에, 사용하는 순간에만 함수를 실행했다. # 그래서 Start, continue, End 까지 출력되었다. \u0026gt; for i in temp3: \u0026gt; print(i) Start A Point.A Point.A Point. continue B Point.B Point.B Point. End 그러면 list comprehension과 generator를 더 자세히 비교해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 \u0026gt; import time \u0026gt; l = [1, 2, 3] \u0026gt; def print_iter(iter): \u0026gt; for element in iter: \u0026gt; print(element) \u0026gt; def lazy_return(num): \u0026gt; print(\u0026#34;sleep 1s\u0026#34;) \u0026gt; time.sleep(1) \u0026gt; return num \u0026gt; print(\u0026#39;comprehension_list = \u0026#39;) comprehension_list = \u0026gt; comprehension_list = [lazy_return(i) for i in I] # 대괄호 \u0026gt; print(comprehension_list) sleep 1s sleep 1s sleep 1s [1,2,3] \u0026gt; print_iter(comprehension_list) sleep 1s sleep 1s sleep 1s 1 2 3 \u0026gt; print(\u0026#39;generator_exp = \u0026#39;) generator_exp = \u0026gt; generator_exp = (lazy_return(i) for i in I) # 소괄호 \u0026gt; print(generator_exp) \u0026lt;generator object \u0026lt;genexpr\u0026gt; at 0x000001ABB5E49510\u0026gt; \u0026gt; print_iter(generator_exp) sleep 1s 1 sleep 1s 2 sleep 1s 3 위 code review\nlist comprehension은 함수를 미리 다 실행시켜서 \u0026lsquo;sleep 1s\u0026rsquo; 문자열이 먼저 출력되었다. 하지만, generator는 실제로 값을 출력하기 전까지 실행하지 않았다. 값을 사용하는 순간에만 함수를 실행하고 있다. 이 내용을 더 자세히 확인해보자.\nprint_iter를 아래와 같이 수정한 후, 실행하자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026gt; def print_iter(iter): \u0026gt; for element in iter: # element가 1일 때 코드 실행은 중단된다. \u0026gt; if element == 1: \u0026gt; break \u0026gt; print(element) \u0026gt; print(\u0026#39;comprehension_list = \u0026#39;) \u0026gt; print_iter(comprehension_list) comprehension_list= sleep 1s sleep 1s sleep 1s \u0026gt; print(\u0026#39;generator_exp = \u0026#39;) \u0026gt; print_iter(generator_exp) generator_exp= sleep 1s 위 code review\nlist comprehension: lazy_return 함수를 모두 실행한 후, print_iter 함수를 실행할 때 멈췄다. generator expression: print_iter 함수가 실행 시, lazy_return 함수를 실행한 걸 확인할 수 있다. 이번에는 속도를 비교해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; start_time = time.time() \u0026gt; comprehension_list=[lazy_return(i) for i in I] \u0026gt; print_iter(comprehension_list) \u0026gt; print(time.time()-start_time) sleep 1s sleep 1s sleep 1s 3.0265092849731445 \u0026gt; start_time = time.time() \u0026gt; generator_exp = (lazy_return(i) for i in I) \u0026gt; print_iter(generator_exp) \u0026gt; print(time.time()-start_time) sleep 1s 1.0092661380767822 위 code review\n제네레이터를 사용했을 때 시간이 단축되었다. 이번에는 메모리를 비교해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026gt; import sys # 크기를 늘렸다. \u0026gt; L = [1,2,3,4,5,6,7,8,9,10] \u0026gt; comprehension_list=[lazy_return(i) for i in L] \u0026gt; print(sys.getsizeof(comprehension_list)) \u0026gt; generator_exp = (lazy_return(i) for i in L) \u0026gt; print(sys.getsizeof(generator_exp)) 184 #list comprehension 112 # generator 데이터의 크기가 커질수록 제네레이터의 효율성이 더 두드러지게 나타난다!! 이렇게 어떤 값이 실제로 쓰일 때까지 그 값의 연산을 뒤로 미루는 방식을 Lazy Evaluation이라 한다. 4. Generator 관련 중요 함수들 Generator 관련 함수들은 itertools를 import하는 것부터 시작한다. 계속 복습을 하면서 활용해보도록 하자. 4.1 itertools.count(시작값, 증가값) 첫 번째는 itertools.count(시작값, 증가값) 이다. 시작값에서 증가하여, 증가값만큼 커져서 무한히 출력된다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; import itertools # 숫자 무한대로 만들기 \u0026gt; gen1 = itertools.count(1, 2.5) \u0026gt; print(next(gen1)) 1 \u0026gt; print(next(gen1)) 3.5 \u0026gt; print(next(gen1)) 6.0 \u0026gt; print(next(gen1)) 8.5 4.2 itertools.takewhile(predicate, iter) 두 번째는 itertools.takewhile(predicate, iter) 다. iter의 원소들 중 predicate의 조건에 참인 값들을 반환한다. predicate는 영어 단어 자체의 의미로는 영어 문법의 서술부를 의미한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 # gen1 에 람다함수로 조건을 추가한다. # 아래 조건은 range(1,1000, 2.5) 와 동일하다. \u0026gt; gen2 = itertools.takewhile(lambda n : n \u0026lt; 20, itertools.count(1, 2.5)) # 이렇게 for문과 같이 쓰인다. \u0026gt; for v in gen2: \u0026gt; print(v) 1 3.5 ... 18.5 4.3 itertools.filterfalse(predicate, iter) 세 번째는 itertools.filterfalse(predicate, iter) 이다. 두 번째인 itertools.takewhile과 반대 의미를 가진 함수다. iter 원소들 중에서 predicate의 조건에 부정인 값들을 반환한다. 1 2 3 4 5 6 7 8 # 필터 반대 \u0026gt; gen3 = itertools.filterfalse(lambda n : n \u0026lt; 3, [1,2,3,4,5]) \u0026gt; for v in gen3: \u0026gt; print(v) 3 4 5 4.4 itertools.accumulate(iterable, func=operator.add) 네 번째는 itertools.accumulate(iterable, func=operator.add) 이다. iterable의 누적 합계나, 다른 이항함수 func의 누적 결과를 반환하는 iterator를 만든다. 총 원소 수가 n개라고 할 때, iterable[0], iterable[0] + iterable[1], \u0026hellip;, iterable[0]+ ~ + iterable[n-1] 1 2 3 4 5 6 7 8 9 10 # 누적 합계 \u0026gt; gen4 = itertools.accumulate([x for x in range(1, 101)]) \u0026gt; for v in gen4: \u0026gt; print(v) 1 3 6 ... 5050 4.5 itertools.chain(*iterables) 다섯 번째는 itertools.chain(*iterables)이다. 첫 번째 iterable에서 소진될 때까지 원소들을 반환한 후, 다음 이터러블로 넘어간다. 이런 식으로 iterables의 모든 iterable이 소진될 때까지 진행하는 iterator를 만든다. 1 2 3 4 5 6 7 8 9 10 11 12 # 연결1 \u0026gt; gen5 = itertools.chain(\u0026#39;ABCDE\u0026#39;, range(1,11,2)) \u0026gt; print(list(gen5)) [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;, 1, 3, 5, 7, 9] # 연결2 # enumerate를 통해서 index와 value를 mapping 했다. \u0026gt; gen6 = itertools.chain(enumerate(\u0026#39;ABCDE\u0026#39;)) \u0026gt; print(list(gen6)) [(0, \u0026#39;A\u0026#39;), (1, \u0026#39;B\u0026#39;), (2, \u0026#39;C\u0026#39;), (3, \u0026#39;D\u0026#39;), (4, \u0026#39;E\u0026#39;)] 4.6 itertools.product(*iterables, repeat=) 여섯 번째는 itertools.product(*iterables, repeat=1) 다. 입력 이터러블들(iterables)의 데카르트 곱을 반환한다. 대략 제너레이터 표현식에서의 중첩된 for-루프와 동일하다. 예를 들어 product(A, B)는 ((x,y) for x in A for y in B)와 같은 것을 반환한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 개별 \u0026gt; gen7 = itertools.product(\u0026#39;ABCDE\u0026#39;) \u0026gt; print(list(gen7)) gen7 - [(\u0026#39;A\u0026#39;,), (\u0026#39;B\u0026#39;,), (\u0026#39;C\u0026#39;,), (\u0026#39;D\u0026#39;,), (\u0026#39;E\u0026#39;,)] # 연산(경우의 수) # repeat = 2는 .product(\u0026#39;ABCDE\u0026#39;, \u0026#39;ABCDE\u0026#39;) 와 동일하다. \u0026gt; gen8 = itertools.product(\u0026#39;ABCDE\u0026#39;, repeat=2) \u0026gt; print(list(gen8)) [(\u0026#39;A\u0026#39;, \u0026#39;A\u0026#39;), (\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;), (\u0026#39;A\u0026#39;, \u0026#39;C\u0026#39;), (\u0026#39;A\u0026#39;, \u0026#39;D\u0026#39;), (\u0026#39;A\u0026#39;, \u0026#39;E\u0026#39;), (\u0026#39;B\u0026#39;, \u0026#39;A\u0026#39;), (\u0026#39;B\u0026#39;, \u0026#39;B\u0026#39;), (\u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;), (\u0026#39;B\u0026#39;, \u0026#39;D\u0026#39;), (\u0026#39;B\u0026#39;, \u0026#39;E\u0026#39;), (\u0026#39;C\u0026#39;, \u0026#39;A\u0026#39;), (\u0026#39;C\u0026#39;, \u0026#39;B\u0026#39;), (\u0026#39;C\u0026#39;, \u0026#39;C\u0026#39;), (\u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;), (\u0026#39;C\u0026#39;, \u0026#39;E\u0026#39;), (\u0026#39;D\u0026#39;, \u0026#39;A\u0026#39;), (\u0026#39;D\u0026#39;, \u0026#39;B\u0026#39;), (\u0026#39;D\u0026#39;, \u0026#39;C\u0026#39;), (\u0026#39;D\u0026#39;, \u0026#39;D\u0026#39;), (\u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;), (\u0026#39;E\u0026#39;, \u0026#39;A\u0026#39;), (\u0026#39;E\u0026#39;, \u0026#39;B\u0026#39;), (\u0026#39;E\u0026#39;, \u0026#39;C\u0026#39;), (\u0026#39;E\u0026#39;, \u0026#39;D\u0026#39;), (\u0026#39;E\u0026#39;, \u0026#39;E\u0026#39;)] 4.7 itertools.groupby(iterable, key = none) 일곱 번쨰는 itertools.groupby(iterable, key = none) 이다. (분류기준, 분류기준으로 묶인 데이터) 순서인 tuple로 값을 반환한다. 1 2 3 4 5 6 7 8 9 10 # 그룹화 \u0026gt; gen9 = itertools.groupby(\u0026#39;AAABBCCCCDDEEE\u0026#39;) \u0026gt; for chr, group in gen9: \u0026gt; print(chr, \u0026#39; : \u0026#39;, list(group)) A : [\u0026#39;A\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;A\u0026#39;] B : [\u0026#39;B\u0026#39;, \u0026#39;B\u0026#39;] C : [\u0026#39;C\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;C\u0026#39;] D : [\u0026#39;D\u0026#39;, \u0026#39;D\u0026#39;] E : [\u0026#39;E\u0026#39;, \u0026#39;E\u0026#39;, \u0026#39;E\u0026#39;] Reference 인프런 파이썬 중급 itertools — Function to create an etherator for efficient looping Python - generator ","permalink":"http://jeha00.github.io/post/python/python_basic_36_generator/","summary":"Generator 1에 이어서 본격적으로 Generator에 대해 알아본다. 그리고, Generator와 관련된 중요 함수들도 알아본다.","title":"[TIL] Python basic 36: Generator"},{"categories":"dev-contents","content":"Dev-contents를 만든 목적과 이유는??? 개발 관련 좋은 컨텐츠를 보관하고 섭취하기\n컨텐츠의 종류는 한정되어 있지 않습니다.\n유익한 개발 관련 컨텐츠를, 주제별로 나눠서 각 주제별로 앞으로 볼 것, 다 본 것들, 현재 보고 있는 것으로 나누고 어느 부분을 중점적으로 공부했는지 직관적으로 알 수 있기 때문입니다. 구매했던 업무와 일상을 정리하는 새로운 방법 Notion을 보고 notion으로 정리 후, 블로그에 업데이트했습니다.\n정리수단으로 notion을 결정한 이유는 다음과 같습니다.\nblock을 이동하기가 쉽습니다. 여러 단락으로 나눠서 사용할 수 있습니다. toggle button이 있어 훨씬 깔끔합니다. 이미지 첨부나, table 등등 만들기가 용이합니다. 나중에 협업 도구로 notion을 사용해볼 생각이라, 미리 익히고 싶었습니다. 디자인이 제 취향에 맞았습니다. notion에 정리한 후, Github blog에 주기적으로 업로드할 예정입니다.\n업데이트 날짜 또한 표시합니다. 📚은 서적을, 💻은 인터넷 강의를, 🖊️ 은 블로그 포스팅 글을 말합니다.\nDoing과 Done의 경우, 위에 있을 수록 최신의 것을 말합니다.\nOS Will\nDoing\nDone\n📚 운영체제와 정보기술의 원리 - 반효경 지음 - 💻 KOCW 운영체제 이화여자대학교 - 반효경 - Network Will\n💻 KOCW 컴퓨터 네트워크 한양대학교 - 이석복 - Doing\n📚 성공과 실패를 결정하는 1%의 네트워크 원리 Done\n💻 모든 개발자를 위한 HTTP 웹 기본 지식 DB Will 💻 관계형 데이터 모델링 - 생활코딩 Doing Done 💻 갖고노는 MySQL 데이터베이스 by 얄코 Algorithum Will\nDoing\n📚 알고리즘 문제해결전략 1,2 세트 📚 자료구조와 함께 배우는 알고리즘 입문 파이썬편 Done\nPython Will\n💻 level 4 고수가 되는 파이썬: 동시성과 병렬성 문법 배우기 Feat. 멀티스레딩 vs 멀티프로세싱 (Inflearn Original) Doing\nDone\n💻 level 3 모두를 위한 파이썬 : 필수 문법 배우기 Feat. 오픈소스 패키지 배포 (Inflearn Original)\n💻 level 2 우리를 위한 프로그래밍 : 파이썬 중급 (Inflearn Original)\n💻 level 1 프로그래밍 시작하기 : 파이썬 입문 (Inflearn Original)\n📚 Do it! 첫 코딩 with 파이썬\nDjango Will\nDoing\n💻 파이썬/장고 웹서비스 개발 완벽 가이드 with 리액트 Done\nLinux Will\n📚 실습과 그림으로 배우는 리눅스 구조 - Doing\nDone\nCloud Will\n📚 따라하며 배우는 AWS 네트워크 입문 Doing\nDone\nDocker Will Doing Done 생산성 도구 Will\n📚 Pro Git 2 edition Doing\nDone\n💻 제대로 파는 Git \u0026amp; GitHub - by 얄코 📚 업무와 일상을 정리하는 새로운 방법 Notion 개발 문화 \u0026amp; 개발 life \u0026amp; 공부법 Will\n🖊️ 개발자가 공부로 살아남는 방법 🖊️ 나는 어떻게 공부했는가? 🖊️ 개발자의 평생공부 🖊️ 프로그래머로서의 성장을 도왔던 태도들 🖊️ 프레임 공부를 멈춰라 🖊️ 회사 밖에서 성장하기 🖊️ 어려운 것을 쉽게 배우는 방법: 슈퍼 파워 장착을 위한 3단계 학습법 🖊️ 개발자는 어떻게 성장해야 할까 🖊️ 어려운 것을 쉽게 배우는 방법 🖊️ 내게 실용적이었던 프로그래밍 공부 방법들 🖊️ 더 나은 개발자가 되는 8가지 방법 🖊️ 개발 배우기가 정말 어려운 이유 🖊️ 개발자의 성장에 대한 이야기 (주니어, 기술, 팀, 이직, 자기 PR) 🖊️ 초보 웹 개발자를 위한 학습 안내서 🖊️ 개발자를 꿈꾸는 취업 준비생에게 Doing\nDone\n🖊️ 프로그래밍 학습 방법 🖊️ 학습에 실패한 이야기 🖊️ 개발자가 실력을 향상시킬 방법은 OO뿐이에요. 반복 기술 면접 Will Doing Done 비전공자 \u0026amp; 신입 Will\n🖊️ 주니어 개발자를 위한 취업 정보 모음 🖊️ Technical Interview Guidelines for beginners 🖊️ 개발자 블로그 모음 🖊️ 개발자 회고 모음 🖊️ iOS 개발에 대한 질문과 답변 모음 Doing\nDone\n🖊️ 3 번째 직장에 오기까지 시리즈 🖊️ 체대 출신 개발자의 연말 회고 시리즈 🖊️ 문돌이가 개발자가 되기까지 시리즈 🖊️ 문과생의 카카오 개발자 이직기 시리즈 🖊️ 늦은 나이, 개발자로 시작해도 좋을까요 - 30대 초반 비전공자의 고민 🖊️ 문과생 비전공자가 웹 개발자가 되기까지.. 🖊️ 32살에 개발에 입문한 비전공자가 인프런 창업한 이야기 (슬라이드) 🖊️ 야 너두 할 수 있어. 비전공자, COBOL 개발자를 거쳐 네이버에서 FE 개발하게 된 이야기 (영상) 🖊️ 비전공자로 개발자 커리어를 시작하는 사람들에게 (영상) 🖊️ 비전공자가 개발자가 되기까지(feat. Wecode) 💻 비전공자를 위한 개발자 취업 올인원 가이드 [통합편] 📚 비전공자를 위한 이해할 수 있는 IT 지식 📚 코딩 진로: IT 진로를 고민하는 이들을 위한 지침서 ","permalink":"http://jeha00.github.io/post/dev-contents/dev-contents/","summary":"Updated on June 17   /  개발 관련 좋은 컨텐츠를 보관하고 섭취하기","title":"Dev-Contents"},{"categories":["Python"],"content":"0. Introduction 병행성을 위한 방법으로 generator와 coroutine을 알아보고자 한다. 이번 포스팅에서는 __iter__와 __next__ 을, 다음 포스팅에서는 generator를 알아본다. 첫 번째로 병행성이 무엇을 의미하는 건지, 이와 유사한 개념으로 병렬성은 무엇인지 학습한다. 두 번째로, Generator를 이해하기 위해서 __iter__와 __next__ 을 먼저 학습한다. 1. 병행성과 병렬성이란?? 동시성, 병행성(Concurrency): 하나의 core에서 하나 이상의 process(또는 thread)가 여러 실행 단위를 번갈아 실행하면서, 동시 진행되는 것처럼 보이는 것 병렬성(parallelism): 물리적으로 둘 이상의 코어를 실행해서 하나 이상의 prcess가 한 꺼번에 진행되는 것- \u0026gt; 속도 향상 목적 병행성 은 단일 프로그램 안에서 여러 일을 쉽게 해결하기 위해 사용된다. thread는 하나지만, 마치 동시에 일을 하고 있는 것처럼 수행한다. 예) 공부하다가 강의 멈춰놓고, 밥 먹고 와서 강의를 중단한 부분부터 다시 시작하는 것 파이썬에서는 병행성 과 병렬성 을 모두 지원한다. 그리고, 파이썬 실력을 결정하는 중요한 내용이다. 2. __iter__와 __next__ 2.1 __iter__와 __next__ 용어 정리 __iter__ __iter__: iter() built-in function이 호출하는 메소드 iter(): 호출된 __iter__의 return 값인 iterator를 반환한다. __next__ __next__: next() built-in function이 호출하는 메소드 iter 가 있는 용어들에 대해 정리하면서 알아보자. iteration이란? The process of looping through the objects or items in a collection 번역하자면 하나의 여러 값들이 담겨진 목록에서 객체들 또는 값들을 \u0026lsquo;순회\u0026rsquo;하는 과정\n그러면 파이썬에서 iteration 상황은 무엇이 있을까??\nDefinite iteration 상황: 미리 반복 횟수를 명백하게 정한 상황. ex) for 문\nIndefinite iteration 상황: 몇 가지 조건이 만족될 때까지 code block을 실행하는 상황. ex) while 문\niteration이란 게 뭔지 알았으니, __iter__를 사용하는 \u0026lsquo;iterable\u0026rsquo; 과 \u0026lsquo;iterator\u0026rsquo;의 차이에 대해 알아보자.\niterable An object(or the adjective used to describe an object) that can be iterated over dir()로 확인했을 때, __iter__ 또는 __getitem__ 을 가지고 있는 객체 iterator: Type의 한 종류 iter():\n__iter__ method를 호출하여 이 method의 값을 반환하는 함수 The built-in function used to obtain an iterator from an iterable 즉, iterator의 의미는\nThe object that produces successive items or values from its associated iterable iterable object로부터 연속적인 값을 낳는(yield) 값 생성기로 \u0026lsquo;반복자\u0026rsquo;라고 한다. iter()이 반환하는 객체의 type next() function의 기준으로 보자면, __next__을 가지고 있는 객체로서 최종적으로 iterator가 갖고 있는 매직메서드는 __iter__ 와 __next__ 라고 볼 수 있다. 2.2 Iterator 관련 data type iterator를 반환하는 data type들:\nfor, collections, string, list, dict, set, tuple, unpacking, *args 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # string \u0026gt; iter(\u0026#39;foobar\u0026#39;) \u0026lt;str_iterator object at 0x036E2750\u0026gt; # list \u0026gt; iter([\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;]) \u0026lt;list_iterator object at 0x036E27D0\u0026gt; # tuple \u0026gt; iter((\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;)) \u0026lt;tuple_iterator object at 0x036E27F0\u0026gt; # set \u0026gt; iter({\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;}) \u0026lt;set_iterator object at 0x036DEA08\u0026gt; # dict \u0026gt; iter({\u0026#39;foo\u0026#39;: 1, \u0026#39;bar\u0026#39;: 2, \u0026#39;baz\u0026#39;: 3}) \u0026lt;dict_keyiterator object at 0x036DD990\u0026gt; iterator를 반환하지 않는 data type들\nInteger, foat, built-in functions 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # Integer \u0026gt;\u0026gt; iter(42) Traceback (most recent call last): File \u0026#34;\u0026lt;pyshell#26\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; iter(42) TypeError: \u0026#39;int\u0026#39; object is not iterable # Float \u0026gt;\u0026gt;\u0026gt; iter(3.1) Traceback (most recent call last): File \u0026#34;\u0026lt;pyshell#27\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; iter(3.1) TypeError: \u0026#39;float\u0026#39; object is not iterable # Built-in functions \u0026gt;\u0026gt;\u0026gt; iter(len) Traceback (most recent call last): File \u0026#34;\u0026lt;pyshell#28\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; iter(len) TypeError: \u0026#39;builtin_function_or_method\u0026#39; object is not iterable 2.3 iter() 과 next() 예제 내장함수 next()는 값 생성기 iterator으로부터 다음 값을 얻기 위해 사용된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # a는 iterable list다. \u0026gt; a = [\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;] # iter을 통해서 a의 iterator를 만든다. \u0026gt; itr = iter(a) \u0026gt; itr \u0026lt;list_iterator object at 0x031EFD10\u0026gt; # nest()를 통해서 itr 안의 다음 값을 얻는다. \u0026gt; next(itr) \u0026#39;foo\u0026#39; \u0026gt; next(itr) \u0026#39;bar\u0026#39; \u0026gt; next(itr) \u0026#39;baz\u0026#39; # 값이 다 소진되면 다음과 같은 Error를 띄운다. \u0026gt; next(itr) StopIteration 만약 iterator로 전환하지 않고, 그냥 사용한다면???\niterator가 아니므로 next()를 사용할 수 없다.\n즉 __iter__을 호출하여 전환해야 사용이 가능하다.\n1 2 3 4 5 6 7 8 \u0026gt; w = [1,2,3,4,5] # iter()로 iterator로 전환하지 않았기 때문에 __next__가 없다. \u0026gt; print(dir(w)) [\u0026#39;__add__\u0026#39;, \u0026#39;__class__\u0026#39;, \u0026#39;__iter__\u0026#39;, ..... \u0026#39;sort\u0026#39;] \u0026gt; print(next(w)) TypeError: \u0026#39;list\u0026#39; object is not an iterator 2.4 iter() 과 next() 토대로 for문 이해하기 그러면 __iter__ 과 __next__를 토대로 for 문을 이해해보자.\n1 2 3 4 5 6 7 8 9 \u0026gt; t = \u0026#39;ABCDEF\u0026#39; \u0026gt; for c in t: \u0026gt; print(c) A B C D E F 어떻게 해서 하나씩 출력되는 것일까???\nfor문의 구조를 다시 확인해보자\n1 2 \u0026gt; for \u0026lt;var\u0026gt; in \u0026lt;iterable\u0026gt;: \u0026gt; \u0026lt;statement(s)\u0026gt; in 다음에는 iterable이 온다. 그러면 어떻게 하나씩 반환될까??\n__iter__ 과 __next__ 와 연결시켜보자.\niterable을 입력하면 for문에서 iter()을 호출하여 iterable객체를 iterator로 바꾼 후, __next__ method를 통해 하나씩 출력된는 원리라는 걸 이해할 수 있다.\n하지만 iterator를 입력해도 for문에서 알아서 __next__ method를 통해 하나씩 출력한다.\n위에 for문을 while문으로 만들어서 구체적으로 이해해보자.\n1 2 3 4 5 6 7 8 \u0026gt; t = \u0026#39;ABCDEF\u0026#39; \u0026gt; while True: \u0026gt; try: \u0026gt; print(next(t)) # iterator의 내부 성분이 다 출력되면 Error가 발생되고, 중단된다. \u0026gt; except Stopiteration \u0026gt; break 2.5 __iter__ 확인하는 방법 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026gt; t = \u0026#39;ABCDEF\u0026#39; # 첫 번째 방법 # 이 방법은 눈으로 찾아봐야하기 때문에, 추천하지 않는다. \u0026gt; print(dir(t)) [\u0026#39;__add__\u0026#39;, \u0026#39;__iter__\u0026#39;, \u0026#39;__le__\u0026#39;, ....\u0026#39;] # 두 번째 방법 # hasattr = has attribution # t가 __iter__를 가지고 있는가?? \u0026gt; print(hasattr(t, \u0026#39;__iter_\u0026#39;)) True # 세 번째 방법 \u0026gt; print(isinstance(t, abc.Iterable)) True 2.6 class로 __next__ 구현하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 \u0026gt; class WordSplitter: \u0026gt; def __init__(self, text): \u0026gt; self._idx = 0 \u0026gt; self._text = text.split(\u0026#39; \u0026#39;) \u0026gt; def __next__(self): \u0026gt; print(\u0026#39;Called __next__\u0026#39;) \u0026gt; try: \u0026gt; word = self._text[self._idx] \u0026gt; except IndexError: \u0026gt; raise StopIteration(\u0026#39;Stopped Iteration\u0026#39;) \u0026gt; self._idx += 1 \u0026gt; return word \u0026gt; def __repr__(self): \u0026gt; return \u0026#39;WordSplit(%s)\u0026#39; % (self._text) \u0026gt; wi = WordSplitter(\u0026#39;Do today what you could do tomorrow\u0026#39;) \u0026gt; print(wi) WordSplit([\u0026#39;Do\u0026#39;, \u0026#39;today\u0026#39;, \u0026#39;what\u0026#39;, \u0026#39;you\u0026#39;, \u0026#39;could\u0026#39;, \u0026#39;do\u0026#39;, \u0026#39;tomorrow\u0026#39;]) \u0026gt; print(next(wi)) Do \u0026gt; print(next(wi)) today \u0026gt; print(next(wi)) what \u0026gt; print(next(wi)) you \u0026gt; print(next(wi)) could \u0026gt; print(next(wi)) do \u0026gt; print(next(wi)) tomorrow \u0026gt; print(next(wi)) Stopped Iteration 구현했지만, 코드량이 많아진다. 그러면 제네레이터를 사용해서 구현해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026gt; class WordSplitter: \u0026gt; def __init__(self, text): # 인덱스를 기억하지 않아도 된다. \u0026gt; self._text = text.split(\u0026#39; \u0026#39;) \u0026gt; def __iter__(self): \u0026gt; for word in self._text: # 이것이 제네레이터이며, 이 제네레이터가 위치 정보를 기억한다. # 따로 예외처리를 하지 않아도 된다. \u0026gt; yield word \u0026gt; return \u0026gt; def __repr__(self): \u0026gt; return \u0026#39;WordSplit(%s)\u0026#39; % (self._text) \u0026gt; wg = WordSplitter(\u0026#39;Do today what you could do tomorrow\u0026#39;) \u0026gt; wt = iter(wg) # 출력 코드는 동일. Reference 인프런 파이썬 중급 04-3 제너레이터와 yield(feat. return 문) (널널한 교수의 고급 파이썬) ft. 파이썬 코딩 ","permalink":"http://jeha00.github.io/post/python/python_basic_35_iter_next/","summary":"첫 번째, 병행성과 병렬성이란 무엇인지 각 개념에 대해 알아본다.  두 번째, Generator를 이해하기 위해 __iter__와 __next__에 대해 알아본다.","title":"[TIL] Python basic 35: \n_\n_iter\n_\n_과 \n_\n_next\n_\n_"},{"categories":["Python"],"content":"1. Decorator가 중요한 이유 데코레이터를 사용하기는 쉽지만, 작성하기는 어렵다고 한다.\n왜냐하면 여러가지 개념들이 합쳐져 있기 때문이다.\n파이썬의 전반적인 과정을 이해해야 가능하다.\nClosure(클로저) -\u0026gt; [TIL] Python basic 33: Closure firt-class(일급 함수) -\u0026gt; [TIL] Python basic 31: First-class 가변 인자(*args, **args) -\u0026gt;[TIL] Python basic 12: Method 인자 풀기(unpacking) -\u0026gt;[TIL] Python basic 12: Method 파이썬이 소스 코드를 불러오는 자세한 과정 from 파이썬 데코레이터를 작성하는 법을 배워야 하는 5가지 이유 그렇다면 왜 데코레이터를 배워야하는가???\n장점 중복 제거, 코드 간결, 공통 함수 작성\n프로그래밍 언어의 패러다임이 이런 방식으로 진행된다. 로깅, 프레임워크, 유효성 체크\n이러한 기능들을 가지는 함수를 만들어서 공통 기능으로 사용 가능하다. 파이썬 기반 프레임 워크의 많은 비중이 데코레이터로 설계되어 있다. 조합해서 사용 용이\n단점\n가독성 감소 특정 기능에 한정된 함수는 단일 함수로 작성하는 것이 유리 디버깅 불편 from 인프런 파이썬 중급\n2. Closure의 기본 패턴 데코레이터는 클로저와 형태가 유사하다. 그래서, 특히 클로저를 이해하지 못하면 데코레이터를 만들 수 없다. 자바에서는 어노테이션이라 한다. 1 2 3 4 5 6 7 8 9 10 11 12 ## closure의 기본 패턴 # outer function \u0026gt; def perf_clock(func): # inner function(nested function) # closure \u0026gt; def perf_clocked(*args): \u0026gt; # inner function의 결과 반환 \u0026gt; return result \u0026gt; # inner function 반환 \u0026gt; return perf_clocked 3. Decorator 실습 예제 decorator를 직접 구현해보자. 모든 함수가 실행될 때마다 performance를 체크하는 함수를 만들 것이다. perf_counter: time module에 있는 method로, 코드 실행 시간을 측정한다. 3.1 Decorator로 사용할 function 만들기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026gt; import time \u0026gt; def perf_clock(func): \u0026gt; def perf_clocked(*args): \u0026gt; # st = start time \u0026gt; st = time.perf_counter() \u0026gt; # outer function의 argument인 func이 inner function 안에서 실행된다. \u0026gt; # 그래서 자유 변수가 된다. \u0026gt; result = func(*args) \u0026gt; # et = end time \u0026gt; et = time.perf_counter() - st \u0026gt; # func의 이름 \u0026gt; name = func.__name__ \u0026gt; # 여러 개의 정수를 하나의 문자열 묶음으로 바꾸기 \u0026gt; arg_str = \u0026#39;, \u0026#39;.join(repr(arg) for arg in args) \u0026gt; print(\u0026#39;[%0.5fs] %s(%s) -\u0026gt; %r\u0026#39; % (et, name, arg_str, result)) \u0026gt; return result \u0026gt; return perf_clocked 3.2 Decorator 없이 사용하기 그러면 데코레이터를 사용하지 않고, 위 function을 사용해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026gt; def time_func(seconds): \u0026gt; time.sleep(seconds) \u0026gt; def sum_func(*numbers): \u0026gt; return sum(numbers) \u0026gt; none_deco1 = perf_clock(time_func) \u0026gt; none_deco2 = perf_clock(sum_func) \u0026gt; print(none_deco1, none_deco1.__code__co_freevars) \u0026lt;function perf_clock.\u0026lt;locals\u0026gt;.perf_clocked at 0x0000021629F6FCA0\u0026gt; (\u0026#39;func\u0026#39;,) \u0026gt; print(none_decow, none_deco2.__code__co_freevars) \u0026lt;function perf_clock.\u0026lt;locals\u0026gt;.perf_clocked at 0x0000021629F6FD30\u0026gt; (\u0026#39;func\u0026#39;,) \u0026gt; print(\u0026#39;-\u0026#39; * 40, \u0026#39;Called None Decorator -\u0026gt; time_func\u0026#39;) ---------------------------------------- Called None Decorator -\u0026gt; time_func \u0026gt; none_deco1(1.5) [1.51397s] time_func(1.5) -\u0026gt; None \u0026gt; print(\u0026#39;-\u0026#39; * 40, \u0026#39;Called None Decorator -\u0026gt; sum_func\u0026#39;) ---------------------------------------- Called None Decorator -\u0026gt; sum_func \u0026gt; none_deco2(100, 150, 250, 300, 350) [0.00001s] sum_func(100, 150, 250, 300, 350) -\u0026gt; 1150 위 코드의 매커니즘에 대해 알아보자.\n첫 번째, perf_clock(func) 의 func 인자에 time_func을 할당했다.\n두 번째, perf_clock(time_func)의 return 값인 perf_clocked fuction을 none_deco1에 할당했다.\n세 번째,\n중첩 함수인 perf_clocked(*args) function에 time_func가 할당된 상태로, none_deco1에 할당된다.\n그러면 인자 func 그리고 *args 중에서 할당되지 않은 인자는 *args다.\n다섯 번째,\nnone_deco1(1.5)를 선언하면서 *args에 1.5가 할당된다.\nnone_deco2(100, 150, 250, 300, 350)은 *args에 100, 150, 200, 300, 350이 할당.\n이처럼 지난 first-class에서 알아본 partial처럼 하나씩 고정인수를 만들어간다.\n이 방식이 가능한 이유는 closure의 개념을 이용했기 때문이다.\n3.3 Decorator로 사용하기 이번에는 데코레이터를 사용해본다. decorator를 사용하니 코드가 훨씬 간결해진 걸 확인해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026gt; @perf_clock \u0026gt; def time_func(seconds): \u0026gt; time.sleep(seconds) \u0026gt;@perf_clock \u0026gt; def sum_func(*numbers): \u0026gt; return sum(numbers) \u0026gt; print(\u0026#39;*\u0026#39; * 40, \u0026#39;Called Decorator -\u0026gt; time_func\u0026#39;) **************************************** Called Decorator -\u0026gt; time_func \u0026gt; time_func(1.5) [1.49993s] time_func(1.5) -\u0026gt; None \u0026gt; print(\u0026#39;*\u0026#39; * 40, \u0026#39;Called Decorator -\u0026gt; sum_func\u0026#39;) **************************************** Called Decorator -\u0026gt; sum_func \u0026gt; sum_func(100, 150, 250, 300, 350) [0.00001s] sum_func(100, 150, 250, 300, 350) -\u0026gt; 1150 Decorator를 사용하면 별도의 변수에 함수를 할당할 필요가 없다.\n@perf_clock을 time_func와 sum_func 위에 각각 입력하여 time_func와 sum_func의 decorator로 사용한다.\n위에 각각 입력하는 의미는 perf_clock의 func 인자에 time_func와 sum_func을 할당하여 고정시킨다.\n이 다음으로 time_func(1.5) 와 time_func(100, 150, 250, 300, 350)처럼 *args 가변인자를 사용하여 할당한다.\n이처럼 decorator는 closure, firt-class, 가변인자, packing \u0026amp; unpacking 개념을 사용한다. Reference 인프런 파이썬 중급 파이썬 데코레이터를 작성하는 법을 배워야 하는 5가지 이유 ","permalink":"http://jeha00.github.io/post/python/python_basic_34_decorator/","summary":"Decorator(데코레이터)가 왜 중요한지, 왜 사용해야 하는지 그리고 작성하기 어려운 지에 대해 알아본다.","title":"[TIL] Python basic 34: Decorator"},{"categories":["Python"],"content":"0. Introudtion Closure가 필요한 이유 그리고, 잘못 사용된 사례에 대해 알아보자.\n1. UnboundLocalError 전역 변수와 지역 변수에 대해 간단히 복습해보자.\n1 2 3 4 5 6 7 8 9 10 11 # global (전역) 변수 \u0026gt; c = 30 \u0026gt; def func_v3(a): \u0026gt; print(a) \u0026gt; # local (지역) 변수 \u0026gt; print(c) \u0026gt; c = 40 \u0026gt; func_v3(10) UnboundLocalError: local variable \u0026#39;c\u0026#39; referenced before assignmnet func_v3를 정의하기 전에 c에 값을 할당했다.\n그래서 func_v3 안에 값은 이름의 c 와 이어질거라 생각했지만, Error가 떴다.\nError의 의미:\nc 라는 변수에 값이 할당되지 않았는데, print(c)로 참조되었다. 함수 블럭에서 할당하는 건 지역 변수다. 하지만, name이 같아도 함수 밖에서 할당했기 때문에 전역 변수로 인식하여 다르다. 해결책\nfunction block 안에 global 선언을 하든가, nonlocal 선언을 한다. local scope에서 전역으로 쓸 수 있는 방법이다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026gt; c = 30 \u0026gt; def func_v3(a): \u0026gt; global c \u0026gt; print(a) \u0026gt; print(c) \u0026gt; c = 40 # 함수 실행 전 이므로 30이 출력된다. \u0026gt; print(\u0026#39;\u0026gt;\u0026gt;\u0026#39;,c) 30 \u0026gt; func_v3(10) 10 30 # 함수 실행 후에는 40이 출력된다. \u0026gt; print(\u0026#39;\u0026gt;\u0026gt;\u0026gt;\u0026#39;,c) 40 해결책의 문제점\n함수 내에 global 또는 nonlocal을 쓰는 건 좋은 방법이 아니다. 왜냐하면 함수 내에 전역 변수와 연결되는 게 있다면 디버깅 할 때 쉽지 않다. 그래서 위의 statement로 local에서 수정하는 건 권하지 않는다. 그래서 또 다른 방법이 바로 closure(클로저) 다.\n이 클로저에 대해 알아보자.\n2. Closure 2.1 What is closure ?? Reference에 따른 closure 정의: 외부에서 호출된 함수의 변수값, 상태(레퍼런스)를 복사 후 저장한다. 그 후에 접근(액세스)이 가능하도록 하는 도구\n나만의 정의: 함수가 선언될 당시의 상황을 기억(closure: 포섭)했다가, 차후 호출될 때 기억한 환경을 사용하는 함수\nscope을 기준으로 설명하자면\nClosure란 enclosing scope에 있는 자유변수(free variable)를 이 scope의 실행이 종료되도 보유하고 있는 내부 함수 또는 중첩함수를 말한다.\n자유변수(free variable)란??\n정의되지 않은 code block에 사용되는 변수 여러 번 호출이 일어나도 상태 정보를 보유하기 위해 closure가 사용하는 원리 closure는 outer function을 호출해서 inner function을 return 했지만, inner function의 enclosing scope 에 있던 자유변수(free variable)를 계속해서 기억한다.\n그래서, 함수실행이 끝나도 그 시점의 변수를 이어서 작업할 수 있다.\n2.2 Why does we need closure ?? 함수 안에 선언된 것들이 함수의 실행이 끝나서 소멸되면 변수 값도 사라지지만, closure를 사용하면 기억되기 때문에, single thread여도 동시성 제어가 가능하다.\n서버 프로그래밍의 관점에서 closure를 바라보면\n서버 프로그래밍에서 어려운 것이 동시성(Concurrency) 제어다. 한정된 메모리 공간에서 여러 자원이 접근하면 교착상태(Dead lock)에 부딪힌다. 이를 해결하는 게 동시성(Concurrency) 제어다. closure는 불변자료 (immutable, Read Only) 구조 및 atom, STM 이므로 multi-thread 프로그래밍에 강점을 가진다. multi-thread가 아닌 단일 thread 인데도 동시성을 갖도록 하는 기반이 되는 게 바로 closure다. 또한, 이 클로저는 함수형 프로그래밍에도 연결된다.\n그러면 class를 사용하여 closure가 무엇인지 구현해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # global scope \u0026gt; class Avenager(): # enclosing scope \u0026gt; def __init__(self): \u0026gt; self._series = [] # local scope # special method __call__은 class를 function처럼 호출해서 사용하도록 한다. \u0026gt; def __call__(self, v): \u0026gt; self._series.append(v) \u0026gt; print(\u0026#39;inner \u0026gt;\u0026gt;\u0026gt; {} / {}\u0026#39;.format(self._series, len(self_.series))) \u0026gt; return sum(self._series) / len(self._series) # local scope # 인스턴스 생성 \u0026gt; averager_cls = Averager() # 누적 # instance를 생성했는데, function처럼 사용하고 있다. # Avenger()를 사용하면 __call_ method의 return 값이 출력된다. \u0026gt; print(averager_cls(15)) \u0026gt; print(averager_cls(35)) \u0026gt; print(averager_cls(40)) inner \u0026gt;\u0026gt;\u0026gt; [15] / 1 15.0 inner \u0026gt;\u0026gt;\u0026gt; [15, 35] / 2 25.0 inner \u0026gt;\u0026gt;\u0026gt; [15, 35, 40] / 3 30.0 위의 예시처럼 class 실행이 끝나서, 변수가 소멸되야하는데 유지되고 있다. 상태를 기억하고 있기 때문에 계속해서 누적된다. 그래서 중간부터 해도 이어서 할 수 있다.\n3. Exercises for closure closure는 pattern이 정해져 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # global scope \u0026gt; def closure_ex1(): # closure_ex1의 local scope이면서 # averager(v)의 the enclosing scope 또는 자유영역 # 이 영역에 정의된 변수: series \u0026gt; series = [] \u0026gt; def averager(v): # averager의 local scope \u0026gt; series.append(v) \u0026gt; print(\u0026#39;inner \u0026gt;\u0026gt;\u0026gt; {} / {}\u0026#39;.format(series, len(series))) \u0026gt; return sum(series) / len(series) ## 반환해야 클로저로서 사용할 수 있다. # 일급 함수의 특징: 함수를 반환할 수 있다. \u0026gt; return averager # make a instance # 반환값인 averager가 avg_closure1에 할당된다. \u0026gt; avg_closure1 = closure_ex1() \u0026gt; print(avg_closure1) \u0026lt;function closure_ex1.\u0026lt;locals\u0026gt;.averager at 0x000001B59D11FC10\u0026gt; # 인자로 입력된 15는 averager function의 인자 v이다. \u0026gt; print(avg_closure1(15)) inner \u0026gt;\u0026gt;\u0026gt; [15] / 1 15.0 \u0026gt; print(avg_closure1(35)) inner \u0026gt;\u0026gt;\u0026gt; [15, 35] / 2 25.0 \u0026gt; print(avg_closure1(40)) inner \u0026gt;\u0026gt;\u0026gt; [15, 35, 40] / 3 30.0 series가 local scope에 있었다면 위 경우처럼 출력할 때 이전 값이 보존되지 않는다. 왜냐하면 averager가 실행이 끝나면 그 안에 local scope에 있던 변수는 소멸된다. 하지만, enclosing scope에 변수를 정의했기 때문에, 함수를 실행할 때마다 자유변수에 접근해서 값이 보존된다. 그래서 새로 추가해도 실행이 가능하다. 그러면 파이썬에서 이 closure를 어떻게 취급하는지 확인해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # function inspection # __closure__ 로 취급된다. # __call__이 있으므로, 호출할 수 있다. \u0026gt; print(dir(avg_closure1)) [\u0026#39;__annotations__\u0026#39;, \u0026#39;__call__\u0026#39;, \u0026#39;__class__\u0026#39;, \u0026#39;__closure__\u0026#39;, \u0026#39;__dict__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__init__\u0026#39;, \u0026#39;__init_subclass__\u0026#39;, \u0026#39;__kwdefaults__\u0026#39;, \u0026#39;__le__\u0026#39;, \u0026#39;__lt__\u0026#39;, \u0026#39;__module__\u0026#39;, \u0026#39;__name__\u0026#39;] # detail한 함수 목록이 나온다. \u0026gt; print(dir(avg_closure1.__code__)) \u0026gt; print(avg_closure1.__code__.co_freevars) (\u0026#39;series\u0026#39;,) # 자유 변수값을 출력할 수 있다. \u0026gt; print(avg_closure1.__closure__[0].cell_contents) [15, 35, 40] __code__: 함수가 컴파일되서 바이트코드 상태의 정보를 출력해주는 역할 4. Incorrect use of closures closure의 잘못된 사용법을 예제로 알아보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026gt; def closure_ex3(): \u0026gt; # Free variable \u0026gt; cnt = 0 \u0026gt; total = 0 \u0026gt; def averager(v): # cnt와 total을 자유변수로 만든다. \u0026gt; nonlocal cnt, total \u0026gt; cnt += 1 \u0026gt; total += v \u0026gt; return total / cnt \u0026gt; return averager \u0026gt; avg_closure3 = closure_ex3() \u0026gt; print(avg_closure3(15)) 15.0 \u0026gt; print(avg_closure3(35)) 25.0 \u0026gt; print(avg_closure3(40)) 30.0 바로 위의 예시처럼 nonlocal을 사용하는 방법 그리고, UnboundLocalError를 설명할 때 언급한 global 을 사용하는 법이 잘못된 closure 사용법이다. UnboundLocalError 를 설명한 경우와 달리, 변수를 전역이 아닌 자유 변수로 만들었고, 내장 함수를 반환했기 때문에 closure지만 좋은 방법이 아니다. 왜냐하면 함수 내에 지역 변수 외의 것과 연결되는 게 있다면 디버깅 할 때 쉽지 않다. Reference 인프런 파이썬 중급 Python Scope \u0026amp; the LEGB Rule: Resolving Names in Your Code ","permalink":"http://jeha00.github.io/post/python/python_basic_33_closure/","summary":"Closure를 설명하기 위해서 global variable, local variable에 추가하여 free variable에 대해 설명하고, 왜 closure가 필요한지, closure의 잘못된 사용법을 알아본다.","title":"[TIL] Python basic 33: Closure"},{"categories":["Python"],"content":"0. Introduction coroutin을 공부하면서 global variable과 local variable 라는 것이 Scoping Rule과 연관이 되어있다는 것과, Stack 과 Heap 이라는 데이터 임시 저장 자료 구조와 연관된 걸 확인하고 이에 대해 정리해보겠다. 1.LEGB rules(Scoping rules) 변수(variable)의 생존 범위(lifetime)에 관련된 규칙으로, 이 변수가 적용되는 범위를 말하는 것으로 이해했다.\nPython scope 개념을 알아야 하는 이유:\n신뢰성 있고, 유지보수성이 좋은 프로그램을 작성할 수 있다. name 충돌을 방지할 수 있고, 버그를 줄일 수 있다. 이와 관련된 tool인 Closure에 대해 알 수 있다. 1.1 초기 Scope의 부재로 인한 문제 초기 프로그래밍은 global만 있었기 때문에, 변수를 수정해야할 때 모든 코드를 동시에 염두에 둬야했다. 그래서 이런 문제를 피하기 위해 scope을 사용했다. scope을 사용한 후, 프로그램의 어디에서든지 해당되는 scope에서 벗어나 있는 변수들에 함부로 접근할 수 없다. (out of scope) name들의 scope은 이 name들을 정의한 코드의 block scope과 동일하다. (in scope) 1.2 파이썬의 이름(name) 만들기 파이썬에서의 변수들에 값이 할당될 때, 즉 파이썬 names을 다음과 같은 방법들로 만들 때 변수들은 존재하게 된다. 변수(variable): 변수에 값을 할당하면, 변수는 만들어진다. function , classes: 예약어 def, classes를 사용하여 정의하면 이용할 수 있다. modules: import하여 사용할 수 있고, as를 통해서 별칭으로 정의할 수 있다. 1.3 Reference operations과 Assignment operations의 차이 operations Reference operations Assignment operations 참조 / 할당 name을 \u0026lsquo;참조\u0026rsquo; 한다 name을 \u0026lsquo;할당\u0026rsquo; 한다 구체적인 의미 name에 담겨진 value를 \u0026lsquo;단지 가져온다\u0026rsquo; name을 \u0026lsquo;새롭게\u0026rsquo; 만들거나, \u0026lsquo;수정\u0026rsquo; 한다 그리고, 할당한다는 건 특정 scope이 결정된다는 걸 말한다.\n1.4 Python scope와 namespace의 관계 Namespace 설명은 [TIL] Python basic 14: class을 참고한다.\nnamespace는 각각 다른 지점에서 만들어지기 때문에, 다른 수명 시간(life time)을 가지고 있다. 어느 위치에서 사용할 수 있는 지가 결정되어 있다. (from Python-course.eu: Namespaces)\n__dir__을 통해서 할당된 name이 가지는 scope을 보여준다.\n.__dict__.keys() 로 key value로 indexing하여 확인할 수 있다. 1.5 Python이 name을 찾는 규칙: LEGB rules Scope Local Enclosed(or Non local) Global(or Module) Built-in 해당 이름 function의 body (= code block)에 정의한 이름 지역 범위에 있는 중첩 함수를 둘러싼 범위에 있는 name 최고 수준으로(Top level) 정의한 이름 python 안에 내장된 예약어들 확인 범위 name이 정의된 function의 코드에서만 확인 가능 name이 정의된 function의 코드에서만 확인 가능 어느 코드에서든지 확인 가능 어느 코드에서든지 확인 가능 수명 시간(life time) 정의한 function이 종료되면 소멸 중첩 함수가 있는 외부 function이 종료되면 소멸 script가 끝날 때까지 지속 인터프리터가 시작되면 만들어져 소멸 X Top level이란?? From: Python Scope \u0026amp; the LEGB rule: Resolving Names in Your code Local(or function) scope: 지역 범위\nPython function의 body 또는 code block 부분이 local scope이다. function이 호출될 때, 이 function에 대한 namespace가 생성된다. 지역 함수 내에 로직을 해결하는 값을 사용한다. Enclosed(or nonlocal or free) scope: 자유 영역\n중첩함수(nested functions)를 위해서만 존재하는 scope\nenclosing function 안에서 정의된 names만 포함한다.\n이 enclosing function의 코드에서만 enclosing scope에 있는 name을 확인할 수 있다.\nGlobal(or module) scope: 전역 범위\nPython program, script, module 안에서 Top level의 scope으로, 이 scope에는 주로 변하지 않는 고정값을 사용한다. Built-in scope: 내장 범위\nscript를 run할 때마다 만들어지는 특별한 scope python은 name의 존재유무를 확인하기 위해서, 여러 scope levels(or namespace)를 찾아보는데, 찾는 순서는 다음과 같다.\nlocal -\u0026gt; global -\u0026gt; global or module -\u0026gt; built-in namespace 1 2 3 4 5 6 7 8 9 10 11 12 13 # This area is the global or module scope \u0026gt; number = 100 \u0026gt; def outer_func(): \u0026gt; # This block is the local scope of outer_func() \u0026gt; # It\u0026#39;s also the enclosing scope of inner_func() \u0026gt; def inner_func(): \u0026gt; # This block is the local scope of inner_func() \u0026gt; print(number) \u0026gt; \u0026gt; inner_func() \u0026gt; outer_func() 100 Inside inner_func(): local scope 이지만, number 변수는 존재하지 않는다. Inside outer_func(): the enclosing scope 이다. number 변수가 정의되지 않았다. In the module scope(or global scope): number 변수를 찾을 수 있어서 출력할 수 있다. 만약 number 변수가 the global scope에서 정의되지 않는다면, 파이썬은 built-in scope에서 찾을 것이다. 2. LEGB rules를 code로 이해해보기 2.1 LEGB rules: The Local Scope 그러면 code를 보면 이해해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; def square(base): \u0026gt; result = base ** 2 \u0026gt; print(f\u0026#39;The square of {base} is : {result}\u0026#39;) \u0026gt; square(10) The square of 10 is : 100 \u0026gt; result NameError: name \u0026#39;result\u0026#39; is not defined \u0026gt; base NameError: name \u0026#39;base\u0026#39; is not defined 위 코드에 대해 알아보자.\nsquare 함수를 호출 시, 파이썬은 base와 result를 포함하는 local scope을 만든다. square(10)으로 호출할 때, base에는 10을, result에는 100을 취한다. 다시 호출할 때는 첫 번째 호출 시 취한 값들은 기억하지 않는다. result와 base는 square() 호출에 의해 만들어진 local scope에만 존재한다. 그래서 square fuction 종료 후 접근한다면 NameError을 얻는다. 그러면 추가로 square function의 local scope에 정의한 변수 이름과 동일한 변수 이름을 가진 function 정의해보자.\n1 2 3 4 5 6 \u0026gt; def cube(base): \u0026gt; result = base ** 3 \u0026gt; print(f\u0026#39;The cube of {base} is : {result}\u0026#39;) \u0026gt; cube(30) The cube of 30 is : 27000 local scope에 동일한 변수이름을 사용했지만, 프로그램 충돌이 일어나지 않은 이유는 local scope에만 살아있는 local variable(지역 변수)이기 때문에, 함수 실행이 끝나면 local scope에서 벗어나 지역 변수의 수명은 끝난다. 이러한 장점 때문에, 디버깅과 수정이 쉽고 가독성이 좋아진다. 2.2 LEGB rules: The Enclosing Scope (Nested Functions) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; def outer_func(): \u0026gt; # 이 block은 외부 함수(outer_func)의 local scope이면서 \u0026gt; # 내부 함수(inner_func)의 enclosing scope이기도 하다. \u0026gt; var = 100 \u0026gt; def inner_func(): \u0026gt; print(f\u0026#39;Printing var from inner_func() : {var}\u0026#39;) \u0026gt; inner_func() \u0026gt; print(f\u0026#39;Printing var from outer_func() : {var}\u0026#39;) \u0026gt; outer_func() Printing var from inner_func(): 100 Printing var from outer_func(): 100 \u0026gt; inner_func() NameError: name \u0026#39;inner_func\u0026#39; is not defined outer_func()이 호출될 때, outer_func()의 local scope이 만들어진다. 이 scope은 동시에 inner_func()의 enclosing scope이기도 한다. global scope과 local scope 둘 다 아니고, 이 사이에 놓여있는 특별한 scope을 의미. 또한, inner_func()은 enclosing function인 outer_func이 실행되는 동안에만 유지되는 일시적인 함수로서, outer_func()의 code에서만 inner_func()을 찾을 수 있다. outer_func()의 실행이 종료되면 inner_func()은 사라진다. 2.3 LEGB rules: Modules - The Global Scope 프로그램을 실행한 순간부터 global scope에 있는 것이다.\n이 global scope은 module scope이라고도 한다.\n그리고 현재 실행되는 script 또는 module이 entry point 역할을 한다면 __main__ module의 범위가 된다.\nnamespace를 확인하기 위해서 dir()을 사용할 때, 아무런 인자 없이 사용하면 main global Python scope에서 이용가능한 name list를 얻는다.\n프로그램 실행할 때 단 하나의 global Python scope만이 존재한다. 그리고, 프로그램 실행이 끝나야 scope이 종료된다.\nlocal scope에 있는 global 변수를 참조할 수 있지만, local scope에서 global variable에 값을 할당할려고 하면 Error가 발생된다.\n1 2 3 4 5 6 7 8 # a global variable \u0026gt; var = 100 \u0026gt; def increment(): \u0026gt; var += 1 # global variable 업데이트 시도하기 \u0026gt; increment() UnboundLocalError: local variable \u0026#39;var\u0026#39; referenced before assignment global variable(전역 변수)를 할당하려고 시도했지만, local scope(지역 범위) 내에서는 global variable에 값을 할당할 수 없다. (6번)\n그래서 전역 변수가 지역 변수와 이어지지 않기 때문에, 할당 없이 지역 변수 \u0026lsquo;var\u0026rsquo;을 참조하여 Error가 발생했다.\n그러면 이렇게 코드를 다시 짜보자.\n1 2 3 4 5 6 7 8 9 10 # 전역 변수 \u0026gt; var = 100 \u0026gt; def func(): # 동일한 이름으로 새로운 지역 변수를 정의한다. \u0026gt; var = 200 # 전역 변수인 var를 참조하는 게 아닌, 지역 변수인 var를 참조한다. \u0026gt; print(var) 전역 변수를 업데이트한 것이 아닌 function의 body 부분에 있기 때문에 지역 변수를 새로 만든 것이다. 즉, 다음 사실을 알 수 있다.\nPython은 global variable과 동일한 이름으로 function body에 선언해도 local variable로 인식한다.\n2.4 Local variable 또는 global variable 찾아보기 locals() 과 globals() function을 통해서 지역 변수와 전역 변수를 출력해보자. 2.4.1 locals() locals(): Return a dictionary containing the current scope\u0026rsquo;s local variables.\n1 2 3 4 5 6 7 8 9 10 \u0026gt; def func(var): \u0026gt; x = 10 \u0026gt; def printer(): \u0026gt; print(\u0026#39;Ex \u0026gt; 5\u0026#39;, \u0026#34;Printer Func Inner\u0026#34;) \u0026gt; print(locals()) \u0026gt; func(\u0026#39;Hi\u0026#39;) {\u0026#39;var\u0026#39;: \u0026#39;Hi\u0026#39;, \u0026#39;x\u0026#39;: 10, \u0026#39;printer\u0026#39;: \u0026lt;function func.\u0026lt;locals\u0026gt;.printer at 0x000001D53343FDC0\u0026gt;} var :func() 함수를 호출하기 위해 인자로 넘겼던 \u0026lsquo;Hi\u0026rsquo; 또한 지역변수임을 알 수 있다. x : enclosing scope에 있는 것 또한 지역변수임을 확인할 수 있다. printer : outer function의 local scope에 정의했기 때문에 printer 또한 지역 변수로 확인할 수 있다. 2.4.2 globals() globals는 이 코드를 실행할 때 입력한 모든 전역 변수가 입력되기 때문에, 다음과 같이 하여 알아본다. globals()는 global 영역의 변수를 입력할 때 호출된다. 1 2 3 4 5 6 7 \u0026gt; print(\u0026#39;Ex \u0026gt;\u0026#39;, globals()) Ex \u0026gt; {.....} \u0026gt; globals()[\u0026#39;text_variable\u0026#39;] = 100 \u0026gt; print(\u0026#39;Ex \u0026gt;\u0026#39;, globals()) Ex \u0026gt; {\u0026#39;__name__\u0026#39;: \u0026#39;__main__\u0026#39;, \u0026#39;__doc__\u0026#39;: None, ..., \u0026#39;__cached__\u0026#39;: None, \u0026#39;func\u0026#39;: \u0026lt;function func at 0x0000028708197F70\u0026gt;, \u0026#39;text_variable\u0026#39;: 100} globals()를 사용한 변수 자동화 생성: 지역 -\u0026gt; 전역 변수로 작성한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; for i in range(1, 6): \u0026gt; for k in range(1, 6): \u0026gt; globals()[\u0026#39;plus_{}_{}\u0026#39;.format(i, k)] = i + k \u0026gt; print(globals()) {\u0026#39;plus_1_1\u0026#39;: 2, \u0026#39;plus_1_2\u0026#39;: 3, \u0026#39;plus_1_3\u0026#39;: 4, \u0026#39;plus_1_4\u0026#39;: 5, \u0026#39;plus_1_5\u0026#39;: 6, \u0026#39;plus_2_1\u0026#39;: 3, \u0026#39;plus_2_2\u0026#39;: 4, \u0026#39;plus_2_3\u0026#39;: 5, \u0026#39;plus_2_4\u0026#39;: 6, \u0026#39;plus_2_5\u0026#39;: 7, \u0026#39;plus_3_1\u0026#39;: 4, \u0026#39;plus_3_2\u0026#39;: 5, \u0026#39;plus_3_3\u0026#39;: 6, \u0026#39;plus_3_4\u0026#39;: 7, \u0026#39;plus_3_5\u0026#39;: 8, \u0026#39;plus_4_1\u0026#39;: 5, \u0026#39;plus_4_2\u0026#39;: 6, \u0026#39;plus_4_3\u0026#39;: 7, \u0026#39;plus_4_4\u0026#39;: 8, \u0026#39;plus_4_5\u0026#39;: 9, \u0026#39;plus_5_1\u0026#39;: 6, \u0026#39;plus_5_2\u0026#39;: 7, \u0026#39;plus_5_3\u0026#39;: 8, \u0026#39;plus_5_4\u0026#39;: 9, \u0026#39;plus_5_5\u0026#39;: 10} \u0026gt; print(plus_3_5) 8 \u0026gt; print(plus_5_5) 10 1.12 LEGB rules: Built-in scope Built-in scope은 builtins 라 불리는 표준 라이브러리 모듈로서 실행되는 특별한 파이썬 scope이다. 파이썬은 LEGB 에서 마지막으로 built-in을 찾는다. 이 scope에서는 어느 모듈이든지 import할 필요 없이 names을 사용할 수 있다. builtins 안에 있는 name들은 언제나 Python의 global scope에, __builtins__로 담겨진다. 밑에 예제를 보자. 1 2 3 4 5 \u0026gt; dir() [\u0026#39;__annotations__\u0026#39;, \u0026#39;__builtins__\u0026#39;,..., \u0026#39;__package__\u0026#39;, \u0026#39;__spec__\u0026#39;] \u0026gt; dir(__builtins__) [\u0026#39;ArithmeticError\u0026#39;, \u0026#39;AssertionError\u0026#39;,..., \u0026#39;tuple\u0026#39;, \u0026#39;type\u0026#39;, \u0026#39;vars\u0026#39;, \u0026#39;zip\u0026#39;] dir()의 첫 호출에서 __builtins__을 확인할 수 있다. 그리고 __builtins__를 dir로 내부를 들여다보면, 파이썬의 built-in names의 전체 목록을 얻을 수 있다. 또 한 가지 특징은 global scope에서 어떠한 built-in names이든 오버라이드할 수 있다. 하지만 우연히 또는 부주의하게 이렇게 오버라이드가 된다면 위험하며, 버그를 찾기 어렵다. 그래서 이런 종류의 실행은 최대한 피하는 게 낫다. 1 2 3 4 5 6 7 8 9 10 11 12 13 # a built-in fuction의 표준 사용 \u0026gt; abs(-15) 15 # global scope에서 built-in name을 재정의한다. \u0026gt; abs = 20 \u0026gt; abs(-15) TypeError: \u0026#39;int\u0026#39; object is not callable \u0026gt; del abs \u0026gt; abs(-15) 15 2. Python memory structure 2.1 코드 영역 실행할 프로그램의 코드가 저장되는 영역 (text 영역이라고도 한다)\n2.2 데이터 영역 프로그램의 global variable과 정적(static) variable가 저장되는 영역\n프로그램이 시작하고, 끝날 때까지 메모리에 계속 남아 있는다. 2.3 Stack 데이터를 임시 저장할 때 사용하는 자료구조로, 데이터의 입력과 출력 순서는 후입선출(Last In First Out, LIFO) 방식 지역 변수 와 매개변수가 저장된다. push(푸쉬): stack에 데이터를 넣는 작업 pop(팝):stack에서 데이터를 꺼내는 작업 데이터를 넣고 꺼내는 작업에서 윗 부분을 top, 아랫 부분을 bottom 이라 한다. stack 영역은 함수의 호출과 함께 생성되고, 함수의 호출이 완료되면 소멸한다. 스택 프레임(stack frame): 스택 영역에 저장되는 함수의 호출 정보 메모리의 높은 주소에서 낮은 주소의 방향으로 할당된다. 한계가 있어서, 한계를 초과하도록 삽입할 수 없다. Stack overflow: 함수는 변수를 저장하기 위해 stack을 만드는데, 만들어진 stack이 메모리 용량을 넘어서면 Stack overflow가 발생한다. 2.2 Heap 사용자가 직접 관리할 수 있는 영역으로, 객체가 생성된다.\n사용자에 의해 메모리 공간이 동적으로 할당되고, 해제된다. heap 영역은 런타임 시에 크기가 결정된다 (메모리가 할당된다) 메모리의 낮은 주소에서 높은 주소로 할당된다. Reference 파이썬 프로그래밍 기초 - 지역 변수와 전역 변수 Python-course.eu: Namespaces 스코핑 룰(Scoping rule) 자료구조와 함께 배우는 알고리즘 입문 파이썬편 Python Scope \u0026amp; the LEGB rule: Resolving Names in Your code ","permalink":"http://jeha00.github.io/post/python/python_basic_32_legb_rules/","summary":"LEGB rules 즉 Local, Enclosing, global(or module), built-in varialbe의 scope에 대해 알아본다. 그리고, Python Memory structure가 어떤지 개괄적으로 알아본다.","title":"[TIL] Python basic 32: LEGB rules and Memory structures"},{"categories":["Python"],"content":"0. Introduction 이번 시간에 배울 내용은 특히 더 중요하다. 이번 시간에는 일급 객체라고도 불리는 일급 함수에 대해 알아보겠다. 그 후, 일급 함수의 예인 lambda, callable, partial에 대해 알아본다. 1. 일급 함수(first-class)란?? 일급 함수(일급 객체, first-class)란?? 객체 취급되는 함수 다음 4가지 특징을 가지는 함수를 말한다. 1. 런타임 초기화: 실행 시점에서 초기화한다. 2. 함수를 변수에 할당 가능하다. 3. 함수를 인수로 전달 가능하다. (Higher - order function의 첫 번째 특징) 4. 함수를 결과값으로서 반환 가능하다. (Higher - order function의 첫 번째 특징) 위 일급 함수의 특징들은 파이썬 함수의 특징이라고 할 수 있다.\n그러면 일급함수는 왜 중요한가??\n일급함수를 알아야 \u0026lsquo;함수형 프로그래밍\u0026rsquo; 을 할 수 있기 때문이다. \u0026lsquo;함수형 프로그래밍\u0026rsquo; 이란?? side effect를 허용하지 않는 순수 함수(pure function)를 지향하여 동시에 여러 thread에서 문제 없이 동작하는 프로그램을 쉽게 작성하는 방식 이러한 이유로 일급 함수에 대해 알아보자.\n일급 함수가 가지는 특징을 모두 예제로 구현해볼 것이다.\n1.1 객체 취급되는 함수 객체란 무엇인가???\n[TIL] Python basic 14: class에 따르면 소프트웨어로 구현할 대상이라 했다. 하지만 파이썬 내부에서의 객체의 정의와 특징은 무엇일까???\n파이썬이 data를 추상화(abstraction)한 것을 말하며,\nid(identity), type(형) 그리고, value(값)을 가dd지는 걸 말 한다.\n파이썬의 모든 데이터는 객체나 객체 간의 관계로 표현된다.\n객체 id는 메모리 상에서 객체의 주소이며, id는 만들어진 후에는 변경되지 않는다.\nfrom 데이터 모델: 객체 attribute란 점표현식을 사용하는 이름으로 참조되는 객체와 결합한 값(value)\n용어집 - python 3.10.4 함수 객체 : 함수처럼 행동하는 객체 from 함수 객체의 장점\n그럼 코드 상에서 확인해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 \u0026gt; def factorial(n): \u0026gt; ```Factorial Function -\u0026gt; n : int ``` \u0026gt; if n == 1: \u0026gt; return 1 \u0026gt; # 이렇게 함수 내에서 함수를 호출하는 걸 재귀함수라 한다. \u0026gt; return n * factorial(n-1) \u0026gt; class A: \u0026gt; pass \u0026gt; print(factorial(6)) 720 # 함수 comment 출력 \u0026gt; print(factorial.__doc__) Factorial Function -\u0026gt; n : int # 함수를 인자로서 넘겼다. \u0026gt; print(type(factorial), type(A)) \u0026lt;class \u0026#39;fuction\u0026#39;\u0026gt;, \u0026lt;class \u0026#39;type\u0026#39;\u0026gt; # 함수 또한 객체임을 확인했다. \u0026gt; print(id(factorial)) id - 2416266045904 # dir은 객체가 가지고 있는 속성(attribute)를 출력하는 함수다. \u0026gt; print(dir(factorial)) [\u0026#39;__annotations__\u0026#39;, \u0026#39;__call__\u0026#39;, \u0026#39;__class__\u0026#39;, \u0026#39;__closure__\u0026#39;, \u0026#39;__code__\u0026#39;, \u0026#39;__defaults__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__dict__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__eq__\u0026#39;, \u0026#39;__format__\u0026#39;, \u0026#39;__ge__\u0026#39;, \u0026#39;__get__\u0026#39;, \u0026#39;__getattribute__\u0026#39;, \u0026#39;__globals__\u0026#39;, \u0026#39;__gt__\u0026#39;, \u0026#39;__hash__\u0026#39;, \u0026#39;__init__\u0026#39;, \u0026#39;__init_subclass__\u0026#39;, \u0026#39;__kwdefaults__\u0026#39;, \u0026#39;__le__\u0026#39;, \u0026#39;__lt__\u0026#39;, \u0026#39;__module__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__ne__\u0026#39;, \u0026#39;__new__\u0026#39;, \u0026#39;__qualname__\u0026#39;, \u0026#39;__reduce__\u0026#39;, \u0026#39;__reduce_ex__\u0026#39;, \u0026#39;__repr__\u0026#39;, \u0026#39;__setattr__\u0026#39;, \u0026#39;__sizeof__\u0026#39;, \u0026#39;__str__\u0026#39;, \u0026#39;__subclasshook__\u0026#39;] # class와 동일하게 가지는 속성들을 빼서 함수만 가진 속성들을 확인할 수도 있다. \u0026gt; print(set(sorted(dir(factorial))) - set(sorted(dir(A))) {\u0026#39;__call__\u0026#39;, \u0026#39;__defaults__\u0026#39;, \u0026#39;__closure__\u0026#39;, \u0026#39;__kwdefaults__\u0026#39;, \u0026#39;__code__\u0026#39;, \u0026#39;__globals__\u0026#39;, \u0026#39;__name__\u0026#39;, \u0026#39;__get__\u0026#39;, \u0026#39;__annotations__\u0026#39;, \u0026#39;__qualname__\u0026#39;} # 함수의 이름을 알려준다. \u0026gt; print(factorial.__name__) factorial # type과 위치, 코드의 몇 번째 줄인지를 알려준다. \u0026gt; print(factorial.__code__) \u0026lt;code object factorial at 0x00000201685D8D40, file \u0026#34;c:\\Users\\rudtl\\Desktop\\Dev\\Python_lecture\\InflearnOriginal\\Level_2_중급\\p_chapter05_01.py\u0026#34;, line 35\u0026gt; 1.2 변수로 할당되는 함수 함수 또한 객체로 취급되는 걸 확인했다. 다음으로 이 함수가 변수에 할당되는지 확인해보자. 1 2 3 4 5 6 7 8 9 10 # 1.1 코드와 이어진다. # 변수에 할당 \u0026gt; var_func = factorial \u0026gt; print(var_func) \u0026lt;function factorial at 0x0000023294ADE9D0\u0026gt; \u0026gt; print(var_func(10)) 3628800 변수에 할당되어 여러 함수에 사용될 수 있다는 걸 확인했다. 1.3 고위 함수의 두 가지 특징 Higher - order function (고위함수)의 특징\n- 1. 함수를 인수로 전달 가능하다.\n- 2. 함수를 결과값으로서 반환 가능하다.\n고위 함수의 대표적인 예로는 map, filter, reduce, lambda 등이 있다.\n그러면 코드로 확인해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 ## range 함수로 iterator를 만들고, iteraotr의 각 성분들이 vap_func의 인자로 넘어간다. # 다음처럼 object로 출력된다면 type conversion을 해야 한다. # map 함수의 인자로 전달 가능하다. \u0026gt; print(map(vap_func, range(1,6))) \u0026lt;map object at 0x000001C1FC0A0DF0\u0026gt; \u0026gt; print(list(map(vap_func, range(1,6)))) [1, 2, 6, 24, 120] # var_func 을 결과값으로 반환 가능하다. \u0026gt; print(list(map(var_func, filter(lambda x: x % 2, range(1,6))))) [1, 6, 120] ## list comprehension을 사용하기 # 위와 동일한 출력값을 갖는다. 하지만, 가독성이 더 좋다. \u0026gt; print([var_func(i) for i in range(1, 6) if i % 2]) [1, 6, 120] reduce : 여러 원소를 하나의 원소로 줄이기 위해, 왼쪽에서부터 오른쪽 방향으로 축적하며 함수를 적용해간다. 1 2 3 4 5 6 7 8 9 10 11 12 13 ## reduce \u0026gt; from functools import reduce \u0026gt; from operator import add \u0026gt; print(list(range(1,11))) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # 인수 하나 하나를 줄여나가면서 더해가는 함수 \u0026gt; print(reduce(add, range(1, 11))) # 하지만 reduce는 잘 사용하지 않고, sum을 사용한다. \u0026gt; print(sum(range(1, 11))) 2. High - order functions 2.1 익명 함수(lambda) 이름 없는 함수로, 익명 함수다. 그래서 익명 함수가 복잡할 때, 주석을 사용해야 한다.\n하지만, 되도록 함수를 만들어서 사용하자. 일반 함수 형태로 refactoring을 권장한다.\n1 2 \u0026gt; print(reduce(lambda x, t : x + t, range(1,11))) 55 2.2 Callable 호출 연산자로 함수, 클래스 인스턴스, 메서드 등이 호출 가능한지 확인하는 함수다. 이를 구체적으로 확인하는 방법은 specail method인 __call__ method의 존재 유무를 확인하는데, 이 method가 있으면 True다.\nfrom What is a \u0026lsquo;callable\u0026rsquo;\n호출한다는 건 무슨 의미일까??? 1 2 3 4 5 6 7 # 아래 예시처럼 함수를 불러와서 사용할 수 있는 걸 의미한다. \u0026gt; str(3) \u0026gt; var_func(5) # 하지만 다음 같은 경우는 호출할 수 없는 함수다. \u0026gt; 3.14(334) 이를 callable로 확인해보자. 1 2 \u0026gt; print(callable(str), callable(list), callable(var_func), callable(3.14)) True True True False 3.14는 호출할 수 없다는 걸 callable을 통해 간단히 확인했다. 2.3 Partial 인수를 고정할 때 사용하는 함수로, 콜백 함수에 사용하기 때문에 매우 중요하다.\n코드로 알아보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; from operator import mul \u0026gt; from functools import partial # mul은 multiply의 약어다. \u0026gt; print(mul(10, 10)) 100 # 그러면 인수 하나를 고정하여, 함수를 변수에 할당하자. \u0026gt; five = partial(mul, 5) \u0026gt; print(five(10)) 50 # 한 번도 고정한다면?? \u0026gt; six = partial(five, 6) \u0026gt; print(six()) 60 2.4 Signature signature(callable, *, follow_wrapped=True) 형식으로 인자로 callable을 취하고, annotation을 반환한다.\nsignature 함수는 inspect module에서 import한다. inspect module은 모듈은 모듈, 클래스, 메서드, 함수, 트레이스백, 프레임 객체 및 코드 객체와 같은 라이브 객체에 대한 정보를 얻는 데 도움이 되는 몇 가지 유용한 함수를 제공한다. 예를 들어 클래스의 내용을 검사하거나, 메서드의 소스 코드를 꺼내오거나, 함수의 인자 리스트를 추출하고 포맷하거나, 자세한 트레이스백을 표시하는 데 필요한 모든 정보를 얻는 데 도움이 될 수 있다. from Inspect: 라이브 객체 검사 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026gt; from inspect import signature \u0026gt; sg = signature(var_func) \u0026gt; print(sg) (n) \u0026gt; print(sg.parameters) OrderedDict([(\u0026#39;n\u0026#39;, \u0026lt;Parameter \u0026#34;n\u0026#34;\u0026gt;)]) \u0026gt; def foo(a, *, b:int, **kwargs): \u0026gt; pass \u0026gt; sig = signature(foo) \u0026gt; print(str(sig)) (a, *, b:int, **kwargs) \u0026gt; print(str(sig.parameters[\u0026#39;b\u0026#39;])) \u0026#39;b:int\u0026#39; \u0026gt; print(sig.parameters[\u0026#39;b\u0026#39;].annotation) \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; Reference 인프런 파이썬 중급 데이터 모델: 객체 Inspect: 라이브 객체 검사 용어집 - python 3.10.4 What is a \u0026lsquo;callable\u0026rsquo; ","permalink":"http://jeha00.github.io/post/python/python_basic_31_firstclass/","summary":"일급 함수(일급 객체, first-class)란 무엇인지 알고, 일급 함수의 예인 lambda function, Callable, Partial에 대해 알아본다.  그리고 추가적으로 Signature에 대해 간단히 알아본다.","title":"[TIL] Python basic 31: First-class"},{"categories":["Python"],"content":"0. Introduction sort와 sorted는 책 한 권으로 나올만큼 많은 내용이 있지만, 무엇보다 이 두가지의 기본적인 차이를 알아본다. 그리고, [TIL] Python basic 29: Data Model에서 상세 분류에서 언급된 Array data type에 대해 알아본다. 1. Sort vs Sorted - sort: sort the list in ascending order and return None.\n- sorted: Return a new list containing all items from the iterable in ascending order.\nsort() sorted() function/method method function 원본 수정 O X 반환값 None New list object reverse와 reversed도 .reverse()는 메서드로 원본 수정하고 반환값은 None, reversed()는 함수로 원본 수정하지 않고 수정된 값을 반환한다.\nlist data model에서 자주 사용하는 함수인 sort 와 sorted에 대해 알아보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026gt; f_list = [\u0026#39;orange\u0026#39;, \u0026#39;apple\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;papaya\u0026#39;, \u0026#39;lemon\u0026#39;, \u0026#39;strawberry\u0026#39;, \u0026#39;coconut\u0026#39;] ## sort # 1. 반환값이 없다. \u0026gt; print(\u0026#39;sort - \u0026#39;, f_list.sort()) sort - None # 2. 원본 객체를 수정한다. \u0026gt; print(f_list) [\u0026#39;apple\u0026#39;, \u0026#39;coconut\u0026#39;, \u0026#39;lemon\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;papaya\u0026#39;, \u0026#39;strawberry\u0026#39;] ## sorted # 1. 반환값이 존재한다. \u0026gt; print(\u0026#39;sort - \u0026#39;, sorted(f_list)) sorted - [\u0026#39;apple\u0026#39;, \u0026#39;coconut\u0026#39;, \u0026#39;lemon\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;papaya\u0026#39;, \u0026#39;strawberry\u0026#39;] # 2. 원본 객체를 수정하지 않는다. \u0026gt; print(f_list) sorted - [\u0026#39;orange\u0026#39;, \u0026#39;apple\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;papaya\u0026#39;, \u0026#39;lemon\u0026#39;, \u0026#39;strawberry\u0026#39;, \u0026#39;coconut\u0026#39;] 다음으로 여러 key 값을 사용하여 sort와 sorted를 활용해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # reverse = True # 순서를 뒤집는다. \u0026gt; print(\u0026#39;sorted - \u0026#39;, sorted(f_list, reverse = True)) sorted - [\u0026#39;strawberry\u0026#39;, \u0026#39;papaya\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;lemon\u0026#39;, \u0026#39;coconut\u0026#39;, \u0026#39;apple\u0026#39;] \u0026gt; print(\u0026#39;sort - \u0026#39;, f_list.sort(reverse = True), f_list) sort - None [\u0026#39;strawberry\u0026#39;, \u0026#39;papaya\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;lemon\u0026#39;, \u0026#39;coconut\u0026#39;, \u0026#39;apple\u0026#39;] # key = len # 단어 길이를 기준으로 정렬한다. \u0026gt; print(\u0026#39;sorted - \u0026#39;, sorted(f_list, key = len)) sorted - [\u0026#39;apple\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;lemon\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;papaya\u0026#39;, \u0026#39;coconut\u0026#39;, \u0026#39;strawberry\u0026#39;] \u0026gt; print(\u0026#39;sort - \u0026#39;, f_list.sort(key = len), f_list) sort - None [\u0026#39;apple\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;lemon\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;papaya\u0026#39;, \u0026#39;coconut\u0026#39;, \u0026#39;strawberry\u0026#39;] # key = lambda x: x[-1] # 마지막 알파벳을 기준으로 정렬한다. \u0026gt; print(\u0026#39;sorted - \u0026#39;, sorted(f_list, key=lambda x: x[-1])) sorted - [\u0026#39;papaya\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;apple\u0026#39;, \u0026#39;lemon\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;coconut\u0026#39;, \u0026#39;strawberry\u0026#39;] \u0026gt; print(\u0026#39;sort - \u0026#39;, sort(f_list, key=lambda x: x[-1]), f_list) sort - None [\u0026#39;papaya\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;apple\u0026#39;, \u0026#39;lemon\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;coconut\u0026#39;, \u0026#39;strawberry\u0026#39;] # key = lambda x: x[-1], reverse = True # 마지막 알파벳을 기준으로 정렬한 후, 뒤집는다. \u0026gt; print(\u0026#39;sorted - \u0026#39;, sorted(f_list, key=lambda x: x[-1], reverse = True)) sorted - [\u0026#39;strawberry\u0026#39;, \u0026#39;coconut\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;lemon\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;apple\u0026#39;, \u0026#39;papaya\u0026#39;] \u0026gt; print(\u0026#39;sort - \u0026#39;, sort(f_list, key=lambda x: x[-1], reverse = True), f_list) sorted - None [\u0026#39;strawberry\u0026#39;, \u0026#39;coconut\u0026#39;, \u0026#39;mango\u0026#39;, \u0026#39;lemon\u0026#39;, \u0026#39;orange\u0026#39;, \u0026#39;apple\u0026#39;, \u0026#39;papaya\u0026#39;] 2. Array data model 1.Python data model 상세 분류에서 꺼냈던 Array data model에 대해 알아보자.\nArray 자료형에 대해 알아보자.\nArray의 구조는 다음과 같다.\nArray(type code, [array 원소값]) 여기서 type code는 형 코드를 말하는데, 다음 대표 reference를 참조하자. Array in docs.python 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # array module을 가져오는 것부터 시작한다. \u0026gt; import array \u0026gt; chars = \u0026#39;+_)(*\u0026amp;^%$#@!~)\u0026#39; # array module의 array method를 사용한다. # ord: Return the Unicode code point for a one-character string \u0026gt; array_g = array.array(\u0026#39;I\u0026#39;, (ord(s) for s in chars)) \u0026gt; print(type(array_g), array_g) \u0026lt;class \u0026#39;array.array\u0026#39;\u0026gt; array(\u0026#39;I\u0026#39;, [43, 95, 41, 40, 42, 38, 94, 37, 36, 35, 64, 33, 126, 41]) # .tolist(): array data type을 list로 바꿔주는 함수 \u0026gt; array_l = array_g.tolist() \u0026gt; print(type(array_l)) \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; \u0026gt; print(array_l) [43, 95, 41, 40, 42, 38, 94, 37, 36, 35, 64, 33, 126, 41] List vs Array 적합한 사용법 List 기반: 다양한 data type을 사용할 수 있기 때문에, 융통성 있게 범용적으로 사용 가능. Array 기반: 한 가지 data type만 사용할 수 있기 때문에, 숫자 기반에 많이 사용한다. Reference 인프런 파이썬 중급 ","permalink":"http://jeha00.github.io/post/python/python_basic_30_sortvssorted_array/","summary":"sort와 sorted의 차이를 알아보고, Array data type 에 대해 알아본다.","title":"[TIL] Python basic 30: Sort VS Sorted"},{"categories":["Python"],"content":"0. Introduction 파이썬에 존재하는 모든 sequence type 및 data structure에 대해 조금 더 깊이 알아보자. data structure: 논리적인 관계로 이루어진 데이터 구성 이러한 Data type 들이 있고, 각각의 특징을 이해하여 코드에 녹여내자. 각 data type에 대해서 여기에 언급된 내용이 전부가 아니니 더 공부하자. 1. Python data type 상세 분류 Python의 data type은 여러 기준으로 분류될 수 있다.\n1.1 무슨 형태의 자료형을 담을 수 있는가??? Container 형: 서로 다른 자료형을 담을 수 있다.\nex) list, tuple, collections.deque..\nflat 형: 한 가지 자료형만 담을 수 있다.\nex) string, bytes, byte array, array, memoryview\u0026hellip;\n1 2 3 4 5 # Container의 예: 정수, 실수, 문자열 같이 서로 다른 자료형을 담을 수 있다. \u0026gt; a = [3, 3.0, \u0026#39;a\u0026#39;] # flat 형 \u0026gt; chars = \u0026#39;+_)(*\u0026#39; 1.2 element가 수정될 수 있는가?? 없는가?? Mutable: 변경할 수 있는 date type\nex) list, dictionary, set, bytearray, array, memoryview, deque..\nImmutable: 변경할 수 없는 data type\nex) tuple, str, bytes, int, float\u0026hellip;\n수정될 수 있으면 element를 교체, 삭제, 추가가 가능하다.\nex) del, append 등등 가능\n1.3 순서가 있는가 없는가??? Sequence: 순서가 존재한다.\nex) list, tuple, string ..\nCollections: 순서가 존재하지 않는다.\nex) set, dictionary ..\n순서가 존재하면 slicing, indexing 이 가능하다.\n2. Mutable 과 Immutable mutable: value를 수정할 수 있기 때문에, \u0026lsquo;id\u0026rsquo; 값을 바꾸지 않는다.\nimmutable: value가 변경되지 못하기 때문에, \u0026lsquo;id\u0026rsquo; 값을 바꾼다.\nid() 을 사용하여 mutable과 immutable에 대해 자세히 알아보자.\nmutable:\n함수 안에서 매개변수의 값을 변경하면 객체 자체를 업데이트 한다. 따라서, 매개변수의 값을 변경하면 호출하는 쪽의 실제 인수는 변경 된다. 그 대신 id 값은 변경되지 않는다. immutable:\n함수 안에서 매개변수 값을 변경하면 다른 객체를 생성 하고, 그 객체에 대한 참조로 업데이트된다. 따라서 매개변수의 값을 변경해도 호출하는 쪽의 실제 인수에는 영향을 주지 않는다. 그 대신 id 값은 변경된다. Data type Mutable Immutable 매개변수 값 변경 시도 객체 자체를 업데이트 다른 객체를 생성 실제 인수 영향 변경 O 변경 X id 값 변경 X 변경 O call by reference value mutable과 immutable에 call by 방식 차이 출처: Python study - call by reference value 2.1 Immutable 문자열과 누적변수 예시를 통해 알아보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026gt; chars = \u0026#39;+_)(*\u0026#39; # immutable data type인 string을 수정하려 하면 다음과 같은 error 가 뜬다. \u0026gt; chars[2] = \u0026#39;h\u0026#39; TypeError: \u0026#39;str\u0026#39; object does not support item assignment \u0026gt; n = 5 \u0026gt; whlie n \u0026gt; 0: \u0026gt; print(n, id(n)) \u0026gt; n -= 1 5 1670466136496 4 1670466136464 3 1670466136432 2 1670466136400 1 1670466136368 int형은 분명 immutable인데 어떻게 수정이 가능할까???\n이는 int형 객체 12의 값 자체를 변경한 것이 아니라, 다른 정수형 객체 13을 참조하도록 업데이트됐다. immutable은 값 자체를 변경할 수 없기 때문에, 다른 객체를 참조하여 id 값이 바뀐다.\n그래서 누적 변수를 출력하면 id가 달라지는 걸 알 수 있다.\n누적 변수: 변수값에 특정값을 더한 결과값을 다시 대입하여 업데이트한 변수 2.2 Mutable 이번에 mutable 예시를 들어보자. 1 2 3 4 5 6 7 8 9 \u0026gt; k = [1, 2, 3] \u0026gt; print(id(k)) 2249826233536 \u0026gt; k[0] = 0 \u0026gt; print(k, id(k)) [0, 2, 3] 2249826233536 list는 mutable로 성분값을 수정할 수 있어서, id 값이 수정 전과 동일하다. 3. List comprehension 3.1 List comprehension의 의미와 구조 List comprehension이란 list를 만드는 간결한 문법을 말한다.\nList comprehensions provide a concise way to create lists.\nfrom: list comprehension\nlist comprehension에 대해 찾아보니 번역이 다양하고, 딱 들어맞는게 없어서 고유 명사의 의미로 그대로 사용하겠다.\n그러면 일반적으로 list를 만드는 방법과 비교해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 일반적으로 list를 만드는 방법 \u0026gt; code_list1 = [] \u0026gt; chars = \u0026#39;+_)(*\u0026amp;^\u0026#39; # ord: Return the Unicode code point for a one-character string. # ord: 유니 코드로 전환하는 함수 \u0026gt; for s in chars: \u0026gt; code_list1.append(ord(s)) [43, 95, 41, 40, 42, 38, 94] ## list comprehension을 이용한 방법 \u0026gt; code_list2 = [ord(s) for s in chars] [43, 95, 41, 40, 42, 38, 94] # for문과 if문을 사용한 list comprehension \u0026gt; code_list3 = [ord(s) for s in chars if ord(s) \u0026gt; 40] [43, 95, 41, 40, 42, 38, 94] \u0026gt; vec = [-4, -2, 0, 2, 4] \u0026gt; [x for x in vec if x \u0026gt;= 0] [0, 2, 4] 그러면 위 예시를 통해 list comprehension의 문법에 대해 정리해보자.\n[\u0026lsquo;변수(B)를 사용하여 list의 성분이 될 값(A)\u0026rsquo; for \u0026lsquo;사용할 변수 이름(B)\u0026rsquo; in \u0026lsquo;iterator\u0026rsquo;]\nlist comprehension에서 if 조건문은 for문 표현식 뒤에 설정할 수 있다.\n지난 번에 알아본 namedtuple을 사용해서 예시를 만들어보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # list comprehension을 통해 3개의 반을 만들고, 각 반마다 6명의 학생이 있는 list를 만들자. # 예제 2-1 \u0026gt; numbers = [str(n) for n in range(1,6)] \u0026gt; ranks = \u0026#39;A B C\u0026#39;.split( ) \u0026gt; print(numbers) \u0026gt; print(ranks) [\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;5\u0026#39;] [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;] # namedtuple 만들기 \u0026gt; Classes = namedtuple(\u0026#39;Classes\u0026#39;, [\u0026#39;rank\u0026#39;, \u0026#39;number\u0026#39;]) # 2개의 for 반복문을 사용하여 list의 성분값으로 만들어질 인수들에 각각 mapping 했다. \u0026gt; students = [Classes(rank, number) for rank in ranks for number in numbers] \u0026gt; print(students) [Classes(rank=\u0026#39;A\u0026#39;, number=\u0026#39;1\u0026#39;), Classes(rank=\u0026#39;A\u0026#39;, number=\u0026#39;2\u0026#39;), Classes(rank=\u0026#39;A\u0026#39;, number=\u0026#39;3\u0026#39;), Classes(rank=\u0026#39;A\u0026#39;, number=\u0026#39;4\u0026#39;), Classes(rank=\u0026#39;A\u0026#39;, number=\u0026#39;5\u0026#39;), Classes(rank=\u0026#39;B\u0026#39;, number=\u0026#39;1\u0026#39;), Classes(rank=\u0026#39;B\u0026#39;, number=\u0026#39;2\u0026#39;), Classes(rank=\u0026#39;B\u0026#39;, number=\u0026#39;3\u0026#39;), Classes(rank=\u0026#39;B\u0026#39;, number=\u0026#39;4\u0026#39;), Classes(rank=\u0026#39;B\u0026#39;, number=\u0026#39;5\u0026#39;), Classes(rank=\u0026#39;C\u0026#39;, number=\u0026#39;1\u0026#39;), Classes(rank=\u0026#39;C\u0026#39;, number=\u0026#39;2\u0026#39;), Classes(rank=\u0026#39;C\u0026#39;, number=\u0026#39;3\u0026#39;), Classes(rank=\u0026#39;C\u0026#39;, number=\u0026#39;4\u0026#39;), Classes(rank=\u0026#39;C\u0026#39;, number=\u0026#39;5\u0026#39;), Classes(rank=\u0026#39;D\u0026#39;, number=\u0026#39;1\u0026#39;), Classes(rank=\u0026#39;D\u0026#39;, number=\u0026#39;2\u0026#39;), Classes(rank=\u0026#39;D\u0026#39;, number=\u0026#39;3\u0026#39;), Classes(rank=\u0026#39;D\u0026#39;, number=\u0026#39;4\u0026#39;), Classes(rank=\u0026#39;D\u0026#39;, number=\u0026#39;5\u0026#39;)] # 예제 2-2 \u0026gt; student = [Classes(rank, number) \u0026gt; for rank in \u0026#39;A B C\u0026#39;.split( ) \u0026gt; for number in [str(n) for n in range(1,6)]] 예제 2-2의 경우, 여러 for문을 사용했다. 한 줄로 표현할 수 있지만, 가독성이 떨어진다. 코드 몇 줄을 줄이기 위해서 가독성이 많이 떨어진다면 재고할 방법이다. 3.2 list comprehension의 주의사항 깊은 복사와 얕은 복사를 주의하라. 깊은 복사와 얕은 복사에 대한 자세한 내용은 [TIL] Python basic 41: Shallow copy \u0026amp; Deep copy을 참고한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 반복은 하지만 사용하지 않는 변수라면 \u0026#39;_\u0026#39; 로 표현한다. \u0026gt; marks1 = [[\u0026#39;~\u0026#39;] * 3 for _ in range(4)] # 하나의 값이 4개로 복사된 것 \u0026gt; marks2 = [[\u0026#39;~\u0026#39;] * 3] * 4 # 동일한 출력물을 갖는다. \u0026gt; print(marks1) \u0026gt; print(marks2) [[\u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;], [\u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;], [\u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;], [\u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;]] # 수정하기 \u0026gt; marks1[0][1] = \u0026#39;x\u0026#39; \u0026gt; marks2[0][1] = \u0026#39;x\u0026#39; \u0026gt; print(marks1) [[\u0026#39;~\u0026#39;, \u0026#39;x\u0026#39;, \u0026#39;~\u0026#39;], [\u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;], [\u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;], [\u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;, \u0026#39;~\u0026#39;]] \u0026gt; print(marks2) [[\u0026#39;~\u0026#39;, \u0026#39;x\u0026#39;, \u0026#39;~\u0026#39;], [\u0026#39;~\u0026#39;, \u0026#39;x\u0026#39;, \u0026#39;~\u0026#39;], [\u0026#39;~\u0026#39;, \u0026#39;x\u0026#39;, \u0026#39;~\u0026#39;], [\u0026#39;~\u0026#39;, \u0026#39;x\u0026#39;, \u0026#39;~\u0026#39;]] \u0026lsquo;marks2\u0026rsquo;\n하나의 값이 4개로 복사되었다는 건 하나의 id값이 복사된 걸 의미한다. 한 객체를 참조하는 게 4개다. 그래서 하나의 객체만 수정해도 이 객체를 참조하는 값들까지 다 수정된다. 이를 얕은 복사(copy)라고 한다. \u0026lsquo;marks1\u0026rsquo;\n\u0026lsquo;marks2\u0026rsquo; 와 달리 for문을 통해 다 새로 만들어졌다. 그래서 각각 다른 객체를 참조 한다. 이를 깊은 복사(deepcopy)라 한다. 이를 id값으로 확인해보자.\n1 2 3 4 5 6 7 # marks1은 다 다른 id 값을 가진다. \u0026gt; print([id(i) for i in marks1]) [2922096396544, 2922096396480, 2922096396352, 2922096396288] # marks2는 다 동일한 id 값을 가진다. \u0026gt; print([id(i) for i in marks2]) [2922096395200, 2922096395200, 2922096395200, 2922096395200] 그래서 copy 형식을 사용할 때는 조심히 다뤄야 한다. id값을 확인해보고, 꼼꼼히 개발하자. 4. Advanced tuple with unpacking 1. 인자를 입력할 때 upacking을 사용할 수 있다.\n2. 반환값을 unpacking하여 출력할 수 있다.\n3. unpacking으로 여러 값을 담을 수 있다.\ntuple에 unpacking을 사용하여 더 깊이 들어가자.\ntuple은 immutable이지만, unpacking으로 풀을 수 있다.\n오픈 소스들을 보면 아래 방식으로 코딩한 경우가 많으므로, 아래 3가지 경우를 눈에 익혀두자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # divmod: Return the tuple (x//y, x%y). # divmode: tuple data type으로 (몫, 나머지)를 반환하는 함수 # 정상적인 입력 \u0026gt; print(divmod(100, 9)) (11, 1) # divmod는 인자를 2개 받아야하는데, 다음과 같이 입력하면 1개만 받은 걸로 인식한다. \u0026gt; print(divmod((100, 9))) TypeError: divmod expected 2 arguments, got 1 ## 1. 인자를 입력할 때, unpacking을 사용할 수 있다. # 인자를 1개만 입력하고 싶다면 unpacking을 사용하자. \u0026gt; print(divmond(*(100, 9))) (11, 1) ## 2. 반환값을 unpacking하여 출력할 수 있다. # divmond가 반환하는 걸 unpacking할 수도 있다. \u0026gt; print(*(divmond(100, 9))) 11 1 range: Return an object that produces a sequence of integers from start (inclusive) to stop (exclusive) by step 1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; x, y, rest = range(10) ValueError: too many values to unpack (expected 3) ## 3. unpacking하여 여러 값을 담을 수 있다. # 그러면 unpacking을 이용해보자. \u0026gt; x, y, *rest = range(10) \u0026gt; print(x, y, rest) 0 1 [2, 3, 4, 5, 6, 7, 8, 9] \u0026gt; x, y, *rest = range(2) \u0026gt; print(x, y, rest) 0 1 [] 5. Advanced dictionary 5.1 hash table이란?? key를 사용하여 적은 리소스로 많은 데이터를 효율적으로 관리하는 데이터 구조 타입으로 그 예가 dictionary다. key : value 로 된 자료형을 의미한다. from reference\ndictionary에 대해 간단히 정리하면\nkey : value로 구성된 data type을 말한다.\ndictionary의 key는 중복을 허용하지 않는다.\nex) 각 사람이 가지고 있는 주민등록번호 python의 dictionary는 key 를 hash 함수를 통해서 hash 주소로 변환하는 원리이기 때문에, key 를 통해서 value 에 접근할 수 있다.\n참고: 파이썬 언어 자체가 강력한 hash table 엔진으로 만들어졌기 때문에, 파이썬에서는 hash table을 별도로 구현할 필요가 없다.\n그러면 직접 이에 대해서 알아보자. 1 2 3 4 5 6 7 8 9 10 \u0026gt; t1 = (10, 20, (30, 40, 50)) \u0026gt; t2 = (10, 20, [30, 40, 50]) # hash: Return the hash value for the given object. # 출력되는 hash index \u0026gt; print(hash(t1)) 465510690262297113 \u0026gt; print(hash(t2)) TypeError: unhashable type: \u0026#39;list\u0026#39; hash 값을 확인할 수 있다는 건 고유하다는 의미로, 수정 불가능하다는 걸 말한다. 그래서 list type의 hash number를 확인할려고 했으나, TypeError가 뜬 것이다. list는 mutable이기 때문이다. 5.2 key가 중복되는 dictionary 만들기 \u0026rsquo; setdefault \u0026lsquo;를 사용하여 만든다. 이 방법은 tuple로 dictionary를 만들 때, 권고되는 방법이다.\n이런 방식으로 자주 구현하므로 눈에 익혀두자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 # 이중 tuple \u0026gt; source = ((\u0026#39;k1\u0026#39;, \u0026#39;val1\u0026#39;), \u0026gt; (\u0026#39;k1\u0026#39;, \u0026#39;val2\u0026#39;), \u0026gt; (\u0026#39;k2\u0026#39;, \u0026#39;val3\u0026#39;), \u0026gt; (\u0026#39;k2\u0026#39;, \u0026#39;val4\u0026#39;), \u0026gt; (\u0026#39;k2\u0026#39;, \u0026#39;val5\u0026#39;)) \u0026gt; new_dict1 = {} \u0026gt; new_dict2 = {} ## No use setdefault # k에는 k1, k2가, v에는 val가 할당된다. \u0026gt; for k, v in source: # new_dict1 에 k1 이나 k2가 있다면, 이에 대한 value 값으로 v를 끝에 추가한다. \u0026gt; if k in new_dict1: \u0026gt; print(k, v) \u0026gt; new_dict1[k] = [] \u0026gt; new_dict1[k].append(v) # new_dict1 에 k1 이나 k2가 없다면 k를 추가하고, 이 k에 대한 value로 v를 추가한다. \u0026gt; else: \u0026gt; new_dict1[k] = [v] \u0026gt; print(new_dict1) k1 val1 {\u0026#39;k1\u0026#39;: [\u0026#39;val1\u0026#39;]} k1 val2 {\u0026#39;k1\u0026#39;: [\u0026#39;val1\u0026#39;, \u0026#39;val2\u0026#39;]} k2 val3 {\u0026#39;k1\u0026#39;: [\u0026#39;val1\u0026#39;, \u0026#39;val2\u0026#39;], \u0026#39;k2\u0026#39;: [\u0026#39;val3\u0026#39;]} k2 val4 {\u0026#39;k1\u0026#39;: [\u0026#39;val1\u0026#39;, \u0026#39;val2\u0026#39;], \u0026#39;k2\u0026#39;: [\u0026#39;val3\u0026#39;, \u0026#39;val4\u0026#39;]} k2 val5 {\u0026#39;k1\u0026#39;: [\u0026#39;val1\u0026#39;, \u0026#39;val2\u0026#39;], \u0026#39;k2\u0026#39;: [\u0026#39;val3\u0026#39;, \u0026#39;val4\u0026#39;, \u0026#39;val5\u0026#39;]} \u0026gt; print(new_dict1) {\u0026#39;k1\u0026#39;: [\u0026#39;val1\u0026#39;, \u0026#39;val2\u0026#39;], \u0026#39;k2\u0026#39;: [\u0026#39;val3\u0026#39;, \u0026#39;val4\u0026#39;, \u0026#39;val5\u0026#39;]} ## use setdefault \u0026gt; for k, v in source: # k는 default로 들어가고, 나머지는 list type에 담는다는 의미다. \u0026gt; new_dict2.setdefault(k, []).append(v) \u0026gt; print(new_dict2) {\u0026#39;k1\u0026#39;: [\u0026#39;val1\u0026#39;, \u0026#39;val2\u0026#39;], \u0026#39;k2\u0026#39;: [\u0026#39;val3\u0026#39;, \u0026#39;val4\u0026#39;, \u0026#39;val5\u0026#39;]} setdefault를 사용하여 훨씬 짧은 코드로 key가 중복된 tuple을 dictionary로 구현했다. setdefault를 사용하여 [] 가 아닌 ()로 했다면 tuple이므로 만들 수 없다. 만약, dictionary를 만들 때 키가 중복되면 나중 값으로 overwritten된다. 1 2 3 \u0026gt; new_dict3 = {k : v for k , v in source} \u0026gt; print(new_dict3) {\u0026#39;k1\u0026#39;: \u0026#39;val2\u0026#39;, \u0026#39;k2\u0026#39;: \u0026#39;val5\u0026#39;} 5.3 Immutable Dictionary 생성하기 immutable dictionary 즉, \u0026lsquo;읽기 전용\u0026rsquo; dictionary를 만들어보자.\n왜 읽기 전용을 만들까???\n\u0026lsquo;읽기 전용\u0026rsquo;을 만들지 않고, 파일을 그냥 두어도 된다. 하지만, communication의 문제로 팀원이 이 데이터를 수정할수도 있다. 그래서 수정하면 안되는 file은 \u0026lsquo;읽기 전용\u0026rsquo;으로 만든다. \u0026lsquo;읽기 전용\u0026rsquo;으로 만들기 위해서\nMappingProxyType 를 사용할 것이다. data 이름에는 _frozen을 작성한다. (외국에서는 이렇게 한다.) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026gt; from types import MappingProxyType \u0026gt; d = {\u0026#39;key1\u0026#39;: \u0026#39;value1\u0026#39;} \u0026gt; d_frozen = MappingProxyType(d) \u0026gt; print(d, id(d)) {\u0026#39;key1\u0026#39;: \u0026#39;value1\u0026#39;} 2586113038272 \u0026gt; print(d_frozen, id(d_frozen)) {\u0026#39;key1\u0026#39;: \u0026#39;value1\u0026#39;} 2586113478608 \u0026gt; print(type(d), type(d_frozen)) \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; \u0026lt;class \u0026#39;mappingproxy\u0026#39;\u0026gt; \u0026gt; print(d is d_frozen, d == d_frozen) False True d와 d_frozen이 ==을 통해서 value가 같다는 건 확인했다. 하지만, 서로 다른 객체라는 걸 id를 통해 확인했다. 다른 객체를 참조했기 때문에 is로 확인했을 때, false가 뜬 것이다. 6. Advanced set 6.1 Immutable set \u0026rsquo; frozenset \u0026lsquo;을 사용하여 \u0026lsquo;mutable\u0026rsquo; 인 set을 \u0026rsquo; immutable\u0026rsquo; 로 바꾸기\nset data type을 선언하는 방법은 다음과 같다. 1 2 3 4 5 6 7 # {}만 사용 \u0026gt; s1 = {\u0026#39;Apple\u0026#39;, \u0026#39;Orange\u0026#39;, \u0026#39;Apple\u0026#39;, \u0026#39;Orange\u0026#39;, \u0026#39;Kiwi\u0026#39;} \u0026gt; s3 = {3} # set([]) 사용 \u0026gt; s2 = set([\u0026#39;Apple\u0026#39;, \u0026#39;Orange\u0026#39;, \u0026#39;Apple\u0026#39;, \u0026#39;Orange\u0026#39;, \u0026#39;Kiwi\u0026#39;]) \u0026gt; s4 = set() # Not {} 그러면 frozenset 을 사용하여 선언해보자. 1 \u0026gt; s5 = frozenset({\u0026#39;Apple\u0026#39;, \u0026#39;Orange\u0026#39;, \u0026#39;Apple\u0026#39;, \u0026#39;Orange\u0026#39;, \u0026#39;Kiwi\u0026#39;}) 그러면 s1과 s5에 각각 원소를 추가한 후, 출력한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026gt; s1.add(\u0026#39;Melon\u0026#39;) # s5인 경우, immutable로 바꼈기 때문에, 수정할 수 없다는 걸 확인했다. \u0026gt; s5.add(\u0026#39;Melon\u0026#39;) AttributeError: \u0026#39;frozenset\u0026#39; object has no attribute \u0026#39;add\u0026#39; ## s1 ~ s5까지 출력해보자. \u0026gt; print(s1, type(s1)) {\u0026#39;Kiwi\u0026#39;, \u0026#39;Orange\u0026#39;, \u0026#39;Melon\u0026#39;, \u0026#39;Apple\u0026#39;} \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; \u0026gt; print(s2, type(s2)) {\u0026#39;Kiwi\u0026#39;, \u0026#39;Apple\u0026#39;, \u0026#39;Orange\u0026#39;} \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; \u0026gt; print(s3, type(s3)) {3} \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; \u0026gt; print(s4, type(s4)) set() \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; \u0026gt; print(s5, type(s5)) frozenset({\u0026#39;Kiwi\u0026#39;, \u0026#39;Orange\u0026#39;, \u0026#39;Apple\u0026#39;}) \u0026lt;class \u0026#39;frozenset\u0026#39;\u0026gt; frozenset을 통해서 immutable set인 frozenset으로 type이 바뀐 걸 알 수 있다. 6.2 선언 최적화 from dis import dis 사용하여, 더 빠른 선언법을 확인하기\n요즘은 하드웨어의 성능이 매우 좋기 때문에, 소량의 데이터에서는 큰 영향이 없다.\n하지만, 데이터량이 늘어남에 따라 작은 최적화가 쌓여 큰 성능 개선을 이룰 수 있으므로, 확인해보자.\n위의 여러 set 선언 방법들 중 어느 것이 제일 빠를까???\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026gt; from dis import dis \u0026gt; print(dis(\u0026#39;{10}\u0026#39;)) 1 0 LOAD_CONST 0 (10) 2 BUILD_SET 1 4 RETURN_VALUE None \u0026gt; print(dis(\u0026#39;set([10])\u0026#39;)) 1 0 LOAD_NAME 0 (set) 2 LOAD_CONST 0 (10) 4 BUILD_LIST 1 6 CALL_FUNCTION 1 8 RETURN_VALUE None set([10]) 은 5단계, {10}은 3단계로 s1처럼 선언하는 방식이 더 빠르다는 걸 알 수 있다. 6.3 Set comprehension list comprehension에서 알아봤기 때문에, comprehension의 의미는 생략한다.\n바로 실습해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ## 예제 1 \u0026gt; l = {(m, n) for n in range(2) for m in range(3, 5)} \u0026gt; l = set([(3, 0), (3, 1), (4, 0), (4, 1)]) \u0026gt; print(l) {(3, 1), (4, 0), (4, 1), (3, 0)} ## 예제 2 \u0026gt; sentence = \u0026#34;The cat in the hat had two sidekicks, thing one and thing two.\u0026#34; \u0026gt; words = sentence.lower().replace(\u0026#39;.\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;,\u0026#39;, \u0026#39;\u0026#39;).split() \u0026gt; unique_word = {word for word in words} \u0026gt; print(unique_word) {\u0026#39;in\u0026#39;, \u0026#39;and\u0026#39;, \u0026#39;the\u0026#39;, \u0026#39;had\u0026#39;, \u0026#39;cat\u0026#39;, \u0026#39;two\u0026#39;, \u0026#39;thing\u0026#39;, \u0026#39;one\u0026#39;, \u0026#39;sidekicks\u0026#39;, \u0026#39;hat\u0026#39;} ## 예제 3 # if 조건문을 함께 사용해보자. \u0026gt; unique_words = {word for word in words if len(word) \u0026lt;= 3} \u0026gt; print(unique_word) {\u0026#39;and\u0026#39;, \u0026#39;cat\u0026#39;, \u0026#39;had\u0026#39;, \u0026#39;hat\u0026#39;, \u0026#39;in\u0026#39;, \u0026#39;one\u0026#39;, \u0026#39;the\u0026#39;, \u0026#39;two\u0026#39;} set 또한 list처럼 comprehension의 방법으로 선언할 수 있다는 걸 확인했다. 간결한 선언법이 장점이지만, 과하면 가독성이 좋지 않다는 걸 기억하자. Reference Data Model 인프런 파이썬 중급 python 공식문서: list comprehension [Python] list comprehension에 대한 즐거운 이해 자료구조와 함께 배우는 알고리즘 입문 - 파이썬편 ","permalink":"http://jeha00.github.io/post/python/python_basic_29_datamodel/","summary":"Python data model을 상세히 분류하여 mutable과 immutable의 차이가 무엇인지,  list comprehension이 무엇인지, unpacking을 tuple에 어떻게 구현하는지, immutable dictionary와 set에 대해 조금 더 깊이 알아보자.","title":"[TIL] Python basic 29: Data Model"},{"categories":["Python"],"content":"0. Introduction 파이썬에서 모든 객체는 데이터에 대한 추상화로 표현될 수 있다. 파이썬에서는 namedtuple외에도 많은 Container datatypes가 있다. 이 종류들은 Collections library에서 찾을 수 있다. 클래스를 사용하기보다 튜플 활용을 공식 레퍼런스에서 추천하고 있다. 1. Namedtuple이란?? namedtuple(typename: str, field_names: str)\ntuple의 기본 성질인 immutable을 가지고 있으며, 다양한 선언법을 지원한다. Dictionary Key와 같이 사용되기 때문에, key 값을 통해서 access할 수 있다. 일반 class 형태보다 적은 메모리를 사용한다. 2. 실습 예제 3차원 좌표 사이의 거리를 구하는 예제를 통해서 namedtuple에 대해 알아보자. 2.1 namedtuple 없이 구하기 namedtuple 없이 거리 구하기 1 2 3 4 5 6 7 8 9 # 두 점을 정의한다. \u0026gt; pt1 = (2.0, 4.0, 5,0) \u0026gt; pt2 = (4.0, 10.0, 25.0) # sqrt를 import 한다. root를 의미한다. \u0026gt; from math import sqrt # index를 통해서 직접 value에 접근해야 한다. \u0026gt; leng1 = sqrt((pt2[0] - pt1[0]) ** 2 + (pt2[1] - pt1[1]) ** 2 + (pt2[2] - pt1[2]) ** 2 ) 2.2 namedtuple로 구해보기 namedtuple을 사용하여 거리를 구해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; from collections import namedtuple # namedtuple 선언 \u0026gt; Point = namedtuple(\u0026#39;Point\u0026#39;, \u0026#39;x y z\u0026#39;) # 두 점을 정의한다. \u0026gt; pt3 = Point(2.0, 4.0, 5.0) \u0026gt; pt4 = Point(4.0, 10.0, 25.0) # index로도 접근이 가능하지만 # value에 직접 접근하지 않고, key 값을 통해서 접근한다. \u0026gt; leng2 = sqrt((pt4.x - pt3.x) ** 2 + (pt4.y - pt3.y) ** 2 + (pt4.z - pt3.z) ** 2) \u0026gt; print(leng1 == leng2) True 이처럼 namedtuple을 사용하면 dictionary처럼 key 값이 생기기 때문에, index로 직접 접근하지 않아 오류를 낼 가능성이 낮다. 2.3 namedtuple의 다양한 선언법 namedtuple은 2개의 위치인자를 취한다.\n다음으로 namedtuple의 다양한 선언법에 대해 알아보자. 1 2 3 4 5 6 7 8 9 10 # list 안에 string 성분으로 입력하는 방법 \u0026gt; Point = namedtuple(\u0026#39;Point\u0026#39;, [\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;z\u0026#39;]) # string 묶음으로 입력하는 방법 \u0026gt; Point = namedtuple(\u0026#39;Point\u0026#39;, \u0026#39;x y z\u0026#39;) \u0026gt; Point = namedtuple(\u0026#39;Point\u0026#39;, \u0026#39;x, y, z\u0026#39;) ## field_name으로 예약어를 사용하고 싶을 때 # 일반적으로 예약어를 name에 사용하면 안된다. 하지만, 사용하고 싶다면?? \u0026gt; Point = namedtuple(\u0026#39;Point\u0026#39;, \u0026#39;x y z class\u0026#39;, rename = True) rename을 입력하지 않으면 rename = False 가 default다. 2.4 namedtuple의 다양한 객체 생성법 객체 생성 방법도 다양하다. 이에 대해서도 알아보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # field name을 직접 입력하여 할당하기 \u0026gt; p1 = Point(x=10, y=35) # 값만 입력 \u0026gt; p2 = Point(20, 40) # field name 부분 입력 \u0026gt; p3 = Point(45, y=20) # 여러 개로도 가능하다. \u0026gt; p4 = Point(10, 20) ## unpacking을 통해 만들기 \u0026gt; temp_dict = {\u0026#39;x\u0026#39;:75, \u0026#39;y\u0026#39;:55} \u0026gt; p5 = Point(**temp_dict) \u0026gt; temp_dict = (2.0, 4.0) \u0026gt; p5 = Point(*temp_dict) ## 출력해보기 \u0026gt; print(p1, p2, p3, p4, p5) Point(x=10, y=35) Point(x=20, y=40) Point(x=45, y=20) Point(x=10, y=20) Point(x=75, y=55) 2.5 namedtuple 메소드 namedtuple에 사용되는 메소드를 몇 가지 알아보자.\n_make(): list를 namedtuple로 만드는 함수 _fields(): field_name 조회 함수 _asdict(): namedtuple을 dictionary로 전환하는 함수 1 2 3 4 5 6 7 8 9 \u0026gt; temp = [52, 38] \u0026gt; p4 = Point._make(temp) Point(x=52, y=38) \u0026gt; print(p1._fields, p2._fields, p3._fields) (\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;) (\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;) (\u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;) \u0026gt; print(p1._asdict(), p4._asdict()) {\u0026#39;x\u0026#39;: 10, \u0026#39;y\u0026#39;: 35} {\u0026#39;x\u0026#39;: 52, \u0026#39;y\u0026#39;: 38} Reference Data Model 인프런 파이썬 중급 Python- namedtuple 사용 예제 및 소스 코드 ","permalink":"http://jeha00.github.io/post/python/python_basic_28_namedtuple/","summary":"Data Model의 한 종류인 namedtuple에 대해 알아보자. namedtuple을 사용하면 key 값이 생기면서 tuple의 특징이 유지되기 때문에 클래스보다도, 딕셔너리보다도 권장되는 데이터 타입이다.","title":"[TIL] Python basic 28: Namedtuple"},{"categories":["Python"],"content":"0. Introduction 예시코드는 Python basic 24에서 작성한 코드를 이어서 사용한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 \u0026gt; class Airline(): \u0026gt; \u0026#34;\u0026#34;\u0026#34; \u0026gt; Airline class \u0026gt; Author: Kim \u0026gt; Data: 2022.03.16 \u0026gt; Description: Class, Static, Instance Method \u0026gt; \u0026#34;\u0026#34;\u0026#34; \u0026gt; price_per_raise = 1.0 \u0026gt; def __init__(self, company, details): \u0026gt; self._company = company \u0026gt; self._details = details \u0026gt; def __str__(self): \u0026gt; return \u0026#39;str : {} - {}\u0026#39;.format(self._company, self._details) \u0026gt; def __repr__(self): \u0026gt; return \u0026#39;repr : {} - {}\u0026#39;.format(self._company, self._details) ### 코드 추가 \u0026gt; def __add__(self, x): \u0026gt; print(\u0026#39;Called \u0026gt;\u0026gt; __add__\u0026#39;) \u0026gt; return (self._details.get(\u0026#39;price\u0026#39;) + x._details.get(\u0026#39;price\u0026#39;)) \u0026gt; def __sub__(self, x): \u0026gt; print(\u0026#39;Called \u0026gt;\u0026gt; __sub__\u0026#39;) \u0026gt; return (self._details.get(\u0026#39;price\u0026#39;) - x._details.get(\u0026#39;price\u0026#39;)) \u0026gt; def __le__(self, x): \u0026gt; print(\u0026#39;Called \u0026gt;\u0026gt; __le__\u0026#39;) \u0026gt; if self._details.get(\u0026#39;price\u0026#39;) \u0026lt;= x._details.get(\u0026#39;price\u0026#39;): \u0026gt; return True \u0026gt; else: \u0026gt; return False \u0026gt; def __ge__(self, x): \u0026gt; print(\u0026#39;Called \u0026gt;\u0026gt; __ge__\u0026#39;) \u0026gt; if self._details.get(\u0026#39;price\u0026#39;) \u0026gt;= x._details.get(\u0026#39;price\u0026#39;): \u0026gt; return True \u0026gt; else: \u0026gt; return False ### 코드 추가 끝 ## Instance \u0026gt; Airline1 = Airline(\u0026#39;Koreanair\u0026#39;, {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000}) \u0026gt; Airline2 = Airline(\u0026#39;Asiana\u0026#39;, {\u0026#39;uniform_color\u0026#39;: \u0026#39;gray\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 6000}) \u0026gt; Airline3 = Airline(\u0026#39;t-way\u0026#39;, {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000}) 1. Python의 핵심: 4가지 파이썬의 핵심은 4 가지다.\n시퀀스(Sequence), 반복(Iterator), 함수(Functions), 클래스(Class)\nSequence를 알아야 Iterator를 할 수 있다. 일급함수 개념을 알아야 Iterator와 함께 Closure와 coroutine을 할 수 있다. special method를 알아야 클래스를 풍부하게 사용할 수 있다. 이 4가지는 서로 유기적으로 연결되어 있다.\n이번 시간에는 이 4가지 중 클래스 안에 정의되는 special method에 대해 알아보자.\n파이썬 공식문서 Data Model 을 꼭 참고하자.\n2. Special method란 ?? double under-bar로 시작하는 이 method는 class 안에서 정의할 수 있는 특별한 method로, 많은 fuction들이 내부적으로 이 special method에 의해 동작된다.\n그렇다면 왜 특별하여, Magic method라 불릴까?\n내장(Built-in)되어 있는 method를 사용자가 오버라이딩하여 사용할 수 있다. Special method를 통해서 클래스끼리의 연산도 가능해진다. low level에서 효율적인 코딩을 작성할 수 있다. low level에서 효율적인 코딩이 가능한 이유는 function의 내부를 보면 이 special method에 의해서 구동되기 때문이다. 왜냐하면 우리가 사용한 모든 데이터 타입을 넘어서 객체는 다 클래스 라서, 많은 연산의 백그라운드에는 special method가 사용되고 있다.\ndir()은 인자로 들어간 클래스 객체에서 사용할 수 있는 Special method 속성을 보여주는데, 이를 통해서 많은 magic method가 class 하에 존재한다는 걸 알 수 있다.\n[TIL] Python basic 46: Metaclass를 참고하여 모든 객체가 클래스임을 확인하자.\n2.1 Special method 예시 1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; n = 10 \u0026gt; print(type(n)) \u0026lt;class \u0026#39;int\u0026gt; # `__add__` 는 `dir()`로 확인할 수 있듯이 \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; 안에 정의된 method다. \u0026gt; print(dir(n)) [\u0026#39;__abs__\u0026#39;, \u0026#39;__add__\u0026#39;, \u0026#39;__and__\u0026#39;, \u0026#39;__bool__\u0026#39;, \u0026#39;__ceil__\u0026#39;, \u0026#39;__class__\u0026#39;, ...] \u0026gt; print(n + 100) 110 # 이는 `__add__` magic method를 사용하는 결과와 동일하다. \u0026gt; print(n.__add__(100)) 110 \u0026lsquo;+\u0026rsquo; 연산자도 __add__ magic method를 호출하기 때문에, 위와 같이 결과가 동일하다.\n2.2 Special method 예시 2 지난 번에 알아봤던 것처럼 repr() 를 사용하는 건 __repr__를 호출하여 이 method에 의한 결과값을 반환하는 것이라 했다.\n2.3 Special method 예시 3 boolean 함수도 그렇다.\n1 2 \u0026gt; print(n.__bool__(), bool(n)) True True 파이썬에서는 많은 함수가 magic method를 호출하여 사용된다.\n3. Special method 연산 예제 1 magic method를 재정의하지 않고, 클래스끼리 덧셈을 해보자. 1 2 3 \u0026gt; print( Airline1 + Airline2 ) \u0026gt; print(Airline1.__add__(Airline2)) TypeError: unsupported operand type(s) for +: \u0026#39;Airline\u0026#39; and \u0026#39;Airline\u0026#39; 피연산자의 type이 지원되지 않는 type이라는 의미다. 이처럼 클래스끼리의 연산은 가능하지 않다. 그러면 이를 magic method를 customizing하여 사용해보자. 1 2 3 4 5 # 각 Airline의 `price` key에 대한 value끼리 덧셈 연산하기 \u0026gt; def __add__(self, x): # 호출되었는지 확인하기 \u0026gt; print(\u0026#39;Called \u0026gt;\u0026gt; __add__\u0026#39;) \u0026gt; return (self._details.get(\u0026#39;price\u0026#39;) + x._details.get(\u0026#39;price\u0026#39;)) instance 끼리 연산을 한다면 instance의 어느 부분들이 더하는 건지 재정의 한다. 그러면 다시 덧셈을 해보자. 1 2 3 4 \u0026gt; print( Airline1 + Airline2 ) \u0026gt; print(Airline1.__add__(Airline2)) Called \u0026gt;\u0026gt; __add__ 14000 위 코드를 보고 이런 생각이 들 수도 있다. 아래와 같이 코드를 짤 수도 있지 않은가?? 1 2 \u0026gt; print(Airline1._details.get(\u0026#39;price\u0026#39;) + Airline2._details.get(\u0026#39;price\u0026#39;)) 14000 동일한 결과를 내지만, 이렇게 직접 값에 접근하는 건 다음 2가지 이유로 좋지 않다.\n코드 양이 많아지고, 가독성이 좋지않다. 위험하다. 그래서 magic method를 잘 활용해야 한다.\n다른 magic method도 만들어보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # 각 Airline의 `price` key에 대한 value끼리 뺄셈 연산하기 \u0026gt; def __sub__(self, x): # 호출되었는지 확인하기 \u0026gt; print(\u0026#39;Called \u0026gt;\u0026gt; __sub__\u0026#39;) \u0026gt; return (self._details.get(\u0026#39;price\u0026#39;) - x._details.get(\u0026#39;price\u0026#39;)) # 각 Airline의 `price` key에 대한 value끼리 비교 연산하기 \u0026gt; def __le__(self, x): # 호출되었는지 확인하기 \u0026gt; print(\u0026#39;Called \u0026gt;\u0026gt; __le__\u0026#39;) \u0026gt; if self._details.get(\u0026#39;price\u0026#39;) \u0026lt;= x._details.get(\u0026#39;price\u0026#39;): \u0026gt; return True \u0026gt; else: \u0026gt; return False # 각 Airline의 `price` key에 대한 value끼리 비교 연산하기 \u0026gt; def __ge__(self, x): # 호출되었는지 확인하기 \u0026gt; print(\u0026#39;Called \u0026gt;\u0026gt; __ge__\u0026#39;) \u0026gt; if self._details.get(\u0026#39;price\u0026#39;) \u0026gt;= x._details.get(\u0026#39;price\u0026#39;): \u0026gt; return True \u0026gt; else: \u0026gt; return False \u0026gt; print(Airline1 \u0026gt;= Airline2) Called \u0026gt;\u0026gt; __ge__ True \u0026gt; print(Airline1 \u0026lt;= Airline2) Called \u0026gt;\u0026gt; __le__ False \u0026gt; print(Airline1 - Airline2) Called \u0026gt;\u0026gt; __sub__ 2000 연산자 약어\nge: greater or equal\nle: less or equal\nlt: little\ngt: greater 4. Special method 연산 예제 2 이번 예제에서는 packin 과 unpacking을 사용한다.\npackin 과 unpacking에 대한 기본 내용은 다음을 참고한다.\n[TIL] Python basic 12: Method 일반적인 덧셈 연산으로는 벡터 연산을 하지 못한다.\n그래서 벡터 연산에 맞게 magic method를 구현한다.\nother이란?? 정의한 class로 만든 또 다른 instance를 의미한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026gt; class Vector(Object): # def __init__(self,x,y) 로 써도 되지만, 팩킹을 사용해보자. # 잘 만든 오픈 소스들을 보면 아래처럼 작성된다. \u0026gt; def __init__(self, *args): \u0026gt; \u0026#39;\u0026#39;\u0026#39; Create a vector, example: v = Vector(5, 10) \u0026#39;\u0026#39;\u0026#39; # 실전에서는, 그리고 잘 만든 소스들에는 주석이 잘 달려있다. \u0026gt; if len(args) == 0: \u0026gt; self._x, self._y = 0, 0 \u0026gt; else: # unpacking \u0026gt; self._x, self._y = args \u0026gt; def __repr__(self): \u0026gt; \u0026#39;\u0026#39;\u0026#39;Returns the vector method informations\u0026#39;\u0026#39;\u0026#39; # raw data로 출력하기 \u0026gt; return \u0026#39;Vector(%r, %r)\u0026#39; % (self._x, self._y) \u0026gt; def __add__(self, other): \u0026gt; \u0026#39;\u0026#39;\u0026#39;Returns the vector addtion of self and other\u0026#39;\u0026#39;\u0026#39; \u0026gt; return Vector(self._x+ other._x) \u0026gt; def __mul__(self, y): \u0026gt; ```Returns the vector multiplication of self and other``` \u0026gt; return Vector(self._x * y, self._y * y ) Vector에 대한 comment를 보고 싶다면??\nprint(Vector.__doc__) 를 사용한다. 그러나 위에 코드에는 Vector에 대한 comment는 없다.\nVector에 대한 comment 대신 Vector.__init__에 대한 comment가 있다.\n이런 경우에는 어떻게 볼 수 있을까???\nprint(Vector.__init__.__doc__)를 사용한다. 위 코드들로 실습을 해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026gt; v1 = Vector(20, 45) \u0026gt; v2 = Vector(2.5, 5) \u0026gt; v3 = Vector() \u0026gt; print(Vector.__init__.__doc__) Create a vector, example : v = Vector(5, 10) \u0026gt; print(Vector.__repr__.__doc__) Returns the vector method infomations \u0026gt; print(Vector.__add__.__doc__) Returns the vector addition of self and other \u0026gt; print(v1, v2, v3) Vector(20, 45) Vector(2.5, 5) Vector(0, 0) \u0026gt; print(v1 + v2) Vector(22.5, 50) \u0026gt; print(v1 * 3) Vector(60, 135) \u0026gt; print(v2 * 10) Vector(25.0, 50) 위 magic method 외에도 매우 많이 있다. 이 문서 A Guide to Python\u0026rsquo;s Magic Methods를 참고하자. Reference 인프런 파이썬 중급 Data Model stackoverflow : \u0026lsquo;What does \u0026ldquo;other\u0026rdquo; mean in python?\u0026rsquo; ","permalink":"http://jeha00.github.io/post/python/python_basic_27_specialmethod/","summary":"지난 번 Python basic 26 Class advanced에 이어서 class 안에 정의되는 built-in method인 special method에 대해 알아보자. 또한 파이썬의 핵심 4가지에 대해 알아보자. 마지막으로 오버라이딩을 통해서 클래스끼리 연산해보자.","title":"[TIL] Python basic 27: Special Method"},{"categories":"Network","content":"Intro HTTP 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다. 이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다. 학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고자 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다. 이번 chapter에서는 지난 HTTP header [TIL] Network HTTP Header 1에 이어서 관련 header에 대해 집중적으로 알아본다.\nHTTP header의 용도는 [TIL] Network HTTP basic을 참고한다.\n1. 캐시 기본 동작 1.1 캐시가 없을 때 클라이언트가 GET 메소드를 사용하여 /star.jpg 를 조회요청을 서버에 보낸다. 서버는 이에 응답하여 HTTP 메세지를 생성하고, HTTP body에 data를 담는다. data의 크기는 다음 같이 가정한다. HTTP header의 data 크기: 0.1 Megabye HTTP body의 data 크기: 1.0 Megabyte 서버의 응답에 클라이언트는 star.jpg를 받는다. 그러면 캐시가 없는 상황에서 서버에 동일한 요청을 또 보내면 어떻게 될까?? 처음과 동일하게, 총 1.1M의 크기를 다운받는다. 캐시가 없기 때문에 데이터가 변경되지 않아도, 계속 네트워크를 통해서 데이터를 다운받아야 한다. 인터넷 네트워크는 비싸고 매우 느리다. 브라우저 로딩 속도가 느리다. 결국, 사용자는 느린 사용 경험을 겪는다. 1.2 캐시를 적용할 때 브라우저에 캐시 저장 공간을 사용한다. 클라이언트의 요청에 서버는 응답 메세지를 생성한다. 그리고, 클라이언트에게 응답 메세지를 보내면서 결과를 캐시에 저장한다. 클라이언트의 두 번째 요청 시, 클라이언트는 서버에 요청을 바로 보내지 않는다. 먼저, 브라우저 캐시에서 캐시 유효 시간을 먼저 검증한다. 유효 시간이 일치하면 캐시에서 조회하여 원하는 데이터를 사용한다. 캐시가 존재하기 때문에 캐시 가능 시간 동안 네트워크를 사용하지 않아도 된다. 비싼 네트워크 사용량을 줄일 수 있다. 브라우저 로딩 속도가 매우 빠르다. 사용자는 빠른 네트워크 경험을 할 수 있다. 1.3 캐시 시간 초과했을 때 캐시 유효 시간을 검증 요청한다. 서버에서 다시 전송한다. 응답 결과를 다시 캐시에 저장한다.\n캐시 유효 시간이 초과하면, 서버를 통해 데이터를 다시 조회하고, 캐시를 갱신한다.\n이때 다시 네트워크 다운로드가 발생한다.\n2. 검증 헤더와 조건부 요청 1 검증 헤더: 캐시 데이터와 서버 데이터가 같은지 검증하는 데이터. ex) Last-Modified header\n조건부 요청 헤더: 검증 헤더로 조건에 따른 분기. ex) if-modified-since: header\n캐시 유효 시간이 초과해서 서버에 다시 요청하면 다음 두 가지 상황이 나타난다.\n서버에서 기존 데이터를 변경하거나, 변경하지 않는 상황 캐시 만료 후에도 서버에서 데이터를 변경하지 않은 상황으로 가정하자.\n데이터를 전송하는 대신에 저장해 두었던 캐시를 재사용할 수 있다. 단, 클라이언트와 서버의 각 데이터가 같다는 사실을 확인할 수 있는 방법이 필요하다. 캐시 시간 초과로 서버에 재요청 시, if-modified-since: header를 메세지에 넣어 보낸다. 이 header가 조건부 요청 header다. 이 header는 캐시가 가지고 있는, 데이터 최종 수정일을 말한다. 서버에서 클라이언트가 보낸 요청과 서버의 해당 data의 데이터 최종 수정일을 비교. 동일할 경우, HTTP body를 전송하지 않고 HTTP header만 전송한다. 데이터가 수정되지 않았기 때문에, 304 Not Modified 상태이며, 검증헤더인 Last-Modified header를 추가한다. 그러면 응답 결과를 재사용하여, header data를 갱신한다.\n정리\n캐시 유효 시간이 초과해도, 서버의 데이터가 갱신되지 않으면 304 Not Modified + Header Meta data만 응답하면 된다. 여기서 Header Meta data란 검증헤더를 말한다. 이 때, HTTP Body는 없어도 된다. -\u0026gt; 클라이언트는 서버가 보낸 응답 헤더정보로 캐시의 메타 정보를 갱신한다. -\u0026gt; 클라이언트는 캐시에 저장되어 있는 데이터를 재활용한다. 결과적으로, 네트워크 다운로드가 발생하지만 용량이 적은 헤더 정보만 다운로드. 실제 웹 브라우저에서 다음 경로를 통해서 조건부 요청 헤더를 볼 수 있다.\n검사(F12) -\u0026gt; Network tab 클릭 -\u0026gt; Status 란에 글씨가 연한 게 Cache에서 불러온 것 다시 이미지 더블클릭 -\u0026gt; 검사 -\u0026gt; Network -\u0026gt; 새로고침(F5) -\u0026gt; 이미지 클릭 -\u0026gt; headers tab -\u0026gt; Request header -\u0026gt; if-modified-since 보기 3. 검증 헤더와 조건부 요청 2 검증 헤더: Last-Modified, ETag\n조건부 요청 헤더: If-Modified-Since:, Last-Modified, If-None-Match:ETag\nLast-Modified header 의 단점을 해결하는 header에 대해 알아보자.\n검증 헤더 (Validator)\nLast-Modified, ETag 조건부 요청 헤더\nIf-Match, If-None-Match:ETag 값 사용 If-Modified-Since, If-Unmodified-Since: Last-Modified 값 사용 조건이 만족하면 200 OK 조건이 만족하지 않으면 304 Not Modified 예시\nIf-Modified-Since: 이후에 데이터가 수정되었다면??? 데이터 미변경 예시 캐시: 2020년 11월 10일 10:00:00 vs 서버:2020년 11월 10일 10:00:00 304 Not Modified, 헤더 데이터만 전송(BODY 미포함) 전송 용량 0.1M (헤더 0.1M, 바디 1.0M) 데이터 변경 예시 캐시: 2020년 11월 10일 10:00:00 vs 서버:2020년 11월 10일 11:00:00 200 OK, 모든 데이터 전송(BODY 포함) 전송 용량 1.1M (헤더 0.1M, 바디 1.0M) 3.1 If-Modified-Since:, Last-Modified 단점 1초 미만(0.x초) 단위로 캐시 조정이 불가능하다. 날짜 기반의 로직을 사용한다. 그래서 데이터를 수정해서 날짜가 다르면, 같은 데이터를 수정해서 데이터 결과가 똑같은 경우에도 다시 다운받아야 한다. 위 문제로 서버에서 별도의 캐시 로직을 관리하고 싶은 경우, 다음 Header들을 사용한다. ex) 스페이스나 주석처럼 크게 영향이 없는 변경에서 캐시를 유지하고 싶은 경우 3.2 해결책: ETag, IF-None-Match 날짜 기반의 date가 기준이 아닌 데이터의 버전 이름이 기준\nETag: Entity Tag 캐시용 데이터에 임의의 고유한 버전 이름을 달아둔다. ex) ETag: v1.0, ETag: a2jiodwjekij3 데이터가 변경되면 이 이름을 바꾸어서 변경한다. (Hash를 다시 생성한다.) ex) ETag: \u0026lsquo;aaaaa\u0026rsquo;, -\u0026gt; ETag: \u0026lsquo;bbbbbb\u0026rsquo; 진짜 단순하게 ETag만 보내서 같으면 유지, 다르면 다시 받는다. ETag: aaaaaaaaaa header 로 서버가 응답했다. 그리고 위 Tag 로 응답 결과를 캐시에 저장했다. 두 번째 요청을 했지만, 캐시 시간이 초과된 상황이다. 서버에 재요청을 보낼 때, 캐시가 가지고 있는 ETag의 내용을 If-None-Match: header로, 요청 message의 header에 함께 보낸다. 서버에서 응답하는 ETag의 내용과 If-None-Match:의 내용을 비교한다. 동일하다는 건, 아직 데이터는 수정되지 않았음을 의미한다. 데이터가 수정되지 않았기 때문에, HTTP 헤더만 보낸다. 응답 결과를 재사용하여, 캐쉬 데이터의 헤더 데이터를 갱신한다. 4. 캐시와 조건부 요청 헤더 캐쉬 제어 헤더의 종류에는 3가지가 있다. Cache-Control: 캐시 제어 Pragma: 캐시 제어(하위 호환) Expires: 캐시 유효 기간(하위 호환) 4.1 Cache-Control 캐시 지시어(directives)\nCache-Control: max-age\n초 단위로, 캐시 유효 시간을 알려준다. Cache-Control: no-cache\n데이터는 캐시해도 되지만, 항상 원(origin) 서버에 검증하고 사용해야 한다. Origin 서버라 하는 이유는 중간에 여러 proxy 서버가 있기 때문이다. Cache-Contrl: no-store\n데이터에 민감한 정보가 있으므로 저장하면 안된다. (메모리에서 사용하고 최대한 빨리 삭제) 4.2 Pragma 캐시 제어(하위 호환)\nPragma:no-cache HTTP 1.0 의 하위 호환 하위 호환이라 지금은 대부분 사용하지 않는다. 하지만, 구글에서는 여러 국가를 지원하기 때문에 사용하고 있다. 4.3 Expires 캐시 만료일 지정(하위 호환)\nexpires: Mon, 01 Jan 1990 00:00:00 GMT\n캐시 만료일을 정확한 날짜로 지정한다. HTTP 1.0부터 사용한다. 지금은 더 유연한 방법인 Cache-Control:max-age 를 권장한다. Cache-Control:max-age와 함께 사용하면 Expires는 무시된다. 4.4 검증 헤더와 조건부 요청 헤더 검증 헤더 (Validator)\nETag: \u0026ldquo;v1.0\u0026rdquo;, ETag: \u0026ldquo;asid93jkrh2l\u0026rdquo; Last-Modified: Thu, 04 Jun 2020 07:19:24 GMT 조건부 요청 헤더\nIf-Match, If-None-Match: ETag 값 사용 If-Modified-Since, If-Unmodified-Since: Last-Modified 값 사용 5. 프록시 캐시 Cache-Control\n캐시 지시어(directives) - 기타\nCache-Control: public\n응답이 public 캐시에 저장되어도 된다. Cache-Control: private\n응답이 해당 사용자만을 위한 것이다. private 캐시에 저장해야 한다. (기본값) Cache-Control: s-maxage\n프록시 캐시에만 적용되는 max-age\nAge: 60(HTTP 헤더)\nOrigin 서버에서 응답 후, proxy 캐시 내에 머문 시간(단위:초) 우리가 데이터를 받아야 알 수 있다. 원 서버와 클라이언트 사이에 중간 서버 없이, Origin (원) 서버에 직접 접근하는 경우 데이터를 가져오는데 비교적 긴 시간이 걸린다. 하지만 이렇게 proxy 캐시 서버를 도입하면 한국에서 보다 빨리 데이터를 받을 수 있다. 6. 캐시 무효화 확실한 캐시 무효화 응답\nCache-Control: no-cache, Cache-Control: no-store, Cache-Control: must-revalidate\nPragma: no-cache : HTTP 1.0 하위호환\n캐시 무효화가 필요한 이유:\n캐쉬를 적용하려고 하지 않아도, 웹 브라우저들이 임의로 적용한다. 그래서, 이 페이지는 캐쉬를 넣으면 안된다면, 위 헤더들을 반드시 넣어야 한다. Cache-Control directives(캐시 지시어) - 확실한 캐시 무효화\nCache-Control: no-cache\n데이터는 캐시해도 되지만, 항상 원 서버에 검증하고 사용해야 한다. Header 이름 혼동 주의! Cache-Control: no-store\n데이터에 민감한 정보가 있으므로 저장하면 안된다.\n(메모리에서 사용하고 최대한 빨리 삭제) Cache-Control: must-revalidate\n캐시 만료 후, 최초 조회시 원 서버에 검증해야 한다. 원 서버 접근 실패시 반드시 오류가 발생해야한다. 504(Gateway Timeout) =\u0026gt; no-cache와의 차이점 must-revalidate는 캐시 유효 시간이라면 캐시를 사용함 Pragma: no-cache\nHTTP 1.0 하위 호환 no-cache vs must-revalidate no-cache의 기본 동작 (데이터가 수정되지 않은 상황) no-cache 상황에서, 프록시 캐시와 원 서버 간 네트워크 단절이 순간 발생한 경우 must=revalidate 상황에서, 프록시 캐시와 원 서버 간 네트워크 단절이 순간 발생한 경우 정리\n프록시 캐시와 원 서버 간 네트워크 단절이 순간 발생한 경우\nno-cache\n원 서버에 접근할 수 없는 경우, 서버 설정에 따라서 프록시 서버에서 응답할 수 있다. 응답한 data가 오류보다 오래된 데이터라도 보여준다. 단, 오류인지는 알려주지 않는다. must=revalidate\n원 서버에 접근할 수 없는 경우, 항상 오류가 발생해야 한다. 504 Gateway Timeout 으로 응답한다. 오류인지 알려준다 Reference 모든 개발자를 위한 HTTP 웹 기본지식 ","permalink":"http://jeha00.github.io/post/network/http/http_8/","summary":"검증 헤더와 조건부 요청 헤더의 종류, 그중 캐시 관련 헤더에 대해서 알아본다. 그리고, 프록시 서버와 원(Origin) 서버의 차이와 캐시를 어떻게 무효화하는지 알아본다.","title":"[TIL] HTTP Header 2"},{"categories":"Network","content":"Intro HTTP 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다. 이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다. 학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고자 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다. 이번 chapter에서는 HTTP header 여러 종류에서 주로 사용하는 헤더에 대해 알아보겠다.\nHTTP header의 용도는 [TIL] Network HTTP basic을 참고한다.\nRFC2616(과거) - HTTP Header 분류 HTTP header 종류에 대해 알아보기 전, 과거 \u0026lsquo;RFC2616\u0026rsquo; 일 때 헤더 분류를 살펴보자. General 헤더: 메시지 전체에 적용되는 정보, 예) Connection: close Request 헤더: 요청 정보, 예) User-Agent: Mozilla/5.0 (Macintosh; ..) Response 헤더: 응답 정보, 예) Server: Apache Entity 헤더: 엔티티 바디 정보, 예) Content-Type: text/html, Content-Length: 3423 RFC2616(과거) - HTTP body 메세지 본문(message body)은 엔티티 본문(entity body)을 전달하는데 사용 entity body는 요청이나 응답에서 전달할 실제 데이터 entity header는 entity 본문의 데이터를 해석할 수 있는 정보를 제공한다. 데이터 유형(html, json), 데이터 길이, 압축 정보 등등 RFC2616 폐지 그리고, RFC7230~7235 등장 RFC2616이 폐지되고, RFC7230~7235가 등장하면서 Entity 라는 표현이 Representation 으로 바꼈다. 그리고, Representation 이란 representation Metadata와 Representation Data를 합친 걸 의미한다. 엔티티(Entity) -\u0026gt; Representation Representation = Representation Metadata + Representation Data RFC7230 - HTTP Body 메시지 본문(message body)을 통해 표현 데이터를 전달한다. 메시지 본문을 다른 말로 페이로드(payload)라 한다. representation은 요청이나 응답에서 전달할 실제 데이터 representation header는 Representation Data를 해석할 수 있는 정보를 제공한다. 데이터 유형(html, json), 데이터 길이, 압축 정보 등등 참고: Representation header는 representation metadata 와 payload message를 구분해야 하지만, 여기서는 생략한다. 그러면 이 representation이 뭔지 알아보자. 1. 표현(representation) 1.0 Representation header 란?? client와 server 간에 주고 받는 resource의 data를 어떻게 표현할지 결정하는 header\n예) DB에 있는 binary data를 바로 서버에 전송하는 게 아니라, HTML 또는 XML 또는 JSON 형태로 전달한다.\nRepresentation header는 전송, 응답 둘 다 사용한다.\n그래서 representation header 에는 여러 정보들이 담긴다.\nContent-Type: 표현 데이터의 형식 설명 Content-Encoding: 표현 데이터의 압축 방식 Content-Language: 표현 데이터의 자연 언어 Content-Length: 표현 데이터의 길이 1.1 Content-Type 표현 데이터의 형식 설명\n미디어 타입, 문자 인코딩 예) text/html; charset =utf-8 application/json image/png 1.2 Content-Encoding 표현 데이터의 압축 방식 설명\n표현 데이터를 압축하기 위해 사용 데이터를 전달하는 곳에서 압축 후 인코딩 헤더 추가 데이터를 읽는 쪽에서 인코딩 헤더의 정보로 압축 해제 예) gzip deflate identity 1.3 Content-Language 표현 데이터의 자연어 설명\n표현 데이터의 자연 언어를 표현 예) ko en en-US 1.4 Content-Length 표현 데이터의 길이 설명\n바이트 단위 Transfer-Encoding(전송 코딩)을 사용하면 Content-Length를 사용하면 안된다. 2. 콘텐츠 협상 클라이언트가 선호하는 표현을 서버에게 요청하는 것\n서버에 요청 사항이 다양하다면, 우선 순위에 맞춰 서버에서 만든다.\n클라이언트가 요청할 때 작성하기 때문에, 요청 시에만 사용한다.\n협상 헤더 종류\nAccept: 클라이언트가 선호하는 미디어 타입 전달 Accept-Charset: 클라이언트가 선호하는 문자 인코딩 Accept-Encoding: 클라이언트가 선호하는 압축 인코딩 Accept-Language: 클라이언트가 선호하는 자연 언어 2.1 Accept-Language 적용 전과 후 적용 전 적용 후 복잡한 예시 2.2 협상과 우선순위 (Quality Values(q)) 2.2.1 협상과 우선순위 첫 번째 첫 번째: Quality Values(q)가 높을 수록 우선순위가 높다.\nQuality Values(q) 값 사용\n0~1, 클수록 높은 우선순위 생략하면 1 Accept-Language: ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\nko-KR;q=1 (q생략) ko;q=0.9 en-US;q=0.8 en:q=0.7 인터넷 창 -\u0026gt; 검사 -\u0026gt; Network -\u0026gt; Headers -\u0026gt; Request Headers 창에 들어가면 사용하는 도메인의 우선순위를 볼 수 있다.\n2.2.2 협상과 우선순위 두 번째 두 번째: 구체적인 것이 우선된다. GET /event\nAccept: text/*, text/plain, text/plain;format=ﬂowed, */*\nAccept: text/_, text/plain, text/plain;format=flowed, _/*\ntext/plain;format=flowed text/plain text/* */* 2.2.3 협상과 우선순위 세 번째 세 번째: 구체적인 것을 기준으로 미디어 타입을 맞춘다.\nMedia Type 우선도 Accept: text/*;q=0.3, text/html;q=0.7, text/html;level=1,text/html;level=2;q=0.4, */*;q=0.5 3. 전송 방식 전송 방식에는 4 종류가 있다. 단순 전송(Content-Length) 압축 전송(Content-Encoding) 분할 전송(Transfer-Encoding) 범위 전송(Range, Content-Range) 3.1 단순 전송(Content-Length) content의 길이를 알 수 있을 때 사용한다. 한 번에 요청하고,한 번에 받는다. 3.2 압축 전송(Content-Encoding) 서버에서 메세지 바디를 압축해서 전달하는 방식 Content-Encoding에 어떻게 압축했는지 알려줘야, 웹 브라우저에서 이에 맞게 풀어서 접근할 수 있다. 3.3 분할 전송(Transfer-Encoding) 용량이 커서 한 번에 보내면 받는데 시간이 걸리기 때문에, 분할하여 보내서 오는 대로 바로 구현한다. 이 때는 content-length를 넣으면 안된다. 전체 길이를 알 수 없기 때문이다. 5 byte 씩 나눠서 보내고, 마지막에는 보낼 게 없어서 0이다. 3.4 범위 전송(Range, Content-Range) 4. 일반 정보 4.1 From 유저 에이전트의 이메일 정보\n일반적으로 잘 사용되지 않는다. 검색 엔진 같은 곳에서, 주로 사용한다. 요청에서 사용한다. 4.2 Referer 이전 웹 페이지 주소\n유입 경로 분석을 위해 많이 사용한다. 현재 요청된 페이지의 이전 웹 페이지 주소 A -\u0026gt; B로 이동하는 경우 B를 요청할 때 Referer: A 를 포함해서 요청한다. Referer를 사용해서 유입 경로 분석이 가능하다. 요청에서 사용한다. 참고: referer는 단어 referrer의 오타다. 이미 너무 많은 곳에서 사용해서 그냥 사용한다. 4.3 User-Agent 유저 에이전트 애플리케이션 정보\nuser-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.183 Safari/537.36\n검사(F12) -\u0026gt; Network -\u0026gt; Headers -\u0026gt; User-Agent 확인 클리이언트의 애플리케이션 정보(웹 브라우저 정보, 등등) 통계 정보 어떤 종류의 브라우저에서 장애가 발생하는지 파악 가능 요청에서 사용 4.4 Server 요청을 처리하는 ORIGIN 서버의 소프트웨어 정보\n여러 proxy server를 거치고, 최종적으로 나의 요청을 처리하는 서버를 ORIGIN 서버라 한다.\nServer: Apache/2.2.22 (Debian) server: nginx 응답에서 사용한다. 4.5 Data 메시지가 생성된 날짜\nDate: Tue, 15 Nov 1994 08:12:31 GMT 응답에서 사용한다. 5. 특별 정보 Host: 요청한 호스트 정보(도메인) Location: 페이지 리다이렉션 Allow: 허용 가능한 HTTP 메서드 Retry-After: 유저 에이전트가 다음 요청을 하기까지 기다려야 하는 시간 5.1 Host GET /search?q=hello\u0026amp;hl=ko HTTP/1.1\nHost: www.google.com\n요청에서 사용 필수 하나의 서버가 여러 도메인을 처리할 때 하나의 IP 주소에 여러 도메인이 적용되어 있을 때 가상 호스트를 통해 여러 도메인을 한 번에 처리할 수 있는 서버에서는 실제 애플리케이션이 여러 개 구동될 수 있다. 이럴 때 HOST가 없이 요청을 하면 어느 도메인으로 들어가야하는지 알 수 없다. 이럴 때, 헤더 정보에 host를 추가하여 어느 도메인으로 들어가야 할지 알 수 있다. 5.2 Location 페이지 리다이렉션\n웹 브라우저는 3xx 응답의 결과에 Location 헤더가 있으면, Location 위치로 자동 이동 (리다이렉트) 응답코드 3xx에서 설명 201 (Created): Location 값은 요청에 의해 생성된 리소스 URI 3xx (Redirection): Location 값은 요청에 의해 생성된 리소스 URI 5.3 Allow 허용 가능한 HTTP 메서드를 명시한다.\n하지만, 실제로 많이 구현되어 있지 않으므로 이런 게 있다 정도만 알자.\n405 (Method Not Allowed) 에서 응답에 포함해야 한다. Allow: GET, HEAD, PUT 5.4 Retry-After 유저 에이전트가 다음 요청을 하기까지 기다려야 하는 시간\n하지만, 실제로는 사용하기 어렵다.\n503 (Service Unavailable): 서비스가 언제까지 불능인지 알려줄 수 있음 Retry-After: Fri, 31 Dec 1999 23:59:59 GMT (날짜 표기) Retry-After: 120 (초단위 표기) 6. 인증 6.1 Authorization 클라이언트 인증 정보를 서버에 전달한다.\nAuthorization: Basic xxxxxxxxxxxxxxxx 인증 관련해서 여러 매커니즘이 있다. 각 매커니즘마다 넣는 헤더가 다르다. 추가적으로 알아보자. 6.2 WWW-Authenticate 리소스 접근시 필요한 인증 방법 정의한다.\n401 Unauthorized 응답과 함께 사용한다. WWW-Authenticate: Newauth realm=\u0026ldquo;apps\u0026rdquo;, type=1, title=\u0026ldquo;Login to \u0026quot;apps\u0026quot;\u0026rdquo;, Basic realm=\u0026ldquo;simple\u0026rdquo; 인증할려면 : 이후의 내용들을 참고해서 인증 방법을 만들라는 의미다. 7. 쿠키(중요) 7.1 쿠키란?? 쿠키: HTTP의 stateless 성질 때문에 필요 하에, 서버가 자동 생성하여 클라이언트에 저장하는 데이터\n캐시: 클라이언트 자체에서 페이지 로드를 효율적으로 하려고 저장하는 데이터\n매우 많이 사용하고, 많이 중요하다.\n웹 브라우저는 서버에서 보낸 이 쿠키를 웹 브라우저 내부에 쿠키 저장소에 저장해 놓았다가, 서버의 응답에 클라이언트가 HTTP 메세지를 보낼 때, 이 쿠키 정보를 포함하여 보내는 용도\nCookie 를 사용할 때는 2가지 header를 사용한다.\nSet-Cookie: server에서 client로 쿠키를 전달할 때(응답) Cookie: client가 server에서 받은 쿠키를 저장하고, HTTP 요청 시 서버로 전달할 때 그러면 먼저 쿠키를 사용하지 않으면 어떻게 되는지 알아보자.\nGET으로 /welcome resource를 조회한다. 서버에서는 손님으로 인식한다. 로그인을 해야 서버에서 가입된 유저로 인식한다. 하지만, 로그인후 다시 welcome page에 접근하면 다시 손님으로 인식한다. HTTP는 stateless 프로토콜이기 때문에, 클라이언트와 서버가 요청과 응답을 주고 받으면 연결이 끊어진다. 그래서 클라이언트가 다시 요청하면 서버는 이전 요청을 기억하지 못하기 때문에, 클라이언트와 서버는 서로 상태를 유지하지 않는다. 이에 대한 대안으로 모든 요청에 사용자 정보가 포함되도록 개발한다면?? 현실적으로 매우 힘들다. 그래서 이에 대한 대책으로 만든게 쿠키(cookie)다. 쿠키를 사용하면 어떻게 되는지 알아보자. 웹 브라우저 내부에 쿠키 저장소가 있어서, 서버가 만든 쿠키를 이 저장소에 저장한다. 서버에 요청을 보낼 때마다 쿠키 저장소를 조회하여 Cookie HTTP header를 생성한다. 모든 요청에 쿠키 정보를 자동으로 포함한다. 7.2 쿠키의 사용처와 문제점 ex) set-cookie: sessionId=abcde1234; expires=Sat, 26-Dec-2020 00:00:00 GMT; path=/; domain=.google.com; Secure\n사용처\n사용자 로그인 세션 관리 (위 이미지 사례) 광고 정보 tracking 이 웹 브라우저의 사용자는 이런 광고를 주로 클릭한다는 걸 추적한다. 문제점\n네트워크 트래픽 추가 유발한다. 그래서 최소한의 정보만 사용한다. (세션 id, 인증토큰) 서버에 전송하지 않고, 웹 브라우저 내부에 데이터를 저장하고 싶으면 웹 스토리지 (localStorage, sessionStroage) 참고 주의사항!\n보안에 민감한 데이터는 저장하면 안된다. ex) 주민번호, 신용카드 번호 등등 7.3 쿠키 - 생명주기 header 쿠키가 언제까지 지속되는지 알려주는 header\nExpries, max-age\nSet-Cookie: expires = Sat, 26-Dec-2020 04:39:21 GMT\n만료일이 되면 쿠키를 삭제한다. Set-Cookie: max-age = 3600 (3600초)\n0이나 음수를 지정하면 쿠키 삭제 세션 쿠키: 만료 날짜를 생략하면 브라우저 종료 시까지만 유지\n영속 쿠키: 만료 날짜를 입력하면 해당 날짜까지 유지\n7.4 쿠키 - domain header ex) domain = example.org\n쿠키는 도메인을 지정할 수 있다.\n2가지 방법\n명시: 명시한 문서 기준 도메인 + 서브 도메인을 포함한다.\ndomain = example.org 를 지정해서 쿠키 생성 example.org는 물론이고, dev.example.org도 쿠키 접근한다. 생략: 현재 무선 기준 도메인만 적용한다.\nexample.org에서 쿠키를 생성하고 domain 지정을 생략한다. exmple.org 에서만 쿠키 접근 가능하다. dev.example.org는 쿠키 미접근 하위 도메인은 접근 불가능하다. 7.5 쿠키 - 경로 header 예) path = /home\n이 경로를 포함한 하위 경로 페이지만 쿠키 접근 가능하다. 일반적으로 path=/ 루트로 지정한다. 예 path =/home 지정 /home -\u0026gt; 가능 /home/level1 -\u0026gt; 가능 /home/level1/level2 -\u0026gt; 가능 /hello -\u0026gt; 불가능 7.6 쿠키 - 보안 header Secure, HttpOnly, SameSite\nSecure\n쿠키는 http, https를 구분하지 않고 전송한다. Secure를 적용하면 https인 경우에만 전송 HttpOnly\nxSS 공격 방지 자바스크립트에서 접근 불가(document.cookie) HTTP 전송에만 사용 SameSite\nXSRF 공격방지 요청 도메인과 쿠키에 설정된 도메인이 같은 경우만 쿠키 전송 Reference 모든 개발자를 위한 HTTP 웹 기본지식 HTTP 헤더1- 일반 헤더 ","permalink":"http://jeha00.github.io/post/network/http/http_7/","summary":"representation, 콘텐츠 협상, 전송 방식, 일반 정보, 특별 정보, 인증 그리고 쿠키에 대해 알아본다.","title":"[TIL] HTTP Header 1"},{"categories":["Python"],"content":"0. Introduction 이번 내용은 Python basic 14: 파이썬 클래스(class)에 이어 진행한다.\n예시코드는 Python basic 24에서 작성한 코드를 이어서 사용한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 \u0026gt; class Airline(): ### 코드 추가 \u0026gt; \u0026#34;\u0026#34;\u0026#34; \u0026gt; Airline class \u0026gt; Author: Kim \u0026gt; Data: 2022.03.16 \u0026gt; Description: Class, Static, Instance Method \u0026gt; \u0026#34;\u0026#34;\u0026#34; \u0026gt; price_per_raise = 1.0 ### 코드 추가 끝 \u0026gt; def __init__(self, company, details): \u0026gt; self._company = company \u0026gt; self._details = details \u0026gt; def __str__(self): \u0026gt; return \u0026#39;str : {} - {}\u0026#39;.format(self._company, self._details) \u0026gt; def __repr__(self): \u0026gt; return \u0026#39;repr : {} - {}\u0026#39;.format(self._company, self._details) ### 코드 추가 ## Instance Method: # Self로 객체의 고유한 속성 값을 사용 \u0026gt; def detail_info(self): \u0026gt; print(\u0026#39;Current ID: {}\u0026#39;.format(id(self))) \u0026gt; print(\u0026#39;Airline Detail Info: {} {}\u0026#39;.format(self._company, self._details.get(\u0026#39;price\u0026#39;))) \u0026gt; def get_price(self): \u0026gt; return \u0026#39;Before Airline ticket price -\u0026gt; Company: {}, price: {}\u0026#39;.format(self._company, self._details.get(\u0026#39;price\u0026#39;)) \u0026gt; def get_price_culc(self): \u0026gt; return \u0026#39;After Airline ticket price -\u0026gt; Company: {}, price: {}\u0026#39;.format(self._company, self._details.get(\u0026#39;price\u0026#39;) * Airline.price_per_raise = 1.0) ## Class Method: # 클래스 변수를 다룰 때는 직접 사용하기보다는 class method로 사용하기. \u0026gt; @classmethod \u0026gt; def raise_price(cls,per) \u0026gt; if per \u0026lt;= 1: \u0026gt; print(\u0026#39;Please Enter 1 or More\u0026#39;) \u0026gt; return \u0026gt; cls.price_per_raise = per \u0026gt; print(\u0026#39;Succeed! price increased\u0026#39;) ## Static Method \u0026gt; @staticmethod \u0026gt; def is_Koreanair(inst): \u0026gt; if inst._company == \u0026#39;Koreanair\u0026#39;: \u0026gt; return \u0026#39;OK! This car is {}\u0026#39;.format(inst._company) \u0026gt; return \u0026#39;Sorry! This is not Koreanair\u0026#39; ### 코드 추가 끝 ## Instance \u0026gt; Airline1 = Airline(\u0026#39;Koreanair\u0026#39;, {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000}) \u0026gt; Airline2 = Airline(\u0026#39;Asiana\u0026#39;, {\u0026#39;uniform_color\u0026#39;: \u0026#39;gray\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 6000}) \u0026gt; Airline3 = Airline(\u0026#39;t-way\u0026#39;, {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000}) 1. Self의 의미 각 인스턴스의 고유값을 인자로 받는 매개변수로, 고유값은 인스턴스뿐만 아니라 클래스도 가진다.\nself._속성으로 입력하기 때문에, 각 인스턴스마다 자신의 영역에 저장할 수 있다.\nself._속성 입력 시, 언더바(_)를 사용하는 이유??\nPEP에서 권장하기 때문에 인스턴스 변수를 만들 때 underbar를 사용한다. 언더바의 의미는 [TIL] Python basic 43: Underscore을 참고하라. 1 2 3 4 5 6 7 ## Instance의 ID 확인 \u0026gt; print(id(Airline1)) \u0026gt; print(id(Airline2)) \u0026gt; print(id(Airline3)) 2866211294752 2866211294368 2866211294176 Instance를 만들기 위한 class도 고유 id 값을 가지고 있다. 1 2 3 4 5 6 7 8 9 10 11 ## Instance가 무슨 class로 만들어졌는지 알 수 있다. \u0026gt; print(Airline1.__class__, Airline2.__class__) \u0026lt;class \u0026#39;__main__.Airline\u0026#39;\u0026gt; ## class의 고유 id값을 알 수 있다. \u0026gt; print(id(Airline)) \u0026gt; print(id(Airline1.__class__), id(Airline2.__class__)) 3104262219664 3104262219664 3104262219664 2. dir, __dict__ 그리고 __doc__ 2.1 dir 과 __dict__ dir 과 __dict__의 차이는 [TIL] Python basic 14: class을 참고하라\n1 2 3 4 5 6 7 8 9 10 11 12 13 # `dir`을 통해서 namespace 안에 class Airline class에 작성된 속성들과 method들을 확인할 수 있다. \u0026gt; print(dir(Airline1)) \u0026gt; print(dir(Airline2)) [\u0026#39;__class__\u0026#39;, \u0026#39;__dict__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__init__\u0026#39;, ..... ,\u0026#39;__repr__\u0026#39;,\u0026#39;__str__\u0026#39;, \u0026#39;_company\u0026#39;, \u0026#39;_details\u0026#39;, \u0026#39;detail_info\u0026#39;, \u0026#39;get_price\u0026#39;, \u0026#39;get_price_culc\u0026#39;, \u0026#39;price_per_raise\u0026#39;, \u0026#39;raise_price\u0026#39;] # __init__ 생성자로 만들어진 instance variable 의 구체적인 값을 확인할 수 있다. \u0026gt; print(Airline1.__dict__) {\u0026#39;_company\u0026#39;: \u0026#39;Koreanair\u0026#39;, \u0026#39;_details\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000}} \u0026gt; print(Airline2.__dict__) {\u0026#39;_company\u0026#39;: \u0026#39;Asiana\u0026#39;, \u0026#39;_details\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;gray\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 6000}} 2.2 __doc__ multi-line으로 입력된 comment가 출력되는 magic method\n코멘트를 입력할 때는 # 도 되지만, \u0026quot;\u0026quot;\u0026quot; \u0026quot;\u0026quot;\u0026quot; 을 통해서 multi-line으로 입력할 수 있다. 상세한 설명을 적으면 doc 예약어를 호출하여 다른 사람들이 확인할 수 있다. 필수적인 건 아니지만, 이러한 원칙을 정해서 개발하는게 실력 향상에 좋다. 그리고, 이런 게 하나 하나 모여서 실력 있는 개발자가 된다. 1 2 3 4 5 6 7 8 # 클래서로 접근한다. # Intro에 작성한 코드에서 \u0026#34;\u0026#34;\u0026#34; \u0026#34;\u0026#34;\u0026#34; 사이에 적은 comment가 출력된다. \u0026gt; print(Airline.__doc__) Airline class Author: Kim Data: 2022.03.16 Description: Class, Static, Instance Method 3. Method의 3종류 Method의 세 종류: class method, Instance method, Static Method\nMethod를 만들어서 사용하는 이유\nclass에 속한 모든 변수들(class variables, instance variables)에 직접 접근해서 사용하는 것보다, method를 통해 사용하는 방법이 \u0026lsquo;캡슐화\u0026rsquo; 성질을 고려했을 때, 좋은 방법이기 때문이다. Static method는 그럼 무엇인가??\npython 전문 서적을 보면 static method가 굳이 필요한지 의문성을 보이는 만큼 반드시 필요하진 않지만 개념적으로 알고 있자. 클래스 변수, 인스턴스 변수를 받기에 조금 적절하지 않을 때 클래스 변수와 인스턴스 변수를 사용하지 않는 대책으로 사용한다. 그래서 위 method들과는 달리, 아무것도 받지 않는다. 또한, @staticmethod라는 decorator를 입력한다. Method Class method Instance method Static method Parameter cls self X Purpose 클래스 변수를 사용하기 위해 인스턴스 변수를 사용하기 위해 옆 두 method에 대한 대책으로 사용 Decorator @classmethod x @staticmethod [TIL] Python basic 14: class - class method, instance method 와 [TIL] Python basic 14: class - class, instance variable 를 참고하자\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 ### Intro code에서 각 method는 다음과 같다. ## Instance Method(self): # 첫 번째 인자로, self 즉 instance를 받는다는 걸 알 수 있다. \u0026gt; def detail_info(self): \u0026gt; print(\u0026#39;Current ID: {}\u0026#39;.format(id(self))) \u0026gt; print(\u0026#39;Airline Detail Info: {} {}\u0026#39;.format(self._company, self._details.get(\u0026#39;price\u0026#39;))) \u0026gt; def get_price(self): \u0026gt; return \u0026#39;Before Airline ticket price -\u0026gt; Company: {}, price: {}\u0026#39;.format(self._company, self._details.get(\u0026#39;price\u0026#39;)) \u0026gt; def get_price_culc(self): \u0026gt; return \u0026#39;After Airline ticket price -\u0026gt; Company: {}, price: {}\u0026#39;.format(self._company, self._details.get(\u0026#39;price\u0026#39;) * Airline.price_per_raise = 1.0) ## Class Method(cls): # @classmethod라는 데코레이터를 입력한 것과 # 첫 번째 인자로, cls == class 를 받는다는 걸 알 수 있다. \u0026gt; @classmethod \u0026gt; def raise_price(cls,per) \u0026gt; if per \u0026lt;= 1: \u0026gt; print(\u0026#39;Please Enter 1 or More\u0026#39;) \u0026gt; return \u0026gt; cls.price_per_raise = per \u0026gt; print(\u0026#39;Succeed! price increased\u0026#39;) ## Static Method # @staticmehod라는 데코레이터를 입력한 걸 알 수 있다. \u0026gt; @staticmethod \u0026gt; def is_Koreaair(inst): \u0026gt; if inst._company == \u0026#39;Koreanair\u0026#39;: \u0026gt; return \u0026#39;OK! This car is {}\u0026#39;.format(inst._company) \u0026gt; return \u0026#39;Sorry! This is not Koreanair\u0026#39; 각 method를 사용하여 variable에 접근하자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 ## instance의 _details에 있는 price 정보에 접근하자. # 직접 접근하기 \u0026gt; print(Airline1._details.get(\u0026#39;price\u0026#39;)) 8000 # method를 통해 접근하기 \u0026gt; print(Airline1.get_price()) Before Airline ticket price -\u0026gt; Company: Koreanair, price: 8000 ## class variable인 price_per_raise에 접근하자. # 직접 접근하기 \u0026gt; Airline.price_per_raise = 1.4 # method를 통해 접근하기 \u0026gt; Airline.raise_price(1.4) Succeed! price increased \u0026gt; print(Airline1.get_price_culc()) After Airline ticket price -\u0026gt; Company: Koreanair, price: 12000.0 ## static method # airline이 Koreanair인지 아닌지 확인해보자. # instance로 접근하든, class로 접근하든 유연하다. # instance로 접근하기: 어느 instance로 접근하든 넘겨주는 값에 따라 결과가 나온다. \u0026gt; print(Airline1.is_koreanair(Airline1)) OK! This car is Koreanair \u0026gt; print(Airline1.is_koreanair(Airline2)) Sorry! This is not Koreanair # class로 접근하기 \u0026gt; print(Airline.is_koreanair(Airline1)) OK! This car is Koreanair Reference 인프런 파이썬 중급 [TIL] Python basic 14: 파이썬 클래스(class) [TIL] Python basic 43: Underscore ","permalink":"http://jeha00.github.io/post/python/python_basic_26_class2/","summary":"Python basic 14의 내용을 이어서 진행한다. instance의 self가 무엇을 의미하는지, dir과 \u003ccode\u003e__dict__\u003c/code\u003e가 무슨 차이인지, 또한 method 3종류인 class method, instance method 마지막으로 static method에 대해 알아본다.","title":"[TIL] Python basic 26: class advanced"},{"categories":"Network","content":"Introduction HTTP 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다. 이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다. 학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고자 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다. 이번 시간에는 상태 코드에 대해 알아본다. 상태 코드란??\n클라이언트가 보낸 요청의 처리 상태를 응답에서 알려주는 기능\n상태 코드의 종류에는 다음과 같다. 1xx (Informational): 요청이 수신되어 처리중 2xx (Successful): 요청 정상 처리 3xx (Redirection): 요청을 완료하려면 추가 행동이 필요 4xx (Client Error): 클라이언트 오류, 잘못된 문법등으로 서버가 요청을 수행할 수 없음 5xx (Server Error): 서버 오류, 서버가 정상 요청을 처리하지 못함 만약 모르는 상태 코드가 나타나면??\n클라이언트가 인식할 수 없는 상태코드를 서버가 반환하면?? 클라이언트는 상위 상태 코드로 해석해서 처리한다. 미래에 새로운 상태 코드가 추가되어도 클라이언트를 변경하지 않아도 된다. 예) 299 ??? -\u0026gt; 2xx (Successful) 451 ??? -\u0026gt; 4xx (Client Error) 599 ??? -\u0026gt; 5xx (Server Error) 그러면 각 상태 코드에 대해 알아보자.\n(1xx는 거의 사용하지 않으므로 생략한다. )\n2xx (Successful) 클라이언트의 요청을 성공적으로 처리한 상태\n2xx state code 종류 200 OK 201 Created 202 Accepted 204 No Content 200 OK 요청이 성공한 상태\n200번대 모든 코드들을 사용하지 않고, 200과 201만 사용하는 경우가 많다. 그래서, 팀 내에서 코드를 어디까지 사용할지 결정한다. 201 Created 요청이 성공하여 새로운 리소스가 생성된 상태\n202 Accepted 요청이 접수되었으나 처리가 완료되지 않은 상태\n배치 처리(batch processing) 같은 곳에서 사용한다. 예) 요청 접수 후, 1시간 뒤에 배치 프로세스가 요청을 처리한다. 배치 처리(batch processing)란??\n일괄 처리라 하며, 데이터를 일괄적으로 모아서 처리하는 작업을 말한다.\n204 No Content 서버가 요청을 성공적으로 수행했으나, 응답 페이로드 본문에 보낼 데이터가 없는 상태\n예) 웹 문서 편집기에서 save 버튼 save 버튼의 결과로 아무 내용이 없어도 된다. save 버튼을 눌러도 같은 화면을 유지해야 한다. 결과 내용이 없어도, 204 메시지(2xx)만으로 성공을 인식할 수 있다. 3xx (Redirection) 요청을 완료하기 위해 유저 에이전트(웹 브라우저)의 추가 조치가 필요한 상태\n3xx status code 종류 300 Multiple Choices 301 Moved Permanently 302 Found 303 See Other 304 Not Modified 307 Temporary Redirect 308 Permanent Redirect 리다이렉트란???\n웹 브라우저가 3xx 응답의 결과에 Location 헤더가 있으면, Location 위치로 자동 이동하는 것 리다이렉션의 종류 영구 리다이렉션:\n특정 리소스의 URI가 영구적으로 이동 예) /members -\u0026gt; /users 예) /event -\u0026gt; /new-event 일시 리다이렉션:\n일시적인 변경 주문 완료 후 주문 내역 화면으로 이동한다. 자주 쓰이는 패턴: PRG (Post/Redirect/Get) 특수 리다이렉션:\n결과 대신 캐시를 사용한다. 클라이언트가 캐시 사용 시간을 확인하기 위해 서버에게 보내어 서버가 캐시 생성일자로 응답하는 것을 말한다. 영구 리다이렉션 (301, 308) 리소스의 URI가 영구적으로 이동 원래의 URL를 사용X, 검색 엔진 등에서도 변경 인지 301 Moved Permanently 리다이렉트 시, 요청 메서드가 POST에서 GET으로 변하고, 본문이 제거될 수 있음(MAY) 본문이 제거될 수 있다는 문제점을 308이 해결할 수 있으나, 대부분 301을 사용한다. 왜냐하면 경로가 /new-event로 바뀌면 내부적으로 전달하는 데이터가 다 바뀌는 것이기 때문에, POST로 와도 GET으로 되돌리는 게 맞다. 308 Permanent Redirect 301과 기능은 같음\n리다이렉트시 요청 메서드와 본문 유지\n(처음 POST를 보내면 리다이렉트도 POST 유지)\n스펙에 나와 있어 설명한다. 실무에서는 거의 이렇게 사용하지 않는다.\n일시적인 리다이렉션 (302, 307, 303) 리소스의 URI가 일시적으로 변경 따라서 검색 엔진 등에서 URL을 변경하면 안됨 302 Found 리다이렉트시 요청 메서드가 GET으로 변하고, 본문이 제거될 수 있음(MAY) 307 Temporary Redirect 302와 기능은 같음 리다이렉트시 요청 메서드와 본문 유지\n(요청 메서드를 변경하면 안된다. MUST NOT) 303 See Other 302와 기능은 같음 리다이렉트시 요청 메서드가 GET으로 변경 PRG 예시 (전, 후) POST로 주문 후, 웹 브라우저를 새로고침하면??\n새로 고침은 다시 요청하는 것이기 때문에, 중복 주문이 될 수 있다. 이를 해결하기 위해 자주 사용하는 패턴이 PRG다.\nPRG: POST/Redirect/Get PRG 사용 전\nPRG 사용 후 302 또는 303 사용한다. POST로 주문 후에도 새로 고침으로 인한 중복 주문을 방지한다. POST로 주문 후에도 주문 결과 화면을 GET method로 리다이렉트하여, 새로 고침해도 결과 화면을 GET 으로 조회한다. 즉, 중복 주문 대신에 결과 화면만 GET으로 다시 요청한다. PRG를 사용해서 경고창이 안뜨고, 서버 입장에서는 오류가 줄어든다. [Summary]\n302 Found -\u0026gt; GET으로 변할 수 있다. 307 Temporary Redirect -\u0026gt; 메서드가 변하면 안된다. 303 See Other -\u0026gt; 메서드가 GET으로 변경한다. [History]\n처음 302 스펙의 의도는 HTTP 메서드를 유지하는 것이다. 그런데 웹 브라우저들이 대부분 GET으로 바꿨다.(일부는 다르게 동작) 그래서 모호한 302를 대신하는 명확한 307, 303이 등장했다.\n(301 대응으로 308도 등장) [Now]\n307, 303을 권장하지만 현실적으로 이미 많은 애플리케이션 라이브러리들이 302를 기본값으로 사용 자동 리다이렉션시에 GET으로 변해도 되면 그냥 302를 사용해도 큰 문제 없음 기타 리다이렉션 (300, 304) 300 Multiple Choices: 안쓴다. 304 Not Modified 매우 많이 사용한다. 캐시를 목적으로 사용 클라이언트에게 리소스가 수정되지 않았음을 알려준다. 따라서 클라이언트는 로컬PC에 저장된 캐시를 재사용한다. (캐시로 리다이렉트 한다.) 304 응답은 응답에 메시지 바디를 포함하면 안된다. (로컬 캐시를 사용해야 하므로) 조건부 GET, HEAD 요청시 사용 4xx (Client Error) 오류의 원인이 \u0026lsquo;클라이언트\u0026rsquo;에게 있어서, 발생하는 클라이언트 오류\n클라이언트의 요청에 잘못된 문법 등으로 서버가 요청을 수행할 수 없다. 클라이언트가 이미 잘못된 요청,데이터를 보내고 있어서, 똑같은 재시도는 실패한다. 400 Bad Request 클라이언트가 잘못된 요청을 해서 서버가 요청을 처리할 수 없다.\n요청 구문, 메시지 등등으로 인한 오류가 발생한 상태다. 클라이언트는 요청 내용을 다시 검토하고, 보내야 한다. 예) 요청 파라미터가 잘못되거나, API 스펙이 맞지 않을 때 401 Unauthorized 클라이언트가 해당 리소스에 대한 인증이 필요하다.\n인증(Authentication) 되지 않은 상태를 말한다. 401 오류 발생시 응답에 WWW-Authenticate 헤더와 함께 인증 방법을 설명한다. [참고]\n인증(Authentication): 본인이 누구인지 확인, (로그인) 인가(Authorization): 권한부여 (ADMIN 권한처럼 특정 리소스에 접근할 수 있는 권한, 인증이 있어야 인가가 있음) 오류 메시지가 Unauthorized 이지만 인증 되지 않음 (이름이 아쉬움) 403 Forbidden 서버가 요청을 이해했지만, 승인을 거부함\n주로 인증 자격 증명은 있지만, 접근 권한이 부충분한 경우 예) Admin 등급이 아닌 사용자가 로그인하여, admin 등급의 resource에 접근하는 경우 404 Not Found 요청 리소스를 찾을 수 없다.\n요청 리소스가 서버에 없다. 클라이언트가 권한이 부족한 리소스에 접근할 때 해당 리소스를 숨기고 싶을 때 5xx (Serve Error) 오류의 원인이 \u0026lsquo;서버\u0026rsquo;에게 있어서, 발생하는 서버 오류\nClient Error와 달리 서버에 문제가 있기 때문에, 재시도하면 성공할 수 있다. 500대 에러는 서버에 심각한 문제가 터졌을 때를 의미한다. 고객의 잔고가 부족할 경우, 20세 이상만 이용 가능한데 15세가 들어왔을 경우 등등은 500번대 에러가 아니다. 500 Internal Server Error 서버 문제로 오류 발생, 애매하면 500 오류\n서버 내부 문제로 오류가 발생한 상황 애매하면 500 오류를 사용 503 Service Unavailable 서비스 이용 불가\n서버가 일시적인 과부하 또는 예정된 작업으로 잠시 요청을 처리할 수 없는 상황 Retry-After 헤더 필드로 얼마 뒤에 복구되는지 보낼 수 있다. 대부분의 서비스 에러는 예측 불가하기 때문에 500번이다. Reference 모든 개발자를 위한 HTTP 웹 기본지식 ","permalink":"http://jeha00.github.io/post/network/http/http_6/","summary":"HTTP status 2xx, 3xx, 4xx, 5xx에 대해 각각 알아본다.","title":"[TIL] HTTP status"},{"categories":"Network","content":"0. Introduction HTTP 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식\n강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다.\n이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다.\n학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고자 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다.\n1. 클라이언트에서 서버로 데이터 전송 클라이언트에서 서버로 데이터를 전달하는 방식은 크게 2가지가 있다.\n쿼리 파라미터를 통한 데이터 전송 GET을 많이 사용한다. 예) 주로 정렬 필터나 검색어를 사용할 때 쿼리 파라미터를 많이 사용한다. 메시지 바디를 통한 데이터 전송 POST, PUT, PATCH를 사용한다. 예) 회원 가입, 상품 주문, 리소스 등록, 리소스 변경하는데 사용한다. 그리고, 클라이언트가 서버로 데이터를 전송하는 4가지 상황이 있다. 각 상황에서 어떻게 클라이언트가 서버에 데이터를 전달하는지 알아보자.\n1.1 정적 데이터 조회 예) 이미지, 정적 텍스트 문서\n정적 데이터는 일반적으로 쿼리 파라미터 없이 GET method로 resource path만 적어, 단순하게 조회가 가능하다.\n1.2 동적 데이터 조회 예) 주로 검색,게시판 목록에서 검색어를 사용하여 정렬 필터한다. (검색어)\n조회 조건을 줄여주는 필터, 조회 결과를 정렬하는 정렬 조건에 주로 사용한다. 조회이기 때문에 GET 사용하지만, 정적 데이터가 아닌 동적 데이터이므로, 쿼리 파라미터를 사용해서 데이터를 클라이언트가 서버에게 넘겨줘야 한다. GET도 메세지 바디를 사용할 수 있지만, 지원하지 않는 경우가 많아서 사용하지 않는다. 1.3 HTML Form을 통한 데이터 전송 HTML Form 전송은 GET, POST만 지원한다. 예) 회원 가입, 상품 주문, 데이터 변경 POST 전송 - 저장 예) 회원 가입, 상품 주문, 데이터 변경 상황 전송 버튼을 누르면 웹 브라우저가 form 태그 정보를 읽어서, HTTP message를 생성한다. 그리고, action에 작성된 경로로 해당 method 요청을 보낸다. 쿼리 파라미터랑 동일한 형식으로 HTTP message body에 넣어 서버에 전송된다. username=kim\u0026amp;age=20 GET 전송 - 저장 (오류) GET이라 메세지 바디를 안쓰기 때문에, url 경로에다가 data를 넣는다. 즉, Query parameter 형식으로 넣어준다. 또한, GET은 조회용으로만 사용가능하므로 저장하는 곳에 사용하면 안된다. GET은 조회이므로, /members 등으로 조회가 가능한 곳으로 보내야 정상적으로 처리된다. [결론]\nFORM에서 GET / POST의 사용에 맞춰서 웹 브라우저가 알아서 HTTP 요청 메세지의 구성을 Query 또는 Body 등으로 맞춰서 생성한다.\nmultipart/form-data 다른 종류의 여러 파일과 폼의 내용을 함께 전송이 가능해서 이름이 multipart다. 주로 binary data를 전송할 때 사용한다. 웹브라우저가 생성한 요청 HTTP 메시지의 content-type에 boundary 가 명시되어 있는데, form data 간 구분을 지어준다. 1.4. HTTP API를 통한 데이터 전송 HTML Form을 쓰지 않는 모든 상황을 말한다. 예) 회원 가입, 상품 주문, 데이터 변경에 사용 그러면 언제 사용하는가??? 서버 to 서버: 백엔드 시스템 통신 앱 클라이언트에서 전송 시 (아이폰,안드로이드) 웹 클라이언트에서 HTML Form 전송 대신 자바 스크립트를 통한 통신에 사용 (AJAX) 예)React, Vue.JS 같은 웹 클라이언트와 API 통신 POST, PUT,PATCH: 사용하며, 메시지 바디를 통해 데이터를 전송 GET: 조회, 쿼리 파라미터로 데이터를 전달 Content-type: application/json을 주로 사용 (사실상 표준) TEXT, XML, JSON 등등이 있지만, XML이 읽기 어렵고, 복잡해서 지금은 JSON을 사용한다. 데이터 크기도 상대적으로 XML보다 작아서, 사실상 JSON이 표준이다. 2. HTTP API 설계 HTTP API 설계에는 3가지 종류가 있다. HTTP API - collection POST 기반 등록 서버가 리소스 URI 결정 HTTP API - store PUT 기반 등록 클라이언트가 리소스 URI 결정 HTML FORM 사용 순수 HTML + HTML form 사용 GET, POST만 지원 이 3가지에 대해 각각 알아보자. 2.1 HTTP API - collection 서버가 새로 등록된 리소스 URI를 생성하고 관리하는 구조: Collection\n회원 관리 시스템: API 설계 - POST 기반 등록 회원 목록 /members -\u0026gt; GET 회원 등록 /members -\u0026gt; POST 회원 조회 /members/{id} -\u0026gt; GET (회원 단권 조회) 회원 수정 /members/{id} -\u0026gt; PATCH, PUT, POST 회원 삭제 /members/{id} -\u0026gt; DELETE 실제로는 위의 경우처럼 명확하게 구분되지 않기 때문에, 컨트롤 URI 를 사용할 수 밖에 없다.\n클라이언트는 등록될 리소소의 URI를 모른다. 회원 등록 /members -\u0026gt; POST POST /members 서버가 새로 등록된 리소스 URI를 생성한다. HTTP/1.1 201 Created\nLocation: /members/100 Collection 서버가 관리하는 리소스 디렉토리 서버가 리소스의 URI를 생성하고 관리 여기서 collection은 /members 2.2 HTTP API - store 클라이언트가 직접 resource uri를 지정하고, 관리하는 구조: Store\n파일 관리 시스템: API 설계 - PUT 기반 등록 파일 목록 /files -\u0026gt; GET 파일 조회 /files/{filename} -\u0026gt; GET 파일 등록 /files/{filename} -\u0026gt; PUT 파일 삭제 /files/{filename} -\u0026gt; DELETE 파일 대량 등록 /files -\u0026gt; POST 파일 등록에 PUT을 썼기 때문에, 대량 등록에는 POST를 썼다. 왜냐하면 POST는 임의로 의미를 만들 수 있다. 클라이언트가 리소스 URI를 알고 있어야 한다. 파일 등록/files/{filename} -\u0026gt; PUT PUT/files/star.jpg 클라이언트가 직접 리소스의 URI를 지정한다. Store 클라이언트가 관리하는 리소스 디렉토리 클라이언트가 리소스의 URI를 생성하고 관리 여기서 store는 /files 그럼 위 두 방식(Collection, Store) 중 무엇을 많이 사용할까??\n대부분 실무에서는 POST를 사용하는 Collection 구조를 사용한다. 하지만, file 관리의 경우, Store를 사용한다.\n2.2 HTML FORM 사용 회원 목록 /members -\u0026gt; GET 회원 등록 폼 /members/new -\u0026gt; GET 회원 등록 /members/new, /members -\u0026gt; POST 위에 등록 폼과 같은 url을 쓰는 것을 추천한다. 회원 조회 /members/{id} -\u0026gt; GET 회원 수정 폼 /members/{id}/edit -\u0026gt; GET 실제로 수정일 일어나는 게 아니기 때문에, GET 을 사용한다. 회원 수정 /members/{id}/edit, /members/{id} -\u0026gt; POST 위에 수정 폼과 같은 url을 쓰는 것을 추천한다. 회원 삭제 /members/{id}/delete -\u0026gt; POST HTML FORM은 GET, POST만 지원 하므로 제약이 있다. 이런 제약을 해결하기 위해 동사로 된 리소스 경로를 사용한다. 최대한 리소스 개념을 가지고 사용하지만, 안될 때 대체제로 컨트롤 URI를 사용한다. AJAX 같은 기술을 사용해서 해결 가능하다 -\u0026gt; 회원 API 참고 여기서는 순수 HTML, HTML FORM 이야기다. 3. 참고하면 좋은 URI 설계 개념 문서(document)\n단일 개념(파일 하나, 객체 인스턴스, 데이터베이스 row) 예) /members/100, /files/star.jpg 컬렉션(collection)\n서버가 관리하는 리소스 디렉터리 서버가 리소스의 URI를 생성하고 관리 예) /members 스토어(store)\n클라이언트가 관리하는 자원 저장소 클라이언트가 리소스의 URI를 알고 관리 예) /files 컨트롤러(controller), 컨트롤 URI\n문서, 컬렉션, 스토어로 해결하기 어려운 추가 프로세스 실행 동사를 직접 사용 예) /members/{id}/delete REST API를 보면 해결이 안되는 경우가 있다.\n그럴 때, 네 번째 개념인 컨트롤 URI가 꼭 있어야 한다.\n문서, collection, store 만으로 부족할 때, 컨트롤 URI 를 사용한다.\nhttps://restfulapi.net/resource-naming 참고하기 여러 사람들이 HTTP API를 하다보니, 좋은 practice가 있다. Reference 모든 개발자를 위한 HTTP 웹 기본지식 HTTP 메서드 활용 ","permalink":"http://jeha00.github.io/post/network/http/http_5/","summary":"HTTP method를 가지고 클라이언트가 서버에 어떻게 데이터를 전송하는지, 그리고 API 설계에는 무슨 종류가 있는지 알아본다.","title":"[TIL] HTTP method use"},{"categories":["Python"],"content":"0. Introduction class에 대해 공부를 더 시작하면서 매직 메소드에 대해 알기 시작했다. 매직 메소드의 종류인 __str__ 과 __repr__ 에 대해 각각 알아보고, 차이점도 알아보자. 1. Magic method 의 종류: str 과 repr python에서 이미 만들어놓은 내장된 method로, special method라 한다.\nmagic method의 종류 중 __str__ 과 __repr__에 대해 알아보겠다.\n__repr__ 의 repr은 representation의 약어다. 예시코드는 Python basic 24에서 작성한 코드를 이어서 사용한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; class Airline(): \u0026gt; def __init__(self, company, details): \u0026gt; self._company = company \u0026gt; self._details = details \u0026gt; Airline1 = Airline(\u0026#39;Koreanair\u0026#39;, {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000}) \u0026gt; Airline2 = Airline(\u0026#39;Asiana\u0026#39;, {\u0026#39;uniform_color\u0026#39;: \u0026#39;gray\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 6000}) \u0026gt; Airline3 = Airline(\u0026#39;t-wau\u0026#39;, {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000}) \u0026gt; print(Airline1) \u0026gt; print(Airline2) \u0026gt; print(Airline3) \u0026lt;__main__.Airline object at 0x000002DFDFF06FD0\u0026gt; \u0026lt;__main__.Airline object at 0x000002DFDFF06F70\u0026gt; \u0026lt;__main__.Airline object at 0x000002DFDFF06400\u0026gt; Airline 클래스의 인스턴스를 보이기 위해서, print()을 사용하면 출력할 instance의 memory address를 보인다.\n1.1 __str__ magic method 그러면 Airline class 내부에 __str__ instance method를 추가해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; class Airline(): \u0026gt; def __init__(self, company, details): \u0026gt; self._company = company \u0026gt; self._details = details \u0026gt; \u0026gt; def __str__(self): \u0026gt; return \u0026#39;str : {} - {}\u0026#39;.format(self._company, self._details) # instance 코드 부분은 생략한다. \u0026gt; print(Airline1) str : Koreanair - {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000} \u0026gt; print(Airline2) str : Asiana - {\u0026#39;uniform_color\u0026#39;: \u0026#39;gray\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 6000} \u0026gt; print(Airline3) str : t-wau - {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000} __str__ method 를 사용하니, memory address를 출력하는 것이 아닌, __str__ method의 return 값을 출력한다.\n1.2 __repr__ magic method 다음으로 __repr__ method를 사용해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026gt; class Airline(): \u0026gt; def __init__(self, company, details): \u0026gt; self._company = company \u0026gt; self._details = details \u0026gt; \u0026gt; def __repr__(self): \u0026gt; return \u0026#39;repr : {} - {}\u0026#39;.format(self._company, self._details) # instance 코드 부분은 생략한다. \u0026gt; print(Airline1) \u0026gt; print(Airline2) \u0026gt; print(Airline3) repr : Koreanair - {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000} repr : Asiana - {\u0026#39;uniform_color\u0026#39;: \u0026#39;gray\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 6000} repr : t-wau - {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000} __repr__ method 를 사용하니, memory address를 출력하는 것이 아닌, __repr__ method에서 return 값을 출력한다. 그러면 __str__ 와 __repr__ 를 같이 사용해보자. __str__ method의 return 문을 출력했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026gt; class Airline(): \u0026gt; def __init__(self, company, details): \u0026gt; self._company = company \u0026gt; self._details = details \u0026gt; \u0026gt; def __str__(self): \u0026gt; return \u0026#39;str : {} - {}\u0026#39;.format(self._company, self._details) \u0026gt; \u0026gt; def __repr__(self): \u0026gt; return \u0026#39;repr : {} - {}\u0026#39;.format(self._company, self._details) # instance 코드 부분은 생략한다. \u0026gt; print(Airline1) \u0026gt; print(Airline2) \u0026gt; print(Airline3) str : Koreanair - {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000} str : Asiana - {\u0026#39;uniform_color\u0026#39;: \u0026#39;gray\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 6000} str : t-wau - {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000} 1.3. __str__ 과 __repr__ 의 공통점과 차이 그러면 여태까지의 증명으로 다음과 같은 사실을 알 수 있다.\n__str__ 과 __repr__ 의 공통점\n__str__ 와 __repr__ 은 클래스의 인스턴스에 대한 memory address를 출력하는 게 아닌, 사용자가 원하는 출력문 즉, 이 magic method에서 반환한 형식으로 출력한다. To customize the string representation of a class instance, the class needs to implement the __str__ magic method. [출처: python tutorial: __str__] __str__ 와 __repr__ 이 같이 사용되면 __str__이 출력된다. __str__ 과 __repr__ 의 차이점 from Python __repr__\nMagic method __str__ __repr__ 대상 사람이 읽기 쉬운 결과물 기계(interpreter)가 읽기 쉬운 결과물 목적 간결히 읽기 위함 문자열로 객체를 다시 생성하기 위함 Informal / Offical Informal string presentation Offical string presentation 1 2 3 4 5 6 7 \u0026gt; a = datetime.datetime(2022,3,13) \u0026gt; print(str(a)) 2022-03-13 00:00:00 \u0026gt; print(repr(a)) datetime.datetime(2022, 3, 13, 0, 0) 2. print ()와 __str__ method의 관계 print( )는 object.__str__를 통해서 문자열로 반환된 걸 출력하는 function\nstr(object)를 통해 문자열로 변환할 때, object.__str__를 호출하여 이 메소드를 통해 변환된 것을 반환한다. print()는 str()에게 출력할 arguments를 전달하여 문자열로 변환 후 출력한다.\n1 2 3 4 5 6 7 8 9 10 \u0026gt; class Airline(): \u0026gt; def __init__(self, company, details): \u0026gt; self._company = company \u0026gt; self._details = details \u0026gt; \u0026gt; def __str__(self): \u0026gt; return \u0026#39;str : {} - {}\u0026#39;.format(self._company, self._details) \u0026gt; print(str(Airline1)) str : Koreanair - {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000} repr() 또한 __repr__을 통해서 변환된 것을 반환한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; class Airline(): \u0026gt; def __init__(self, company, details): \u0026gt; self._company = company \u0026gt; self._details = details \u0026gt; \u0026gt; def __repr__(self): \u0026gt; return \u0026#39;repr : {} - {}\u0026#39;.format(self._company, self._details) # instance 코드 부분은 생략한다. \u0026gt; print(repr(Airline1)) repr : t-wau - {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000} \u0026gt; print(str(Airline1)) repr : t-wau - {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000} __str__이 별도로 정의되지 않았고 __repr__만 정의된 상황일지라도, str()을 실행하면 __repr__가 실행된다.\nSummary print() \u0026ndash;(호출)\u0026ndash;\u0026gt; str(object) \u0026ndash;(호출)\u0026ndash;\u0026gt; object.__str__ \u0026ndash;(호출)\u0026ndash;\u0026gt; object.__repr__\nprint()는 object.__str__를 통해 변환된 걸 출력한다. __str__은 내부적으로 default로 __repr__을 호출한다. repr(object) \u0026ndash;(호출)\u0026ndash;\u0026gt; object.__repr__\nobject.__repr__ 를 통해 변환된 걸 반환한다. Reference 인프런 파이썬 중급 Python tutorial Data model ","permalink":"http://jeha00.github.io/post/python/python_basic_25_str_repr/","summary":"__str__ 과 __repr__ 이 각각 무엇인지, 이 둘의 차이는 무엇인지, print 함수와 __str__ 사이에는 무슨 관계가 있는지 알아본다.","title":"[TIL] Python basic 25: \n_\n_str\n_\n_ vs \n_\n_repr\n_\n_"},{"categories":["Python"],"content":"0. Introduction [TIL] Python basic 14: class 에서 언급한 절차지향 프로그래밍이 구체적으로 무엇인지 간단히 구현한다.\n그 다음 클래스를 사용한 객체지향 프로그래밍에 대해 알아보겠다.\n절차지향 프로그래밍은 일반적인 과거의 코딩방식으로, 함수 중심이기 때문에, 데이터가 방대하여 복잡하다는 단점이 있다.\n이에 대한 해결책이 OOP(Object Oriented Programming) 으로 객체지향 프로그래밍이다.\n클래스 중심으로 사용하기 때문에 객체로 관리하기 때문에, 다음과 같은 특징이 있다.\n코드의 재사용성이 낮다. 코드 중복을 방지할 수 있다. 유지보수가 좋다. 대형 프로젝트에 적합하다. 1. 절차지향 프로그래밍 (Procedural Programming) 그럼 예시 코드로 절차지향 프로그래밍을 구현해보자. 절차지향으로 프로그래밍할 경우, 항공사의 종류 갯수대로 직접 다 입력해야 한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 항공사 1 \u0026gt; airline_company_1 = \u0026#39;Koreaair\u0026#39; \u0026gt; airline_detail_1 = [ \u0026gt; {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;}, \u0026gt; {\u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;}, \u0026gt; {\u0026#39;price\u0026#39;: 8000}, \u0026gt; ] # 항공사 2 \u0026gt; airline_company_2 = \u0026#39;Asiana\u0026#39; \u0026gt; airline_detail_2 = [ \u0026gt; {\u0026#39;color\u0026#39;: \u0026#39;gray\u0026#39;}, \u0026gt; {\u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;}, \u0026gt; {\u0026#39;price\u0026#39;: 6000}, \u0026gt; ] # 항공사 3 \u0026gt; airline_company_3 = \u0026#39;t-way\u0026#39; \u0026gt; airline_detail_3 = [ \u0026gt; {\u0026#39;color\u0026#39;: \u0026#39;red\u0026#39;}, \u0026gt; {\u0026#39;kind\u0026#39;: \u0026#39;LCC\u0026#39;}, \u0026gt; {\u0026#39;price\u0026#39;: 3000}, \u0026gt; ] 리스트 구조로 또 입력해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026gt; airline_company_list = [\u0026#39;Koreanair\u0026#39;, \u0026#39;Asiana\u0026#39;, \u0026#39;t-way\u0026#39;] \u0026gt; airline_detail_list = [ \u0026gt; {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000}, \u0026gt; {\u0026#39;color\u0026#39;: \u0026#39;gray\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 6000}, \u0026gt; {\u0026#39;color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000} \u0026gt; ] \u0026gt; del airline_company_list[1] \u0026gt; del airline_detail_list[1] \u0026gt; print(airline_company_list) [\u0026#39;Koreanair\u0026#39;, \u0026#39;t-way\u0026#39;] \u0026gt; print(airline_detail_list) [{\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000}, {\u0026#39;color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000}] 이런 방식으로 입력할 경우, 데이터를 삭제하기가 불편하다. index를 사용하여 삭제할 때, 데이터 양이 많으면 index 번호를 알기가 어렵기 때문이다. 그리고, index로 접근 시 실수할 가능성이 높다. 다음으로 딕셔너리 구조로 입력해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; airlines_dicts = [ \u0026gt; {\u0026#39;airline_company\u0026#39;: \u0026#39;Koreanair\u0026#39;, \u0026#39;airline_detail\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000}}, \u0026gt; {\u0026#39;airline_company\u0026#39;: \u0026#39;Asiana\u0026#39;, \u0026#39;airline_detail\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;gray\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 6000}}, \u0026gt; {\u0026#39;airline_company\u0026#39;: \u0026#39;t-way\u0026#39;, \u0026#39;airline_detail\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000}} \u0026gt; ] \u0026gt; airlines_dicts[1].pop(\u0026#39;airline_company\u0026#39;) \u0026gt; print(airlines_dicts) [{\u0026#39;airline_company\u0026#39;: \u0026#39;Koreanair\u0026#39;, \u0026#39;airline_detail\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000}}, {\u0026#39;airline_detail\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;gray\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 6000}}, {\u0026#39;airline_company\u0026#39;: \u0026#39;t-way\u0026#39;, \u0026#39;airline_detail\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000}}] \u0026gt; del airlines_dicts[1] [{\u0026#39;airline_company\u0026#39;: \u0026#39;Koreanair\u0026#39;, \u0026#39;airline_detail\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000}}, {\u0026#39;airline_company\u0026#39;: \u0026#39;t-way\u0026#39;, \u0026#39;airline_detail\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000}}] 딕셔너리 안에 딕셔너리가 있는 형식으로 작성했다. 여전히 코드의 반복은 지속되어, 개발자에게 피로도를 증가시킨다. 키 중첩 문제가 존재하며, 키 조회 시 예외 처리를 해야한다. 2. 객체지향 프로그래밍 (OOP) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026gt; class Airline(): \u0026gt; def __init__(self, company, details): \u0026gt; self._company = company \u0026gt; self._details = details \u0026gt; Airline1 = Airline(\u0026#39;Koreanair\u0026#39;, {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000}) \u0026gt; Airline2 = Airline(\u0026#39;Asiana\u0026#39;, {\u0026#39;uniform_color\u0026#39;: \u0026#39;gray\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 6000}) \u0026gt; Airline3 = Airline(\u0026#39;t-wau\u0026#39;, {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;:\u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000}) \u0026gt; print(Airline1) \u0026gt; print(Airline2) \u0026gt; print(Airline3) \u0026lt;__main__.Airline object at 0x000001AC6C87CFD0\u0026gt; \u0026lt;__main__.Airline object at 0x000001AC6C87CF70\u0026gt; \u0026lt;__main__.Airline object at 0x000001AC6C87CEE0\u0026gt; \u0026gt; print(Airline1.__dict__) \u0026gt; print(Airline2.__dict__) \u0026gt; print(Airline3.__dict__) {\u0026#39;_company\u0026#39;: \u0026#39;Koreanair\u0026#39;, \u0026#39;_details\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;skyblue\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 8000}} {\u0026#39;_company\u0026#39;: \u0026#39;Asiana\u0026#39;, \u0026#39;_details\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;gray\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;FSC\u0026#39;, \u0026#39;price\u0026#39;: 6000}} {\u0026#39;_company\u0026#39;: \u0026#39;t-wau\u0026#39;, \u0026#39;_details\u0026#39;: {\u0026#39;uniform_color\u0026#39;: \u0026#39;red\u0026#39;, \u0026#39;kind\u0026#39;: \u0026#39;LCC\u0026#39;, \u0026#39;price\u0026#39;: 3000}} class 로 틀을 만들어서 airline instance를 손쉽게 만들었다.\ninstance에 담긴 구체적인 정보를 알고싶을 때는 __dict__ 를 사용하는 것도 알 수 있다.\n이렇듯 절차지향과 객체지향 다 장단점이 있어 적절한 곳에 사용해야 한다.\n하지만, 절차지향의 단점을 해결하는 객체지향을 잘 사용해서 코드의 재사용성과 유지보수까지 고려하자.\nReference 파이썬 중급 ","permalink":"http://jeha00.github.io/post/python/python_basic_24_oop/","summary":"절차형 프로그래밍과 객체지향 프로그래밍 각 방식으로 작성하여 직접 차이를 느껴본다.","title":"[TIL] Python basic 24: Procedural Programming vs OOP"},{"categories":["Python"],"content":"0. Introdction [TIL] Python basic 15: module에서 학습했지만, 내용이 빈약하여 별도로 정리한다. 1. __name__ 에 대해 알아보자. 1.1 __name__이란?? The file name is the module name with the suffix .py appended.\nWithin a module, the module’s name (as a string) is available as the value of the global variable __name__\n출처: 파이썬 공식 문서\n위 내용을 요약하면 __name__이란? __name__은 .py인 파이썬 모듈 파일이 가지고 있는 global variable(전역변수)이다.\n그리고, 모듈의 이름을 담고 있다.\n1.2 __name__이 다르게 출력되는 상황 2가지 그리고, 다음 두 가지 상황에서 다르게 출력된다. 첫 번째, script 프로그램이 \u0026lsquo;직접\u0026rsquo; 실행될 때 변수 __name__은 \u0026lsquo;__main__\u0026rsquo; 이다. 두 번째, 스크립트 프로그램이 import될 때 변수 __name__은 import된 모듈 이름이다. 2개의 파일 (hello.py 와 python.py) 을 작성하자. 그리고 이 두 개의 파일을 module로서 import하는 test.py 를 작성하자. 그러면 총 3개의 파일을 작성한 상태다. hello.py, python.py 그리고 test.py의 내용은 다음과 같다. 1 2 3 4 5 6 7 8 9 # hello.py \u0026gt; print(\u0026#34;hello.py: \u0026#34;, __name__) # python.py \u0026gt; print(\u0026#34;python.py: \u0026#34;, __name__) # test.py \u0026gt; import hello \u0026gt; import python 첫 번째 경우 hello.py 와 python.py 를 직접 실행해보겠다. 두 파일 모두 다음과 같이 출력되었다. 1 2 hello.py: __main__ python.py: __main__ 두 번째 경우 test.py 를 실행해보겠다. 아래 코드를 보면 __main__ 이 아닌, import된 모듈명이 출력된다. 1 2 hello.py: hello python.py: python 결론: __name__은 직접 실행될 때 __main__\u0026lsquo;이 출력되거나, import 시에는 import된 module file name이 출력된다.\n하지만, 이걸로 완전히 의문점을 해결되지 않았다. 그러면 __main__은 무엇을 의미하는 것인가??? 2. __main__ 에 대해 알아보자. 2.1 Main Module이란?? 파이썬 공식 문서를 보면 __main__에 대해 다음과 같이 설명한다. the name of the main module is always \u0026ldquo;__main__\u0026rdquo;\nmain module에서의 __name__ 은 항상 \u0026ldquo;__main__\u0026rdquo; 이다.\n출처: Modules\n그러면 main module의 정의는 무엇인가??? main module (the collection of variables that you have access to in a script executed at the top level and in calculator mode)\ntop level에서 실행되는 script 안에 접근 권한을 가지고 있는 변수들의 집합을 말한다.\n출처: 파이썬 공식 문서: Module\n2.2 Top level 이란?? __main__ is the name of the environment where top-level code is run.\n“Top-level code” is the first user-specified Python module that starts running.\nIt’s “top-level” because it imports all other modules that the program needs.\nSometimes “top-level code” is called an entry point to the application.\n__main__은 top-level code 가 운영되는 환경의 이름인데,\nTop-level code는 사용자가 지정한 Python module 중에서 최초로 실행하기 시작하는 Python module로서,프로그램이 필요한 다른 모듈들을 import 하는 module이다. 그래서 \u0026ldquo;top-level code\u0026rdquo; 는 애플리케이션의 관점에서 entry point (시작점) 이라 불린다. __main__이 출력되는 모듈이 entry point라는 걸 알 수 있다. 그리고, 다른 module들을 import 하는 파일을 말한다.\n출처: 파이썬 공식 문서: __main__\n[결론]\n_ __name__ 변수를 통해서 현재 진행되는 파일이 entry point인지, module인지 판단할 수가 있다._\n3. if __name__ == \u0026lsquo;__main__\u0026rsquo; 에 대해 알아보자. 3.1 if __name__ == '__main__' 이란 무엇인가?? 그러면 if __name__ == '__main__ 의미는 다음과 같다. 이 조건문이 있는 파일을 import가 아닌 직접 실행을 한다면 아래 코드들을 실행하라.\n마지막으로 한 예를 들고 끝내겠다. 예시의 출처는 What does if name == \u0026ldquo;main\u0026rdquo;: do?이다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026gt; print(\u0026#34;before import\u0026#34;) \u0026gt; import math \u0026gt; print(\u0026#34;before functionA\u0026#34;) \u0026gt; def functionA(): \u0026gt; print(\u0026#34;Function A\u0026#34;) \u0026gt; print(\u0026#34;before functionB\u0026#34;) \u0026gt; def functionB(): \u0026gt; print(\u0026#34;Function B {}\u0026#34;.format(math.sqrt(100))) \u0026gt; print(\u0026#34;before __name__ guard\u0026#34;) \u0026gt; if __name__ == \u0026#39;__main__\u0026#39;: \u0026gt; functionA() \u0026gt; functionB() \u0026gt; print(\u0026#34;after __name__ guard\u0026#34;) 위 code가 import 되어 실행된다면 다음과 같다. 1 2 3 4 5 before import before functionA before functionB before __name__guard \u0026lt;- after __name__guard \u0026lt;- 직접 실행한다면 다음과 같다. 1 2 3 4 5 6 7 before import before functionA before functionB before __name__guard \u0026lt;- Function A Function B 10.0 after __name__guard \u0026lt;- import되어 실행할 때는 \u0026lt;- 사이에 아무것도 출력되지 않았지만, 직접 실행할 때는 무언가 출력된 걸 확인할 수 있다. if __name__ == '__main__' 조건문에서 출력된 결과물이다. 직접 실행되었기 때문에 출력되었다. 3.2 if __name__ == '__main__' 을 왜 사용하는 걸까?? if __name__ == '__main__' code는 의도치 않고 불필요한 코드를 호출하는걸 방지하기 위한 guard로서 사용한다.\nstack-over-flow What does if__name__ == \u0026lsquo;__main__\u0026rsquo;: do? [TIL] Python basic 15: module 위 두 링크에 따르면 다음과 같은 이유로 작성한다.\n외부 module file을 import 시, import된 파일에 있는 script 중 의도치 않게 호출한 것으로부터 보호하기 위해 사용하는 상용구 코드다. 스크립트에서 이 guard를 생략하면 구체적으로 다음과 같은 문제가 발생한다. 첫 번째, run time 시 의도치 않게 불러온 script에 있는 여러 인자들로 main script가 작동된다. 두 번째, guard를 생략한 script를 저장할 파일에 담아 저장하면, 이 파일을 불러올 때 guard를 생략한 script를 import 할 수 있다. Reference [TIL] Python basic 15: module [python] if __name__ == \u0026lsquo;__main__\u0026rsquo; : 의 정체 자료구조와 함께 배우는 알고리즘 입문 파이썬편 What does if__name__ == \u0026lsquo;__main__\u0026rsquo;: do? 파이썬 공식 문서: Modules 파이썬 공식 문서: __main__ ","permalink":"http://jeha00.github.io/post/python/python_basic_23_ifnamemain/","summary":"'\n_\n_name\n_\n_\u0026rsquo; 과 '\n_\n_main\n_\n_\u0026rsquo; 를 이해한 걸 바탕으로, if\n_\n_name\n_\n_ == '\n_\n_main\n_\n_\u0026rsquo; 에 대해 알아본다.","title":"[TIL] Python basic 23:  if \n_\n_name\n_\n_ == '\n_\n_main\n_\n_'"},{"categories":"Network","content":"0. Introduction HTTP 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식\n강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다.\n이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다.\n학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고자 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다.\n1. HTTP API 설계해보기 1.1 HTTP API 설계에서 중요한 것 API 설계에서 가장 중요한 것은 resource를 식별하는 게 중요하다.\n그 다음으로 해야할 것이 resource와 행위를 분리하는 것 이다.\n회원 정보 관리 API를 만든다고 가정하자.\n회원 목록 조회 회원 조회 회원 등록 회원 수정 회원 삭제 1.2 잘못된 API 설계 사례의 문제점 그러면 초보 개발자인 경우, 다음과 같이 API URI 설계할 수 있다.\n회원 목록 조회 /read-member-list 회원 조회 /read-member-by-id 회원 등록 /create-member 회원 수정 /update-member 회원 삭제 /delete-member 위 방식의 문제점은 URI의 정의를 정확히 살리지 못하는 방법이다.\nURI = Uniform Resource Identifier 가장 중요한 것은 resource 식별 이다.\nresource의 의미는\n회원을 등록하고, 수정하고 조회하는 게 리소스가 아니다. 예) 미네랄을 캐라 -\u0026gt; 미네랄이 resource 회원이라는 개념 자체가 바로 resource다. 그러면 resource를 어떻게 식별하는게 좋을까??\n회원을 등록하고, 수정하고, 조회하는 것을 모두 배제한 다음 회원이라는 resource만 식별하면 된다 -\u0026gt; 회원 resource를 URI에 매핑한다. 1.3 잘못된 API 개선하기 위 사항들을 반영하면 다음과 같다. (resource 식별, URI 계층 구조 활용)\n참고: 계층 구조상 상위를 컬렉션으로 보고 복수단어 사용 권장(member -\u0026gt; members)\n회원 목록 조회 /members 회원 조회 /members/{id} 회원 등록 /members/{id} 회원 수정 /members/{id} 회원 삭제 /members/{id} 그러면 회원 조회부터 삭제는 어떻게 구분할 수 있을까???\nresource와 행위를 분리 하여 구분한다. resource: 회원 행위: 조회, 등록,삭제, 변경 resource는 명사, 행위는 동사 행위는 어떻게 구분할 수 있을까??\nHTTP method를 사용하여 구분한다. HTTP method에 대해 알아보자. 2. HTTP method - GET, POST 2.1 HTTP 주요 method GET: resource 조회\nPOST: 요청 데이터 처리, 주로 등록에 사용\nPUT: 리소스를 대체, 해당 리소스가 없으면 생성\nPATCH: resource 부분 변경\nDELETE: resource 삭제\nHTTP 기타 method\nHEAT: GET과 동일하지만 메시지 바디 부분을 제외하고, 상태 줄과 헤더만 반환 OPTIONS: 대상 리소스에 대한 통신 가능 옵션(메서드)을 설명(주로 CORS에서 사용) CONNECT: 대상 자원으로 식별되는 서버에 대한 터널을 설정 TRACE: 대상 리소스에 대한 경로를 따라 메시지 루프백 테스트를 수행 CONNECT 와 TRACE는 거의 사용안한다. 2.2 HTTP method - GET 1 2 GET /search?q=hello\u0026amp;hl=ko HTTP/1.1 Host: www.google.com resource 조회 (/search?q=hello\u0026amp;hl=ko에 있는 자원을 가져와라.) 서버에 전달하고 싶은 데이터는 query (쿼리 파라미터, 쿼리 스트링)를 통해서 전달 메시지 바디를 사용해서 데이터를 전달할 수 있다. 하지만, 지원하지 않는 곳이 많아서 권장하지 않는다. 실무에서는 GET에 메시지 바디를 안넣는다. resource 조회 예시 클라이언트에서 /members/100 으로 100번 유저를 조회한다. 그 후, 정보를 달라고 GET 요청을 보낸다. 서버에서는 받은 메세지를 분석하여 내부의 유저 정보를 조회한다. 그 후, JSON data 형태로 결과 Response를 만든다. 응답 메세지를 받았고, 정상적으로 받았기에 200 OK status를 가진다. 또한, 회원 정보도 담겨있다. 위 에시에는 JSON이지만, 실제로는 HTML일수도 있고, 다양한다. 2.3 HTTP method - POST 2.3.1 POST란? 1 2 3 4 5 6 POST /members HTTP/1.1 Content-Type: application/json { \u0026#34;username\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 20 } 요청 데이터 처리하는 method 메시지 바디를 통해 서버로 요청 데이터를 전달한다. GET과의 차이점 서버는 요청 데이터를 처리 메시지 바디를 통해 들어온 데이터를 처리하는 모든 기능을 수행한다. 주로 전달된 데이터로 신규 resource 등록, 프로세스 처리에 사용 2.3.2 POST를 사용한 resource 등록 과정 첫 번째: 메세지 전달\n클라이언트는 메세지 바디에 등록할 회원 정보를 JSON형태로 만들어 담는다. 그리고 해당 정보를 서버로 전송한다.\n( 정보를 전달하기 전에, 사전에 서버가 무엇을 할지 미리 약속이 되어 있어야 한다.) 두 번째: 신규 resource 생성\n서버에서 받는 메세지를 분석해 데이터베이스에 등록한다. 이 때 신규 아이디도 생성. 세 번째: 응답 데이터\nLocation이라는 헤더 정보로 회원이 생성된 경로를 첨부한다. 신규회원에 대한 데이터를 바디에 담아서 보내준다. 만들어졌기 때문에 Created라 뜬다. 그리고, 자원의 신규 생성된 URL을 보내준다. 2.3.3 요청 데이터를 어떻게 처리한다는 뜻일까?? 리소스 URI에 POST 요청이 오면, 요청 데이터를 어떻게 처리할지 리소스마다 따로 정해야한다 -\u0026gt; 정해진 것이 없다.\n예를 들어 POST는 다음과 같은 기능에 사용된다. HTML 양식에 입력된 필드와 같은 데이터 블록을 데이터 처리 프로세스에 제공 예) HTML, FORM에 입력한 정보로 회원 가입, 주문 등에서 사용 게시판, 뉴스 그룹, 메일링 리스트, 블로그 또는 유사한 기사 그룹에 메시지 게시 예) 게시판 글쓰기, 댓글 달기 서버가 아직 식별하지 않은 새 resource 생성 예) 신규 주문 생성 기존 자원에 데이터 추가 예) 한 문서 끝에 내용 추가하기 2.3.4 POST method 정리 1. 새 resource 생성(등록)\n서버가 아직 식별하지 않은 새 resource 생성 2. ❗️ 요청 데이터 처리\n단순히 데이터를 생성하거나, 변경하는 것을 넘어서 프로세스를 처리해야 하는 경우 상태가 변하기 위해서 POST를 사용하기 때문에, 새로운 리소스가 생성되지 않을 수 있다. 그렇다 할지라도, 서버에 큰 변화를 일으킬 때는 POST를 생성해야 한다. 예) 주문에서 결제완료 -\u0026gt; 배달시작 -\u0026gt; 배달완료처럼 단순히 값 변경을 넘어 프로세스의 상태가 변경되는 경우 POST의 결과로 새로운 리소스가 생성되지 않을 수도 있음 예) POST/orders/{orderld}/start-delivery (컨트롤 URI) URI를 설계할 때는 resource 단위로 설계해야 하지만, 어쩔 수 없이 행동으로 할 때가 있다. 이 때 동사의 URI가 나올 수 있다. 이 URI를 컨트롤 URI 라 한다. 3. 다른 메서드로 처리하기 애매한 경우\n예) JSON으로 조회 데이터를 넘겨야 하는데, GET 메서드를 사용하기 어려운 경우 애매하면 POST 3. HTTP method - PUT,PATCH,DELETE 3.1 HTTP method - PUT 1 2 3 4 5 6 PUT /members/100 HTTP/1.1 Content-Type: application/json { \u0026#34;username\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 20 } resource\n리소스가 있으면 대체하고, 없으면 생성한다. (Overwirte) POST와의 차이점: 클라이언트가 리소스를 식별한다.\n클라이언트가 resource 위치를 알고 URI 지정한다. 예) 리소스가 없는 경우 /members/100 이라는 신규 리소스를 생성한다.\n신규 리소스의 내용은 다음과 같다.\n1 { \u0026#34;username\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 20 } 예) 리소스가 있는 경우 /members/100 경로에 아래 내용으로 리소스가 있다면\n1 { \u0026#34;username\u0026#34;: \u0026#34;young\u0026#34;, \u0026#34;age\u0026#34;: 50 } PUT method로 보내면 다음과 같이 대체된다.\n1 { \u0026#34;username\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 20 } 하지만 아래 내용으로 리소스를 보낸다면 아래 내용으로 완전히 대체된다.\nusername 필드가 삭제된다.\n1 { \u0026#34;age\u0026#34;: 50 } 3.2 HTTP method - PATCH 1 2 3 4 5 PUT /members/100 HTTP/1.1 Content-Type: application/json { \u0026#34;age\u0026#34;: 50 } 그러면 기존 리소스를 갈아치우는 게 아니라, 수정하고 싶으면 어떻게 해야할까??\nPATCH method 를 사용한다.\n만약 PATCH가 지원되지 않은 서버라면 POST를 사용한다. PUT과 양식은 비슷하지만, 서버에서 PATCH로 전송된 경우 필요한 부분만 업데이트된다.\n그 결과, PUT과는 다르게 회원 정보에서 age만 변경된다.\n1 { \u0026#34;age\u0026#34;: 50 } 3.3 HTTP method - DELETE 1 2 DELETE /members/100 HTTP/1.1 Host: localhost:8080 클라이언트가 보내면 위 resource url에 해당되는 회원 정보를 서버에서 삭제한다. 4. HTTP method의 속성 HTTP 메서드별 속성 메서드의 속성\n안전(Safe Methods) 멱등(idempotent Methods) 캐시가능(Cacheable Methods) 4.1 안전(Safe) 호출해도 리소스를 변경하지 않는 속성\nGET은 단지 조회만 하기 때문에 안전하지만, 나머지는 아니다. Q. 그래도 변경을 요청하면 변경되진 않아도, 로그에 계속 남게되어 터지지 않을까?? A: 안전은 해당 리소스만 고려한다. 그런 부분까지 고려하지 않는다. 4.2 멱등(Idempotent Methods) f(f(x)) = f(x) 몇 번을 호출하든 결과가 똑같은 속성 멱등 메서드\nGET: 몇 번을 조회하든 같은 결과가 조회된다. PUT: 결과를 대체한다. 따라서 같은 요청을 여러번 해도 최종 결과는 동일. DELETE: 결과를 삭제한다. 같은 요청을 여러번 해도 결과는 동일. POST : 멱등이 아니다! 두 번 호출하면 같은 결제가 중복해서 발생할 수 있다. 활용\n자동 복구 메커니즘 서버가 TIMEOUT 등으로 정상 응답을 못 주었을 때, 클라이언트가 같은 요청을 다시 해도 되는가?? 판단근거 멱등은 외부 요인으로 인해 리소스가 변경되는 건 고려하지 않는다.\n내가 호출하는 것에 한정한다. 예시: 사용자1: GET -\u0026gt; username:A, age:20 사용자2: PUT -\u0026gt; username:A, age:30 사용자1: GET -\u0026gt; username:A, age:30 -\u0026gt; 사용자2의 영향으로 바뀐 데이터 조회 이런 부분은 멱등하지 않다고 생각하자. 4.3 캐시가능(Cacheable Methods) 응답 결과 리소스를 캐시해서 사용해도 될까? GET, HEAD, POST, PATCH 캐시가 가능하지만, 실제로는 GET, HEAD 정도만 캐시로 사용한다. POST, PATCH는 본문 내용까지 캐시 키로 고려해야 하는데, 구현이 쉽지 않다. GET은 URL만 캐시 키로 관리하면서 구현이 쉽기에 사용이 편하다. Reference 모든 개발자를 위한 HTTP 웹 기본지식 HTTP 메서드 ","permalink":"http://jeha00.github.io/post/network/http/http_4/","summary":"HTTP method인 GET, POST, PUT, PATCH, DELETE 그리고 속성에 대해 알아본다.","title":"[TIL] HTTP method"},{"categories":"Network","content":"0. Introduction HTTP 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 이다.\n강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다.\n이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다.\n학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고자 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다.\n1. 모든 것이 HTTP 1.1 HTTP란? (지금은 HTTP 시대!) : 링크를 통해 HTML 같은 문서를 연결할 수 있는 프로토콜을 의미한다. 하지만, 이제는 문서 뿐만 아니라 HTTP 메세지에 모든 것을 전송한다.\nHTML, TEXT IMAGE, 음성, 영상, 파일 JSON, XML (API) 거의 모든 형태의 데이터를 저장하여 전송 가능하다. 서버 간에 데이터를 주고 받을 때도 대부분 HTTP를 사용한다. 1.2 HTTP 역사 (HTTP/1.1을 기준으로 학습) HTTP/0.9 1991년: GET 메서드만 지원, HTTP 헤더X HTTP/1.0 1996년: 메서드, 헤더 추가 HTTP/1.1 1997년: 가장 많이 사용, 우리에게 가장 중요한 버전 HTTP 강의는 이 버전을 기준으로 설명한다. RFC2068 (1997) -\u0026gt; RFC2616 (1999) -\u0026gt; RFC7230~7235 (2014) 현재는 RFC7230 버전부터 본다. HTTP/2 2015년: 성능 개선 HTTP/3 진행중: TCP 대신에 UDP 사용, 성능 개선 1.3 기반 프로토콜 TCP 기반으로 작동하는 프로토콜은 HTTP/1.1, HTTP/2 다. UDP 기반으로 작동하는 프로토콜은 HTTP/3 다. 기본적으로 HTTP/1.1에서 개선된 것이므로 우리는 HTTP/1.1을 공부한다. 현재 HTTP/1.1 주로 사용한다. HTTP/2, HTTP/3도 점점 증가하고 있다. [HTTP/3가 UDP 기반인 이유]\n기본 TCP는 3 way handshake로 신뢰성이나 연결성이 보장되지만, 속도가 떨어진다. 그래서 UDP를 애플리케이션 레벨에서 재설계되어 나온게 HTTP/3다.\n사이트에서 기반 프로토콜을 확인하려면 검사(F12)에 들어가 Network tab을 클릭 한다. 하단에 Name tab을 오른쪽 마우스 클릭하여 Protocol을 체크한다. h3는 http/3 고, h2는 http/2 를 의미한다. 구글은 h3를 사용하고, 네이버는 h2를 사용한다. 1.4 HTTP 특징 클라이언트 서버 구조 무상태 프로토콜(stateless), 비연결성 HTTP 메시지 단순함, 확장 가능 HTTP는 단순하고, 스펙도 읽어볼만 하다. HTTP 메시지도 매우 단순하다. 크게 성공하는 표준 기술의 하나의 예로, 단순하지만 확장 가능한 기술이다. 각 특징들에 대해 알아보자.\n2. 클라이언트 서버 구조 HTTP는 클라이언트와 서버 구조로 되어있다.\n클라이언트는 HTTP 메세지를 만들어서 서버에 요청(request)을 보낸 후, 서버로부터 응답(response)이 올 때까지 기다린다.\n서버는 클라이언트로부터 온 요청(request)에 대한 결과를 만들어서 응답(response)한다.\n[클라이언트 서버 구조가 중요한 이유]\n독립적 구조 -\u0026gt; 각자의 역할에 집중 옛날에는 클라이언트와 서버가 분리되어 있지 않고, 합쳐져 있었다. 그후 비지니스 로직과 데이터는 서버가 담당하여 집중하고, 클라이언트는 UI 사용성에 집중했다. 이로 인해서 클라이언트와 서버는 각각 독립적으로 진화할 수 있었다. 3. Stateful, Stateless 3.1 Stateful \u0026lsquo;Stateful\u0026rsquo; 이란?? \u0026lsquo;한 서버\u0026rsquo;가 클라이언트의 이전 상태를 보존(기억)하기 때문에, 클라이언트의 요청에 응답하는 서버가 항상 같은 서버로 유지 되어야 하는 상태를 말한다.\n\u0026lsquo;Stateful(상태 유지)\u0026lsquo;의 문제점은 무엇일까?? 서버가 멈추거나 하는 여러 이유로 해당 서버를 쓸 수가 없는 상황이 발생했다. 다른 서버를 이용해야 한다. 이런 경우, 새로운 서버에서 이전 서버에 가지고 있던 상태값들을 가지고 있지 않아 에러가 발생된다.\n예시: 고객을 클라이언트, 점원을 서버라고 생각하자.\n서버가 문제 없이 유지되는 경우 1 2 3 4 5 6 7 8 9 고객: 이 `노트북` 얼마인가요? 점원: 100만원 입니다. (노트북 상태 유지) 고객: `2개` 구매하겠습니다. 점원: 200만원 입니다. 신용카드, 현금중에 어떤 걸로 구매 하시겠어요? (노트북, 2개 상태 유지) 고객: `신용카드`로 구매하겠습니다. 점원: 200만원 결제 완료되었습니다. (노트북, 2개, 신용카드 상태 유지) 서버가 바뀔 경우 1 2 3 4 5 6 7 8 고객: 이 `노트북` 얼마인가요? 점원 A: 100만원 입니다. 고객: `2개` 구매하겠습니다. 점원 B: ? 무엇을 2개 구매하시겠어요? (상태유지 X) 고객: `신용카드`로 구매하겠습니다. 점원C: ? 무슨 제품을 몇 개 신용카드로 구매하시겠어요? (상태 유지 X) 한 서버에서만 클라이언트의 상태를 기억하기 때문에, 서버가 변경되면 기존 서버에 저장된 클라이언트의 상태를 기억하지 못하여 에러가 발생했다. 그래서 항상 같은 서버로 유지 되어야 한다.\n3.2 Stateless Stateless 란?? 서버가 클라이언트의 이전 상태를 보존(기억)하지 않고, 클라이언트가 요청할 때마다 매번 모든 상태 값들을 전달 하기 때문에, 서버 변경이 용이 하다.\n예시 고객을 클라이언트, 점원을 서버라고 생각하자.\n서버가 문제 없이 유지되는 경우\n1 2 3 4 5 6 7 8 고객: 이 `노트북` 얼마인가요? 점원: 100만원 입니다. 고객: `노트북 2개` 구매하겠습니다. 점원: 노트북 2개는 200만원 입니다. 신용카드, 현금중에 어떤 걸로 구매 하시겠어요? 고객: `노트북 2개`를 `신용카드`로 구매하겠습니다. 점원: 200만원 결제 완료되었습니다. 서버가 바뀔 경우\n1 2 3 4 5 6 7 8 고객: 이 \u0026#39;노트북\u0026#39; 얼마인가요? 점원A: 100만원 입니다. 고객: \u0026#39;노트북 2개\u0026#39; 구매하겠습니다. 점원B: 노트북 2개는 200만원 입니다. 신용카드, 현금중에 어떤 걸로 구매 하시겠어요? 고객: \u0026#39;노트북 2개\u0026#39;를 \u0026#39;신용카드\u0026#39;로 구매하겠습니다. 점원C: 200만원 결제 완료되었습니다. 클라이언트가 모든 상태 값을 서버에 전달하기 때문에, 서버가 중간에 바뀌어도 문제가 되지 않는다. 항상 같은 서버로 유지될 필요없다. 그래서 서버 변경이 용이하기 때문에, stateless 는 무한한 서버 증설이 가능하다.\n무한한 서버 증설로 인한 이점 그러면 서버 증설이 무한히 가능하다면 어떤 이점이 있을까???\n같은 기능을 하는 서버들 안에서 서버의 수평 확장(scale out) 에 유리하다.\n🔆 stateless의 한계와 실무 방식 좋은 이점들이 많지만 실무 한계가 존재하여, 모든 것을 stateless(무상태) 로 할 수 없다 실무 한계가 존재한다.\n무상태 예시: 로그인이 필요 없는 단순한 서비스 소개 화면 상태 유지 예시: 로그인 로그인한 사용자의 경우, 로그인 했다는 상태를 서버에 유지해야 한다. 일반적으로 브라우저 쿠키와 서버 세션 등을 사용해서 상태를 유지한다. 그래서 상태유지는 최소한만 사용하고, 최대한 무상태로 서버를 설계한다.\n❗️ 수평 확장(scale out)과 수직 확장(scale up)의 차이: 스케일 아웃과 스케일 업\n3.3 🔆 정리 http는 stateful, stateless 두 상태를 모두 사용한다.\nStateful (상태유지): 중간에 서버가 변경되면 안된다.\n만약 서버가 변경되야 한다면 상태 정보를 전부 다른 서버에게 미리 알려줘야 한다. Stateless (무상태): 중간에 서버가 바뀌어도 된다.\n그래서 서버는 수평적 확장에 유리한다. (scale out) 하지만 모든 걸 무상태로 할 수 없기 때문에, 무상태로 서버를 최대한 설계하며, 상태 유지로 서버를 최소한 설계한다. 4. 비연결성 (connectionless)과 지속 연결 HTTP/1.0 에서는 지속 연결(persistent connection) 기능이 없었지만, HTTP/2.0 부터는 추가되었다.\n지속 연결을 사용하기 위해서는 Connection: keep-alive 을 HTTP 헤더에 추가한다.\n4.1 연결을 유지하는 모델 TCP/IP 연결로 새로운 클라이언트와 연결하면서 이전 클라이언트와의 연결을 유지한다. 연결된 클라이언트가 놀고 있어도 서버가 유지해야 하는게 단점이다. 왜냐하면 서버의 자원이 연결을 유지하는데 계속 소모 되기 때문이다. 4.2 연결을 유지하지 않는 모델 (비연결성) TCP/IP 연결 후, 클라이언트와 서버의 단 하나의 요청 응답 흐름이 끝나면 연결을 바로 종료한다. 그리고 다른 클라이언트와 연결 시, 이전 클라이언트와의 연결은 유지하지 않는다. 즉, 서버는 연결 유지를 하지 않아 최소한의 자원만 사용 할 수 있다. HTTP의 비연결성 장점 HTTP는 기본이 연결을 유지하지 않는 모델이고, 일반적으로 초 단위 이하의 빠른 속도로 응답한다. 그래서 1시간 동안 수천명이 서비스를 사용해도 실제 서버에서 동시에 처리하는 요청은 수십개 이하로 매우 적다. 예) 웹 브라우저에서 계속 연속해서 검색 버튼을 누르지 않는다. 즉, 서버 자원을 매우 효율적으로 사용할 수 있다. 비연결성의 단점과 해결 방법 단점 TCP/IP 연결을 새로 맺어야 하기 때문에, 3 way handshake 시간이 추가된다. 웹 브라우저로 사이트를 요청하면 HTML 뿐만 아니라 JavaScript, css, 추가 이미지 등 수많은 자원이 함께 다운로드된다. 해결 방법 지금은 HTTP 지속 연결(Persistent Connections)로 문제 해결했다. HTTP/2 와 HTTP/3에서 더 많은 최적화를 한다. 4.3 HTTP 지속 연결: 비연결성의 한계 해결 방법 비연결성의 한계를 해결한 방법인 HTTP 지속 연결에 대해 알아보자.\nHTTP 초기에는 모든 자료에 대해서 비연결성으로 \u0026lsquo;연결 -\u0026gt; 응답 -\u0026gt; 종료\u0026rsquo; 를 반복하여, 시간이 대략적으로 1초 가량 소모되었다고 한다.\n아래 이미지를 참조하자.\n그러면 HTTP 지속 연결로 어떻게 변했을까??\n클라이언트는 서버와 연결을 한 다음, 필요한 자원들을 모두 다운받을 때까지 요청/응답이 반복된 뒤 종료된다.\n옛날에는 문서를 주로 주고 받았다면 시대가 발전해가면서 이미지, 동영상 이외의 파일을 보내는 작업들이 많아지면서 지속 연결이 필요해졌다.\n또한, HTTP/2,3으로 오면서 더 빨라졌다. 특히, HTTP 3으로 오면서 UDP를 사용하여 연결 속도 자체도 줄어들었다.\n지속 연결을 사용하고 싶다면 http header에 connection: keep-alive를 담아 보낸다.\n4.4 🔆 실무에서 HTTP 지속 연결하는 경우 실무 상황에서 특정 시간에 발생하는 대용량 트래픽의 경우, 수만명이 동시 요청하기 때문에 무상태와 HTTP 지속 연결로 서버를 설계해야 대응할 수 있는 부분이 매우 많아진다.\n예) 선착순 이벤트, 명절 KTX 예약, 학과 수업 등록, 선착순 할인 이벤트 5. HTTP 메시지 HTTP 메시지 구조를 알아보자. 공백 라인은 아래 순서로, 필수로 존재해야 한다. 5.1 시작 라인(start line) start line은 요청 메시지와 응답 메시지 로 나눠진다.\nstart line = request - line (요청 메시지) / status - line (응답 메시지)\nrequest-line = method SP(공백) request-target SP HTTP-version CRLF(엔터) status-line = HTTP-version SP status-code SP reason-phrase CRLF 5.1.1 요청 메시지 start line = request - line (요청 메시지) / status - line (응답 메시지)\nrequest-line = method SP(공백) request-target SP HTTP-version CRLF(엔터)\nHTTP method (GET /search?q=hello\u0026amp;hl=ko HTTP/1.1)\n종류: GET, POST, PUT, DELETE \u0026hellip; 서버가 수행해야 할 동작 지정 GET: 리소스 조회 / POST: 요청 내역 처리 request-target (GET /search?q=hello\u0026amp;hl=ko HTTP/1.1)\nabsolute-path[?query] (절대경로[?쿼리]) 절대경로= \u0026ldquo;/\u0026rdquo; 로 시작하는 경로 참고: *, http://...?x=y 와 같이 다른 유형의 경로지정 방법도 있다. HTTP verison (GET /search?q=hello\u0026amp;hl=ko HTTP/1.1)\n5.1.2 응답 메시지 start line = request - line (요청 메시지) / status - line (응답 메시지) status-line = HTTP-version SP status-code SP reason-phrase CRLF HTTP version HTTP 상태 코드: 요청 성공, 실패를 나타냄 200: 성공 400: 클라이언트 요청 오류 500: 서버 내부 오류 이유 문구: 사람이 이해할 수 있는 짧은 상태 코드 설명 글 5.2 HTTP header header - field = field - name \u0026ldquo;:\u0026rdquo; OWS field - value OWS\n(OWS: 띄어쓰기 허용)\nfield - name: 대소문자 구분 없음 field - value: 대소문자 구문 있음 용도 HTTP 전송에 필요한 모든 부가정보가 담겨져 있다. 예) 메시지 바디의 내용, 크기, 압축, 인증 예) 요청 클라이언트(브라우저) 정보, 서버 애플리케이션 정보, 캐시 관리 정보 표준 헤더가 너무 많다. (https://en.wikipedia.org/wiki/List_of_HTTP_header_fields) 필요한 경우, 임의의 헤더 추가 가능 5.3 HTTP message body 실제 전송할 데이터 HTML 문서, 이미지, 영상, JSON 등등 byte로 표현할 수 있는 모든 데이터 전송 가능 HTTP 정리 HTTP 메시지에 모든 것을 전송한다. HTTP 역사: HTTP/1.1을 기준으로 학습한다. 클라이언트 서버 구조이다. stateful과 무상태 프로토콜(stateless) 모두 사용한다. HTTP 메시지 단순하며 확장 가능하다. 지금은 HTTP 시대다. Reference 모든 개발자를 위한 HTTP 웹 기본지식 HTTP 기본\u0026gt; 스케일 아웃과 스케일 업 ","permalink":"http://jeha00.github.io/post/network/http/http_3/","summary":"HTTP란 무엇이고, HTTP의 특징인 클라이언트 서버 구조, stateless, connectionless, HTTP mesage에 대해 알아본다.","title":"[TIL] HTTP basic"},{"categories":"Network","content":"0. Introduction HTTP에 관한 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식\n강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다.\n이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다.\n학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고 시작하고 싶어 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다.\n1. URI URI (Uniform Resource Identifier)란?? 로케이터(locater), 이름(name) 또는 둘 다 추가로 분류될 수 있다. from https://www.ietf.org/rfc/rfc3986.txt - 1.1.3. URI, URL, and URN 1.1 URI, URL, URN의 각 의미 URI의 단어 뜻\n통일된 방식으로 다른 자원들과 구별할 수 있는 정보 Uniform: 리소스를 식별하는 통일된 방식 Resource: URI로 식별하는 수 있는 모든 자원으로, 제한 없다. Identifier: 다른 항목과 구분하는데 필요한 정보 (식별자) URL\nLocator: resource가 있는 위치를 지정한다. URN\nName: resource에 이름을 부여한다. urn:isbn:8960777331 (어떤 책의 isbn URN) URN 이름만으로 실제 리소스를 찾을 수 있는 방법이 보편화 되지 않았다. 위치는 변할 수 있지만, 이름은 변하지 않는다. 그래서 앞으로 URI를 URL과 같은 의미로 이야기하겠다\n1.2 URL 분석 URL 전체 문법 구조\nscheme://[userinfo@]host[:port][/path][?query][#fragment]\n예시: https://www.google.com:443/search?q=hello\u0026amp;hl=ko 프로토콜: https 호스트명: google.com 포트번호: 443 path: \\search query parameter: ?q=hello\u0026amp;hl=ko 1.2.1 scheme scheme://[userinfo@]host[:port][/path][?query][#fragment]\nhttps://www.google.com:443/search?q=hello\u0026amp;hl=ko\n주로 프로토콜을 사용한다. 프로토콜이란 어떤 방식으로 자원에 접근할건지 약속된 규칙이다. 예: http, https, ftp 등등 http는 80포트, https는 443포트를 주로 사용하며 포트는 생략 가능하다. https는 http에 보안 사용을 추가한 것이다. (HTTP Secure) 1.2.2 userinfo scheme:// [userinfo@] host[:port][/path][?query][#fragment]\nhttps://www.google.com:443/search?q=hello\u0026amp;hl=ko\nURL에 사용자 정보를 포함해서 인증할 때 사용한다. 하지만 거의 사용하지 않는다. 1.2.3 host scheme://[userinfo@]host[:port][/path][?query][#fragment]\nhttps:// www.google.com :443/search?q=hello\u0026amp;hl=ko\n호스트명이다. domain 명 또는 IP 주소를 직접 입력한다. 1.2.4 PORT scheme://[userinfo@]host [:port][/path][?query][#fragment]\nhttps://www.google.com :443 /search?q=hello\u0026amp;hl=ko\n접속 포트 일반적으로 생략한다. 생략시 http는 80, https는 443이다. 1.2.5 path scheme://[userinfo@]host[:port][/path][?query][#fragment]\nhttps://www.google.com:443 /search ?q=hello\u0026amp;hl=ko\n리소스의 경로다. 계층적 구조로 되어있다. /home/file1.jpg /members /members/100, /item/iphone12 1.2.6 query scheme://[userinfo@]host[:port][/path][?query][#fragment]\nhttps://www.google.com:443/search ?q=hello\u0026amp;hl=ko\nkey = value 형태로 되어 있다. ?로 시작하며 \u0026amp;로 추가 가능하다. ex) ?keyA=valueA\u0026amp;keyB=valueB query parameer, query string 등으로 불린다. 웹서버에 제공하는 파라미터, 문자형태다.\n1.2.7 fragment scheme://[userinfo@]host[:port][/path][?query][#fragment]\nhttps://docs.spring.io/spring-boot/docs/current/reference/html/gettingstarted.html #getting-started-introducing-spring-boot\nhtml 내부 북마크 등에 사용한다. 서버에 전송하는 정보가 아니다. 2. 웹 브라우저 요청 흐름 다음 URL을 가지고 https://www.google.com:443/search?q=hello\u0026amp;hl=ko 웹 브라우저가 어떻게 요청해서 진행되는지 흐름을 파악해보자.\nDNS 조회: google.comd을 DNS에서 조회하여 해당 IP 주소를 찾는다. HTTPS PORT는 생략한다. 443 HTTP 요청 메시지를 클라이언트가 생성한다. HTTP 요청 메시지는 다음과 같다. 그러면 \u0026lsquo;Introduction 1: Internet Network\u0026rsquo; 에서 학습한 과정이 진행된다.\nHTTP 메시지 전송 resource 요청 시, Application layer에서 HTTP 메세지를 생성한다. 3 way handshake를 통해 socket에 연결한다. socket library를 통해 transport layer으로 데이터를 전송한다. transport layer에서 HTTP를 포함한 TCP 정보를 씌운다. Internet layer에서 TCP 정보를 포함하는 IP 패킷을 생성한다. 패킷이 도착하면 서버는 패킷 내부 HTTP method를 해석하여 정보에 맞는 동작을 한다. 서버에서 HTTP 응답 메세지를 생성한다. 클라이언트에서는 응답 메세지를 받아 HTML 렌더링을 한다. Reference 모든 개발자를 위한 HTTP 웹 기본지식 URI와 웹 브라우저 요청 흐름 ","permalink":"http://jeha00.github.io/post/network/http/http_2/","summary":"URI, URL, URN 에 대해 알아보고, 웹 브라우저의 요청 흐름에 대해 알아본다.","title":"[TIL] HTTP intro. 2: URI 와 웹 브라우저 요청 흐름"},{"categories":"Network","content":"0.Introduction HTTP에 관한 학습내용의 기본 출처는 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 이다. 강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다.\n이 강의는 HTTP에 대한 웹 기본지식으르 설명하는 강의이므로, 내용이 간략할 수 있다.\n프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고 시작하고 싶어 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 학습한다.\n1. IP에 대해서 컴퓨터는 랜선 또는 인터넷 망을 통해서 통신한다. 그리고 인터넷 망은 수 많은 서버들로 구성되어 있으며, 이 서버들을 node(노드)라 한다.\n그러면 수 많은 node들을 거쳐서 \u0026lsquo;어떻게\u0026rsquo; data를 보낼 수 있을까??\n바로 IP 라는 규약을 통해서 보낸다.\n1.1 IP란?? Internet Protocol 약어로, 인터넷 데이터 통신을 원활히 하기 위해 필요한 통신 \u0026lsquo;규약\u0026rsquo;\nIP의 역할은\n지정한 IP 주소로, packet이라는 통신 단위로, 데이터를 전달하는 역할이다. 그래서, 원하는 서버와 클라이언트에 데이터가 도달하기 위해서는 컴퓨터를 구분하는 고유 IP 주소(IP address)를 부여받아야 한다. 이 IP 주소의 형식은 100.100.100.1 같이 각 부분을 점으로 구분하여 표현한다.\nIP 주소 형식에 대해서도 IPv4, IPv6 로 분류된다. IPv 는 Internet Protocol version 을 의미한다. 1.2 Packet이란? 수화물을 의미하는 Package와 덩어리를 의미하는 bucket의 합성어로, 통신 단위 packet에는 여러 데이터가 담겨져 있지만, 기본적으로 \u0026lsquo;주소지 정보(출발지의 IP 주소, 도착지의 IP 주소)\u0026rsquo; 그리고, 전달하려는 \u0026lsquo;전송 데이터\u0026rsquo;가 있다.\n인터넷 망을 구성하는 node들은 다 IP를 따르기 때문에, node는 출발지가 어디고, 어디가 도착지인지 이해할 수 있다. 그래서 IP를 참고하여 서로 packet을 던지면서 원하는 목적지로 보내진다.\n위의 이미지는 클라이언트의 패킷을 전달하는 내용이다.\n서버의 패킷을 전달하는 것도 동일한 원리다.\n2. IP 문제점의 해결책: TCP 이 IP는 3가지 문제점(한계)이 있다.\n비연결성 문제\n상대방이 받을 수 없는 상태여도 패킷을 전송한다. 패킷을 받는 대상이 없거나 (컴퓨터가 off된 경우), 서비스 불능 상태여도 패킷을 전송한다. 연결이 안되도 보내지는 문제점이 존재한다. ex) 우편물을 A 주소로 보냈지만, 도착해서 보니 A 주소에 집이 없는 경우를 말한다. 비신뢰성 문제\n손실 문제: packet이 전송되는 과정에 중간에 사라지는 경우 ex) 노드 서버에 도착했는데, 갑자기 케이블이 끊어지는 경우 순서 바뀜 문제: packet의 용량 문제로 나눠 보낼 때 순서에 문제가 발생한 경우 프로그램 구분 문제\n한 IP 주소에서 2개 이상의 application을 사용하고 있을 때, 무슨 application에 관한 정보인지 어떻게 구분하는가?? 2.1 인터넷 프로토콜 스택의 4계층 이를 해결한 것이 바로 TCP 다.\nTCP에 대해 알기에 앞서 인터넷 프로토콜 스택의 4계층에 대해 알아보자.\n인터넷 프로토콜은 4계층으로, 순서는 애플리케이션(응용) 계층 \u0026gt; 전송 계층 \u0026gt; 인터넷 계층 \u0026gt; 네트워크 인터페이스 순으로 구성된다.\n애플리케이션 계층(Application layer) - HTTP, FTP 전송계층(Transport layer) - TCP, UDP 인터넷 계층(Internet layer) - IP 네트워크 인터페이스 계층(Network Access layer) 이 계층 순서로 어떻게 packet을 보내는지 알아보자.\nresource 요청 시, Application layer에서 HTTP 메세지를 생성한다.\n-\u0026gt; 3 way handshake를 통해 socket에 연결한다.\n-\u0026gt; socket library를 통해 transport layer 계층으로 데이터를 전송한다.\n-\u0026gt; transport layer에서 HTTP를 포함한 TCP 정보를 씌운다.\n-\u0026gt; Internet layer에서 TCP 정보를 포함하는 IP 패킷을 생성한다.\n-\u0026gt; IP 패킷 정보가 인터넷을 거쳐서 서버에 도착한다.\n-\u0026gt; IP 패킷이 서버에 도착하면 IP 패킷과 TCP 세그먼트는 버리고, HTTP 메세지를 서버가 해석한다.\n-\u0026gt; HTTP 응답 메시지를 동일한 방식으로 packet을 생성하여 응답 패킷을 전달한다.\n-\u0026gt; 수 많은 노드를 통해서 응답 패킷이 도착하면, 웹 브라우저가 HTML 렌더링하여 화면에 보여준다.\nsocket이란??\napplication layer와 transport layer 사이에 위치하여, process가 메시지를 송신하고 수신할 수 있도록 API를 제공해주는 역할을 한다. TCP 정보와 IP packet을 생성한 데이터 안에 담겨진 구체적인 내용은 다음과 같다.\n2.2 IP 문제점의 해결책: TCP TCP (Transmisstion Control Protocol)는 전송 제어 프로토콜로, IP의 3가지 문제점에 대한 해결책이다. TCP에 여러 특징들이 있지만, 위 문제점을 해결하는 3가지 특징에 대해 중점적으로 알아보자.\n2.2.1 연결지향 - TCP 3 way handshake (가상 연결) 클라이언트가 서버에 데이터를 전송하기 전에 \u0026lsquo;연결과정\u0026rsquo;을 거친다. 이 과정으로 IP의 비연결성 문제를 해결한다.\n첫 번째, 클라이언트가 서버에 접속 요청(SYN)한다. 접속 요청하는 걸 SYN(Synchronization) 이라 한다. 두 번째, 그 후 서버는 클라이언트의 요청을 수락(ACK)한다. 서버도 클라이언트에게 접속 요청(SYN)한다. 요청을 수락하는 걸 ACK(Acknowledgement) 라 한다. 세 번째, 클라이언트가 서버의 접속 요청에 수락(ACK)한다. 이 3가지 단계를 거친 후, 클라이언트가 서버에 데이터를 전송한다. 그래서 SYN -\u0026gt; SYN + ACK -\u0026gt; ACK 순서로 3 way handshake가 진행된 후, 데이터를 전송한다.\n하지만, 때로는 세 번째 단계 ACK할 때 데이터를 함께 전송한다.\n3 way handshake 방식은 물리적으로 직접 연결된 상태가 아니라, 논리적으로 연결된 상태이다. 이 의미는 클라이언트와 서버 사이에 무수히 많은 노드들을 거쳐서 연결된 것을 의미한다. 물리적으로 직접 연결된 상태라는 건 클라이언트와 서버가 직섭 랜선으로 연결된 경우를 말한다.\n2.2.2 데이터 전달 보증 데이터를 전송하면 수신 확인 메세지를 클라이언트에게 보내준다. IP의 \u0026lsquo;비신뢰성\u0026rsquo; 문제를 해결한다.\n2.2.3 순서 보장 생성한 HTTP data에 TCP 정보를 씌울 때, 순서 정보가 들어가기 때문에, 데이터를 받고 나서 의도한 순서대로 온 건지 판단할 수 있다. IP의 \u0026lsquo;순서 바뀜\u0026rsquo; 문제를 해결한다.\n3. TCP 문제점의 해결책: UDP IP의 여러 문제점을 해결하는 TCP이지만, 위에 TCP segment에 들어가는 정보들처럼 정보양이 많기 때문에 시간이 오래 걸리고, 최적화가 어렵다. 또한, 인터넷 자체도 이미 TCP 기반이라 다듬을 수 없다. 그래서 UDP를 최적화하여 속도를 증가시킬 수 있다. 최근에 이 UDP가 뜨고 있다. 웹 브라우저가 TCP handshake 과정을 줄일려고 하기 때문이다.\nTCP의 속도 문제를 해결할 수 있는게 UDP(User Datagram Protocol)이다. 데이터를 \u0026lsquo;데이터그램 단위\u0026rsquo;로 처리하는 프로토콜이란 의미다. 연결지향 X, 데이터 전달 보증과 순서보장 X 지만, 단순하고 빠르다. IP와 거의 같지만, 차이점은 PORT와 checksum 기능이 있다. 그리고 바로 이 PORT라는 기능이 IP의 세 번째 문제점을 해결해준다.\n4. Port와 DNS란 무엇인가?? 4.1 Port란? 한 IP에서 여러 Application을 사용하고 있을 때, 데이터를 원하는 Application으로 보내기 위해서 PORT 가 필요하다. 이 port 정보는 TCP 세그먼트에 포함되어 있다.\n그래서 IP packet에 있는 IP 주소로 원하는 클라 또는 서버에 도달한다. 그리고, 클라 또는 서버 안에 원하는 Application에 데이터를 제공하기 위해서 PORT 정보를 활용한다.\nPort number는\n0 ~ 65535번까지 할당이 가능하다. 0 ~ 1023번은 잘 알려진 포트이기 때문에, 사용하지 않는 것이 낫다. FTP - 20, 21 TELNET - 23 HTTP - 80 HTTPS - 443 위 이미지를 예를 들어 서버 IP 200.200.200.3 에서 클라이언트의 웹 브라우저 요청에 응답하기를 원한다면 도착지 IP는 100.100.100.1 이고, PORT는 10010 이다.\n4.2 DNS란? DNS는 Domain Name System으로, 기억하기 어렵고 변경될 수 있는 IP address 대신에 Domain Name을 사용하면 DNS에서 이 Domain name에 해당되는 IP주소로 응답하여 접속하는 시스템이다.\nReference 모든 개발자를 위한 HTTP 웹 기본지식 1. 인터넷 네트워크 Application layer Socket ","permalink":"http://jeha00.github.io/post/network/http/http_1/","summary":"HTTP를 학습하기 위해 사전지식으로 IP,TCP/UDP, PORT, DNS를 알아본다.","title":"[TIL] HTTP intro. 1: Internet network"},{"categories":["Python"],"content":"1. Error 종류와 원인 Python basic 과정 강의를 끝내고, 간단한 프로젝트로 Hangman game 만들기를 해봤다. 그 과정에서 발생한 오류를 기록하고자 한다. 만드는 과정에서 모르는 에러가 발생했다. 바로 이 에러(: TypeError: 'NoneType' object is not subscriptable) 다. 에러가 발생한 코드는 다음과 같다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; import csv \u0026gt; import random \u0026gt; words = [] \u0026gt; with open(\u0026#39;./resource/word_list.csv\u0026#39;, \u0026#39;r\u0026#39;, encoding = \u0026#39;utf-8\u0026#39;) as f: \u0026gt; reader = csv.reader(f) \u0026gt; next(reader) \u0026gt; for v in reader: \u0026gt; words.append(v) \u0026gt; q = random.shuffle(words) # 이 line에서 에러가 발생했다. \u0026gt; print(q[0]) 2. Error 해결과정 위 코드를 작성한 이유는 words 의 성분들을 섞은 상태로 다른 변수에 할당하고 나서, Hangman game의 답을 random으로 q에서 뽑아내고자 했다. 지금 보면 터무니 없는 코드로 당연히 오류날만한 부분이었고, 너무 어렵게 생각했다. 왜 이렇게 작성한 것인지 원인을 생각해보았고, 어떻게 접근해야할지 생각해 보았다.\nrandom.shuffle() 의 내부 원리를 정확히 이해하지 못 했다. 급하게 생각하여 차근 차근 생각하지 못 했다. A 과정을 거쳐 B 과정을 수행한다고 했을 때, 각 과정을 위해서 무슨 함수를 사용할지 정한다. 각 함수의 기능을 영문으로 찾아보자. 그래서 결과부터 말하자면 위 코드는 다음과 같이 수정했다.\n1 2 3 \u0026gt; random.shuffle(words) \u0026gt; q = random.choice(words) 그러면 하나 하나 파악해보자.\n제일 먼저 .shuffle()의 의미를 확인해보았다.\nrandom.shuffle(x) : Shuffle list x in place, and return None. random.shuffle(x) 은 list x의 성분들의 순서를 섞지만, 아무것도 반환하지 않는 함수라는 의미다. q에는 아무것도 할당되지 않았다는 의미다.\n그렇기 때문에 'Nonetype'으로 object가 떴다. subscriptable은 구글 영문 사전, 네이버 영영 사전을 검색해도 의미가 나오지 않아, stackoverflow를 검색해보았다. What does it mean if a Python object is \u0026ldquo;subscriptable\u0026rdquo; or not? 이 글을 보면 다음과 같은 의미를 가진다.\nThe [...] indexing syntax is called a subscript, because it\u0026#39;s equivalent to mathematical notation that uses actual subscripts; e.g. a[1] is Python for what mathematicians would write as a₁. So \u0026#34;subscriptable\u0026#34; means \u0026#34;able to be subscripted\u0026#34;. Which, in Python terms, means it has to implement __getitem__(), since a[1] is just syntactic sugar for a.__getitem__(1). - Mark Reed Apr 2, 2020 at 14:15 [\u0026hellip;] 는 인덱싱 문법에 사용되는 기호로, subscript라 한다. 왜냐하면 수학 표기법에서 a[1]은 a₁ 와 같기 때문이다. 즉, subscriptable는 able to be subscripted: 인덱싱에 사용할 수 있다를 의미한다. 파이썬 용어의 관점에서 [] indexing은 __getitem__을 실행한다는 의미다. (ex) a[1] == a.__getitem__(1)\n결론\n- TypeError: 'NoneType' object is not subscriptable : data type error의 종류이며, NoneType 객체는 인덱싱에 사용할 수 없다.\n- 구글 번역도 좋지만 보다 직접 번역하며 분석하는 게 훨씬 공부에 도움이 된다.\nReference What does it mean if a Python object is \u0026ldquo;subscriptable\u0026rdquo; or not? 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_22_nonetypeerror/","summary":"Python basic 과정을 마치고, 간단한 프로젝트로 Hangman game을 만들었다. 그 과정에서 NoneTypeError가 발생했다. \u0026lsquo;TypeError:\u0026lsquo;NoneType\u0026rsquo; object is not subscriptable\u0026rsquo; 에 대해 알아보자.","title":"[TIL] Python basic 22: NoneTypeError"},{"categories":["Python"],"content":"0. Introduction csv 파일이란?? Comma-Separated Values의 약자로, 콤마로 구분된 텍스트 파일이다. 확장자 명은 .csv이다. csv 파일은 data science 분야에서 주로 사용하여, 데이터를 주고 받을 때 사용하는 형식이다. data science 분야나 전처리할 때, csv로 임시로 저장을 했다가 나중에 활용하는 형식으로도 많이 사용하고 있다. csv의 MIME 형식은 text/csv 이다. MIME type이란 client에서 전송하는 문서의 종류를 표시하는 기능이다. 서버에서 이 type을 이용해서 각각 파일의 확장자를 확인할 수 있다. csv의 파일 1행을 열머리글로 header라고 한다. 콤마(,)로 반드시 구분되는 게 아니지만, 정석은 콤마다. 1. Read csv file (csv 파일 읽기) 두 개의 예제를 통해 읽기 실습을 해보겠다. 첫 번째 예제는 정석으로 콤마(,)로 구분되는 파일이다. (text1.csv) 두 번째 예제는 코마가 아닌 합기호로 구분되는 파일이다. (text2.csv) csv 파일을 읽기 위해서는 csv.reader 함수를 사용해야한다. csv.reader: Return a reader object which will iterate over lines in the given csvfile. csvfile can be any object which supports the iterator protocol. the iterator protocol을 지원하는지 알기 위해서 dir() 함수를 사용하여 __iter__이 있는지 확인한다. 그리고, 파이썬은 list 형태로 가져오고, 작성한다. 예제 파일 내용은 아래와 같다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 ## text1.csv # 콤마로 구분 Name,Code Afghanistan,AF Åland Islands,AX Albania,AL Algeria,DZ American Samoa,AS Andorra,AD ## text2.csv # 합기호로 구분 Name|Code Afghanistan|AF Åland Islands|AX Albania|AL Algeria|DZ American Samoa|AS Andorra|AD 첫 번째 예제 csv 파일의 첫 행 부분을 Header라고 한다. Header skip을 원한다면 next() 함수를 사용한다. next(): Return the next item from the iterator. 괄호 안에 입력한 iterator의 두 번째 행부터 출력하겠단 의미다. seek() 함수처럼 cursor를 이동한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 # 외장 함수를 import 한다. \u0026gt; import csv # 별도로 close 하지 않기 위해 with open 함수를 사용한다. # 현재 경로에서 resource 폴더에 있는 tes1.csv 파일을 읽고, f에 연결한다. \u0026gt; with open(\u0026#39;./resource/test1.csv\u0026#39;, \u0026#39;r\u0026#39;) as f: \u0026gt; reader = csv.reader(f) \u0026gt; print(reader) \u0026lt;_csv.reader object at 0x00000206CB2F5100\u0026gt; \u0026gt; print(type(reader)) \u0026lt;class \u0026#39;_csv.reader\u0026#39;\u0026gt; ## __iter__을 확인한다. \u0026gt; print(dir(reader)) [\u0026#39;__class__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;, ... \u0026#39;__iter__\u0026#39;,...] ## __iter__이면 for문에도 사용할 수 있다. # list 형식으로 가져온다는 걸 확인할 수 있다. \u0026gt; for c in reader: \u0026gt; print(type(c)) \u0026gt; print(c) \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; [\u0026#39;Name\u0026#39;, \u0026#39;Code\u0026#39;] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; [\u0026#39;Afghanistan\u0026#39;, \u0026#39;AF\u0026#39;] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; [\u0026#39;횇land Islands\u0026#39;, \u0026#39;AX\u0026#39;] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; [\u0026#39;Albania\u0026#39;, \u0026#39;AL\u0026#39;] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; [\u0026#39;Algeria\u0026#39;, \u0026#39;DZ\u0026#39;] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; [\u0026#39;American Samoa\u0026#39;, \u0026#39;AS\u0026#39;] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; [\u0026#39;Andorra\u0026#39;, \u0026#39;AD\u0026#39;] ## list를 string 형식으로 바꿔보자. # 첫 번째 Name, Code가 헤더로, 열정보 다. \u0026gt; print(\u0026#39;\u0026#39;.join(c)) NameCode AfghanistanAF 횇land IslandsAX AlbaniaAL AlgeriaDZ American SamoaAS AndorraAD ## 헤더를 출력하고 싶지 않으면?? \u0026gt; with open(\u0026#39;./resource/test1.csv\u0026#39;, \u0026#39;r\u0026#39;) as f: \u0026gt; reader = csv.reader(f) # with open 문 안에 아래 함수를 추가한다. # Header Skip: csv 파일의 첫 행 부분은 보통 헤더값이라 하며, 생략한다. \u0026gt; next(reader) # 다시 실행시켜보자. # NameCode가 없는 걸 확인할 수 있다. \u0026gt; print(\u0026#39;\u0026#39;.join(c)) AfghanistanAF 횇land IslandsAX AlbaniaAL AlgeriaDZ American SamoaAS AndorraAD 두 번째 예제 (test2.csv) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \u0026gt; import csv \u0026gt; with open(\u0026#39;./resource/test2.csv\u0026#39;, \u0026#39;r\u0026#39;) as f: \u0026gt; reader = csv.reader(f, delimiter = \u0026#39;|\u0026#39;) \u0026gt; next(reader) \u0026gt; for c in reader: \u0026gt; print(c) [\u0026#39;Afghanistan\u0026#39;, \u0026#39;AF\u0026#39;] [\u0026#39;횇land Islands\u0026#39;, \u0026#39;AX\u0026#39;] [\u0026#39;Albania\u0026#39;, \u0026#39;AL\u0026#39;] [\u0026#39;Algeria\u0026#39;, \u0026#39;DZ\u0026#39;] [\u0026#39;American Samoa\u0026#39;, \u0026#39;AS\u0026#39;] [\u0026#39;Andorra\u0026#39;, \u0026#39;AD\u0026#39;] ## 만약 delimiter = \u0026#39;|\u0026#39; 를 입력하지 않는다면?? # name과 code가 하나의 값으로 인식된다. [\u0026#39;Afghanistan|AF\u0026#39;] [\u0026#39;횇land Islands|AX\u0026#39;] [\u0026#39;Albania|AL\u0026#39;] [\u0026#39;Algeria|DZ\u0026#39;] [\u0026#39;American Samoa|AS\u0026#39;] [\u0026#39;Andorra|AD\u0026#39;] DictReader 를 사용하여 test2.csv의 내용을 dictionary 형태로 formatting한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 \u0026gt; import csv \u0026gt; with open(\u0026#39;./resource/test1.csv\u0026#39;, \u0026#39;r\u0026#39;) as f: \u0026gt; reader = csv.DictReader(f) \u0026gt; print(reader) \u0026lt;csv.DictReader object at 0x000001DD1A8A2F70\u0026gt; \u0026gt; print(type(reader)) \u0026lt;class \u0026#39;csv.DictReader\u0026#39;\u0026gt; \u0026gt; print(dir(reader)) [\u0026#39;__class__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__dict__\u0026#39;, \u0026#39;__dir__\u0026#39;, ...\u0026#39;, \u0026#39;__iter__\u0026#39;] ## __iter__ 확인 완료 \u0026gt; for c in reader: \u0026gt; print(c) {\u0026#39;Name\u0026#39;: \u0026#39;Afghanistan\u0026#39;, \u0026#39;Code\u0026#39;: \u0026#39;AF\u0026#39;} {\u0026#39;Name\u0026#39;: \u0026#39;횇land Islands\u0026#39;, \u0026#39;Code\u0026#39;: \u0026#39;AX\u0026#39;} {\u0026#39;Name\u0026#39;: \u0026#39;Albania\u0026#39;, \u0026#39;Code\u0026#39;: \u0026#39;AL\u0026#39;} {\u0026#39;Name\u0026#39;: \u0026#39;Algeria\u0026#39;, \u0026#39;Code\u0026#39;: \u0026#39;DZ\u0026#39;} {\u0026#39;Name\u0026#39;: \u0026#39;American Samoa\u0026#39;, \u0026#39;Code\u0026#39;: \u0026#39;AS\u0026#39;} {\u0026#39;Name\u0026#39;: \u0026#39;Andorra\u0026#39;, \u0026#39;Code\u0026#39;: \u0026#39;AD\u0026#39;} ## 위 내용을 Name과 Code로 나누고 싶으면?? \u0026gt; for c in readers: \u0026gt; for k, v in c.items() \u0026gt; print(k) Name Code Name Code Name Code Name Code Name Code Name Code \u0026gt; print(v) Afghanistan AF 횇land Islands AX Albania AL Algeria DZ American Samoa AS Andorra AD \u0026gt; print(k,v) Name Afghanistan Code AF Name 횇land Islands Code AX Name Albania Code AL Name Algeria Code DZ Name American Samoa Code AS Name Andorra Code AD 2. Write csv file (csv 파일 쓰기) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026gt; import csv \u0026gt; w = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15], [16, 17, 18], [19, 20, 21]] \u0026gt; with open(\u0026#39;./resoucre/write1.csv\u0026#39;, \u0026#39;w\u0026#39;, encoding = \u0026#39;utf-8\u0026#39;) as f: \u0026gt; wt = csv.writer(f) \u0026lt;class \u0026#39;_csv.writer\u0026#39;\u0026gt; \u0026gt; for v in w \u0026gt; # v를 wt에 작성한다. 하나의 list가 하나의 record가 된다. \u0026gt; wt.writerow(v) 1,2,3 4,5,6 7,8,9 10,11,12 13,14,15 16,17,18 19,20,21 dict의 key 값을 field명으로 활용해서 써보기 .writeheader: Write a row with the field names (as specified in the constructor) to the writer’s file object .writerow: Write the row parameter to the writer’s file object, formatted according to the current Dialect. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \u0026gt; import csv \u0026gt; w = [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15], [16, 17, 18], [19, 20, 21]] \u0026gt; with open(\u0026#39;./resource/write2.csv\u0026#39;, \u0026#39;w\u0026#39;, encoding = \u0026#39;utf - 8\u0026#39;) as f: \u0026gt; # w의 list 성분이 3개의 성분을 가지고 있으므로, 3개를 입력 \u0026gt; fields = [\u0026#39;one\u0026#39;, \u0026#39;two\u0026#39;, \u0026#39;three\u0026#39;] \u0026gt; wt = csv.DictWriter(f, fieldnames = fields) \u0026gt; # header write \u0026gt; # header로 one, two, three가 작성된 상태다. \u0026gt; wt.writeheader() \u0026gt; for v in w: \u0026gt; wt.writerow({\u0026#39;one\u0026#39;: v[0], \u0026#39;two\u0026#39;:v[1], \u0026#39;three\u0026#39;:v[2]}) one,two,three 1,2,3 4,5,6 7,8,9 10,11,12 13,14,15 16,17,18 19,20,21 Reference 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) CSV란?? ","permalink":"http://jeha00.github.io/post/python/python_basic_21_filereadwrite_2/","summary":"with open() as 를 사용하여 외부 csv 파일을 읽고, 쓰는 방법을 알아보자.","title":"[TIL] Python basic 21: csv.read, write"},{"categories":["Python"],"content":"0. Introduction 이번 chapter에서는 외부에서 수집하거나 작성한 어떠한 text 파일, csv 파일, json 같은 다양한 형식의 외부 파일들을 읽고 쓰는 작업을 알아본다.\n이번 chapter에서 중요한 것은\n첫 번째, 외부 resource를 파이썬에 list type으로 읽어와서 저장하고, list type으로 원하는 파일을 쓴다는 것 readlines 함수와 writelines 함수 두 번째, 사용한 resource는 반드시 close를 해야 한다. 그래서 with문을 사용한다. close를 하는 이유는 하지 않을 경우 다음 코드를 사용할 때 원활하지 않을 수 있다. 1. Read file (파일 읽기) 파일을 읽고 쓰는 작업을 하기 위해 open 이란 함수를 사용한다. 이 함수에서 사용하는 몇 가지 용어와 경로의 두 종류에 대해 알아보자. r: 읽기모드 (read) w: 쓰기모드 (write) a: 추가모드 (append) t: text 모드 (기본모드라 생략 가능) b: binary 모드 경로의 종류: 상대 경로와 절대 경로 상대 경로(../, ./): 점 하나는 현재 위치를, 점 두 개는 상위 폴더를 의미한다. 절대 경로: C:\\Django\\example..' 다른 컴퓨터에 다운을 받을 때는 절대 경로보다 상대 경로가 맞다. 그 이유는 경로가 절대적으로 같지 않기 때문이다. 외부에 있는 파일을 읽을 때는 먼저 함수를 사용하여 연결한 후, 내용을 읽는다. Encoding 이란 사람의 언어를 컴퓨터 언어로 암호화하는 걸 의미한다. Ecoding의 한 방식이 \u0026lsquo;UTF-8\u0026rsquo; 이다. 원문이 무엇으로 인코딩되었는지를 알아야 파이썬으로 불러왔을 때 깨지지 않는다. 먼저 원하는 경로에 파일을 만들어놓은 후, 실습을 진행했다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 ## open(\u0026#39;경로\u0026#39;, \u0026#39;rt\u0026#39; \u0026#39;rb\u0026#39; \u0026#39;w\u0026#39; \u0026#39;a\u0026#39; \u0026#39;a\u0026#39;, A) # 1) 현재 경로를 기준으로 상대 경로로 입력한다. # 2) rt이지만, t는 기본값이므로 r만 입력한다. # 3) encoding 방식으로 UTF-8 사용 \u0026gt; f = open(\u0026#39;./resource/it_news.txt\u0026#39;, \u0026#39;r\u0026#39;, encoding = \u0026#39;UTF-8\u0026#39;) ## 인코딩 방식 확인 \u0026gt; print(f.encoding) UTF - 8 ## 파일 이름 \u0026gt; print(f.name) ./resource/it_news.txt ## 모드 확인 \u0026gt; print(f.mode) r ## 외부 파일 읽은 후, 변수에 할당하기 \u0026gt; content = f.read() \u0026gt; print(content) Right now gamers can pay just $1 for access to hundreds of titles across PC and Xbox via Microsoft Xbox Game Pass Ultimate service?but dont activate that insanely cheap one-month trial just yet. You can lock in up to three years of Xbox Game Pass Ultimate with that same dollar if you play your cards right. ## 사용 후 반드시 close 한다. \u0026gt; f.close() open하여 사용 후, 반드시 close를 해야한다. 하지만, with 문을 사용하면 close를 하지 않아도, 저절로 반환하기 때문에 with문을 사용하자. 1 2 3 4 5 6 \u0026gt; with open(\u0026#39;./resource/it_news.txt\u0026#39;, \u0026#39;r\u0026#39;, encoding = \u0026#39;UTF-8\u0026#39;) as f: \u0026gt; c = f.read() \u0026gt; print(c) # it_news.txt 파일의 내용이 문자 하나 하나로 쪼개져서 list로 출력된다. \u0026gt; print(list(c)) read() 함수에 intger type의 인자를 넣으면, 입력한 값만큼의 Byte를 읽는다. 그리고, 또 실행하면 이어서 읽는다. 왜냐하면 cursor가 움직이기 때문이다. seek() 함수를 사용하여 이 cursor의 위치를 초기화할 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026gt; with open(\u0026#39;./resource/it_news.txt\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f: \u0026gt; c = f.read(20) \u0026gt; print(c) Right now gamers can # 다시 처음부터 20Byte를 읽어오는 것이 아니라, 전 마지막 읽은 부분부터 시작한다. \u0026gt; c = f.read(20) \u0026gt; print(c) pay just $1 for acc # seek은 커서의 이동 위치를 말해준다. 0,0으로 이동하고 다시 20byte 만큼 읽겠다. \u0026gt; f.seek(0,0) \u0026gt; c = f.read(20) \u0026gt; print(c) Right now gamers can readline 함수를 사용하여 한 줄 씩 읽기 1 2 3 4 5 6 7 8 9 \u0026gt; with open(\u0026#39;./resource/it_news.txt\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f: \u0026gt; line = f.readline() \u0026gt; print(line) Right now gamers can pay just $1 for access to hundreds of titles across PC \u0026gt; line = f.readline() \u0026gt; print(line) and Xbox via Microsoft Xbox Game Pass Ultimate service?but dont 처음부터 다시 읽는 것이 아닌, 이어서 읽기 때문에 반복문을 통해서 처리하자. readlines 함수를 사용한다. 전체를 읽은 후, 라인 단위 리스트로 저장한다. 즉, 파일을 list로 만든다. list로 만들어 원하는 부분만 가져와 텍스트 처리를 할 수 있기 때문에, 반드시 알고 있어야 하는 함수다. 1 2 3 4 5 6 7 8 9 \u0026gt; with open(\u0026#39;./resource/it_news.txt\u0026#39;, \u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f: \u0026gt; cts = f.readlines() \u0026gt; for c in cts: \u0026gt; print(c, end=\u0026#39;\u0026#39;) Right now gamers can pay just $1 for access to hundreds of titles across PC and Xbox via Microsoft Xbox Game Pass Ultimate service?but dont activate that insanely cheap one-month trial just yet. You can lock in up to three years of Xbox Game Pass Ultimate with that same dollar if you play your cards right. 2. Write file (파일 쓰기) 없는 파일을 쓰고자 할 때도 연결하기 위해 open함수를 사용한다. write이기 때문에 t 말고 w를 입력한다. 1 2 3 4 5 ## contents1.txt 라는 파일 만들기 \u0026gt; with open(\u0026#39;./resources/contents1.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: \u0026gt; f.write(\u0026#39;I love python/n\u0026#39;) ## 위 ./resources 경로로 contents1.txt 파일이 생성된다. 그 파일 안에 내용은 I love python이 있다. a(append) 를 사용하여 내용 추가하기 1 2 3 4 5 6 \u0026gt; with open(\u0026#39;./resources/contents1.txt\u0026#39;, \u0026#39;a\u0026#39;) as f: \u0026gt; f.write(\u0026#39;I love python2\\n\u0026#39;) ## contents1.txt 파일 내용을 보면 다음과 같이 되어 있다. I love python I love python2 writelines 함수를 사용하여 line list를 파일에 작성하기 1 2 3 4 5 6 7 8 \u0026gt; with open(\u0026#39;./resource/content2.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: \u0026gt; list = [\u0026#39;Orange\\n\u0026#39;, \u0026#39;Apple\\n\u0026#39;, \u0026#39;Banana\\n\u0026#39;, \u0026#39;Melon\\n\u0026#39;] \u0026gt; f.writelines(list) Orange Apple Banana Melon terminal이 아닌 파일로 출력을 해주는 방법 1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; with open(\u0026#39;./resource/contents3.txt\u0026#39;, \u0026#39;w\u0026#39;) as f: \u0026gt; print(\u0026#39;Test Text Write!\u0026#39;, file=f) \u0026gt; print(\u0026#39;Test Text Write!\u0026#39;, file=f) \u0026gt; print(\u0026#39;Test Text Write!\u0026#39;, file=f) # contents3.txt 파일을 보면 다음과 같다. Test Text Write! Test Text Write! Test Text Write! # 위에 file = f 를 없애면 terminal로 출력된다. Reference 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_20_filewriteread_1/","summary":"with open() as 함수를 사용해서 외부 파일을 읽고, 작성하는 방법을 알아보겠다.","title":"[TIL] Python basic 20: with open as"},{"categories":["Python"],"content":" 여러 외장 함수들 중 sys, pickle, os, time, random, webbrowser 에 대해 예제 실습으로 알아보겠다. 특히 sys, os, time은 훨씬 자주 사용되므로 중요하다. 외장함수는 import를 하는 것부터 시작한다. 이 포스팅의 목적은 외장 함수에는 이런 것들이 있다는 기록하기 위해서다. 해당 포스팅으로는 각 외장 모듈에 대한 내용이 부족하니, 추가적인 학습을 하자. 1. sys 파이썬 인터프리터가 제공하는 변수와 함수를 직접 제어할 수 있게 해주는 모듈\nsys.argv는 명령행에 인수를 전달하도록 하는 명령어다. 1 2 3 4 5 6 7 8 \u0026gt; import sys ## module 파일이 있는 위치들이 출력된다. \u0026gt; print(sys.path) ## 강제 종료 함수다. 함부로 사용하지 않는다. # visual studio code에서는 작동되지 않는다. 해당 언어 shell에서 작동한다. \u0026gt; sys.exit() 2. pickle 텍스트 상태의 데이터가 아닌 객체의 형태를 그대로 유지하면서, 파일에 저장하고 불러올 수 있게 하는 파이썬이 제공하는 모듈\n파이썬 객체를 파일에 저장하는 과정을 피클링(pickling)이라 하고, 파일에서 객체를 읽어오는 과정을 언피클링(unpickling)이라 한다. test.obj라는 파일이 binary 형식으로 작성된다. 이 test.obj에 pickle.dump() 명령어로 obj 변수 내용을 저장한다. 그리고 나서, pickle.load() 명령어로 test.obj 파일을 읽는다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026gt; import pickle # w: write , b: binary, r: read \u0026gt; f = open(\u0026#39;test.obj\u0026#39;, \u0026#39;wb\u0026#39;) \u0026gt; obj = {1: \u0026#39;python\u0026#39;, 2: \u0026#39;study\u0026#39;, 3: \u0026#39;basic\u0026#39;} \u0026gt; pickle.dump(obj, f) # 열고 나서 반드시 닫아야 한다. # 쓴 resource는 컴퓨터한테 반드시 반환해야 한다. \u0026gt; f.close() ## binary file은 컴퓨터가 처리하는 파일 형식이다. ## 사람이 알아보기 힘든 상태로, txt 파일은 이 binary 파일을 사람이 읽기 쉽게 만든 파일 형식이다. ## 그러면 이걸 어떻게 열 수 있을까?? \u0026gt; f = open(\u0026#34;test.obj\u0026#34;, \u0026#39;rb\u0026#39;) \u0026gt; data = pickle.load(f) \u0026gt; print(data) \u0026gt; f.close() 3. os 환경 변수나 디렉터리, 파일 등의 OS 자원을 제어할 수 있게 해주는 모듈\n1 2 3 4 5 6 7 8 9 \u0026gt; import os # 사용자의 운영체제 정보를 파이썬에게 넘겨준다. \u0026gt; print(os.environ) environ({{\u0026#39;ALLUSERSPROFILE\u0026#39;: \u0026#39;C:\\\\ProgramData\u0026#39;, \u0026#39;APPDATA\u0026#39;: C:\\\\Users\\\\rudtl\\\\AppData\\\\Roaming\u0026#39;, ....}) \u0026gt; print(os.environ[\u0026#39;USERNAME\u0026#39;]) rudtl 4. time 시간과 관련된 모듈\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 \u0026gt; import time ## 1970년 1월 1일 0시 0분 0초를 기준으로 지난 시간을 초 단위로 반환한다. \u0026gt; print(time.time()) 1646220813.7009172 ## 하지만 위 방식은 알아보기가 힘들다. # time.time이 반환한 시간을 사용하여 연도,월,일,시,분,초의 형태로 바꿔주는 함수다. \u0026gt; print(time.localtime(time.time())) time.struct_time(tm_year=2022, tm_mon=3, tm_mday=2, tm_hour=20, tm_min=41, tm_sec=0, tm_wday=2, tm_yday=61, tm_isdst=0) ## local.time 보다 더 간단히 표현하는 모듈이다. \u0026gt; print(time.ctime()) Wed Mar 2 20:42:50 2022 ## 원하는 형식으로 시간을 출력해주는 모듈이다. # Year, Month, Day, hour , Minute, Second \u0026gt; print(time.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;, time.localtime(time.time()))) 2022-03-02 20:42:50 ## 시간 간격 발생 # 출력 간 delay를 1초로 한다. \u0026gt; for i in range(5): \u0026gt; print(i) \u0026gt; time.sleep(1) 0 1 2 3 4 5. random 난수(규칙이 없는 임의의 수)를 발생시키는 모듈\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026gt; import random ## 0에서 1 사이의 아무 난수를 반환한다. \u0026gt; print(random.random()) ## 1에서 45 사이의 정수값을 랜덤으로 갖고 온다. \u0026gt; print(random.randint(1, 45)) ## 1에서 44 사이의 정수값을 랜덤으로 갖고 온다. \u0026gt; print(random.randrange(1, 45)) ## Iterable object의 argument의 순서를 섞어서 출력한다. # 출력할 때마다 순서가 바뀐다. \u0026gt; d = [1, 2, 3, 4, 5] \u0026gt; random.shuffle(d) \u0026gt; print(d) [2, 5, 3, 4, 1] [2, 4, 1, 3, 5] ... ## Iterable object의 argument들 중 무작위로 선택하는 함수 \u0026gt; d = [1, 2, 3, 4, 5] \u0026gt; c = random.choice(d) \u0026gt; print(c) 1 4 3 2 6. webbrowser 본인 OS의 web browser를 실행\n1 2 3 4 5 6 7 \u0026gt; import webbrowser ## 기본 웹 브라우저를 사용하여 아래 url로 자동으로 이동한다. 이미 실행된 상태라면 기존에 있던 tab이 이동된다. \u0026gt; webbrowser.open(\u0026#34;https://google.com\u0026#34;) ## 기본 웹 브라우저에 새로운 탭이 생기면서 아래 url로 이동한다. \u0026gt; webbrowser.open_new(\u0026#34;https://google.com\u0026#34;) Reference 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) 라이브러리 pickling ","permalink":"http://jeha00.github.io/post/python/python_basic_19_external_functions/","summary":"외장 함수를 실행하는 방법과 외장 함수의 여러 종류들을 알아보겠다.","title":"[TIL] Python basic 19: external functions"},{"categories":["Python"],"content":" 내장 함수란 프로그래밍 언어의 라이브러리에(파이썬의 인터프리터에) 이미 등록되어 있는 함수를 말한다. 그래서 별도의 정의나 설치가 필요없다. 외장 내장 구분하는 건 중요하지 않고, 필요한 곳에 이미 파이썬에 내장된 함수를 찾아서 프로그램을 개발할 때, 적합한 어떤 위치에서 사용하는 게 중요하다. 예시를 사용하여 내장함수에 대해 알아보겠다. 아래에 예시로 사용하는 내장함수는 반드시 알고 있자. abs(): 입력된 숫자형 데이터를 절대값으로 반환해주는 함수 1 2 \u0026gt; print(abs(-3)) 3 all() , any: interable 요소를 검사하여 성분이 참인지 거짓인지 검사하는 함수 (True or False) all() 은 안에 있는 요소가 논리 연산자 and처럼 다 True여야 True를 반환한다. any() 는 논리 연산자 or처럼 안에 있는 요소들 중 하나라도 True가 있으면 True다. 1 2 3 4 5 6 7 8 \u0026gt; print(all([1, 2, 3])) True \u0026gt; print(all([False, True])) False \u0026gt; print(any([False, True])) True \u0026gt; print(any([False, False])) False chr(): 아스키 코드를 문자로 반환하는 함수 ord(): 문자를 아스키 코드로 반환하는 함수 1 2 3 4 \u0026gt; print(chr(67)) C \u0026gt; print(ord(\u0026#39;C\u0026#39;)) 67 enumerate(): index + Iterable 객체(list, tuple, dictionary, set)을 생성한다. 1 2 3 4 5 \u0026gt; for i, name in enumerate([\u0026#39;abc\u0026#39;, \u0026#39;bcd\u0026#39;, \u0026#39;eft\u0026#39;]): \u0026gt; print(i, name) 0 abc 1 bcd 2 efg filter(): Iterable 객체를 지정한 함수 조건에 맞는 값만 추출한다. filter(function or None, iterable) \u0026ndash;\u0026gt; filter object 1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; def conv_positive(x): \u0026gt; return abs(x) \u0026gt; 2 # 위에서 지정한 함수 조건은 \u0026#39;conv_posotive\u0026#39; 에 의해서 주어지고, interable 데이터가 입력된다. \u0026gt; print(filter(conv_positive, [1, -3, 2, 0, -5, 6])) \u0026lt;filter object at 0x0000025A0B362FA0\u0026gt; \u0026gt; print(list(filter(conv_pos, [1, -3, 2, 0, -5, 6]))) [-3, -5, 6] ## 단 한 번 쓸 함수를 위해 위에처럼 정의하면 분량이 늘어난다. 이럴 때, lamda 함수를 사용한다. \u0026gt; print(list(filter(lambda x: abs(x) \u0026gt; 2, [1, -3, 2, 0, -5, 6]))) id(): 객체의 주소값(reference)를 반환한다. id(): Return the identity of an object. 1 2 3 4 5 \u0026gt; print(id(5)) 2144671066544 \u0026gt; print(id(float(4))) 2144671700368 len: 요소의 길이를 반환한다. len: Return the number of items in a container. 1 2 3 4 5 \u0026gt; print(len(\u0026#39;123456789\u0026#39;)) 9 \u0026gt; print(len([1,2,3,4,5,6,7])) 7 max: 입력된 iterable 자료형 중에 가장 큰 값을 반환한다. max: With a single iterable argument, return its biggest item. With two or more arguments, return the largest argument. min: max와 반대로 가장 작은 값을 반환한다. 1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; print(max([1,2,3])) 3 ## 오름차순 시, y가 제일 크다. \u0026gt; print(max(\u0026#39;python study\u0026#39;)) y \u0026gt; print(min([1,2,3])) 1 # blank가 제일 작은 값이라, 아무것도 없어보인다. \u0026gt; print(min(\u0026#39;python study\u0026#39;)) map: iterable 객체 요소를 지정한 함수에 실행 후 추출 map: map(func, *iterables) \u0026ndash;\u0026gt; map object Make an iterator that computes the function using arguments from each of the iterables. 데이터 전처리 과정에서 많이 사용한다. 1 2 3 4 5 6 7 8 9 10 11 \u0026gt; def conv_abs(x): \u0026gt; return abs(x) \u0026gt; print(list(map(conv_abs,[1,-3,2,0,-5,6]))) [1, 3, 2, 0, 5, 6] ## 또는 위에 함수 정의를 하지 않고, 람다 함수를 사용한다. \u0026gt; print(list(map(lambda x:abs(x),[1,-3,2,0,-5,6]))) [1, 3, 2, 0, 5, 6] pow : 제곱값 반환 1 2 \u0026gt; print(pow(2,10)) 1024 range: 반복가능한 객체(Iterable) 반환 1 2 3 4 5 6 7 8 \u0026gt; print(range(1,10,2)) range(1, 10, 2) \u0026gt; print(list(range(1,10,2))) [1, 3, 5, 7, 9] \u0026gt; print(list(range(0,-15,-1)) [0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11, -12, -13, -14] round: 반올림 1 2 3 4 5 ## 소수점 둘째자리에서 반올림한다. \u0026gt; print(round(6.5781, 2)) 6.58 \u0026gt; print(round(5.6)) 6 sum: 반복가능한 객체(Iterable) 합 반환 1 2 3 4 \u0026gt; print(sum([6, 7, 8, 9, 10])) 40 \u0026gt; print(sum(range(1,101))) 5050 type: 자료형의 type을 확인 1 2 3 4 5 6 7 8 9 10 11 \u0026gt; print(type(3)) \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; \u0026gt; print(type({})) \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; \u0026gt; print(type(())) \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; \u0026gt; print(type([])) \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; zip: Iterable 객체의 요소를 묶어서 tuple type으로 반환 zip: A zip object yielding tuples until an input is exhausted. 1 2 3 4 5 6 7 8 9 10 \u0026gt; print(list(zip([10,20,30],[40,50,777]))) [(10, 40), (20, 50), (30, 777)] # 짝이 맞는 것만 반환한다. # list 안에 tuple type의 argument가 담겨져있다. \u0026gt; print(list(zip([10,20,],[40,50,777]))) [(10, 40), (20, 50)] \u0026gt; print(type(list(zip([10,20,30],[40,50,777]))[0])) \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; Reference 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_18_built_in_fuctions/","summary":"내장 함수란 무엇이고, 내장 함수에서 자주 사용된 것들로 실습을 해보겠다.","title":"[TIL] Python basic 18: built-in functions"},{"categories":["Python"],"content":"1. Exception(예외) and Error(에러)의 차이점 Exception(예외) 와 Error(에러)에 대해 설명하겠다. 예외는 무엇이고 에러는 무엇이다라고 외우진 말자. 예외를 에러의 범주에 포함하기도 하기 때문이다. 다만, 예외와 에러에 대한 틀을 잡기 위해 설명한다. Exception(예외)는 우리가 작성한 로직에서 비정상적으로 발생한 사건(event)이다. 예외에는 \u0026lsquo;예측이 가능한 예외\u0026rsquo;와 \u0026lsquo;예측이 불가능한 예외\u0026rsquo;로 나눠진다. \u0026lsquo;예측 가능한 예외\u0026rsquo;의 경우는 id 입력을 생각해보자. 영어로 입력해야하는데, 한글을 입력했을 경우 예외가 발생한다. \u0026lsquo;예측 불가능한 예외\u0026rsquo;의 경우는 메모리의 용량이 부족해서, \u0026lsquo;OS\u0026rsquo;에서 발생한 에러, 하드웨어적인 에러 등등이 해당된다. 이 예외와 에러를 잘 처리해야 내가 의도한대로 작동하는 어플리케이션을 만들 수 있다. 2. Error의 종류 2.1 SyntaxError: 문법 오류 1 2 3 4 5 6 # 조건문의 헤더에 콜론(:)을 하지 않아 발생했다. \u0026gt; print(\u0026#39;error\u0026#39;) \u0026gt; print(\u0026#39;error\u0026#39;) \u0026gt; if True \u0026gt; pass SyntaxError: invalid syntax 2.2 TypeError: 자료형에 맞지 않는 연산을 수행하여 발생하는 오류 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; x = [1,2] \u0026gt; y = (1,2) \u0026gt; z = \u0026#39;test\u0026#39; # list와 tuple은 합칠 수 없다. \u0026gt; print(x + y) TypeError: can only concatenate list (not \u0026#34;tuple\u0026#34;) to list # string과 list는 합칠 수 없다. \u0026gt; print(x + z) TypeError: can only concatenate list (not \u0026#34;str\u0026#34;) to list # tuple과 string은 합칠 수 없다. \u0026gt; print(y + z) TypeError: can only concatenate list (not \u0026#34;str\u0026#34;) to list 2.3 NameError: 참조가 없을 때 발생하는 오류 1 2 3 4 \u0026gt; a = 10 \u0026gt; b = 15 \u0026gt; print(c) NameError: name \u0026#39;c\u0026#39; is not defined 2.4 IndexError: index가 존재하지 않아 발생하는 오류 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; x = [50, 70, 90] \u0026gt; print(x[1]) 70 \u0026gt; print(x[4] IndexError: list index out of range # 알고리즘에서 op을 사용할 때 발생할 수 있는 에러 \u0026gt; print(x.pop()) 50 \u0026gt; print(x.pop()) 70 \u0026gt; print(x.pop()) 90 \u0026gt; print(x.pop()) IndexError: pop from empty list 2.5 ValueError: 참조값이 없을 때 발생하는 오류 1 2 3 4 5 6 7 \u0026gt; x = [10, 50, 90] \u0026gt; x.remove(50) \u0026gt; print(x) [10, 90] \u0026gt; x.remove(200) ValueError: list.remove(x): x not in list 2.6 KeyError: 해당되는 key가 없을 때 발생하는 오류 1 2 3 4 5 6 7 # `key` 값으로 `value` 값을 출력할 때는 `.get()` 함수를 사용한다. \u0026gt; x = {\u0026#39;A\u0026#39;: \u0026#39;apple\u0026#39;, \u0026#39;B\u0026#39;: \u0026#39;Banana\u0026#39;, \u0026#39;C\u0026#39;: \u0026#39;coffee\u0026#39;} \u0026gt; print(x[\u0026#39;D\u0026#39;]) KeyError: \u0026#39;D\u0026#39; \u0026gt; print(x.get(\u0026#39;D\u0026#39;)) None 2.7 AttributeError: 모듈, 클래스에 있는 잘못된 속성을 사용하여 발생한 오류 1 2 3 \u0026gt; import time \u0026gt; print(time.time2()) AttributeError: module \u0026#39;time\u0026#39; has no attribute \u0026#39;time2\u0026#39; 2.8 FileNotFoundError: 파일을 찾을 수 없을 때 발생하는 오류 1 2 \u0026gt; f = open(\u0026#39;test.txt\u0026#39;) FileNotFoundError: [Errno 2] No such file or directory: \u0026#39;test.txt\u0026#39; 2.9 ZeroDivisionError: 0으로 나눠서 발생하는 오류 1 2 \u0026gt; print(100 / 0) ZeroDivisionError: division by zero 3. 예외 처리 (try ~ exception) try: 에러가 발생할 가능성이 있는 코드 실행 이 에러는 내 코드가 정확해도, 방문한 사이트 서버나 여러 프로그램이 외부와 연결될 때, 문제가 있을 수 있기 때문이다. 그래서 외부적으로 문제가 발생해도 try ~ except로 대비한다. except 에러명 1~n: error가 발생했을 때 잡아내어 다음 코드로 넘어가도록 해준다. 여러 개 가능하다. 어떤 Error만 잡을지 정할 수 있다. 모든 error 잡아내기 except Exception:은 모든 예외의 부모격이라 모든 error를 잡아낸다. except: 또한, 모든 error을 잡아낸다. 하지만, 정확히 어떤 error가 발생했는지 알 수 없다. 정확히 어떤 error가 발생했는지 알아야 로그를 남길 때 정확히 남길 수 있다. 예제 3에서처럼 예제 2에서 alias를 줘서 except Exception as e 와 print(e) 을 사용하여, 대략적인 error 내용을 확인하여 출력하도록 할 수 있다. else: try block에 에러가 없을 경우 실행한다. 정상적으로 흘러갈 때 실행된다. for ~ else 에서도 for문에 break를 만나지 않으면 else가 실행했듯이, except를 만나지 않으면 실행된다. finally: 에러발생 유무와 상관없이 무조건 실행된다. error 발생 유무에 상관없이 항상 실행해줘야 하는 구문으로 finally를 사용한다. 예를 들어 error가 발생했을 경우, 연결된 메모리를 끊어줘야 메모리가 새지 않기 때문에 finally를 통해서 실행한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 ## 예제 1 ## error 발생하지 않는 코드 \u0026gt; name = [\u0026#39;Kim\u0026#39;, \u0026#39;Lee\u0026#39;, \u0026#39;Park\u0026#39;] \u0026gt; print(name.index(\u0026#39;Kim\u0026#39;)) \u0026gt; try : \u0026gt; z = \u0026#39;Kim\u0026#39; \u0026gt; x = name.index(z) \u0026gt; print(\u0026#39;{} Found it! {} in name\u0026#39;.format(z, x + 1)) # error 중 ValueError 만 잡는다. # error 처리 시, 이렇게 error의 정확한 유형대로 잡아내느 것이 제일 좋은 case다. \u0026gt; except ValueError: \u0026gt; print(\u0026#39;Not found it! - Occurred ValueError!\u0026#39;) # error가 발생되지 않았으므로 else 구문이 작동된다. \u0026gt; else: \u0026gt; print(\u0026#39;Ok! else.\u0026#39;) \u0026gt; print(\u0026#39; \u0026#39; ) 0 Kim Found it! 1 in name Ok! else. ## 예제 2 # error 발생 코드 # error가 발생했어도 except로 잡아냈기 때문에 else 구문을 출력된다. # 그리고, 그 다음 코드를 계속해서 실행한다. print(\u0026#39;pass\u0026#39;)가 출력된 걸 확인할 수 있다. # 또한, 예제 1에서의 ValueError를 지웠기 때문에 모든 Error를 잡아낸다. # 하지만, 그래서 어떤 Error를 잡았는지 정확히 알 수 없다. \u0026gt; name = [\u0026#39;Kim\u0026#39;, \u0026#39;Lee\u0026#39;, \u0026#39;Park\u0026#39;] \u0026gt; try: \u0026gt; z = \u0026#39;Cho\u0026#39; \u0026gt; x = name.index(z) \u0026gt; print(\u0026#39;{} Found it! {} in name\u0026#39;.format(z, x + 1)) # except Exception: \u0026gt; except: \u0026gt; print(\u0026#39;Not found it! - Occurred Error!\u0026#39;) \u0026gt; else: \u0026gt; print(\u0026#39;Ok! else.\u0026#39;) \u0026gt; \u0026gt; print(\u0026#39;pass\u0026#39;) Not found it! - Occurred Error! pass ## 예제 3 # 예제 2를 보완한 코드 \u0026gt; name = [\u0026#39;Kim\u0026#39;, \u0026#39;Lee\u0026#39;, \u0026#39;Park\u0026#39;] \u0026gt; try: \u0026gt; z = \u0026#39;Cho\u0026#39; \u0026gt; x = name.index(z) \u0026gt; print(\u0026#39;{} Found it! {} in name\u0026#39;.format(z, x + 1)) # 예제 2와 달리 추가된 부분 \u0026gt; except Exception as e: \u0026gt; print(e) # \u0026gt; print(\u0026#39;Not found it! - Occurred Error!\u0026#39;) \u0026gt; else: \u0026gt; print(\u0026#39;Ok! else.\u0026#39;) # 예외 유무에 상관없이 finally는 실행된다. \u0026gt; finally: \u0026gt; print(\u0026#39;Ok! finally\u0026#39;) \u0026#39;Cho\u0026#39; is not in list Not found it! - Occurred Error! Ok! finally error 를 일부러 발생시킨 경우를 생각해보자. 언제 일부러 error 를 발생시킬까?? 여기서 error 란 Python에서 발생시킨 게 아니라, 설계자가 회사에서 요구하는 논리상 알기 위해서 일부러 발생시킨 error를 말한다. 아래 코드로 설명을 하자면 a가 \u0026lsquo;Kim\u0026rsquo;이 아니라면 이는 파이썬 내에 ValueError가 발생된 것이 아니다. 하지만 회사에서 \u0026lsquo;Kim\u0026rsquo;이 아닌 경우에 대해 알기 위해서 error를 발생시켰다. 이를 토대로 언제 \u0026lsquo;Kim\u0026rsquo;이 아닌지 역으로 분석할 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 ## error 발생 X \u0026gt; name = [\u0026#39;Kim\u0026#39;, \u0026#39;Lee\u0026#39;, \u0026#39;Park\u0026#39;] \u0026gt; try: \u0026gt; a = \u0026#39;Park\u0026#39; \u0026gt; if a == \u0026#39;Park\u0026#39;: \u0026gt; print(\u0026#39;OK! Pass!\u0026#39;) \u0026gt; else: \u0026gt; raise ValueError \u0026gt; except ValueError: \u0026gt; print(\u0026#39;Occurred! Exception!\u0026#39;) \u0026gt; else: \u0026gt; print(\u0026#39;Ok! else!\u0026#39;) OK! Pass! Ok! else! ## error 발생 O \u0026gt; name = [\u0026#39;Kim\u0026#39;, \u0026#39;Lee\u0026#39;, \u0026#39;Park\u0026#39;] \u0026gt; try: \u0026gt; a = \u0026#39;Park\u0026#39; \u0026gt; if a == \u0026#39;Kim\u0026#39;: \u0026gt; print(\u0026#39;OK! Pass!\u0026#39;) \u0026gt; else: \u0026gt; raise ValueError \u0026gt; except ValueError: \u0026gt; print(\u0026#39;Occurred! Exception!\u0026#39;) \u0026gt; else: \u0026gt; print(\u0026#39;Ok! else!\u0026#39;) Occurred! Exception! a에는 \u0026lsquo;Park\u0026rsquo;가 할당되었다. \u0026lsquo;Kim\u0026rsquo;이 아니기 때문에, 일부러 ValueError를 발생시켰다. 그래서 except ValueError 문이 실행이 되어 print문이 출력되었다. 일부러 Error를 일으키고, ErrorType도 정할 수 있다는 걸 알고 있자. Reference 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_17_try_exception/","summary":"Error의 종류와 예외 처리문에 대해 알아보고, 일부러 에러를 일으키는 이유와 방법에 대해 알아보겠다.","title":"[TIL] Python basic 17: try ~ exception"},{"categories":["Python"],"content":"1. Pacakge 구조 Package는 module의 묶음을 의미하며, 폴더에 담아 관리한다. pacakge를 불러와서 사용하기 위해서는 2가지 방법이 있다. 첫 번째, 현재 경로를 기준으로 상대 경로 개념을 사용하여, module 경로를 직접 입력 하여 사용하는 방식 두 번째 방법: import와 from을 사용하는 방식 경로 이동: cd .. 을 하면 \u0026lsquo;상위 directory\u0026rsquo;로 이동 여러 명과 project를 진행한다면 위 방법 2가지 보다는 컴퓨터 공용 위치에 package 파일들을 두고, sys.path 또는 환경설정에서 경로를 설정하는 방법을 사용하자. 2. 패키지 경로 및 패키지 함수 실행 2.1 패키지 경로 와 inspect.getfile 함수 예제를 설명하기에 앞서 module로 사용할 package인 module1.py 와 module2.py의 위치는 다음과 같다. __init__.py 파일도 기억해놓자. 1 2 3 4 5 6 7 8 9 10 sub ├─sub1 │ │─ module1.py │ │─ __init__.py │ └─ __pycache__ ├─sub2 │ │─ module2.py │ │─ __init__.py │ └─__pycache__ └─__pycache__ 그리고 module 파일인 module1.py와 module2.py의 내부 코드는 다음과 같다. inspect 함수는 파이썬의 객체들로부터 유용한 정보를 얻고자 할 때 사용하는 함수다. inspect 에 의해 제공되는 함수가 .getfile 이다. .getfile은 object가 어느 위치에 있는지 알고자 할 때 사용한다. .currentframe 은 실행 중인 파일의 이름과 경로를 보여준다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 ## module1.py \u0026gt; import sys \u0026gt; import inspect # from ..sub2 import module2 \u0026gt; def mod1_test1(): \u0026gt; print (\u0026#34;Module1 -\u0026gt; Test1\u0026#34;) \u0026gt; print(\u0026#34;Path : \u0026#34;, inspect.getfile(inspect.currentframe())) \u0026gt; def mod1_test2(): \u0026gt; print (\u0026#34;Module1 -\u0026gt; Test2\u0026#34;) \u0026gt; print(\u0026#34;Path : \u0026#34;, inspect.getfile(inspect.currentframe())) # 만약 inspect.currentframe()만 입력하면 다음과 같이 뜬다. # \u0026lt;frame at 0x00000296CE1BB7C0, file c:\\\\Users ~~ \\module1.py, line 9, code mod1_test1\u0026gt; # 파일 경로와, 파일 내의 몇 번째 줄인지까지 확인할 수 있다. # 하지만, insepct.getfile(inspect.currentframe())) 을 입력하면 다음과 같이 뜬다. # c:\\Users\\ ~ sub\\sub1\\module1.py # 경로만 출력된다. # 코드 경로를 넘어서 더 상세한 위치를 알고 싶다면 `inspect.currentframe()`을 사용해야겠다. ## module2.py \u0026gt; import sys \u0026gt; import inspect \u0026gt; def mod2_test1(): \u0026gt; print (\u0026#34;Module2 -\u0026gt; Test1\u0026#34;) \u0026gt; print(\u0026#34;Path : \u0026#34;, inspect.getfile(inspect.currentframe())) \u0026gt; def mod2_test2(): \u0026gt; print (\u0026#34;Module2 -\u0026gt; Test2\u0026#34;) \u0026gt; print(\u0026#34;Path : \u0026#34;, inspect.getfile(inspect.currentframe())) 2.2 패키지 함수 실행하기: 2가지 방법 첫 번째, 경로를 하나 하나 입력하는 것 두 번째, from ~ import ~ as 사용하기 그러면 패키지를 불러오는 방법 2가지에 대해 알아보자.\n폴더명을 입력하고 점.을 입력하면 입력했던 폴더명의 하위 object가 뜬다.\n폴더, 파일, method 등등이 뜬다. 첫 번째 방법 단점: 경로가 너무 다르면 입력해야할 경로가 너무 길어진다. 그래서 현재 경로와 같을 경우에 사용한다. 경로가 길어질 경우를 대비해서 from을 사용한다. (두 번째 방법) 장점: sys.path.append() 함수로 경로를 추가하지 않아도 불러올 수 있다. 1 2 3 4 5 6 7 8 9 ## 첫 번째 방법 \u0026gt; sub.sub1.module1.mod1_test1() \u0026gt; sub.sub2.module2.mod2_test1() # 또는 \u0026gt; import sub.sub1.module1 \u0026gt; import sub.sub2.module2 두 번째 방법 첫 번째보다 경로를 짧게 입력할 수 있기 때문에, 깔끔하고 가독성이 좋다. from을 통해 사용하고 싶은 모듈만 import 하여 사용한다. as는 alias로 별명, 별칭이다. as를 설정하면 모듈 이름을 다 입력할 필요 없이, as만 입력하면 된다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## 두 번째 방법 \u0026gt; from sub.sub1 import module1 \u0026gt; from sub.sub2 import module2 as m2 # 호출하기 \u0026gt; module1.mod1_test1() Module1 -\u0026gt; Test1 Path : c:\\Users\\ ~ \\sub\\sub1\\module1.py \u0026gt; module1.mod1_test2() Module1 -\u0026gt; Test2 Path : c:\\Users\\ ~ \\sub\\sub1\\module1.py # 아래 2가지는 서로 같다. \u0026gt; module2.mod2_test1() \u0026gt; m2.mod2_test1() Module2 -\u0026gt; Test1 Path : c:\\Users\\ ~ \\sub\\sub2\\module2.py from ~ import * 로 모든 module 파일을 가져올 수도 있다. * 이 모든 파일을 의미한다. 하지만 이런 경우 안쓰는 파일을 가져오는데, 현재 HW의 발달로 눈에 띄는 성능 저하는 드러나지 않지만, 이런 것들이 쌓이면 run time에서 메모리를 잡아먹는다. 항상 메모리 를 신경쓰는 습관을 가지자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; from sub.sub1 import * \u0026gt; from sub.sub2 import * \u0026gt; module1.mod1_test1() Module1 -\u0026gt; Test1 Path : c:\\Users\\ ~ \\sub\\sub1\\module1.py \u0026gt; module1.mod1_test2() Module1 -\u0026gt; Test2 Path : c:\\Users\\ ~ \\sub\\sub1\\module1.py \u0026gt; module2.mod2_test1() Module2 -\u0026gt; Test1 Path : c:\\Users\\ ~ \\sub\\sub2\\module2.py \u0026gt; module2.mod2_test2() Module2 -\u0026gt; Test2 Path : c:\\Users\\ ~ \\sub\\sub2\\module2.py 3. __init__.py 가 존재하는 이유 파이썬에게 해당 폴더가 패키지임을 알려준다. 이 파일이 없으면 패키지로 인식하지 않는다. Python 3.3부터는 __init__.py 파일이 없어도 패키지로 인식한다.\n그러면 __init__.py 을 작성할 필요가 없을까?? 아니다. Python 3.3 이전 버전으로 의뢰가 들어올 경우가 있기 때문에, 그리고 하위 호환을 위해 작성한다. Python 3.3 이전 버전으로 작성하다가 새롭게 업데이트를 하면 거의 작동되겠지만, 예상치 못한 side effect가 있을 수 있기 때문에 작성한다. package 폴더에 있는 pyecache 파일은 빠른 실행을 위해 파이썬 엔진이 만드는 것이기 때문에, 지워도 실행하면 다시 생긴다. 그러면 __init__.py 파일 내부를 살펴보자. 1 2 3 4 5 6 7 # sub1 폴더에는 module1.py 이 있다. # sub1 의 __init__.py 작성 명령어는 다음과 같다. \u0026gt; __all__ = [\u0026#39;module1\u0026#39;] # sub2 폴더에는 module2.py 이 있다. # sub2 의 __init__.py 작성 명령어는 다음과 같다. \u0026gt; __all__ = [\u0026#39;module2\u0026#39;] 아래 내용은 Python 3.3 이전 버전에 관한 내용이다. 이후부터는 필수가 아니다. __all__ = [ ] 에서 대괄호에 module 파일명이 적혀 있어야, 외부에서 import 할 때 해당 module 파일을 허가해준다. 이 list에 파일명이 다르면 작동할 수 없다. 파이썬이 import할 때, __init__을 먼저 검사하기 때문에, all에 없으면 error가 발생된다. Python 3.3부터는 __init__.py 가 필수가 아니어도, 아직 많은 오픈 소스에는 존재한다. Reference 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_16_package/","summary":"package란 무엇인지, package의 경로와 함수를 어떻게 실행하는지, \u003cstrong\u003einit\u003c/strong\u003e.py가 존재하는 이유에 대해 알아보겠다.","title":"[TIL] Python basic 16: package"},{"categories":["Python"],"content":"1. Module이란?? \u0026lsquo;Module\u0026rsquo;이란 하나의 파일 안에 함수, 변수, 클래스 등 파이썬 구성 요소 등을 모아놓아 공용적으로 쓸 수 있도록 만든 파일\n공용적으로 쓸 수 있는 파일이기 때문에, \u0026lsquo;타인\u0026rsquo;으로부터 \u0026lsquo;웹\u0026rsquo;으로부터 가져다 사용한다. module 을 사용하기 위해서, 사용하기 전에 모듈파일이 있는 경로를 추가 해야한다. 일시적 등록: sys.path 사용하기 영구적 등록: 환경 변수에 있는 python path에 추가하기 이 Module 파일이 모여지면 Package가 된다. 1.2 Import 사용하기 외부 module을 사용하기 위해서는 import 를 사용한다.\n1 2 3 4 5 6 7 8 \u0026gt; import math \u0026gt; print(math.pi) 3.1415926535 # random은 0부터 1 사이의 난수를 출력한다. \u0026gt; import random \u0026gt; random.random()) 0.71924824 1.3 경로 추가하기 import 된 module 파일의 module 타입을 알 수 있다.\n1 2 3 \u0026gt; import sys \u0026gt; print(sys) \u0026lt;module \u0026#39;sys\u0026#39; (built-in)\u0026gt; built-in은 내장 파일을 말한다. sys는 파이썬의 내장 모듈 파일임을 알 수 있다. python 파일 설치 경로 확인하기\n아래 이 경로들에 있는 파일을 파이썬이 가져다가 사용하는 것이 파이썬의 원리다. Python 파일이 설치된 모듈 파일 경로들이 출력된다. 파이썬 내부에 있기 때문에 import로 가져다가 사용할 수 있다. 1 2 3 \u0026gt; print(sys.path) [\u0026#39;c:\\\\Users\\\\rudtl\\\\Desktop\\\\Dev\\\\Python 강의\\\\Inflearn Original \\\\Level 1 입문_프로그래밍 시작하기\u0026#39;, ....] Module 경로 추가하기\n추가하기 위해 모듈 경로의 데이터 타입을 확인한다. 경로를 추가하기 전에 밑에 경로로 동일한 명칭의 폴더를 만들어놔야 한다. 1 2 3 4 5 6 7 \u0026gt; print(type(sys.path)) \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; # 끝에 경로가 추가된 걸 확인할 수 있다. \u0026gt; sys.path.append(\u0026#39;C:/math\u0026#39;) \u0026gt; print(sys.path) [\u0026#39;c:\\\\Users\\\\...\\\\Inflearn Original\\\\Level 1 입문_프로그래밍 시작하기\u0026#39;,..., \u0026#39;C:/math\u0026#39;] module 파일을 만들고, 추가한 경로 폴더에 넣기\n\u0026lsquo;module_test` 란 이름으로 파이썬 파일을 만든다. module 파일의 내용은 다음과 같다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026gt; def add(x, y): \u0026gt; return x + y \u0026gt; def subtract(x, y): \u0026gt; return x - y \u0026gt; def multiply(x, y): \u0026gt; return x * y \u0026gt; def divide(x , y): \u0026gt; return x / y \u0026gt; def power(x, y): \u0026gt; return x ** y \u0026gt; print(\u0026#39;-\u0026#39; * 15) \u0026gt; print(\u0026#39;called! inner!\u0026#39;) \u0026gt; print(add(5,5)) \u0026gt; print(subtract(15,5)) \u0026gt; print(multiply(5,5)) \u0026gt; print(divide(10,2)) \u0026gt; print(power(5,3)) \u0026gt; print(\u0026#39;-\u0026#39; * 15) module file 실행해보기\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026gt; import module_test # import가 되자마다 바로 명령어들이 실행된다. --------------- called! inner! 10 10 25 5.0 125 --------------- # import된 module 내의 함수를 사용해보기 \u0026gt; import module_test \u0026gt; print(test_module.power(10, 3)) --------------- called! inner! 10 10 25 5.0 125 --------------- 2. If __name__ == \u0026ldquo;__main__\u0026quot; Problem\n위와 같은 방식은 module을 외부에서 가져오는 사람들에게 편의성이 좋지 않다. Solution\nif __name__ == \u0026quot;__main__\u0026quot;: 을 추가하기\n그래서 호출 시, 즉시 출력을 방지하기 위해서 print 문을 삭제하거나 주석처리를 하는 방법을 사용할 수도 있다.\npython에서는 이에 대해 다른 방법을 만들었는데, 예약어를 사용하여 아래 2가지로 나눠서 실행할 수 있다.\n다른 곳에서 외부적으로 import를 할 경우 자기 자신을 스스로 실행할 경우 if __name__ == \u0026quot;__main__\u0026quot;: 명령어를 추가하여 해당 모듈이 import 된 경우가 아니라, 인터프리터에서 직접 실행된 경우에만 if 문 이하의 코드를 돌리라를 명령이다.\nmodule 파일에 아래 코드를 추가한다.\n1 2 3 4 5 6 7 8 9 \u0026gt; if __name__ == \u0026#34;__main__\u0026#34;: \u0026gt; print(\u0026#39;-\u0026#39; * 15) \u0026gt; print(\u0026#39;called! __main__\u0026#39;) \u0026gt; print(add(5,5)) \u0026gt; print(subtract(15,5)) \u0026gt; print(multiply(5,5)) \u0026gt; print(divide(10,2)) \u0026gt; print(power(5,3)) \u0026gt; print(\u0026#39;-\u0026#39; * 15) main: 실행되는 주체가 이 코드가 작성된 파일인 경우를 의미\nimport를 하면 바로 실행되지 않는다. 왜냐하면 실행되는 주체가 다른 파일이기 때문이다. 하지만, module 파일에서 인터프리터로 직접 실행하면, 실행주체이기 때문에 출력된다. import 한 파일에서는 명령어를 입력하면 실행된다.\n1 2 3 \u0026gt; import module_test \u0026gt; print(module_test.power(10,3)) 1000 그래서 바로 실행되지 않도록 if __name__ == \u0026quot;__main__\u0026quot;놔둔다.\n더 자세한 내용은 [TIL] Python basic 23: if _ _name _ _ == \u0026rsquo; _ _main _ _\u0026rsquo; 을 참고한다.\nReference 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_15_module/","summary":"Module이란 무엇인지, Module을 어떻게 사용하는지, Module 관련 함수에 대해 알아본다.","title":"[TIL] Python basic 15: module"},{"categories":["Python"],"content":"1. OOP란? OOP : Object Oriented Programming 의 약자로, `객체 지향 프로그래밍\u0026rsquo; 이라 한다. Object(객체) : 소프트웨어로 구현할 대상 OOP의 특징: Encapsulation(캡슐화) 로 \u0026lsquo;attribute\u0026rsquo; 와 \u0026lsquo;method\u0026rsquo;를 하나로 묶어서 객체로 구성하는 것 \u0026lsquo;OOP\u0026rsquo;의 이점 Encapsulation(캡슐화)를 통해서 내부 정보를 외부로부터 보호하면서, 주변에 악영향 (side effect)을 최소화할 수 있다. 이를 Infomation hiding(정보 은폐)이라 한다. class를 통해 만들기 때문에 코드의 재사용성이 용이하다. =\u0026gt; 경제적 코드의 개선, 수정이 용이하다. 버그가 발생했을 때 유지보수 또한 용이하다. 하지만, \u0026lsquo;OOP\u0026rsquo;가 항상 빠르진 않다. 경우에 따라서는 객체 지향보다 절차 지향이 더 빠른 퍼포먼스를 가질 수 있으므로, 객체 지향과 절차 지향을 적절히 섞어 사용하자. 절차 지향 : 위에서부터 아래로 실행하는 것 절차지향과 OOP 비교해보기 : [TIL] Python basic 24: Procedural Programming vs OOP\n2. Class와 instatnce의 차이 눈에 보이는 \u0026lsquo;실체\u0026rsquo;들 중에서 \u0026lsquo;소프트웨어로 구현할 대상`\u0026lsquo;을 선정한다. 소프트웨어로 구현할 대상을 객체(Object)라 한다. 이 객체(Object) 를 class라는 틀 을 통해서 소프트웨어적으로 묘사한 것을 instance 라 한다. 2.1 Class 만들고 호출하기 class 만들기 위한 상황\n애완견 용품에서 사용하는 소프트웨어를 개발한다고 가정하자. 개의 종은 매우 다양해서 개의 종이 추가될 때마다 변수 입력한다면 그 양이 매우 많아지고 가독성도 떨어진다. 하지만, 클래스를 이용한다면 눈에 보이는 애완견 실체를 클래스 형태로 구성해서 instance로 만들 수 있다. 즉 클래스는 설계도라고 생각하면 되고, 인스턴스(instance)는 이 설계도를 토대로 만들어진 것이라 생각하자. class 라는 예약어를 통해 클래스를 만들기 시작한다.\n모든 클래스는 object를 상속받기 때문에, 선언 방법은 자유롭다. __init__에 대해서 파이썬에서 클래스가 초기화될 때 반드시 호출되는 함수다. 반드시 호출되는 이유는 개발자가 초기화 작업을 잊을 경우, 예상치 못한 오류가 발생할 수 있다. 예를 들어 의도한 대로라면 특정 정보를 가지고 있어야 하는데 아무런 정보를 가지고 있지 않아 오류가 발생할 수 있다. 그래서 \u0026lsquo;반드시\u0026rsquo; 초기화 작업을 해야 한다. 사용자가 스스로 \u0026lsquo;__init__\u0026rsquo; 사용자 정의 생성자를 만들지 않아도 \u0026lsquo;__init__\u0026rsquo; 이 없으면 파이썬이 알아서 클래스를 만들 때 내부적으로 실행한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Dog라는 class를 생성한다. \u0026gt; class Dog(): # 또는 \u0026gt; class Dog(object): \u0026gt; species = \u0026#34;firstdog\u0026#34; \u0026gt; \u0026gt; # 모든 class는 초기화 method 및 인스턴스 속성을 가질 수 있다. \u0026gt; # self 후에, 인스턴스에 사용할 변수 속성들을 입력한다. \u0026gt; def __init__(self, name, age): \u0026gt; # 초기화 method를 입력하고 나서, 입력한 인스턴스 속성들에 정확히 mapping 한다. \u0026gt; self.name = name \u0026gt; self.age = age 클래스 정보를 호출해보자. 1 2 3 4 ## class 정보 호출하기 # 클래스가 코드로 구현된 걸 확인할 수 있다. \u0026gt; print(Dog) \u0026lt;class \u0026#39;__main__.Dog\u0026#39;\u0026gt; 2.2 인스턴스화하기 \u0026lsquo;인스턴스화\u0026rsquo;란 class를 통해 구현된 instance에 변수를 할당하는 걸 의미하는데, 인스턴스화한 변수들은 모두 다른 id값을 가진다. 즉 각 인스턴스는 고유의 것이다.\ninstance는 변수에 할당하여 활용되며, 이는 메모리에 올라가서 각각의 다른 id값을 가진다. 전혀 다른 객체로 간주된다. 또한, 각 instance는 동일한 속성값을 가져도, 파이썬에게는 전혀 다른 객체로 간주된다. 1 2 3 4 5 6 7 8 9 ## 인스턴스화 # 할당될 변수 = 클래스 이름(instance 속성들) \u0026gt; a = Dog(\u0026#34;mikky\u0026#34;, 2) \u0026gt; b = Dog(\u0026#34;baby\u0026#34;, 3) \u0026gt; c = Dog(\u0026#34;mikky\u0026#34;, 2) # 모두 다른 id값을 가진다. \u0026gt; print(a == c, id(a), id(b), id(c)) False 2542532857088 2542532856992 2542532856560 2.3 namespace 확인하기 namespace란 python의 해당 객체와 관련된 attribute의 name들이 저장된 공간 으로서, dictionary가 python의 naming system에 사용하기 때문에, 각 name은 key로서 중복되지 않는다.\ndir() 과 .__dict__를 통해서 namespace를 확인할 수 있는데, 그럼 이 두 가지의 차이는 무엇일까?? dir( ) .__dict__ function or method built-in function(내장함수) magic method(special method) Data type list dictionary 호출 내용 객체를 만든 class가 가진 attribute와 method 정보 ( key name만 ) 인스턴스 객체만의 attribute와 value ( key name과 value ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # dict로 instance의 namespace 확인하기 \u0026gt; print(\u0026#39;dog1\u0026#39;, a.__dict__) \u0026gt; print(\u0026#39;dog2\u0026#39;, b.__dict__) dog1 {\u0026#39;name\u0026#39;: \u0026#39;mikky\u0026#39;, \u0026#39;age\u0026#39;: 2} dog2 {\u0026#39;name\u0026#39;: \u0026#39;baby\u0026#39;, \u0026#39;age\u0026#39;: 3} # dir로 instance의 namespace 확인하기 \u0026gt; print(\u0026#39;instance dir \u0026gt; \u0026#39;, dir(a)) instance dir \u0026gt; [\u0026#39;__class__\u0026#39;,\u0026#39;__dict__\u0026#39;, \u0026#39;__dir__\u0026#39;, ..., \u0026#39;age\u0026#39;, \u0026#39;name\u0026#39;, \u0026#39;species\u0026#39;] # dict로 class의 namespace 확인하기 \u0026gt; print(\u0026#39;class dict \u0026gt; \u0026#39;, Dog.__dict__) class dict \u0026gt; {\u0026#39;__module__\u0026#39;: \u0026#39;__main__\u0026#39;, \u0026#39;species\u0026#39;: \u0026#39;firstdog\u0026#39;, \u0026#39;__init__\u0026#39;: \u0026lt;function Dog.__init__ at 0x0000019C2641AA60\u0026gt;, \u0026#39;__dict__\u0026#39;: \u0026lt;attribute \u0026#39;__dict__\u0026#39; of \u0026#39;Dog\u0026#39; objects\u0026gt;, \u0026#39;__weakref__\u0026#39;: \u0026lt;attribute \u0026#39;__weakref__\u0026#39; of \u0026#39;Dog\u0026#39; objects\u0026gt;, \u0026#39;__doc__\u0026#39;: None} # dir로 class의 namespace 확인하기 \u0026gt; print(\u0026#39;class dir \u0026gt; \u0026#39;, dir(Dog)) class dir \u0026gt; [\u0026#39;__class__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__dict__\u0026#39;, \u0026#39;__dir__\u0026#39;,..., \u0026#39;species\u0026#39;] namespace 를 통해서 class와 instance들이 가지고 있는 속성들을 확인할 수 있다. class 는 하나지만, instance를 만들 때 다른 속성 값을 입력했기 때문에, dir() 이 아닌, .__dict__를 통해서 이를 확인할 수 있다. 그래서 instance의 속성값을 확인할 때는 .__dict__ 를 사용하자. 3. Self 의 이해: class method, instance method class method : 클래스 변수를 인자로 받는 method instance method : 인스턴스 변수를 인자로 받는 method self : instance를 인자로 받는 매개변수 method 호출방법 class method 1가지 방법 ❗️ 주의 사항: 인스턴스화한 변수를 통해서 class method 를 호출하면 error가 뜬다. class로 바로 호출하는 방법 (1-1 방법) instance method 2가지 방법 첫 번째: 인스턴스화 변수를 통해서 instance method 를 호출하는 방법 (2-1 방법) 두 번째: 클래스로 접근하여 인자에 인스턴스를 넘겨주는 방법 (2-2 방법) instance 변수를 만들지 않고 사용할 것이기 때문에, \u0026lsquo;__init__\u0026rsquo; 사용자 정의 생성자를 만들지 않는다 \u0026lsquo;__init__\u0026rsquo; 이 없으면 파이썬이 알아서 클래스를 만들 때 내부적으로 실행한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026gt; class SelfTest: \u0026gt; def func1(): \u0026gt; print(\u0026#39;Func1 called\u0026#39;) \u0026gt; def func2(self): \u0026gt; print(id(self)) \u0026gt; print(\u0026#39;Func2 called\u0026#39;) # 변수를 인스턴스화 한다. \u0026gt; f = SelfTest() # dir로 변수 내부를 확인한다. \u0026gt; print(dir(f)) [\u0026#39;__class__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__dict__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;,..., \u0026#39;func1\u0026#39;, \u0026#39;func2\u0026#39;] 인스턴스화된 f를 통해서 func1을 호출해보자. func1에는 매개변수가 없는데, 1개가 넘어갔다는 걸 알 수 있다.\n1 2 \u0026gt; f.func1() TypeError: func1() takes 0 positional arguments but 1 was given func1은 매개변수가 없는데, 왜 매개변수로 1개가 넘어간 것일까? 넘어간 매개변수는 무엇일까??\n바로 인스턴스가 인자로 넘어간 것이다. 인스턴스에 dot operator로 class의 method에 접근하면 인스턴스가 인자로 넘어가기 때문에, 위와 같은 TypeError가 발생했다. 인스턴스 메서드 호출 방법: 2-1 2-1 방법으로 인스턴스화된 f를 통해서 func2를 호출해보자.\n1 2 3 4 5 6 7 \u0026gt; f.func2() 2799723753424 Func2 called # f의 id 값을 호출해보자. \u0026gt; print(id(f)) 2799723753424 위 결과를 통해서 다음과 같은 이유로 self는 instance를 인자로 받는 매개변수 이며, self가 있는 method 는 instance의 method 인 걸 알 수 있다. 첫 번째, func1을 호출한 방법과 동일한 방법으로 self가 매개변수로 있는 func2를 호출하니 Error가 뜨지 않았다. 두 번째, f.func2() 에 의해서 출력된 id 와 id(f)의 값이 동일하다. 클래스 메서드 호출 방법: 1-1 1-1 방법으로 class method를 호출해보자.\n1 2 3 ## class method 호출하기 (1-1 방법) \u0026gt; SelfTest.func1() Func1 called 위 결과를 통해서 다음과 같은 이유로 self가 없는 method 는 class method인 걸 알 수 있다. func1을 인스턴스로 접근하여 호출했을 때는 TypeError가 떴었다. 하지만, class로 직접 접근하여 호출하니, 정상적으로 출력된 걸 알 수 있다. 만약 class로 접근하여 func2를 호출한다면 어떻게 될까???\n1 2 \u0026gt; SelfTest.func2() Typeerror: func2() missing 1 required positional argument: \u0026#39;self\u0026#39; func2가 요구하는 매개변수 1개를 놓쳤다는 TypeError를 확인할 수 있다.\n인스턴스 메서드 호출 방법: 2-2 그러면 2-2 방법으로 매개변수 1개를 입력해보자.\n1 2 3 \u0026gt; SelfTest.func2(f) 2332370018256 Func2 called 그래서 클래스로 접근해도 instance method에 인스턴스화한 변수를 인자로 넘기니 정상적으로 작동됨을 알 수 있다.\n4. class, instance variable 다른 클래스를 만들어보자.\ninstance attribute를 만들어서 사용할 것이기 때문에 사용자 정의 생성자를 위해 __init__ 를 사용한다.\n그리고 생성자와는 반대로 소멸자를 사용했다.\n소멸자: 객체가 소멸될 때 즉, 메모리에서 지워질 때 자동으로 호출되는 함수 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026gt; class Warehouse(): \u0026gt; # class variable \u0026gt; stock_num = 0 \u0026gt; \u0026gt; def __init__(self, name): # 생성자 \u0026gt; # instance variable \u0026gt; # mapping \u0026gt; self.name = name \u0026gt; Warehouse.stock_num += 1 \u0026gt; \u0026gt; def __del__(self): # 소멸자 \u0026gt; Warehouse.stock_num -= 1 # user1 instance의 name을 Lee로 한다. \u0026gt; user1 = Warehouse(\u0026#39;Lee\u0026#39;) # user2 instance의 name을 Cho로 한다. \u0026gt; user2 = Warehouse(\u0026#39;Cho\u0026#39;) 4.1 class 속성, instance 속성 확인하기 namespace에는 객체의 속성들이 있는 곳임을 확인했다. 그러면 class와 instance의 각 속성들을 한층 더 들어가 확인해보자.\nClass variable(클래스 변수) class 내부 method를 정의하기 전인 enclosing-scope에 정의한 변수 현재 상태로는 직접 접근이 가능하다. 접근 제어자라는 개념을 나중에 학습하면 접근 권한을 차등적으로 변수마다 부여할 수 있다. 클래스 변수는 공유되기 때문에, 모든 인스턴스에서 공통으로 가지고 있는 변수 instance의 namespace에 있지 않고, class의 namespace에 존재한다. instance variable(인스턴스 변수) self가 붙은 것들이 instance varible(인스턴스 변수)다. 직접 접근이 아닌, 인스턴스화된 변수로 접근이 가능하다. 객체마다 별도로 존재한다. namespace 라는 인스턴스만의 공간 을 별도로 갖고 있어서, namespace를 통해 인스턴스 변수를 확인한다. 클래스 변수에 접근하기 class name으로 접근하기\n인스턴스화된 변수를 통해서 접근하기\n1 2 3 4 5 6 7 # 클래스로 직접 접근하기 \u0026gt; print(Warehouse.stock_num) 2 # 인스턴스화된 변수를 통해서 접근하기 \u0026gt; print(user1.stock_num) 2 직접 접근이 가능하며, 모든 인스턴스가 공유한다는 걸 알 수 있다. 인스턴스 변수에 접근하기 인스턴스화된 변수를 통해서 접근하기 1 2 3 4 5 \u0026gt; print(user1.name) Lee \u0026gt; print(user2.name) Cho 클래스 변수와 인스턴스 변수 확인하기 class와 instance의 각 namespace에서 class 변수와 instance 변수를 확인해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # instance의 namespace에서는 공통적으로 가지고 있는 클래스 변수를 찾을 수 없다. # instance 변수는 찾을 수 있다. \u0026gt; print(user1.__dict__) {\u0026#39;name\u0026#39;: \u0026#39;Lee\u0026#39;} \u0026gt; print(user2.__dict__) {\u0026#39;name\u0026#39;: \u0026#39;Cho\u0026#39;} # class의 namespace에서 찾을 수 있다. \u0026gt; print(Warehouse.__dict__) {\u0026#39;__module__\u0026#39;: \u0026#39;__main__\u0026#39;, \u0026#39;stock_num\u0026#39;: 2, \u0026#39;__init__\u0026#39;: \u0026lt;function Warehouse.__init__ at 0x000002DC6B59F8B0\u0026gt;, \u0026#39;__del__\u0026#39;: \u0026lt;function Warehouse.__del__ at 0x000002DC6B59F940\u0026gt;, \u0026#39;__dict__\u0026#39;: \u0026lt;attribute \u0026#39;__dict__\u0026#39; of \u0026#39;Warehouse\u0026#39; objects\u0026gt;, ...} 위 코드를 통해서 다음을 알 수 있다.\n클래스 변수는 인스턴스의 공통된 변수이지만, 인스턴스의 네임스페이스에서는 찾을 수 없다. 클래스 변수는 클래스의 네임스페이스에서 찾을 수 있다. 소멸자를 사용하여 instance를 삭제하면, 클래스 변수인 stock_num이 감소한 걸 확인할 수 있다.\n1 2 3 \u0026gt; del user1 \u0026gt; print(\u0026#39;after\u0026#39;, Warehouse.__dict__) {\u0026#39;__module__\u0026#39;: \u0026#39;__main__\u0026#39;, \u0026#39;stock_num\u0026#39;: 1, ...} 4.2 Python의 namespace lookup 원리 파이썬은 object의 이름을 다음 순서로 찾는다.\nsuper class는 해당 class의 상위 class를 의미한다.\ninstance의 namespace -\u0026gt; class의 namespace -\u0026gt; super의 namespace\n한 가지 의문 instance의 namespace에서는 class 변수가 없다.\n그러면 인스턴스화한 변수를 통해서 클래스 변수가 어떻게 출력되는걸까???\n이는 python이 instance의 namespace에서 찾지 못하면 class의 namespace에서 찾아 출력한다.\n5. Class의 장점 마지막으로 또 다른 클래스를 만들어보면서 위 내용들을 음미해보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ## Dog라는 class를 만든다. \u0026gt; class Dog(): \u0026gt; # 클래스 변수 선언 \u0026gt; species = \u0026#39;Firstdog\u0026#39; \u0026gt; # 생성자 및 인스턴스 속성 생성 그리고 mapping \u0026gt; def __init__(self, name, age): \u0026gt; self.name = name \u0026gt; self.age = age \u0026gt; # 인스턴스 메소드 \u0026gt; def info(self): \u0026gt; return \u0026#39;{} is {} years old\u0026#39;.format(self.name, self.age) \u0026gt; # 인스턴스 메소드 \u0026gt; # sound는 호출 시에 입력한다. \u0026gt; def speak(self, sound): \u0026gt; return \u0026#39;{} says {}!\u0026#39;.format(self.name, sound) ## 인스턴스화 + 인스턴스 속성값 입력 \u0026gt; c = Dog(\u0026#39;july\u0026#39;, 4) \u0026gt; d = Dog(\u0026#39;Marry\u0026#39;, 10) ## 인스턴스 메소드 호출 \u0026gt; print(c.info()) july is 4 years old \u0026gt; print(d.info()) Marry is 10 years old ## 인스턴스 메소드 호출 + sound 매개변수 입력 \u0026gt; print(c.speak(\u0026#39;wal wal\u0026#39;)) july says wal wal! \u0026gt; print(d.speak(\u0026#39;Mung Mung\u0026#39;)) Marry says Mung Mung! 위 예제들을 통해서 class의 장점을 다시 한 번 확인할 수 있다.\nclass 하나를 만들어놓고 찍어내듯이 사용할 수 있다. instance만의 공간도 있고, 공유하는 공간이 있다. 그래서 코드의 재사용성이 좋다는 것이다. 코드의 재사용성이 좋다는 의미는 더 구체적으로 말하자면\n객체지향에 입각하여 불필요한 중복을 방지한다. 깔끔한 코드를 통해 프로그램 개발을 할 수 있다. 생산성이 향상되고, 성능도 코드에 따라 좋아진다. Summary namespace: 파이썬의 객체들과 관련된 속성들이 dictionary 형태로 저장된 공간\ndir과 __dict__의 차이점\ndir( ) .__dict__ function or method built-in function(내장함수) magic method(special method) Data type list dictionary 호출 내용 객체가 가진 속성 name과 method 정보 ( key name만 ) 객체의 속성 name과 name의 value까지 ( key name과 value ) method의 종류: class method, instance method, static method\n인스턴스의 namespace에는 class 변수는 존재하지 않지만, 인스턴스를 통해서 접근할 수 있다. 그 이유는 인스턴스의 namespace에서 찾지 못하면 class의 namespace에서 찾기 때문이다.\n인스턴스화된 변수를 통해서는 클래스 메서드에 접근할 수 없다.\n클래스 메서드에 접근하기 위해서는 클래스를 통해서 바로 접근해야 하며, 인스턴스 메서드에 접근하기 위해서는 인스턴스화된 변수를 통한 방법과 클래스로 접근하여 인자에 인스턴스를 넘겨주는 방법이 있다.\nReference 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_14_class/","summary":"OOP의 의미가 무엇인지, Class와 Instance의 차이가 무엇인지, self가 무엇을 의미하는지, class variable과 instance variable에 대해 알아본다.","title":"[TIL] Python basic 14: class"},{"categories":["Python"],"content":"1. 사용자 입력 1 2 3 4 5 6 7 \u0026gt; name = input(\u0026#39;Enter Your Name : \u0026#39;) \u0026gt; grade = input(\u0026#39;Enter Your grade : \u0026#39;) \u0026gt; school = input(\u0026#39;Enter Your school : \u0026#39;) \u0026gt; print(name, grade, school) \u0026gt; print(type(name), type(grade), type(school)) Jeha A+ here \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; 2. 형 변환 입력 input 함수는 기본 타입은 string 이다. string 외의 원하는 형태가 있다면 반드시 형 변환을 해야 한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026gt; first_number = int(input(\u0026#34;Enter number1 : \u0026#34;)) Enter number1 : 20 \u0026gt; second_number = int(input(\u0026#34;Enter number2 : \u0026#34;)) Enter number2 : 15 \u0026gt; total = first_number + second_number \u0026gt; print(\u0026#34;fist_number + second_number : \u0026#34;, total) fist_number + second_number : 35 \u0026gt; float_number = float(input(\u0026#34;Enter a float number : \u0026#34;)) Enter a float number : 15 \u0026gt; print(\u0026#34;input float : \u0026#34;, float_number) input float : 15 \u0026gt; print(\u0026#34;input type : \u0026#34;, type(float_number)) \u0026lt;class \u0026#39;float\u0026#39;\u0026gt; Reference 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_13_input/","summary":"input을 통한 사용자 입력과 형 변환(type conversion) 입력을 알아본다.","title":"[TIL] Python basic 13: input"},{"categories":["Python"],"content":"1. 함수 중요성 첫 번째 , 코드의 흐름을 원활히 할 수 있다. 요즘은 코드의 복잡도가 커지면서 코드 양이 매우 많아졌다. 그래서 이 코드를 일괄작성하기가 힘들다. 이에 대한 대책으로 단계별로 생각하여 각 단계마다 함수를 사용하여 개발을 원활하게 풀어갈 수 있다. 두 번째, 함수로 사용하면 코드의 재사용성이 향상된다. 하나의 기능을 각 소스마다 중복하여 집어 넣으면, 그 기능을 수정해야할 경우, 다 수정해야하는 번거로움이 있다. 이런 것들이 비효율적이기 때문에, 함수로 만들면 한 번의 수정으로 다 수정할 수 있다. 세 번째, 코드의 안정성이 좋아진다. 그 이유는 개발자가 자신이 담당하는 함수에만 집중할 수 있기 때문에, 함수 이외의 부분과 나눠서 생각할 수 있다. 2. 함수 선언 및 사용 2.1 return의 유무 함수에서 return을 사용하지 않으면\nprint로 출력할 수 없다. unpacking을 사용할 수 없다. 여러 값을 return 으로 반환하는 것을 다중 반환이라 한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 ## return 명령어가 없을 경우 \u0026gt; def func_mul(x): \u0026gt; y1 = x * 10 \u0026gt; x1 = func_mul(10) \u0026gt; print(x1, type(x1)) None \u0026lt;class \u0026#39;NoneType\u0026#39;\u0026gt; # 출력할 수 없다. ## return 명령어가 있을 경우 \u0026gt; def func_mul(x): \u0026gt; y1 = x * 10 \u0026gt; return y1 \u0026gt; x1 = func_mul(10) \u0026gt; print(x1) 100 ## No return and unpacking \u0026gt; def func_mul1(x): \u0026gt; y1 = x * 10 \u0026gt; y2 = x * 20 \u0026gt; y3 = x * 30 # unpacking \u0026gt; x1, x2, x3 = func_mul1(10) \u0026gt; print(x1, x2, x3) TypeError: cannot unpack non-iterable NoneType object # 다중 반환 확인하기 \u0026gt; def func_mul1(x): \u0026gt; y1 = x * 10 \u0026gt; y2 = x * 20 \u0026gt; y3 = x * 30 \u0026gt; return y1, y2, y3 # unpacking \u0026gt; x1, x2, x3 = func_mul1(10) \u0026gt; print(x1, x2, x3) 100 200 300 2.2 원하는 data type으로 return하기 원하는 data type으로 함수값을 출력하려면 어떻게 해야하는지 알아보자.\nreturn 할 data의 type이 출력할 data type이 된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 ## tuple return \u0026gt; def func_mul1(x): \u0026gt; y1 = x * 10 \u0026gt; y2 = x * 20 \u0026gt; y3 = x * 30 \u0026gt; return (y1, y2, y3) # tuple 형식 \u0026gt; t1 = func_mul1(10) \u0026gt; print(t1, type(t1)) (100, 200, 300) \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; ## list return \u0026gt; def func_mul2(x): \u0026gt; y1 = x * 10 \u0026gt; y2 = x * 20 \u0026gt; y3 = x * 30 \u0026gt; return [y1, y2, y3] # list 형식 \u0026gt; t1 = func_mul2(10) \u0026gt; print(t1, type(t1)) [100, 200, 300] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; ## dictionary return \u0026gt; def func_mul3(x): \u0026gt; y1 = x * 10 \u0026gt; y2 = x * 20 \u0026gt; y3 = x * 30 \u0026gt; return {\u0026#39;v1\u0026#39; : y1, \u0026#39;v2\u0026#39; : y2, \u0026#39;v3\u0026#39; : y3} # keyword 형식 \u0026gt; t1 = func_mul3(10) \u0026gt; print(t1, type(t1)) \u0026gt; print(t1.values()) {\u0026#39;v1\u0026#39;: 100, \u0026#39;v2\u0026#39;: 200, \u0026#39;v3\u0026#39;: 300} \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; dict_values([100, 200, 300]) \u0026gt; d = func_mul3(30) \u0026gt; print(type(d), d, d.get(\u0026#39;v2\u0026#39;), d.items(), d.keys()) \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; {\u0026#39;v1\u0026#39;: 300, \u0026#39;v2\u0026#39;: 600, \u0026#39;v3\u0026#39;: 900} 600 dict_items([(\u0026#39;v1\u0026#39;, 300), (\u0026#39;v2\u0026#39;, 600), (\u0026#39;v3\u0026#39;, 900)]) dict_keys([\u0026#39;v1\u0026#39;, \u0026#39;v2\u0026#39;, \u0026#39;v3\u0026#39;]) 3. Packing, Unpacking 3.1 Positional argument, Keyword argument 함수 인자에는 Positional argument(위치인자)와 Keyword argument(키워드 인자)가 있다. 인자란 함수 기능에 필요한 값을 말한다. 기본값이란 미리 기본으로 지정된 값을 말한다. Positional argument는 인자값이 위치 에 의해 결정되는 인자다. 순서 가 중요하다. Keyword argument는 key value가 key 에 의해 결정되는 인자다. 순서 상관 없이 keyword 가 중요하다. 1 2 3 4 5 6 7 8 9 10 ## Positional argument(위치인자) # real number (실수)는 앞에, imaginary number(허수)는 뒤에 위치해야 된다. # 위치 즉, 순서가 중요하다. \u0026gt; complex(3, 5) (3 + 5j) ## Keyword argument(키워드 인자) # key = value \u0026gt; complex (real = 3, imag = 5) (3 + 5j) 3.2 Packing의 두 종류 print함수처럼 함수가 받을 인자의 갯수를 유연하게 지정 하기 위해 사용하는 것\nprint 함수는 객체의 갯수에 제한 없이 출력한다.\n1 2 3 4 5 6 7 # 1개 \u0026gt; print(\u0026#39;123 456 789\u0026#39;) 123 456 789 # 3개 \u0026gt; print(\u0026#39;123\u0026#39;, \u0026#39;456\u0026#39;, \u0026#39;789\u0026#39;) 123 456 789 packing 은\narguments를 하나의 객체로 합쳐서 받을 수 있도록 한다. positional argument packing 과 keyword argument packing이 있다. 다음 table과 같은 특징을 가진다. args: arguments / kwargs: keyword arguments args와 kwargs는 매개변수 명으로, 자유롭게 명명한다. packing positional argument packing keyword argument packing expression *args **kwargs data type tuple dictionary 3.2.1 Positional arguments packing positional argument에 대해 앞서서 enumerate () 에 대해 알아보겠다.\nenumerate는 index 와 value 를 tuple 형식으로 하나의 성분으로서 맺어주고, return 해주는 함수다.\n1 2 3 4 5 6 7 8 9 10 11 12 ## enumerate() \u0026gt; seasons = [\u0026#39;Spring\u0026#39;, \u0026#39;Summer\u0026#39;, \u0026#39;Fall\u0026#39;, \u0026#39;Winter\u0026#39;] # enumerate()를 하면 바로 id 값만 출력된다. \u0026gt; print(enumerate(seasons)) \u0026lt;enumerate object at 0x000002957E6DE640\u0026gt; \u0026gt; print(list(enumerate(seasons))) [(0, \u0026#39;Spring\u0026#39;), (1, \u0026#39;Summber\u0026#39;), (2, \u0026#39;Fall\u0026#39;), (3, \u0026#39;Winter\u0026#39;)] \u0026gt; print(tuple(enumerate(seasons))) ((0, \u0026#39;Spring\u0026#39;), (1, \u0026#39;Summber\u0026#39;), (2, \u0026#39;Fall\u0026#39;), (3, \u0026#39;Winter\u0026#39;)) enumerate () 를 사용하여 positional arguments packing을 설명하겠다.\nenumerate ()를 for ~ in문에 사용하겠다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # args == arguments \u0026gt; def args_func(*args): \u0026gt; for i, v in enumerate(args): \u0026gt; print(\u0026#39;Result : {}\u0026#39;.format(i), v) # 인자의 수가 다양해도 다 받아지는 걸 알 수 있다. \u0026gt; args_func(\u0026#39;Lee\u0026#39;) Result : 0 Lee # 위치인자로 보낸 모든 객체들(\u0026#39;Lee\u0026#39;, \u0026#39;Park\u0026#39;)을 *args로 하나의 객체로서 관리해준다. \u0026gt; args_func(\u0026#39;Lee\u0026#39;, \u0026#39;Park\u0026#39;) Result : 0 Lee Result : 1 Park \u0026gt; args_func(\u0026#39;Lee\u0026#39;, \u0026#39;Park\u0026#39;, \u0026#39;Kim\u0026#39;) Result : 0 Lee Result : 1 Park Result : 2 Kim 3.2.2 Keyword arguments packing keyword argument packing을 사용하는 방법\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026gt; def kwargs_func(**kwargs): \u0026gt; for v in kwargs.keys(): \u0026gt; print(\u0026#34;{}\u0026#34;.format(v), kwargs[v]) # keyword arguments를 packing 하여 dictionary로 관리한다. \u0026gt; kwargs_func(name1=\u0026#39;Apple\u0026#39;) name1 Apple \u0026gt; kwargs_func(name1=\u0026#39;Apple\u0026#39;, name2=\u0026#39;Window\u0026#39;) name1 Apple name2 Window \u0026gt; kwargs_func(name1=\u0026#39;Apple\u0026#39;, name2=\u0026#39;Window\u0026#39;, name3=\u0026#39;Choice\u0026#39;) name1 Apple name2 Window name3 Choice positional argument 와 keyword argument를 같이 사용해보자.\n1 2 3 4 \u0026gt; def example(args_1, args_2, *args, **kwargs): \u0026gt; print(args_1, args_2, args, kwargs) \u0026gt; example(10, 20, \u0026#39;Lee\u0026#39;, \u0026#39;Kim\u0026#39;, \u0026#39;Park\u0026#39;, \u0026#39;Cho\u0026#39;, age1=20, age2=30, age3=40) 10 20 (\u0026#39;Lee\u0026#39;, \u0026#39;Kim\u0026#39;, \u0026#39;Park\u0026#39;, \u0026#39;Cho\u0026#39;) {\u0026#39;age1\u0026#39;: 20, \u0026#39;age2\u0026#39;: 30, \u0026#39;age3\u0026#39;: 40} args_1, args_2 로 총 2개이므로, print의 매개변수 앞에서 2개까지가 일반적인 positional argument이다.\n그 뒤에, *args 는 positional argument packing이므로 제한 없다. tuple 로 출력된 걸 확인할 수 있다.\n맨 마지막 인자는 ** 이므로, keyword argument packing이다. dictionary로 출력된 걸 확인할 수 있다.\n3.3 Unpacking 주의사항: Unpacking 시 해체되는 인자의 수와 매칭되는 변수의 수가 동일해야 가능하다.\nUnpacking은 packing과는 반대로 여러개의 객체를 포함하고 있는 하나의 객체를 푼다.\npacking 시에는 function (or method) 정의 시, parameter에 *을 붙였지만,\nunpacking 시에는 function (or method) 사용 시, argument 앞에 *를 붙여서 사용한다.\n1 2 3 4 5 \u0026gt; def sum(a, b, c): \u0026gt; return a + b + c \u0026gt; number = (1, 2, 3) \u0026gt; print(sum(*number)) 6 또는 다음과 같은 방식으로 unpacking 할 수 있다.\n1 2 3 4 5 6 7 \u0026gt; def func_mul1(x): \u0026gt; y1 = x * 10 \u0026gt; y2 = x * 20 \u0026gt; y3 = x * 30 \u0026gt; return y1, y2, y3 # unpacking \u0026gt; x1, x2, x3 = func_mul1(10) 4. 중첩 함수 (Nested function) 함수 내부에 정의된 또 다른 함수\n중첩 함수는 함수형 프로그래밍에서 많이 사용된다.\n부모 함수(외부 함수)와 하위 함수(내부 함수)\n호출하는 함수는 부모 함수다. 하위 함수는 호출할 수 없다. 그 이유는 [TIL] Python basic 32: LEGB rules and Memory structures 을 참고하자. 하위 함수는 부모 함수의 매개변수를 받아서 사용한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 # 중첩 함수 \u0026gt; def nested_func(num): # 부모 함수 \u0026gt; def func_in_func(num): # 부모 함수의 매개변수를 받아서 사용 가능 \u0026gt; print(num) \u0026gt; print(\u0026#34;In func\u0026#34;) \u0026gt; func_in_func(num + 100) \u0026gt; nested_func(100) 200 # 부모 함수의 하위 함수를 호출하여 사용할 수 없다. \u0026gt; func_in_func(100) NameError: name \u0026#39;func_in_func\u0026#39; is not defined 5. 람다(lambda) 함수 (익명함수) 람다식의 장점 from python 공식 사이트\n메모리 절약 가독성 향상 코드 간결 람다식의 단점 (많은 실력자 분들이 람다식을 부정적으로 피력한다.)\n과한 사용 시, 가독성 감소된다. 왜냐하면 익명 함수이기 때문이다. 일반적인 함수는 함수명을 보고 그 기능을 추측할 수 있으나, 익명 함수라 추측할 수 없다. 일반적인 함수와 람다식 함수의 차이\n일반적인 함수는 함수명 이 있기 때문에, 객체 생성 된다. 그 후, resource(memory)를 할당 한다. 하지만, 람다식 함수는 즉시 실행 함수 라서 일회성이고, Heap 영역에 저장되고 (Heap 초기화), 파이썬의 garbage collection에 의해 메모리 초기화가 되기 때문에, 메모리를 효율적으로 사용할 수 있다. 함수명이 존재하지 않아, 익명 함수라 한다. 그래서 별도의 변수에 할당해야 한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 ## 첫 번째: 이미 변수에 할당해 놓은 일반적인 함수를 넣는 방법 \u0026gt; def mul_func(x, y): \u0026gt; return x * y \u0026gt; print(mul_func(10, 50)) 500 \u0026gt; mul_func_var = mul_func \u0026gt; print(mul_func_var(10, 50)) 500 ## 두 번째: 자주 쓰는 람다 함수이기 때문에, 정의를 해서 변수로 넘기는 방식 # 일시적으로 그 자리에서 함수가 필요할 때 사용한다. # def 와 return이 없어도 가능하다. # 람다식을 넣은 함수 \u0026gt; lambda_mul_func = lambda x,y : x * y \u0026gt; print(lambda_mul_func(10, 50)) 500 # 함수 안에서 함수를 인자로 받는 함수 \u0026gt; def func_final(x, y, func): \u0026gt; print(x * y * func(1,1)) ## 첫 번째 방식 \u0026gt; func_final(10, 50, mul_func_var) 500 ## 두 번째 방식 \u0026gt; func_final(10, 50, lambda_mul_func) 500 ## 세 번째 방식: 바로 그 자리에서 람다식을 써서 넘기는 방법 \u0026gt; func_final(10, 50, lambda x,y : x * y) 위 방식대로 총 함수를 정의하는데 3가지 방식이 있다.\n각 방식에 대해서 언제 무엇을 써야할지 생각해보자.\n6. 함수 Type Hint: Annotation 함수의 매개변수와 함수의 결과값의 각 데이터 타입을 알려주기 위해 python 3.5 부터 나온 기능\ndef \u0026lt;function-name\u0026gt;(parameter1: \u0026lt;data type\u0026gt;) -\u0026gt; \u0026lt;함수 결과값의 data type\u0026gt;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 아래 예시처럼 각 매개변수의 데이터 타입이 무엇인지 알려준다. # 그리고, 함수의 결과값의 데이터 타입도 알려준다. \u0026gt; def tot_length1(word: str, num: int) -\u0026gt; int: \u0026gt; return len(word) * num # 아래 함수는 위 함수와 동일하다. \u0026gt; def tot_length1(word, num): \u0026gt; return len(word) * num \u0026gt; print(\u0026#39;hint exam1 : \u0026#39;, tot_length1(\u0026#34;i love you\u0026#34;, 10)) \u0026gt; print(type(tot_length1(\u0026#34;i love you\u0026#34;, 10))) hint exam1 : 100 \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; \u0026gt; def tot_length2(word: str, num: int) -\u0026gt; None: \u0026gt; print(\u0026#39;hint exam2 : \u0026#39;, len(word) * num) \u0026gt; print(tot_length2(\u0026#34;niceman\u0026#34;, 10)) \u0026gt; print(type(tot_length2(\u0026#34;i love you\u0026#34;, 10))) hint exam2 : 70 \u0026lt;class \u0026#39;Nonetype\u0026#39;\u0026gt; \u0026rsquo;tot_length2\u0026rsquo;의 data type이 \u0026lsquo;Nonetype\u0026rsquo;인 이유는 return 값이 없기 때문이다.\n7. Method와 function 과의 차이 Method: 객체에 속한 function\n해당 내용은 다음 문서를 참고했다.\nDifference between Method and Function in Python 기본적인 function의 expression은 다음과 같다.\n1 2 3 4 5 6 7 8 9 10 \u0026gt; def functionName(arg1, arg2, ...): \u0026gt; \u0026#34;\u0026#34;\u0026#34; \u0026gt; # Function _body \u0026gt; \u0026#34;\u0026#34;\u0026#34; \u0026gt; def sum(num1, num2): \u0026gt; return num1 + num2 \u0026gt; sum(5,6) 11 Method의 expression은 다음과 같다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026gt; class ClassName: \u0026gt; def method_name(): \u0026gt; ………….. \u0026gt; # Method_body \u0026gt; ……………… \u0026gt; class Pet(object): \u0026gt; def my_method(self): \u0026gt; print(\u0026#34;I am a Cat\u0026#34;) \u0026gt; cat = Pet() \u0026gt; cat.my_method() I am a Cat 그러면 위 두 가지 코드를 통해서 function과 method의 차이는 무엇일까??\nfunction과 달리 method는 class object와 관련하여 호출된다. 위 코드를 보자면 \u0026ldquo;cat\u0026rdquo; 인스턴스 객체에 관련된 \u0026ldquo;my_method\u0026rdquo; 를 호출했다. 하지만, function \u0026ldquo;sum\u0026rdquo; 은 객체 없이 호출된다. 또한, method는 클래스 객체에 관련하여 호출되기 때문에, 객체 안에 있는 data에 접근할 수 있다. 그래서 객체의 상태를 바꿀 수 있지만, function은 할 수 없다. 즉, method는 클래스 객체에 속한 function임을 알 수 있다.\nfunction과 method의 호출 방법 차이: 그래서 method는 . dot annotation을 통해 사용된다. 이를 보다 깊이 들어가자면 Docs.python - Functions and methods 이 공식 문서를 참고해보자.\n클래스의 namespace에 저장된 functions들은 호출될 때, method로 바뀐다고 한다. 단지 method는 \u0026ldquo;객체 인스턴스\u0026quot;가 다른 인자들보다 앞에 오는 점에서 일반 function들과 다르다고 한다. Reference 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) Positional argument, Keyword argument Packing, Unpacking enumerate lambda function Docs.python - Functions and methods ","permalink":"http://jeha00.github.io/post/python/python_basic_12_method/","summary":"함수의 중요성 및 선언, Packing \u0026amp; Unpacking, 중첩 함수(Nested function), 람바 함사(익명 함수), 함수 Type hint인 annotation 에 대해 알아본다.","title":"[TIL] Python basic 12: function과 Method"},{"categories":["Python"],"content":"Introduction for, if, while 문을 흐름 제어문 이라 한다. for 문은 원하는 \u0026lt;collection\u0026gt;의 갯수만큼 반복한다면, while 문 은 if 문 처럼 조건을 만족할 때까지 계속 반복한다. While문 은 if문 처럼 조건이 들어간다. 그런데, 무한 반복될 수도 있기 때문에, 조건의 변화 가 필요하다. 아니면 break 를 사용한다. 조건을 만족하면 while문 을 빠져나온다. python 공식 사이트에서 while 의 구조는 다음과 같다. [expr]은 expression을 의미한다. 1 2 \u0026gt; while [expr]: \u0026gt; [statement(s)] 1. While 기본 사용법 whlie 문은 무한 반복문 이 되지 않도록, 조건의 변화 를 일으키는 코드 를 넣어야 한다. 그래서 while문의 경우, 눈으로 중간 결과를 디버깅해서 무한 반복문 인지 확인한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 예제 1 \u0026gt; m = 3 \u0026gt; while m \u0026gt; 0: \u0026gt; print(m) # 여기까지 쓰면 계속해서 m \u0026gt; 0 이므로 `무한 반복문`이 된다. \u0026gt; m -= 1 3 2 1 # 예제 2 \u0026gt; z = [\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;] \u0026gt; whlie z: # z 변수 안에 데이터가 존재하므로 True 상태이기 때문에 무한 반복문이다. # 위험한 코드이므로, 조건의 변화를 일으켜 무한 반복문을 방지한다. \u0026gt; print(z.pop()) # pop으로 성분의 갯수가 0이 되면 False가 되므로 중단된다. 2. Break, continue 조건의 변화 를 일으키면서, 원하는 조건에서 중단하거나, 조건 판단문으로 되돌아가기 위해서 break와 continue를 사용한다. break 문과 continue문은 while문 과 자주 사용된다. 중간에 if 조건문이 껴져 있는 방식이 많다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # 예제 3 \u0026gt; m = 5 \u0026gt; while m \u0026gt; 0: \u0026gt; m -= 1 \u0026gt; if m == 2: \u0026gt; break \u0026gt; print(m) \u0026gt; print(\u0026#39;Loop Ended\u0026#39;) 4 3 Loop Ended # 예제 4 \u0026gt; m = 5 \u0026gt; while m \u0026gt; 0: \u0026gt; m -= 1 \u0026gt; if m == 2: # 위에서 break를 continue로 바꿨다. \u0026gt; continue \u0026gt; print(m) \u0026gt; print(\u0026#39;Loop Ended\u0026#39;) 4 3 1 0 Loop Ended # 예제 5 \u0026gt; i = 1 \u0026gt; while i \u0026lt;= 10: \u0026gt; print(\u0026#39;i : \u0026#39;, i) \u0026gt; if i ==6: \u0026gt; break \u0026gt; i += 1 i : 1 i : 2 i : 3 i : 4 i : 5 i : 6 ❗ pass에 대해 설명하자면 다른 언어의 경우 빈 줄로 넘겨도 Error가 나지 않지만, 파이썬은 Error가 나기 때문에 나중에 작성하고자 빈란으로 남기면 안된다. 그럴 때 파이썬은 pass를 사용한다.\n3. While ~ else 구문 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 예제 6 \u0026gt; n = 5 \u0026gt; while n \u0026gt; 0: \u0026gt; print(n) \u0026gt; n -= 1 \u0026gt; if n == 3: \u0026gt; break \u0026gt; else: \u0026gt; print(\u0026#39;else out.\u0026#39;) 5 4 # 예제 7 \u0026gt; g = [\u0026#39;red\u0026#39;, \u0026#39;blue\u0026#39;, \u0026#39;white\u0026#39;, \u0026#39;black\u0026#39;] \u0026gt; c = \u0026#39;black\u0026#39; \u0026gt; i = 0 \u0026gt; while i \u0026lt; len(g): \u0026gt; if g[i] == c: \u0026gt; print(\u0026#39;find {}\u0026#39;.format(c)) \u0026gt; break \u0026gt; i += 1 \u0026gt; else: \u0026gt; print(\u0026#39;not found in lise.\u0026#39;) find black 4. 무한 반복 구문 무한정 반복되는 구문을 말한다. 이 구문이 실행되면 다운되므로, break와 continue로 방지한다. 무한 반복문의 한 예가 다음과 같다. 1 2 \u0026gt; while True: \u0026gt; print(\u0026#39;Foo\u0026#39;) 무한 반복문을 방지하기 위해 다음과 같이 수정한다. 1 2 3 4 5 6 7 8 \u0026gt; a = [\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;] \u0026gt; while True: \u0026gt; if not a: \u0026gt; break \u0026gt; print(a.pop()) baz bar foo a의 원소가 존재하지 않으므로 if not a가 참이 되어 break가 실행된다. Reference Python tutorial 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_11_while/","summary":"While 반복문의 기본 사용법, break \u0026amp; continue 문, While ~ else 구문, 무한 반복 구문에 대해 알아본다.","title":"[TIL] Python basic 11: 흐름 제어문 (while 반복문)"},{"categories":["Python"],"content":"0. Introduction for 문은 코딩에서 중요하다. 파이썬의 for 문은 다른 for 문과 달리 독자적인 특징이 있다. if else 처럼 for else도 가능하나, 자주 사용하지 않는다. iterable과 iterator 1 2 \u0026gt; for i in \u0026lt;collection\u0026gt;: \u0026gt; \u0026lt;loop body\u0026gt; 파이썬 공식 사이트에서는 다음과 같은 구조로 설명한다.\n\u0026lt;collection\u0026gt; 이란 반복 가능한 객체, iterable object를 말한다.\n그래서 collection 위치에는 iterator를 입력하면 된다.\n그러면 어떤 게 iterable 인가?\n예를 들어서 string, list, tuple, dictionary, set을 말한다.\n이에 대한 더 자세한 설명은 __iter__와 __next__를 확인해보자.\n1. for ~ range pattern: 3가지 첫 번째 패턴 for n in range(j) : 변수 n이 0부터 j가 아닌 (j-1)까지 반복된다. 1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; for v in range(10): \u0026gt; print(\u0026#34;v is : \u0026#34;, v) v is : 0 v is : 1 v is : 2 v is : 3 v is : 4 v is : 5 v is : 6 v is : 7 v is : 8 v is : 9 두 번째 패턴 for n in range(i,j): n이 i부터 (j-1)까지 반복된다. 1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; for v in range(1, 11): \u0026gt; print(\u0026#34;v is : \u0026#34;, v) v is : 1 v is : 2 v is : 3 v is : 4 v is : 5 v is : 6 v is : 7 v is : 8 v is : 9 v is : 10 세 번째 패턴 for n in range(i,j,k): n이 i부터 k씩 증가하여 (j-1)까지 반복된다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026gt; for v in range(1, 11, 2): \u0026gt; print(\u0026#34;v is :\u0026#34;, v) v is : 1 v is : 3 v is : 5 v is : 7 v is : 9 \u0026gt; for v in range(1, 11, 3): \u0026gt; print(\u0026#34;v is :\u0026#34;, v) v is : 1 v is : 4 v is : 7 v is : 10 1 ~ 1000까지 합 구하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # 첫 번째 방법 \u0026gt; j = 0 \u0026gt; for v in range(1, 1001): \u0026gt; j += v \u0026gt; print(\u0026#39;1 ~ 1000 Sum : \u0026#39;, j) 1 ~ 1000 sum : 500500 # 두 번째 방법 \u0026gt; print(\u0026#39;1 ~ 1000 Sum : \u0026#39;, sum(range(1, 1001))) 1 ~ 1000 Sum : 500500 \u0026gt; print(\u0026#39;1 ~ 1000 안에 4의 배수의 합 : \u0026#39;, sum(range(1, 1001, 4))) 1 ~ 1000 안에 4의 배수의 합 : 124750 \u0026gt; print(type(range(1,11))) \u0026lt;class \u0026#39;range\u0026#39;\u0026gt; 2. Iterable 자료형 활용과 Iterable 함수 iterable 리턴 함수 : range, reversed, enumerate, filter, map, zip 이런 것들 다 for 문에서 사용할 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 # 예제1 # Iterable: string으로 구성된 list \u0026gt; names = [\u0026#34;Kim\u0026#34;, \u0026#34;Park\u0026#34;, \u0026#34;Cho\u0026#34;, \u0026#34;Lee\u0026#34;, \u0026#34;Choi\u0026#34;, \u0026#34;Yoo\u0026#34;] \u0026gt; for name in names: \u0026gt; print(\u0026#34;You are\u0026#34;, name) You are Kim You are Park You are Cho You are Lee You are Choi You are Yoo # 예제2 # Iterable: interger 로 구성된 list \u0026gt; lotto_numbers = [11, 19, 21, 28, 36, 37] \u0026gt; for number in lotto_numbers: \u0026gt; print(\u0026#34;Current number : \u0026#34;, number) Current number : 11 Current number : 19 Current number : 21 Current number : 28 Current number : 36 Current number : 37 # 예제3 # Iterable : string \u0026gt; word = \u0026#39;Beautiful\u0026#39; \u0026gt; for s in word: \u0026gt; print(\u0026#39;word : \u0026#39;, s) word : B word : e word : a word : u word : t word : i word : f word : u word : l # 예제4 # Iterable: dictionary \u0026gt; my_info = { \u0026gt; \u0026#34;name\u0026#34;: \u0026#34;Lee\u0026#34;, \u0026gt; \u0026#34;Age\u0026#34;: 33, \u0026gt; \u0026#34;City\u0026#34;: \u0026#34;Seoul\u0026#34; \u0026gt; } # key 값들이 출력된다. \u0026gt; for key in my_info: \u0026gt; print(\u0026#34;value :\u0026#34;, my_info[key]) value : Lee value : 33 value: Seoul # 또는 아래 방법으로 value만 순차적으로 출력할 수 있다. \u0026gt; for val in my_info.values(): \u0026gt; print(val) Lee 33 Seoul Iterable에 사용되는 함수를 사용하여 대문자로 출력해보자. \u0026lt;string iterable\u0026gt;.isupper : 문자가 대문자인지 확인하는 함수 \u0026lt;string iterable\u0026gt;.islower : 문자가 소문자인지 확인하는 함수 \u0026lt;string iterable\u0026gt;.upper : 문자열을 대문자로 변경하는 함수 \u0026lt;string iterable\u0026gt;.lower : 문자열을 소문자로 변경하는 함수 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # Iterable : string \u0026gt; name = \u0026#39;FineApplE\u0026#39; # 지난 시간에 배운 중첩 조건문을 의미 \u0026gt; for n in name: \u0026gt; if n.isupper(): \u0026gt; print(n) \u0026gt; else: \u0026gt; print(n.upper()) F I N E A P P L E 3. break, continue 문 break 문: 가장 가까운 반복문을 강제로 탈출한다. 내가 원하는 특정 조건에서, 멈추기 원할 때 사용된다. 현업에서는 수집하는 데이터량이 매우 많기 때문에, break로 반복문을 조절하는 게 중요하다. continue 문: break문과 달리 특정 조건이 되면 탈출하는 것이 아니라, continue 문 아래의 코드가 실행되지 않고, 조건을 판단하는 곳으로 점프한다. 많은 데이터 중에 내가 보기 싫은 또는 불필요하게 출력되거나 계산되지 말아야 하는 것이 list에 있을 때, 스킵할 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # break \u0026gt; numbers = [14, 3, 4, 7, 10, 24, 17, 2, 33, 15, 34, 36, 38] \u0026gt; for num in numbers: \u0026gt; if num == 34: \u0026gt; print(\u0026#34;Found : 34!\u0026#34;) \u0026gt; break \u0026gt; else: \u0026gt; print(\u0026#34;Not found : \u0026#34;, num) Not found : 14 Not found : 3 Not found : 4 Not found : 7 Not found : 10 Not found : 24 Not found : 17 Not found : 2 Not found : 33 Not found : 15 Found : 34! # continue \u0026gt; lt = [2, 5, True, 4.3, complex(4)] \u0026gt; for v in lt: \u0026gt; if type(v) is bool: \u0026gt; continue \u0026gt; print(\u0026#34;current type : \u0026#34;, type(v)) \u0026gt; print(\u0026#34;multiply by 2:\u0026#34;, v * 2) \u0026gt; print(True * 3) current type : \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; multiply by 2: 4 3 current type : \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; multiply by 2: 10 3 current type : \u0026lt;class \u0026#39;float\u0026#39;\u0026gt; multiply by 2: 8.6 3 current type : \u0026lt;class \u0026#39;complex\u0026#39;\u0026gt; multiply by 2: (8+0j) 3 # true가 1이기 때문에 3이 나온다. ❗ pass에 대해 설명하자면 다른 언어의 경우 빈 줄로 넘겨도 Error가 나지 않지만, 파이썬은 Error가 나기 때문에 나중에 작성하고자 빈란으로 남기면 안된다. 그럴 때 파이썬은 pass를 사용한다.\n4. for ~ else 구문 for ~ else 구문: python에만 있는 for-else 구문으로, 자주 사용하지는 않지만, 알고 있자. 1 2 3 4 5 6 7 \u0026gt; numbers = [14, 3, 4, 7, 10, 24, 17, 2, 33, 15, 34, 36, 38] \u0026gt; for num in numbers: \u0026gt; if num == 34: \u0026gt; print(\u0026#34;Found : 34!\u0026#34;) \u0026gt; break \u0026gt; else: \u0026gt; print(\u0026#34;Not Found 45...\u0026#34;) Reference Python tutorial 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_10_for/","summary":"for ~ range의 3가지 pattern, for문에 interable 자료형 활용하기, break 문과 continue 문 사용하기, for ~ else 구문에 대해 알아본다.","title":"[TIL] Python basic 10: 흐름 제어문 (for 반복문)"},{"categories":["Python"],"content":"1. 조건문 기본 형식 콜론(:)으로 끝나는 부분을 헤더(Header)라고 한다.\n헤더의 마지막 콜론은 바로 뒤에 스위트가 이어진다.\n스위트는 헤더와 한 세트로 따라다니는 실행문을 의미한다.\nif - elif - else\nif 식: 스위트 =\u0026gt; if 문으로, 반드시 1개 필요하다.\nelif 식: 스위트 =\u0026gt; elif 문으로, 없어도 되며 있으면 n개 가능 (여러개 가능)\nelse 식: 스위트 =\u0026gt; else 문으로, 없어도 되며 있으면 별다른 조건문 없이 else:로 끝난다. 1개만 가능하다.\n반드시 True 여야 제어문이 실행된다.\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; print(type(True)) \u0026gt; print(type(False)) \u0026lt;class \u0026#39;bool\u0026#39;\u0026gt; \u0026gt; if True: \u0026gt; print(\u0026#34;Good\u0026#34;) Good \u0026gt; if False: \u0026gt; print(\u0026#34;Bad\u0026#34;) 실행 X 그러면 언제 True이고, False인지 알아보자. 2. 연산자 연산자에는 지난 번에 봤던 산술 연산자 그리고, 관계 연산자, 논리 연산자가 있다. 관계 연산자 에는 \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;=, ==, != 가 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \u0026gt; x = 15 \u0026gt; y = 10 # == 양 변이 같을 때 참 \u0026gt; print(x == y) False # != 양변이 다를 때 참 \u0026gt; print(x != y) True # \u0026gt; 왼쪽이 클 때 참 \u0026gt; print(x \u0026gt; y) True # \u0026gt;= 왼쪽이 크거나 같을 때 참 \u0026gt; print(x \u0026gt;= y) True # \u0026lt; 오른쪽이 클 때 참 \u0026gt; print(x \u0026lt; y) False # \u0026lt;= 오른쪽이 크거나 같을 때 참 \u0026gt; print(x \u0026lt;= y) False 논리 연산자에는 and, or, not이 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; a = 75 \u0026gt; b = 40 \u0026gt; c = 10 \u0026gt; print(\u0026#39;and : \u0026#39;, a \u0026gt; b and b \u0026gt; c) and : True \u0026gt; print(\u0026#39;or : \u0026#39;, a \u0026gt; b or b \u0026gt; c) or : True \u0026gt; print(\u0026#39;not : \u0026#39;, not a \u0026gt; b) not : False \u0026gt; print(\u0026#39;not : \u0026#39;, not b \u0026gt; c) not : False 산술, 관계, 논리 우선순위 산술 \u0026gt; 관계 \u0026gt; 논리 순서로 적용한다. 1 2 3 4 5 6 7 8 9 10 11 \u0026gt; print(\u0026#39;e1 : \u0026#39;, 3 + 12 \u0026gt; 7 + 3) e1 : True \u0026gt; print(\u0026#39;e2 : \u0026#39;, 5 + 10 * 3 \u0026gt; 7 + 3 * 20) e2 : False \u0026gt; print(\u0026#39;e3 : \u0026#39;, 5 + 10 \u0026gt; 3 and 7 + 3 == 10) e3 : True \u0026gt; print(\u0026#39;e4 : \u0026#39;, 5 + 10 \u0026gt; 0 and not 7 + 3 == 10) e4 : False 3. 참거짓 판별 종류 참 : \u0026ldquo;values\u0026rdquo;, [values], (values), {values}, 1 거짓 : \u0026ldquo;\u0026rdquo;, [], (), {}, 0, None 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # city가 공란이므로 False를 의미한다. # 그래서 else 문을 출력한다. \u0026gt; city = \u0026#34;\u0026#34; \u0026gt; \u0026gt; if city: \u0026gt; print(\u0026#34;You are in:\u0026#34;, city) \u0026gt; else: \u0026gt; print(\u0026#34;Please enter your city\u0026#34;) Please enter your city # city에 값이 value가 있으므로 True를 의미한다. # 그래서 if 문을 출력한다. \u0026gt; city = \u0026#34;Seoul\u0026#34; \u0026gt; \u0026gt; if city: \u0026gt; print(\u0026#34;You are in:\u0026#34;, city) \u0026gt; else: \u0026gt; print(\u0026#34;Please enter your city\u0026#34;) You are in: Seoul 4. 다중 조건문, 중첩 조건문, in \u0026amp; not in 4.1 다중 조건문 동일한 syntax의 조건문이 여러 개인 조건문을 다중 조건문이라 한다. 1 2 3 4 5 6 7 8 9 10 11 \u0026gt; nume = 90 \u0026gt; if num \u0026gt;= 90: \u0026gt; print(\u0026#39;Grade : A\u0026#39;) \u0026gt; elif num \u0026gt;= 80: \u0026gt; print(\u0026#39;Grade : B\u0026#39;) \u0026gt; elif num \u0026gt;= 70: \u0026gt; print(\u0026#39;Grade : C\u0026#39;) \u0026gt; else: \u0026gt; print(\u0026#39;과락\u0026#39;) Grade : A 4.2 중첩 조건문 한 syntax 조건문 하에 여러 개의 조건문을 중첩 조건문이라 한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026gt; grade = \u0026#39;A\u0026#39; \u0026gt; total = 80 \u0026gt; if grade == \u0026#39;A\u0026#39;: \u0026gt; if total \u0026gt;= 90: \u0026gt; print(\u0026#34;장학금 100%\u0026#34;) \u0026gt; elif total \u0026gt;= 80: \u0026gt; print(\u0026#34;장학금 80%\u0026#34;) \u0026gt; else: \u0026gt; print(\u0026#34;장학금 70%\u0026#34;) \u0026gt; else: \u0026gt; print(\u0026#34;장학금 50%\u0026#34;) 장학금 80% 4.3 in \u0026amp; not in A in B : B 안에 A가 있으면 참 A not in B : B 안에 A가 없으면 참 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # list \u0026gt; q = [10, 20, 30] # sets \u0026gt; w = {70, 80, 90} # dictionary \u0026gt; e = {\u0026#34;name\u0026#34;: \u0026#39;Lee\u0026#39;, \u0026#34;city\u0026#34;: \u0026#34;Seoul\u0026#34;, \u0026#34;grade\u0026#34;: \u0026#34;A\u0026#34;} # tuple \u0026gt; r = (10, 12, 14) \u0026gt; print(15 in q) False \u0026gt; print(90 in w) True \u0026gt; print(12 not in r) False # key 검색. dictionary를 in 사용하여 검색할 때 default는 keys 다. \u0026gt; print(\u0026#34;name\u0026#34; in e) True # value 검색 \u0026gt; print(\u0026#34;seoul\u0026#34; in e.values()) False Reference Python tutorial 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_9_if/","summary":"조건문의 기본 형식, 연산자를 통해서 제어하는 방법, 참거짓을 의미하는 값들, 다중 및 중첩 조건문, in \u0026amp; not in 으로 제어하는 방법을 알아본다.","title":"[TIL] Python basic 9: 흐름 제어문 (if 조건문)"},{"categories":["Python"],"content":"0. Introduction Sets은 한국어로 집합을 의미한다. 수학의 집합을 생각해보자. sequence X, 중복 X 순서가 없기 때문에, 출력할 때마다 달라진다. slicing 과 indexing 안된다. mutable 자료형 =\u0026gt; 수정 O, 삭제 O 집합 자료형 활용에 핵심이다. 1. Sets 선언 dictionary 처럼 sets 도 다양한 선언 방식이 있다. 빈집합, list 형식으로도, 중괄호로도 가능하다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 \u0026gt; a = set() \u0026gt; b = set([1,2,3,4,4]) \u0026gt; c = set([1, 4, 5, 6]) # 서로 다른 자료형을 저장할 수 있다. \u0026gt; d = set([1, 2, \u0026#39;Pen\u0026#39;, \u0026#39;Cap\u0026#39;, \u0026#39;Plate\u0026#39;]) \u0026gt; e = {\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;bz\u0026#39;, \u0026#39;foo\u0026#39;, \u0026#39;qux\u0026#39;} # 튜플도, 실수형도 넣을 수 있다. \u0026gt; f = {42, \u0026#39;foo\u0026#39;, (1,2,3), 3.14159} \u0026gt; print(\u0026#39;a\u0026#39;, type(a), a, 2 in a) a \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; set() False # b에 4를 중복으로 입력했지만, 출력은 하나만 나온다. \u0026gt; print(\u0026#39;b\u0026#39;, type(b), b) b \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; {1, 2, 3, 4} \u0026gt; print(\u0026#39;c\u0026#39;, type(c), c) c \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; {1, 4, 5, 6} \u0026gt; print(\u0026#39;d\u0026#39;, type(d), d) d \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; {1, 2, \u0026#39;Pen\u0026#39;, \u0026#39;Cap\u0026#39;, \u0026#39;Plate\u0026#39;} # foo를 중복으로 입력했지만, 출력은 하나만 나온다. \u0026gt; print(\u0026#39;e\u0026#39;, type(e), e) e \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; {\u0026#39;qux\u0026#39;, \u0026#39;bz\u0026#39;, \u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;} \u0026gt; print(\u0026#39;f\u0026#39;, type(f), f) f \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; {42, 3.14159, \u0026#39;foo\u0026#39;, (1, 2, 3)} ❗ set 빈집합 선언 시, 주의사항\nset과 dictionary는 중괄호를 동일하게 사용하여, 아래 b와 같이 사용하면 dict로 인식한다. 그래서 중괄호를 사용하여 빈집합을 선언할 수는 없다.\n빈집합으로 set을 만들고 싶으면 함수를 사용해야 한다.\n1 2 3 4 5 6 7 8 9 \u0026gt; a = set() \u0026gt; b = {} print(type(a), type(b)) \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; \u0026gt; b = {1,2} \u0026gt; b = {1,2,} print(type(b)) \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; 2. Sets type converison 파이썬의 장점 중 하나: 간단한 형 변환 sets에 중복으로 값을 입력해도, 중복을 허락하지 않기 때문에 type conversion 시에도 중복된 값들은 하나만 있는 걸 확인할 수 있다. tuple로 변환 1 2 3 4 5 6 7 8 \u0026gt; t = tuple(b) \u0026gt; print(\u0026#39;t - \u0026#39;, type(t), t) t - \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; (1, 2, 3, 4) \u0026gt; print(\u0026#39;t - \u0026#39;, t[0], t[1:3]) t - 1 (2, 3) list로 변환 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026gt; l = list(c) \u0026gt; print(\u0026#39;l - \u0026#39;, type(l), l) l - \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; [1, 4, 5, 6] \u0026gt; print(\u0026#39;l - \u0026#39;, l[0], l[1:3]) l - 1 [4, 5] \u0026gt; le = list(e) \u0026gt; print(\u0026#39;le - \u0026#39;, type(le), le) le - \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; [\u0026#39;bz\u0026#39;, \u0026#39;foo\u0026#39;, \u0026#39;qux\u0026#39;, \u0026#39;bar\u0026#39;] # reversed() 함수와 함께 해보자. \u0026gt; name = \u0026#39;Aceman\u0026#39; # id 값이 나오므로, 뒤집어진 값을 원하면 형 변환을 해야 한다. \u0026gt; print(\u0026#39;Reversed : \u0026#39;, reversed(name)) \u0026gt; print(\u0026#39;List : \u0026#39;, list(reversed(name))) \u0026gt; print(\u0026#39;Tuple : \u0026#39;, tuple(reversed(name))) \u0026gt; print(\u0026#39;Set : \u0026#39;, set(reversed(name))) Reversed : \u0026lt;reversed object at 0x000001F1E690AFA0\u0026gt; List : [\u0026#39;n\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;A\u0026#39;] Tuple : (\u0026#39;n\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;A\u0026#39;) Set : {\u0026#39;m\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;n\u0026#39;, \u0026#39;A\u0026#39;} # set은 출력할 떄마다 순서가 달라진다. 또한 len 함수로 길이를 구할 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt; print(len(a)) 0 \u0026gt; print(len(b)) 4 \u0026gt; print(len(c)) 4 \u0026gt; print(len(d)) 5 \u0026gt; print(len(e)) 4 3. 집합 자료형 함수: Sets 함수 교집합\nA \u0026amp; B A.intersection(B) 합집합\nA | B A.union(B) 차집합\nA - B A.difference(B) 교집합 유무 판단\nA.isdisjoint(B): A와 B에 교집합이 존재하는가?? 부분집합 유무 판단\nA.issubset(B): A는 B의 부분집합인가?? 상위집합 유무 판단\nA.issupset(B): A는 B의 상위집합인가?? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 \u0026gt; s1 = set([1, 2, 3, 4, 5, 6]) \u0026gt; s2 = set([4, 5, 6, 7, 8, 9]) # 교집합 \u0026gt; print(\u0026#39;l - \u0026#39;, s1 \u0026amp; s2) \u0026gt; print(\u0026#39;l - \u0026#39;, s1.intersection(s2)) l - {4, 5, 6} # 합집합 \u0026gt; print(\u0026#39;l - \u0026#39;, s1 | s2) \u0026gt; print(\u0026#39;l - \u0026#39;, s1.union(s2)) l - {1, 2, 3, 4, 5, 6, 7, 8, 9} # 차집합 \u0026gt; print(\u0026#39;l - \u0026#39;, s1 - s2) \u0026gt; print(\u0026#39;l - \u0026#39;, s1.difference(s2)) l - {1, 2, 3} \u0026gt; print(\u0026#39;l - \u0026#39;, s2 - s1) \u0026gt; print(\u0026#39;l - \u0026#39;, s2.difference(s1)) l - {8, 9, 7} # 중복 원소 확인 # 겹치는 원소가 없는지에 대해 알려주는 함수 # 겹치는 원소가 없으면 True, 있으면 False 다. \u0026gt; print(s1.isdisjoint(s2)) False # 부분집합 확인 # s1은 s2의 부분 집합인가요?? # 아니면 False, 맞으면 True \u0026gt; print(s1.issubset(s2)) False # 상위 집합 확인 # s1은 s2의 상위 집합인가요? # 아니면 False, 맞으면 True \u0026gt; print(s1.issuperset(s2)) False 4. Sets 수정, 추가, 제거 추가하는 건 .add(추가하려는 원소) 를 사용한다.\n삭제하는 건 .remove(삭제하려는 원소) 또는 .discard(삭제하려는 원소)를 사용한다.\n전자는 error가 뜨지만, 후자는 error를 발생시키지 않는다. 모두 제거하는 건 .clear() 함수를 사용한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; s1 = set([1,2,3,4]) \u0026gt; s1.add(5) \u0026gt; print(sl) {1, 2, 3, 4, 5} \u0026gt; s1.remove(5) \u0026gt; print(sl) {1, 2, 3, 4} \u0026gt; s1.discard(4) \u0026gt; print(sl) {1, 2, 3} \u0026gt; s1.clear() \u0026gt; print(s1) set() Reference Python tutorial 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_8_set/","summary":"set 선언법, set type conversion, 집합 자료형 활용을 위한 함수, set type의 수정하기를 알아본다.","title":"[TIL] Python basic 8: set"},{"categories":["Python"],"content":"0. Introduction 범용적으로 가장 많이 사용되는 기초 자료형\n형식\nkey : value로 구성된다. A가 key이고, B가 value라고 할 때, 주로 중괄호 {A : B} 를 사용한다. 또 다른 선언법으로는 dict([(A, B)]), dict(A = B)을 사용한다. sequence X =\u0026gt; key 값으로 index 접근한다. =\u0026gt; key 값은 중복되면 안된다.\nkey는 숫자, 문자 다 가능하다. key만 존재하면 value는 어떤 자료 형태든 가능하다. key가 중복되지 않기 때문에, value는 중복 가능하다. immutable과 mutable이 공존\nkey 는 immutable 이다. 그래서 key 값으로 list data type은 불가능하고, tuple data type은 가능하다. value는 mutable이다. 만약 mutable data type으로 key 값을 만들었을 경우, TypeError가 뜬다.\n1 2 # key 를 list로 만들었을 경우 TypeError: unhashable type: \u0026#39;list\u0026#39; 1. dictionary 선언 dictionary 선언에는 매우 다양한 방법이 있다. 이 다양한 방법들의 공통점은 { }, key, value 로 기본적으로 구성된다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 # key와 value 모두 string \u0026gt; a = {\u0026#39;name\u0026#39; : \u0026#39;Kim\u0026#39;, \u0026#39;phone\u0026#39;: \u0026#39;01012345678\u0026#39;, \u0026#39;birth\u0026#39;: \u0026#39;870124\u0026#39;} # key는 integer 자료형, value는 string \u0026gt; b = {0 : \u0026#39;Hello Python!\u0026#39;} # key는 string, value는 list \u0026gt; c = {\u0026#39;arr\u0026#39;: [1, 2, 3, 4]} \u0026gt; d = { \u0026#39;Name\u0026#39; : \u0026#39;Niceman\u0026#39;, \u0026#39;City\u0026#39; : \u0026#39;Seoul\u0026#39;, \u0026#39;Age\u0026#39; : 33, \u0026#39;Grade\u0026#39; : \u0026#39;A\u0026#39;, \u0026#39;Status\u0026#39; : True } # 하나 하나 튜플 형식으로 입력한다. 가독성이 좋지 않은 단점이 있다. # 그래서 개선된 방법이 f 다. \u0026gt; e = dict([ ( \u0026#39;Name\u0026#39;, \u0026#39;Niceman\u0026#39;), (\u0026#39;City\u0026#39;, \u0026#39;Seoul\u0026#39;), (\u0026#39;Age\u0026#39;, \u0026#39;33\u0026#39;), (\u0026#39;Grade\u0026#39;, \u0026#39;A\u0026#39;), (\u0026#39;Status\u0026#39;, True) \u0026gt; ]) # 이 형태로 DB에 저장하거나, 엑셀이 쓰거나, 웹 서비스 형태에 사용된다. # java에서는 map 이라고 한다. # JSON 형태도 이런 방식으로 되어 있다. \u0026gt; f = dict( Name = \u0026#39;Niceman\u0026#39;, City = \u0026#39;Seoul\u0026#39;, Age = \u0026#39;33\u0026#39;, Grade = \u0026#39;A\u0026#39;, Status = True \u0026gt; ) \u0026gt; print(\u0026#39;a - \u0026#39;, type(a),a) a - \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; {\u0026#39;name\u0026#39;: \u0026#39;Kim\u0026#39;, \u0026#39;phone\u0026#39;: \u0026#39;01012345678\u0026#39;, \u0026#39;birth\u0026#39;: \u0026#39;870124\u0026#39;} \u0026gt; print(\u0026#39;b - \u0026#39;, type(b),b) b - \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; {0: \u0026#39;Hello Python!\u0026#39;} \u0026gt; print(\u0026#39;c - \u0026#39;, type(c),c) c - \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; {\u0026#39;arr\u0026#39;: [1, 2, 3, 4]} \u0026gt; print(\u0026#39;d - \u0026#39;, type(d),d) d - \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; {\u0026#39;Name\u0026#39;: \u0026#39;Niceman\u0026#39;, \u0026#39;City\u0026#39;: \u0026#39;Seoul\u0026#39;, \u0026#39;Age\u0026#39;: 33, \u0026#39;Grade\u0026#39;: \u0026#39;A\u0026#39;, \u0026#39;Status\u0026#39;: True} \u0026gt; print(\u0026#39;e - \u0026#39;, type(e),e) e - \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; {\u0026#39;Name\u0026#39;: \u0026#39;Niceman\u0026#39;, \u0026#39;City\u0026#39;: \u0026#39;Seoul\u0026#39;, \u0026#39;Age\u0026#39;: \u0026#39;33\u0026#39;, \u0026#39;Grade\u0026#39;: \u0026#39;A\u0026#39;, \u0026#39;Status\u0026#39;: True} \u0026gt; print(\u0026#39;f - \u0026#39;, type(f),f) f - \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; {\u0026#39;Name\u0026#39;: \u0026#39;Niceman\u0026#39;, \u0026#39;City\u0026#39;: \u0026#39;Seoul\u0026#39;, \u0026#39;Age\u0026#39;: \u0026#39;33\u0026#39;, \u0026#39;Grade\u0026#39;: \u0026#39;A\u0026#39;, \u0026#39;Status\u0026#39;: True} 2. dictionary value 출력과 수정 2.1 dictionary value 출력 value 출력에는 2가지 방법이 있다.\nprint(a[key]) 로 출력하는 방법 print(a.get(key))로 출력하는 방법 첫 번째 방법은 key에 해당하는 value 값이 존재하지 않으면 keyError가 발생한다.\n두 번째 방법은 key에 해당하는 value 값이 존재하지 않으면 none처리를 한다.\nerror가 발생하면 중단되기 때문에, 실무에서는 두 번째 방법을 많이 사용한다.\n결론: Key에 해당하는 값을 사용할 때는 함수 .get(key) 를 사용하자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026gt; print(\u0026#39;a - \u0026#39;, a.get(\u0026#39;name1\u0026#39;)) None \u0026gt; print(\u0026#39;a - \u0026#39;, a[\u0026#39;name1\u0026#39;]) # error 발생으로 중단 \u0026gt; print(\u0026#39;b - \u0026#39;, b[0]) \u0026gt; print(\u0026#39;b - \u0026#39;, b.get(0)) Hello Python! \u0026gt; print(\u0026#39;c - \u0026#39;, c[\u0026#39;arr\u0026#39;]) \u0026gt; print(\u0026#39;c - \u0026#39;, c.get(\u0026#39;arr\u0026#39;)) [1, 2, 3, 4] # value 값이 여러 원소를 가지고 있을 경우, index를 사용하여 출력할 수 있다. \u0026gt; print(\u0026#39;c - \u0026#39;, c[\u0026#39;arr\u0026#39;][3]) \u0026gt; print(\u0026#39;c - \u0026#39;, c.get(\u0026#39;arr\u0026#39;)[3]) 4 \u0026gt; print(\u0026#39;d - \u0026#39;, d.get(\u0026#39;Age\u0026#39;)) 33 \u0026gt; print(\u0026#39;e - \u0026#39;, e.get(\u0026#39;Status\u0026#39;)) True \u0026gt; print(\u0026#39;f - \u0026#39;, f.get(\u0026#39;City\u0026#39;)) Seoul 2.2 dictionary 수정 index에 key 값을 입력했을 때, 기존에 있던 key 면 수정이 되고, 없는 key면 추가된다. 1 2 3 4 5 6 7 8 9 10 11 # 수정 \u0026gt; b = {0 : \u0026#39;Hello Python!\u0026#39;} \u0026gt; b[0] = \u0026#39;Good backend developer\u0026#39; \u0026gt; print(b) {0: \u0026#39;Good backend developer\u0026#39;} # 추가 \u0026gt; b[2] = \u0026#39;Python Python\u0026#39; \u0026gt; print(b) {0: \u0026#39;Good backend developer\u0026#39;, 2: \u0026#39;Python Python\u0026#39;} 3. dictionary 함수 len : key의 갯수 구하기 .keys(): key 값만 출력 .values(): value 값만 출력 .items(): key, value 다 출력 .pop(): list에서 배운 것처럼 한 성분을 빼서 제거하여 저장하는 함수이지만, list는 순서가 있기 때문에 항상 맨 마지막 성분이 제거된다. 하지만, dictionary는 순서가 없어서 key 값을 인자로 입력해야 한다. .popitem(): key와 value 중 아무거나 하나를 임의로 도출하여 없앤다. .update(): 다른 리스트를 넣어서, 키가 똑같은 것을 수정할 수 있다. in 연산자를 사용해서 해당하는 키 값이 있는지 알 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 \u0026gt; a = {\u0026#39;name\u0026#39; : \u0026#39;Kim\u0026#39;, \u0026#39;phone\u0026#39;: \u0026#39;01012345678\u0026#39;, \u0026#39;birth\u0026#39;: \u0026#39;870124\u0026#39;} \u0026gt; d = { \u0026#39;Name\u0026#39; : \u0026#39;Niceman\u0026#39;, \u0026#39;City\u0026#39; : \u0026#39;Seoul\u0026#39;, \u0026#39;Age\u0026#39; : 33, \u0026#39;Grade\u0026#39; : \u0026#39;A\u0026#39;, \u0026#39;Status\u0026#39; : True } # len \u0026gt; print(len(a)) 3 \u0026gt; print(len(d)) 5 # .keys() \u0026gt; print(a.keys()) dict_keys([\u0026#39;name\u0026#39;, \u0026#39;phone\u0026#39;, \u0026#39;birth\u0026#39;]) \u0026gt; print(d.keys()) dict_keys([\u0026#39;Name\u0026#39;, \u0026#39;City\u0026#39;, \u0026#39;Age\u0026#39;, \u0026#39;Grade\u0026#39;, \u0026#39;Status\u0026#39;]) # .values() \u0026gt; print(a.values()) dict_values([\u0026#39;Kim\u0026#39;, \u0026#39;01012345678\u0026#39;, \u0026#39;870124\u0026#39;]) \u0026gt; print(d.values()) dict_values([\u0026#39;Niceman\u0026#39;, \u0026#39;Seoul\u0026#39;, 33, \u0026#39;A\u0026#39;, True]) # .items() \u0026gt; print(a.items()) dict_items([(\u0026#39;name\u0026#39;, \u0026#39;Kim\u0026#39;), (\u0026#39;phone\u0026#39;, \u0026#39;01012345678\u0026#39;), (\u0026#39;birth\u0026#39;, \u0026#39;870124\u0026#39;)]) \u0026gt; print(d.items()) dict_items([(\u0026#39;Name\u0026#39;, \u0026#39;Niceman\u0026#39;), (\u0026#39;City\u0026#39;, \u0026#39;Seoul\u0026#39;), (\u0026#39;Age\u0026#39;, 33), (\u0026#39;Grade\u0026#39;, \u0026#39;A\u0026#39;), (\u0026#39;Status\u0026#39;, True)]) # list 안에 넣으면 key 값들만, value 값들만, item 값들만으로 list를 만든다. \u0026gt; print(list(a.keys()) [\u0026#39;name\u0026#39;, \u0026#39;phone\u0026#39;, \u0026#39;birth\u0026#39;] \u0026gt; print(list(a.values()) [\u0026#39;Kim\u0026#39;, \u0026#39;01012345678\u0026#39;, \u0026#39;870124\u0026#39;] \u0026gt; print(list(a.items()) [(\u0026#39;name\u0026#39;, \u0026#39;Kim\u0026#39;), (\u0026#39;phone\u0026#39;, \u0026#39;01012345678\u0026#39;), (\u0026#39;birth\u0026#39;, \u0026#39;870124\u0026#39;)] # .pop() \u0026gt; print(a.pop(\u0026#39;birth\u0026#39;)) 870124 \u0026gt; print(a) {\u0026#39;name\u0026#39;: \u0026#39;Kim\u0026#39;, \u0026#39;phone\u0026#39;: \u0026#39;01012345678\u0026#39;} \u0026gt; print(d.pop(\u0026#39;Age\u0026#39;)) 33 \u0026gt; print(d) {\u0026#39;Name\u0026#39;: \u0026#39;Niceman\u0026#39;, \u0026#39;City\u0026#39;: \u0026#39;Seoul\u0026#39;, \u0026#39;Grade\u0026#39;: \u0026#39;A\u0026#39;, \u0026#39;Status\u0026#39;: True} # .popitem(): 추첨기에 사용할 수 있다. \u0026gt; print(d.popitem()) (\u0026#39;Status\u0026#39;, True) \u0026gt; print(d) {\u0026#39;Name\u0026#39;: \u0026#39;Niceman\u0026#39;, \u0026#39;City\u0026#39;: \u0026#39;Seoul\u0026#39;, \u0026#39;Grade\u0026#39;: \u0026#39;A\u0026#39;} \u0026gt; print(d.popitem()) (\u0026#39;Grade\u0026#39;, \u0026#39;A\u0026#39;) \u0026gt; print(d) {\u0026#39;Name\u0026#39;: \u0026#39;Niceman\u0026#39;, \u0026#39;City\u0026#39;: \u0026#39;Seoul\u0026#39;, \u0026#39;Grade\u0026#39;: \u0026#39;A\u0026#39;} in 연산자 사용하여 key 값 존재유무 확인 1 2 3 4 5 6 \u0026gt; a = {\u0026#39;name\u0026#39; : \u0026#39;Kim\u0026#39;, \u0026#39;phone\u0026#39;: \u0026#39;01012345678\u0026#39;, \u0026#39;birth\u0026#39;: \u0026#39;870124\u0026#39;} \u0026gt; print(\u0026#39;name\u0026#39; in a) True \u0026gt; print(\u0026#39;addr\u0026#39; in a) False ❗ 다른 data type을 dictionary로 만들 때 유의사항: 갯수가 맞아야 한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; a = [\u0026#39;ab\u0026#39;, \u0026#39;cd\u0026#39;, \u0026#39;ef\u0026#39;] \u0026gt; print(dict(a)) {\u0026#39;a\u0026#39;: \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;: \u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;: \u0026#39;f\u0026#39;} # 하지만 갯수가 안맞으면?? # 길이가 맞지 않아 Error가 발생 \u0026gt; a = [\u0026#39;ab\u0026#39;, \u0026#39;cd\u0026#39;, \u0026#39;eff\u0026#39;] \u0026gt; print(dict(a)) ValueError: dictionary update sequence element; \u0026gt; a = [[\u0026#39;a\u0026#39;, 1], [\u0026#39;b\u0026#39;, 2], [\u0026#39;c\u0026#39;, 3]] \u0026gt; print(a) {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2, \u0026#39;c\u0026#39;: 3} \u0026gt; a = [[\u0026#39;a\u0026#39;, 1], [\u0026#39;b\u0026#39;, 2], [\u0026#39;c\u0026#39;, 3, 4]] \u0026gt; print(a) # 위와 똑같은 Error가 발생된다. Reference Python tutorial 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_7_dictionary/","summary":"dictionary type의 선언, 출력과 수정 그리고, dictionary에 사용되는 함수에 대해 알아본다.","title":"[TIL] Python basic 7: dictionary "},{"categories":["Python"],"content":"0. Introduction list와 tuple의 차이를 알아야 비교해서 무엇을 쓸 지 결정한다.\ntuple은 sequence형, immutable, 중복가능하기 때문에\n순서가 있다. 하지만, list의 순서는 변할 수 있고, tuple의 순서는 불변이다. tuple의 순서는 한 번 생성되면 변경할 수 없다. 중복 가능 =\u0026gt; list와 동일 수정 X =\u0026gt; del, remove, slicing, insert 로 값 변경 X list 와 마찬가지로 다양한 타입이 함께 포함될 수 있다. 1. tuple 선언 list는 대괄호다. tuple은 소괄호 또는 무괄호다. 소괄호는 괄호만 해도 tuple로 인식된다. 무괄호는 최소 원소 하나 이상이어야 하며, 쉼표가 있어야 한다. 쉼표가 있어야 하는 이유는 성분 integer일 때, 쉼표가 없으면 tuple이 아닌 numeric data로 인식한다. 소괄호 또한 최소 원소 하나 이상 입력할 때, 쉼표가 있어야 한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 # tuple 선언 \u0026gt; a = () \u0026gt; b = (1,) \u0026gt; b = 1, \u0026gt; print(type(a)) # 위 방식 다 tuple 선언법이다. \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; \u0026gt; c = (11, 12, 13, 14) \u0026gt; d = (100, 1000, \u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;) \u0026gt; e = (100, 1000, (\u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;)) 2. tuple indexing, slicing, 연산 tuple에 indexing 사용하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 \u0026gt; c = (11, 12, 13, 14) \u0026gt; d = (100, 1000, \u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;) \u0026gt; e = (100, 1000, (\u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;)) \u0026gt; print(\u0026#39;d - \u0026#39;, type(d), d) d - \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt;, (100, 1000, \u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;) \u0026gt; print(\u0026#39;d - \u0026#39;, d[1]) d - 1000 \u0026gt; print(\u0026#39;d - \u0026#39;, d[0] + d[1] * 2) d - 2100 \u0026gt; print(\u0026#39;d - \u0026#39;, d[-1]) d - Captine \u0026gt; print(\u0026#39;e - \u0026#39;, e[-1]) e - (\u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;) \u0026gt; print(\u0026#39;e - \u0026#39;, e[-1][1]) e - Base \u0026gt; print(\u0026#39;e - \u0026#39;, list(e[-1][1])) e - [\u0026#39;B\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;s\u0026#39;, \u0026#39;e\u0026#39;] tuple의 value 수정은 안되지만, 형 변환은 가능하다.\ntuple에 slicing 사용하기\n1 2 3 4 5 6 7 8 \u0026gt; print(\u0026#39;d - \u0026#39;, d[0:3]) d - (100, 1000, \u0026#39;Ace\u0026#39;) \u0026gt; print(\u0026#39;d - \u0026#39;, d[2:]) d - (\u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;) \u0026gt; print(\u0026#39;e - \u0026#39;, e[2][1:3]) e - (\u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;) tuple로 연산하기 1 2 3 4 5 6 7 8 \u0026gt; print(\u0026#39;c + d - \u0026#39;, c + d) c + d - (11, 12, 13, 14, 100, 1000, \u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;) \u0026gt; print(\u0026#39;c * 3 - \u0026#39;, c * 3) c * 3 -(11, 12, 13, 14, 11, 12, 13, 14, 11, 12, 13, 14) \u0026gt; print(\u0026#34;\u0026#39;Test\u0026#39; + c[0] - \u0026#34;, \u0026#39;Test\u0026#39; + str(c[0])) \u0026#39;Test\u0026#39; + c[0] - Test11 3. tuple 함수: index, count index(): 원하는 성분 값의 index를 구하는 function count(): 원하는 성분의 수량을 구하는 function 1 2 3 4 5 6 7 8 9 \u0026gt; a = (5, 2, 3, 1, 4) \u0026gt; print(\u0026#39;a - \u0026#39;, a) a - (5, 2, 3, 1, 4) \u0026gt; print(\u0026#39;a - \u0026#39;, a.index(5)) a - 0 \u0026gt; print(\u0026#39;a - \u0026#39;, a.count(4)) a - 1 4. tuple의 중요한 특징: packing \u0026amp; unpacking packing이란 단어 그대로의 의미로, 하나로 묶는 것을 말한다. unpacking은 하나로 묶여있던 tuple을 풀어서 각각 할당하는 것을 말한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 # packing \u0026gt; t = (\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;, \u0026#39;qux\u0026#39;) #출력 확인 \u0026gt; print(t) (\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;, \u0026#39;qux\u0026#39;) \u0026gt; print(t[0]) foo \u0026gt; print(t[-1]) qux # unpacking 1 \u0026gt; (x1, x2, x3, x4) = t # 출력 확인 \u0026gt; print(x1, x2, x3, x4) foo bar baz qux # unpacking 2 \u0026gt; (x1, x2, x3, x4) = (\u0026#39;foo\u0026#39;, \u0026#39;bar\u0026#39;, \u0026#39;baz\u0026#39;, \u0026#39;qux\u0026#39;) \u0026gt; print(x1, x2, x3, x4) foo bar baz qux # unpacking 3 \u0026gt; t2 = 2, 3, 4 \u0026gt; t3 = 4, \u0026gt; x1, x2, x3 = t2 \u0026gt; x4, x5, x6 = 4, 5, 6 # tuple을 출력하는 것이므로 괄호가 존재한다. \u0026gt; print(t2) (2, 3, 4) \u0026gt; print(t3) (4, ) # 각 원소 값을 출력하는 것이므로 괄호가 없다. \u0026gt; print(x1, x2, x3) 2 3 4 \u0026gt; print(x4, x5, x6) 4 5 6 Reference Python tutorial 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_6_tuple/","summary":"list와 tuple의 차이. tuple의 indexing, slicing, 연산. 그리고, tuple의 중요한 특징 중 하나인 packing \u0026amp; unpacking에 대해 알아본다.","title":"[TIL] Python basic 6: tuple"},{"categories":["Python"],"content":"0. Introduction List 자료형은 sequence형이고, mutable이기 때문에\n순서 존재한다. =\u0026gt; len, index, slicing 이 가능 수정, 삭제가 가능하다. 중복이 가능하다. 다른 언어에서는 배열이라 하는데 알고리즘을 풀기 위해서 굉장히 중요한 자료 형태다.\n1. List 선언 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 빈 리스트 선언 \u0026gt; a = [] \u0026gt; print(type(a)) \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; \u0026gt; b = list() \u0026gt; print(type(b)) \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; # 값은 동일하지만, id 값이 다르다. \u0026gt; print(id(a), id(b)) # 정수만 list 구성 \u0026gt; c = [70, 75, 80 ,85] # 문자열, 정수, 실수형으로 list 구성 \u0026gt; d = [1000, 1000.5, \u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;] # list 안에 list를 넣을 수 있다. \u0026gt; e = [1000, 1000.5, [\u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;]] \u0026gt; f = [21.42, \u0026#39;foobar\u0026#39;, 3, 4, \u0026#39;bark\u0026#39;, False, 3.14159] 2. List indexing, slicing list도 string처럼 sequence 형이기 때문에, len, index, slicing을 사용할 수 있다.\nindexing: 원하는 데이터를 꺼내는 과정 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026gt; print(\u0026#39;d - \u0026#39;, type(d), d) d - \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; [1000, 10000.1, \u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;] # index의 시작은 0부터이기 때문 \u0026gt; print(\u0026#39;d - \u0026#39;, d[1]) d - 1000.5 \u0026gt; print(\u0026#39;d - \u0026#39;, d[0] + d[1] + d[1]) d - 3001 \u0026gt; print(\u0026#39;d - \u0026#39;, d[-1]) d - Captine # list의 성분이 list이기 때문에, 성분 list의 [1] 성분을 말한다. \u0026gt; print(\u0026#39;e - \u0026#39;, e[-1][1]) e - Base # 문자열을 문자행 단위로 쪼개서 list로 만든다. \u0026gt; print(\u0026#39;e - \u0026#39;, list(e[-1][1])) e - [\u0026#39;B\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;s\u0026#39;, \u0026#39;e\u0026#39;] ❗ 문자열을 list로 바꾸면 최소 단위로 쪼갠다.\nslicing: 같은 데이터 타입으로, 원하는 부분의 데이터를 뽑아내는 것 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026gt; d = [1000, 1000.5, \u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;] \u0026gt; e = [1000, 1000.5, [\u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;]] \u0026gt; print(\u0026#39;d - \u0026#39;, d[0:3]) d - [1000, 1000.5, \u0026#39;Ace\u0026#39;] \u0026gt; print(\u0026#39;d - \u0026#39;, d[2:]) d - [\u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;] \u0026gt; print(\u0026#39;e - \u0026#39;, e[2][1:3]) e - [\u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;] \u0026gt; print(\u0026#39;e - \u0026#39;, e[-1][1:3]) e - [\u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;] 3. List 연산 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026gt; c = [70, 75, 80 ,85] \u0026gt; print(\u0026#39;c + d -\u0026#39;, c + d) [70, 75, 80 ,85, 1000, 1000.5, \u0026#39;Ace\u0026#39;, \u0026#39;Base\u0026#39;, \u0026#39;Captine\u0026#39;] \u0026gt; print(\u0026#39;c * 3 -\u0026#39;, c * 3) [70, 75, 80 ,85, 70, 75, 80 ,85, 70, 75, 80 ,85] \u0026gt; print(\u0026#39;Test + c[0] - \u0026#39;, \u0026#39;Test\u0026#39; + str(c[0])) Test + c[0] - Test70 # 값 비교 \u0026gt; print(c == c[:3] + c[3:]) True # 동일한 id 값 \u0026gt; python = c \u0026gt; print (python == c) True # 동일한 id가 출력된다. \u0026gt; print(id(c), id(python)) # in을 통해 리스트 안에 값이 있는지 판단여부를 확인할 수 있다. \u0026gt; 85 in c \u0026gt; print(85 in c) True 4. List 함수 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 a = [5, 3, 4, 7, 8 ] # 끝에 데이터를 삽입할 때 사용 # append가 매달다 라는 의미이므로 \u0026gt; a.append(6) \u0026gt; print(a) [5, 3, 4, 7, 8, 6] # 정렬 \u0026gt; a.sort() \u0026gt; print(a) [3, 4, 5, 7, 8] # 뒤집음 \u0026gt; a.reverse() \u0026gt; print(a) [8, 7, 5, 4, 3] # sort와 reverse는 데이터가 많으면 오랜 시간이 걸린다. # index(x) 는 x 값의 첫 번째 index를 출력한다. \u0026gt; print(\u0026#39;a - \u0026#39;, a.index(3), a[3]) a - 4 4 # insert(추가할 위치, 추가할 값) \u0026gt; a.insert(2,7) \u0026gt; print(a) [8, 7, 7, 5, 4, 3] # count(): 원하는 값의 갯수를 새는 method다. # a list에 7이 2개가 있으므로 출력값 2가 나온다. \u0026gt; print(\u0026#39;a - \u0026#39;, a.count(7)) a - 2 # extend(): 괄호 안에 값을 list에 연장한다. \u0026gt; ad = [2, 1] \u0026gt; a.extend(ad) \u0026gt; print(a) [8, 7, 7, 5, 4, 3, 2, 1] 결론 a.append(): 끝에 데이터를 삽입한다. 매달은다 a.sort(): 데이터를 정렬한다. a.reverse(): 데이터 방향을 뒤집는다. 반환값이 없고, 뒤집어져서 객체에 바로 저장된다. 그러므로, 객체 출력을 따로 해야 한다. reversed는 method가 아닌 함수다. 그래서 인자로 리스트를 입력한다. a.index(): 괄호 값의 첫 번째 index를 알려준다. a.insert(x,y): index x 번째 있는 자리에 y 값을 삽입한다. a.count(): 원하는 값의 갯수를 세는 method int를 반환한다. a.extend(): 괄호 안의 값을 list에 연장한다. reverse()처럼 반환값이 없고, 객체에 바로 저장된다. 5. List 수정, 삭제 5.1 slicing과 index를 사용하여 수정, 삭제하는 방법 수정하기\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 \u0026gt; c = [70, 75, 80 ,85] ## 수정하기 # index 번호로 접근하여 수정 \u0026gt; c[0] = 4 \u0026gt; print(c) [4, 75, 80, 85] # insert 되는 결과 \u0026gt; c[1:2] = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] \u0026gt; print(c) [4, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, 80, 85] # 하지만 slicing이 아닌 index로 명령하면 선언한 value 그대로 원소가 된다. \u0026gt; c[1] = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] \u0026gt; print(c) [70, [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;], 80, 85] # list 자체가 하나의 원소로 list에 들어갔다. # slicing으로 list를 원소로 넣고 싶으면 다음과 같이 한다. \u0026gt; c[1:2] = [[\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;]] \u0026gt; print(c) [70, [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;], 80, 85] ## list 안에 list가 들어간 걸 `중첩`이라 한다. 삭제하기\n1 2 3 4 5 6 7 8 9 10 # 빈 값을 선언하는 것이 삭제하는 걸 의미한다. # c[1], c[2] 원소가 삭제된다. \u0026gt; c = [70, 75, 80 ,85] \u0026gt; c[1:3] = [] \u0026gt; print(c) [70, 85] \u0026gt; c[0] = [] [[], 85] 즉, slicing으로 수정 및 삭제를 하면 list 중괄호 안의 성분들이 원본 객체 index에 들어간다.\n하지만, indexing으로 하면 할당된 괄호 자체도 다 들어간다.\n5.2 함수를 사용하여 삭제하는 방법: remove, pop, del remove(): 삭제할 데이터 값을 직접 지정한다.\n1 2 3 4 5 \u0026gt; c = [70, 75, 80 ,85] \u0026gt; c.remove(70) \u0026gt; print(c) [75, 80, 85] pop(): 마지막 원소를 뽑아내고, 나머지로 만든다.\n1 2 3 4 \u0026gt; c = [70, 75, 80 ,85] \u0026gt; print(\u0026#39;c - \u0026#39;, c.pop()) c - 85 del c[index]: index를 기준으로 데이터를 삭제하기 때문에, 지울려는 데이터가 몇 번째인지 알아야 한다.\n데이터가 많아지면, 세기가 어렵다. 그럴 때는 위에 remove를 사용한다. 1 2 3 4 5 \u0026gt; c = [70, 75, 80 ,85] \u0026gt; del c[1] \u0026gt; print(c) 75 pop( )\nstack 자료 구조에서는 마지막에 들어온 애가 가장 먼저 나간다. Last In, First Out로 LIFO라 한다. 예1) 음식을 접시에 담을 때, 마지막에 쌓은 접시를 꺼내서 사용한다. 예2) 웹 브라우저를 뒤로 가기 버튼을 누르면, 마지막 페이지가 먼저 나온다. 이런 자료 구조에서 많이 사용되는 method가 pop 입니다. Queue 는 스택과 반대로 가장 처음에 들어온 걸 빼는 구조로, First In, First Out로 FIFO라 한다.\n반복문과 pop() 을 활용하여 제거하는 방법도 있다.\n따로 break 를 사용하지 않아도, a가 비워지면 끝난다.\n1 2 3 4 5 \u0026gt; a = [8, 7, 7, 5, 4, 3] \u0026gt; while a: \u0026gt; data = a.pop() \u0026gt; print(data) Reference Python tutorial 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_5_list/","summary":"list의 생성, indexing, slicing, 연산, list에 쓰이는 함수 그리고, list를 수정하고 삭제하는 방법에 대해 알아보겠다.","title":"[TIL] Python basic 5: list"},{"categories":["Python"],"content":"1. 문자열 생성, 출력 그리고, 길이 문자열 생성하기(선언하기) 및 출력하기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 문자열 생성 \u0026gt; str1 = \u0026#34;I am Python\u0026#34; \u0026gt; str2 = \u0026#39;Python\u0026#39; # 빈 문자열 생성 \u0026gt; str_t1 = \u0026#39;\u0026#39; \u0026gt; str_t2 = str() # 문자열 출력 \u0026gt; print(str1, type(str1)) I am Python \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026gt; print(str2, type(str2)) Pyton \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026gt; print(str_t1, type(str_t1)) \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026gt; print(str_t2, type(str_t2)) \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; 문자열 길이 측정: len() 을 많이 사용한다. 길이에는 공백을 포함한다. 1 2 3 4 5 \u0026gt; print(len(str1)) 11 \u0026gt; print(len(str2)) 6 결론 문자열 선언에는 \u0026ldquo;\u0026rdquo;, \u0026lsquo;\u0026rsquo;, \u0026ldquo;\u0026rdquo;\u0026quot;\u0026quot;\u0026quot;\u0026quot;, \u0026rsquo;\u0026rsquo;\u0026rsquo;\u0026rsquo;\u0026rsquo;\u0026rsquo; 을 사용한다. 문자열 출력에는 다른 출력과 동일하게 print를 사용한다. 문자열 길이 측정에는 len() 함수를 사용한다. 길이에는 공백을 포함한다. 2. Escape, raw string and multi line 2.1 Escape code 1 2 3 4 5 \\n: 개행(줄바꿈) \\t: 탭키를 누른 만큼 벌어짐 \\\\: 문자 삽입 \\\u0026#39;: 문자 삽입 \\\u0026#34;: 문자 삽입 위에 escape code 예시를 작성해보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 ## 문자 삽입 escape code \u0026gt; escape_str1 = \u0026#34;do you have a \\\u0026#34;retro games\\\u0026#34;?\u0026#34; \u0026gt; print(escape_str1) do you have a \u0026#34;retro games?\u0026#34; # 홀따옴표 사용 \u0026gt; escape_str2 = \u0026#39;What\\\u0026#39;s on TV??\u0026#39; # 쌍따옴표 사용 \u0026gt; escape_Str3 = \u0026#34;what\u0026#39;s one TV??\u0026#34; \u0026gt; print(escape_str2) \u0026gt; print(escape_str3) What\u0026#39;s on TV?? ## 개행, 탭 # tab 누른 만큼 떨어져서 출력 \u0026gt; t_s1 = \u0026#34;Click \\t Start!\u0026#34; \u0026gt; print(t_s1) Click Start! # 줄 바껴서 출력 \u0026gt; t_s2 = \u0026#34;New Line\\n Check!\u0026#34; \u0026gt; print(t_s2) New Line Check! 2.2 Raw String 소문자 r을 붙이면 Escape 표현을 무시하고 그대로 다 출력한다. Escape 표현을 사용하지 않기 위해 선언! 이런 게 있다는 정도만 알고 있기 1 2 3 4 5 6 7 8 9 # raw string 미포함 \u0026gt; raw_s1 = \u0026#34;\\\\x\\y\\z\\q\u0026#34; \u0026gt; print(raw_s1) \\x\\y\\z\\q # raw string 포함 \u0026gt; raw_s1 = r\u0026#34;\\\\x\\y\\z\\q\u0026#34; \u0026gt; print(raw_s1) \\\\x\\y\\z\\q 2.3 Multi Line 여러 줄 출력하는 방법으로 \\(역슬러쉬) 를 사용한다. 역슬러쉬를 사용하여 파이썬에게 어떤 변수를 binding 한다는 걸 의미한다. 그래서 다음 줄에 변수를 선언한다는 걸 의미한다. 콤마는 ```,\u0026quot;\u0026quot;\u0026quot; 처럼 3개 이상을 사용한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026gt; multi_str1 = \\ \u0026#34;\u0026#34;\u0026#34; 문자열 멀티라인 입력 테스트 \u0026#34;\u0026#34;\u0026#34; \u0026gt; print(multi_str1) 문자열 멀티라인 입력 테스트 결론 이스케이프 코드를 사용하여 개행, 탭만큼 띄우기, 따옴표 문자 삽입이 가능하다. 이스케이프 코드를 사용하고 싶지 않을 때는 string code를 사용한다. 한 줄로는 너무 길어서 여러 줄로 표현하고 싶을 때, 백슬러쉬와 따옴표 3개를 사용하여 멀티라인으로 출력한다. 3. 문자형 연산 문자형끼리 덧셈과 문자형을 반복해서 출력하기 위한 곱셈이 가능하다. 1 2 3 4 5 6 7 8 9 10 \u0026gt; str_o1 = \u0026#34;python\u0026#34; \u0026gt; str_o2 = \u0026#34;Apple\u0026#34; \u0026gt; str_o3 = \u0026#34;How are you doing\u0026#34; \u0026gt; str_o4 = \u0026#34;Korea Japan America\u0026#34; \u0026gt; print(3 * str_o1) pythonpythonpython \u0026gt; print(str_o1 + str_o2) pythonApple in 예약어를 사용하여 문자열 안에 원하는 문자가 있는지도 확인할 수 있다. 1 2 3 4 5 6 7 8 \u0026gt; print(\u0026#39;y\u0026#39; in str_o1) True \u0026gt; print(\u0026#39;n\u0026#39; in str_o1) True \u0026gt; print(\u0026#39;P\u0026#39; not in str_o1) False 4. 문자형 형 변환(Type conversion), 문자형 함수 4.1 Type Conversion 파이썬에서 type conversion은 자유롭게 가능하다고 생각하자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 정수 -\u0026gt; 문자열 \u0026gt; print(str(66)) # 실수 -\u0026gt; 문자열 \u0026gt; print(str(10.1)) # boolean -\u0026gt; string \u0026gt; print(str(True), type(str(True))) True \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; # complex -\u0026gt; string \u0026gt; print(str(complex(12))) 12 + 0j 4.2 문자열 함수 print(dir()) 함수에 변수를 입력하면 그 변수의 속성들을 보여준다.\n이 속성들에는 변수가 사용할 수 있는 함수들도 포함된다. string type의 data를 넣으면 string이 사용할 수 있는 함수를 보여준다. list면 list가 사용할 수 있는 함수를 보여준다. 1 2 3 \u0026gt; im_str = \u0026#34;Good Boy\u0026#34; \u0026gt; print(dir(im_str)) [\u0026#39;capitalize\u0026#39;, \u0026#39;encode\u0026#39;, .....] 위 함수들에서 일부만 출력해보겠다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 \u0026gt; str_o1 = \u0026#34;python\u0026#34; \u0026gt; str_o2 = \u0026#34;Apple\u0026#34; \u0026gt; str_o3 = \u0026#34;How are you doing\u0026#34; \u0026gt; str_o4 = \u0026#34;Korea Japan America\u0026#34; # 첫 글자를 대문자로 바꿔주는 함수 \u0026gt; print(\u0026#34;Capitalize : \u0026#34;, str_o1.capitalize()) Capitalize : Python # 모든 문자를 대문자로 바꿔주는 함수 \u0026gt; print(\u0026#34;upper : \u0026#34;, str_o1.upper()) upper : PYTHON # 모든 문자를 소문자로 바꿔주는 함수 \u0026gt; print(\u0026#34;lower : \u0026#34;, str_o2.lower()) lower : apple # 마지막 글자가 s로 끝나는가? \u0026gt; print(\u0026#34;endswith? : \u0026#34;, str_o1.endswith(\u0026#39;s\u0026#39;)) endswith : False # 해당 문자열 앞 뒤로 join하는 함수 \u0026gt; print(\u0026#34;join str : \u0026#34;, str_o1.join([\u0026#34;I\u0026#39;m\u0026#34;, \u0026#34;!\u0026#34;])) join str : I\u0026#39;m python! # 해당 문자열을 입력한 다른 문자열로 바꿔주는 함수 \u0026gt; print(\u0026#34;replace : \u0026#34;, str_o1.replace(\u0026#39;thon\u0026#39;, \u0026#39;Good\u0026#39;)) replace : pyGood # 해당 문자열을 입력한 문자열을 기준으로 쪼개어 list로 만드는 함수 \u0026gt; print(\u0026#34;split : \u0026#34;, str_o4.split(\u0026#39; \u0026#39;)) split : Korea Japan America # 최소 단위까지 쪼개어 알파벳 순으로 list로 만드는 함수 \u0026gt; print(\u0026#39;sorted : \u0026#39;, sorted(str_o3)) sorted : [\u0026#39; \u0026#39;, \u0026#39; \u0026#39;, \u0026#39; \u0026#39;, \u0026#39;?\u0026#39;, \u0026#39;H\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;g\u0026#39;, \u0026#39;i\u0026#39;, \u0026#39;n\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;u\u0026#39;, \u0026#39;w\u0026#39;, \u0026#39;y\u0026#39;] \u0026gt; print(\u0026#39;reversed1: \u0026#39;, reversed(str_o2)) reversed1: \u0026lt;reversed object at 0x000001ECEA15CFD0\u0026gt; # reversed는 return 값이 존재하기에 list로 출력이 가능하다. \u0026gt; print(\u0026#39;reversed2: \u0026#39;, list(reversed(str_o2)) reversed2: [\u0026#39;e\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;p\u0026#39;, \u0026#39;p\u0026#39;, \u0026#39;A\u0026#39;] 4.3 reverse 와 reversed 의 차이 reverse list 자료형만 단순히 뒤집어서 저장해주는 역할 다른 자료형에는 사용할 수 없다. tuple 또한 container 지만, immutable이므로 뒤집을 수 없다. 리턴값이 없어서 for문 같은 조건문 반복문에 사용하지 못 한다. for문에 사용하고 싶으면 원본 객체를 사용한다. reversed sequence 데이터 타입이면 타입 상관 없이 사용할 수 있다. 원본에서 뒤집어진 순서의 새로운 객체(reverse iterator)를 만들어 반환한다. 그래서 id 값으로 나온다. 뒤집어진 형태를 보고 싶으면 반드시 형 변환 을 해야 한다. 5. Slicing 문자열의 일부분을 원하는 대로 잘라오는 것을 말한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # index[0] 부터 [3]까지가 아닌, [2]까지이기 때문이다. \u0026gt; sl = \u0026#39;Nice Python\u0026#39; \u0026gt; print(sl[0:3]) Nic # 아무런 값이 없으면 끝까지 또는 처음부터라는 의미다. \u0026gt; print(sl[5:]) Python # 끝부분의 index를 모를 때, len 함수를 사용한다. 끝까지 출력된다. # 위에 [0:3] 처럼 끝에가 -1 이 되지 않는다. \u0026gt; print(sl[:len(sl)]) Nice Python \u0026gt; print(sl[:len(sl)-1]) Nice Pytho # 처음과 끝을 의미한다. \u0026gt; print(sl[:]) Nice Python # index[1]부터 시작하여 2씩 증가하며, index[4] 미만까지 한다. \u0026gt; print(sl[1:4:2]) ie # index[-4]부터 시작하여 [-3] 미만까지 한다. \u0026gt; print(sl[-4:-2]) th # index를 역으로 해도 가능하다. \u0026gt; print(sl[-5:]) ython # index를 역으로 하는 것과 정방향으로 하는 것을 같이 해도 가능하다. \u0026gt; print(sl[1:-2]) ice Pyth # 역으로 출력된다. \u0026gt; print(sl[::-1]) nohtyP eciN 결론: slicing을 사용하여 원하는 정보를 추출하기에 slicing은 중요하다. Reference Python tutorial 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_4_string/","summary":"string type의 생성부터 연산, len 함수 사용, type conversion, 문자형 함수 그리고 slicing을 알아보겠다.","title":"[TIL] Python basic 4: string"},{"categories":["Python"],"content":"1. 파이썬의 모든 자료형 파이썬이 지원하는 자료형은 다음과 같다. 1 2 3 4 5 6 7 8 9 int: 정수 float: 실수 complex: 복소수 bool: 불린 (True or False) str: 문자열(시퀀스) list: 리스트(시퀀스) tuple: 튜플(시퀀스) set: 집합 dict: 사전 그러면 각 자료형의 구체적인 예를 알아보자. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # str : string 의 약어로, 문자열 자료형을 의미한다. \u0026gt; str1 = \u0026#34;Jeha\u0026#34; \u0026gt; str2 = \u0026#34;Anacondacong\u0026#34; # bool: boolean 의 약어로, True or False 자료형을 의미한다. \u0026gt; bool1 = True # float: 실수형 자료형을 의미한다. 소수점이 존재한다. # 소수점 아래가 0이어도, 소수점이 존재하므로 실수형 데이터다. \u0026gt; float1 = 10.0 # int : integer의 약어로, 정수형 데이터를 말한다. \u0026gt; int1 = 7 # list : 리스트형으로 대괄호 안에 열거된 데이터 타입을 말합니다. \u0026gt; list1 = [str1, str2] # tuple: 튜플이라 하며, 소괄호 또는 괄호 없이 , 괄호만 열거된 형태를 말합니다. \u0026gt; tuple1 = (str1, str2) # dict : dictionary의 약어로, 중괄호 안에 key : value 로 구성된 데이터 형태입니다. \u0026gt; dict1 = { \u0026#34;name : \u0026#34;Machine Learning\u0026#34;, \u0026#34;version\u0026#34; : 2.0 } # set : 집합형 데이터 타입으로, dict 와 마찬가지로 중괄호 형태의 데이터입니다. \u0026gt; set1 = {7, 8, 9} 각 데이터 타입 출력은 다음과 같이 한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \u0026gt; print(type(str1)) \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026gt; print(type(bool1)) \u0026lt;class \u0026#39;bool\u0026#39;\u0026gt; \u0026gt; print(type(str2)) \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026gt; print(type(float1)) \u0026lt;class \u0026#39;float\u0026#39;\u0026gt; \u0026gt; print(type(int1)) \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; \u0026gt; print(type(dict1)) \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; \u0026gt; print(type(tuple1)) \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt; \u0026gt; print(type(set1)) \u0026lt;class \u0026#39;set\u0026#39;\u0026gt; - 결론: 데이터 타입의 종류에는 숫자형, 문자형, 리스트, 튜플, 딕셔너리, 셋이 있다.\n2. 숫자형 데이터 선언 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 정수 선언 \u0026gt; i = 77 \u0026gt; i2 = -14 \u0026gt; big_int = 888888888888888 #정수 출력 \u0026gt; print(i) 77 \u0026gt; print(i2) -14 \u0026gt; print(big_int) 888888888888888 # 실수 선언 \u0026gt; f = 0.9999 \u0026gt; f2 = 3.141592358 \u0026gt; f3 = - 4.2 # 실수 출력 \u0026gt; print(f) 0.9999 \u0026gt; print(f2) 3.141592358 \u0026gt; print(f3) -4.2 - 결론: 변수명 = 할당할 value값\n3. 연산자 활용 숫자형 연산자 종류에는 다음과 같다. 1 2 3 4 5 6 7 + : 덧셈 - : 뺼셈 * : 곱셈 / = 나누기를 의마하며, 몫과 나머지로 구성된다. // : 나누기의 몫 부분을 출력한다. % : 나누기의 나머지 부분을 출력한다. x ** y : 제곱으로, x의 y제곱 을 의미한다. 그러면 연산 실습을 해보겠다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 # 변수 선언 \u0026gt; i1 = 39 \u0026gt; i2 = 939 \u0026gt; big_int1 = 123456789123456789012345678901234567890 \u0026gt; big_int2 = 999999999999999999999999999999999999999 \u0026gt; f1 = 1.234 \u0026gt; f2 = 3.939 # + \u0026gt; print(\u0026#34;i1 + i2 : \u0026#34;, i1 + i2) i1 + i2 : 978 \u0026gt; print(\u0026#34;f1 + f2 : \u0026#34;, f1 + f2) f1 + f2 : 5.173 # 큰 값들도 연산이 가능하다. \u0026gt; print(\u0026#34;big_int1 + big_int2 : \u0026#34;, big_int1 + big_int2) big_int1 + big_int2 : 1123456789123456789012345678901234567889 # 정수형과 실수형을 같이 연산할 때, 정수형을 자동적으로 실수형으로 변환하여 계산한다. \u0026gt; a = 3 + 1.0 \u0026gt; print(a, type(a)) 4.1 \u0026lt;class \u0026#39;float\u0026#39; \u0026gt; # - \u0026gt; print(\u0026#34;i1 - i2: \u0026#34;, i1 - i2) i1 - i2: -900 \u0026gt; print(\u0026#34;f1 - f2: \u0026#34;, f1 - f2) f1 - f2: -2.705 \u0026gt; print(\u0026#34;big_int1 - big_int2: \u0026#34;, big_int1 - big_int2) big_int1 - big_int2: -876543210876543210987654321098765432109 # * \u0026gt; print(\u0026#34;i1 * i2: \u0026#34;, i1 * i2) i1 * i2: 36621 \u0026gt; print(\u0026#34;f1 * f2: \u0026#34;, f1 * f2) f1 * f2: 4.860726 \u0026gt; print(\u0026#34;big_int1 * big_int2: \u0026#34;, big_int1 * big_int2) big_int1 * big_int2: 123456789123456789012345678901234567889876543210876543210987654321098765432110 # / \u0026gt; print(\u0026#34;i2 / i1: \u0026#34;, i2 / i1) i2 / i1: 24.076923076923077 \u0026gt; print(\u0026#34;f2 / f1: \u0026#34;, f2 / f1) f2 / f1: 3.1920583468395463 \u0026gt; print(\u0026#34;big_int2 / big_int1: \u0026#34;, big_int2 / big_int1) big_int2 / big_int1: 8.10000006561 # // \u0026gt; print(\u0026#34;i2 // i1: \u0026#34;, i2 // i1) i2 // i1: 24 # i2 / i1 의 연산값의 몫 부분임을 알 수 있다. \u0026gt; print(\u0026#34;f2 // f1: \u0026#34;, f2 // f1) f2 // f1: 3.0 # f2 / f1 의 연산값의 몫 부분임을 알 수 있다. \u0026gt; print(\u0026#34;big_int2 // big_int1: \u0026#34;, big_int2 // big_int1) big_int2 // big_int1: 8 # big_int2 / big_int1 의 연산값의 몫 부분임을 알 수 있다. # % \u0026gt; print(\u0026#34;i2 % i1 :\u0026#34;, i2 % i1) i2 % i1 : 3 # i1 * (i2 // i1) 으로 i2를 나누고 나온 나머지값 \u0026gt; print(\u0026#34;f2 % f1 :\u0026#34;, f2 % f1) f2 % f1 : 0.2370000000000001 \u0026gt; print(\u0026#34;big_int1 % big_int2 :\u0026#34;, big_int1 % big_int2) big_int1 % big_int2 : 123456789123456789012345678901234567890 # ** 와 pow(x,y) \u0026gt; print(\u0026#34;2 ** 3: \u0026#34;, 2 ** 3) \u0026gt; print(\u0026#34;2 ** 3: \u0026#34;, pow(2,3)) 2 ** 3: 8 2 ** 3: 8 \u0026gt; print(\u0026#34;i1 ** i2: \u0026#34;, i1 ** i2) \u0026gt; print(\u0026#34;i1 ** i2: \u0026#34;, pow(i1,i2)) i1 ** i2: 102250631262663558380..... i1 ** i2: 102250631262663558380..... # 너무 길어서 생략 \u0026gt; print(\u0026#34;f1 ** f2: \u0026#34;, f1 ** f2) \u0026gt; print(\u0026#34;f1 ** f2: \u0026#34;, pow(f1,f2)) f1 ** f2: 2.289235194260789 f1 ** f2: 2.289235194260789 4. 형 변환 형 변환 함수는 다음과 같다. 1 2 3 4 5 abs(x): absolute의 약어로, 절대값으로 변환한다. int(x): 정수형으로 만듭니다. 실수를 입력했다면 실수의 정수 부분을 출력한다. float(x): 실수형으로 만듭니다. 정수를 입력했다면 소수점 .0 으로 나온다. complex(x): 복소수로 허수까지 포함해서 a+bi 형태로 변환한다. pow(x, y): x의 y승 제곱으로 출력된다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 a = 3. b = 9 c = .65 d = 13.55 # type 출력 \u0026gt; print(type(a), type(b), type(c), type(d)) \u0026lt;class \u0026#39;float\u0026#39;\u0026gt; \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; \u0026lt;class \u0026#39;float\u0026#39;\u0026gt; \u0026lt;class \u0026#39;float\u0026#39;\u0026gt; # 형 변환 \u0026gt; print(float(b)) #정수 -\u0026gt; 실수 9.0 \u0026gt; print(int(c)) # 실수 -\u0026gt; 정수 0 \u0026gt; print(ind(D)) # 실수 -\u0026gt; 정수 13 \u0026gt; print(int(True)) # Bool -\u0026gt; 정수 1 \u0026gt; print(float(True)) # Bool -\u0026gt; 실수 1.0 \u0026gt; print(int(False)) 0 \u0026gt; print(float(False)) 0.0 \u0026gt; print(complex(3)) # 정수 -\u0026gt; 복소수 3 +0j # string data type을 숫자형으로 바꾸고 나서 복소수를 처리해야 하는데, 바로 처리된다. \u0026gt; print(complex(\u0026#39;3\u0026#39;)) # 문자형 -\u0026gt; 복소수 3 + 0j \u0026gt; print(complex(False)) # Bool -\u0026gt; 복소수 0j # 수치 연산 함수 \u0026gt; print(abs(-7)) 7 # divmod(x,y) : x를 y로 나눴을 때, 몫과 나머지를 반환한다. 많이 사용되는 함수로 중요하다. \u0026gt; x, y = divmod(100, 8) #몫 과 나머지 \u0026gt; print(x, y) 12 4 \u0026gt; print(pow(5, 3)) \u0026gt; print(5**3) 125 125 - 결론: 다른 data type으로 형 변환이 가능하다.\n5. 외부 모듈 사용 import 를 사용한다. 1 2 3 4 5 6 7 8 9 10 # 외부 모듈을 불러오는 함수 \u0026gt; import math # math 모듈에서 ceil 이란 함수를 사용하겠다. # ceil(x) : x 이상의 수중에서 가장 작은 정수를 반환한다. \u0026gt; print(math.ceil(5.2)) 6 \u0026gt; print(math.pi) 3.1415926535 - 결론: import를 사용하여 외부 module을 가져온다.\nReference Python tutorial 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_3_numericdata/","summary":"첫 번째, python의 자료형 종류에는 무엇이 있는지 알아본다. 두 번째, 숫자형 데이터 타입의 선언, 연산, 그리고 형 변환에 대해 중점적으로 알아보겠다.","title":"[TIL] Python basic 3: numeric data"},{"categories":["Python"],"content":"1. 기본 출력 1.1 Escape 코드 1 2 3 4 5 6 \\n: 개행 \\t: 탭 \\\\: 문자 \\\u0026#39;: 문자 \\\u0026#34;: 문자 \\000: 널 문자 1.2 기본 출력 \u0026rsquo;\u0026rsquo; 또는 \u0026quot;\u0026quot; 를 자주 사용한다. 1 2 3 4 5 6 7 8 9 10 11 \u0026gt; print(\u0026#39;JeHa start!\u0026#39;) \u0026gt; print(\u0026#34;JeHa start!\u0026#34;) \u0026gt; print() \u0026gt; print(\u0026#39;\u0026#39;\u0026#39;JeHa start!\u0026#39;\u0026#39;\u0026#39;) \u0026gt; print(\u0026#39;\u0026#39;) \u0026gt; print(\u0026#34;\u0026#34;\u0026#34;JeHa start!\u0026#34;\u0026#34;\u0026#34;) # 아무것도 출력되지 않는다. \u0026gt; print(\u0026#39;\u0026#39;) \u0026gt; print() 결과는 다음과 같다. 1 2 3 4 5 6 JeHa start! JeHa start! JeHa start! JeHa start! 1.3 Separator 옵션 여러 data를 열거하여 출력할 때, 각 data 사이 사이를 분리할 string을 입력할 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026gt; print(\u0026#39;python\u0026#39;, \u0026#39;start!\u0026#39;, sep=\u0026#39;@\u0026#39;) python @ start! \u0026gt; print(\u0026#39;p\u0026#39;,\u0026#39;y\u0026#39;,\u0026#39;t\u0026#39;,\u0026#39;h\u0026#39;,\u0026#39;o\u0026#39;,\u0026#39;n\u0026#39;) p y t h o n \u0026gt; print(\u0026#39;p\u0026#39;,\u0026#39;y\u0026#39;,\u0026#39;t\u0026#39;,\u0026#39;h\u0026#39;,\u0026#39;o\u0026#39;,\u0026#39;n\u0026#39;, sep = \u0026#39;\u0026#39;) python \u0026gt; print(\u0026#39;010\u0026#39;, \u0026#39;6677\u0026#39;, \u0026#39;6677\u0026#39;, sep = \u0026#39;-\u0026#39; ) 010-6677-6677 \u0026gt; print(\u0026#39;python\u0026#39;, \u0026#39;google.com\u0026#39;, sep = \u0026#39;@\u0026#39;) python@google.com 1.4 End 옵션 print에는 자동적으로 행간을 나누는 기능이 있다. 이를 end를 통해서 합칠 수 있다. 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026gt; print(\u0026#39;I\u0026#39;) \u0026gt; print(\u0026#39;love\u0026#39;) \u0026gt; print(\u0026#39;u\u0026#39;) I Love u \u0026gt; print(\u0026#39;I\u0026#39;, end = \u0026#39; \u0026#39;) \u0026gt; print(\u0026#39;love\u0026#39;, end = \u0026#39; \u0026#39;) \u0026gt; print(\u0026#39;u\u0026#39;) I love u 2. String 문자열 출력 (s) formatting으로 특정 케이스에 원하는 형식대로 출력할 수 있고, 가독성이 높아진다.\nd는 정수, s는 string, f는 실수를 의미한다. ' % ' % () 로 formatting 하는 방법과 ' {} '.format() 을 사용해서 formatting하는 방법이 있다. 다 익숙해져야 하지만, 후자를 더 빈번히 사용한다. 1 2 3 4 5 6 7 8 9 10 11 # 순서에 맞게 자동적으로 mapping 해준다. \u0026gt; print(\u0026#39;%s %s\u0026#39; % (\u0026#39;one\u0026#39;,\u0026#39;two)) \u0026gt; print(\u0026#39;{} {}\u0026#39;.format(\u0026#39;one\u0026#39;,\u0026#39;two\u0026#39;)) # 순서를 지정해서도 할 수 있다. # index[1] 은 two, index[0]은 one 이므로, 교차해서 mapping 된다. \u0026gt; print(\u0026#39;{1} {0}\u0026#39;.format(\u0026#39;one\u0026#39;,\u0026#39;two\u0026#39;)) one two one two two one 전체 자릿수를 지정하는 방법과 정렬 방향을 바꾸는 방법을 알아보겠다. 1 2 3 4 5 6 7 8 9 10 # 문자열 총 자리 수는 10자리를 의미한다. # 오른쪽 정렬 # 즉, blank 시작은 왼쪽부터다. \u0026gt; print(\u0026#39;%10s\u0026#39; % (\u0026#39;likelike\u0026#39;)) # 왼쪽 blank는 2칸이다. likelike # 방향을 반대로 하기 위해서는 (-)를 붙힌다: 왼쪽정렬 \u0026gt; print(\u0026#39;%-10s\u0026#39; % (\u0026#39;likelike\u0026#39;)) likelike 위 내용을 .format으로 표현해보자. .format은 string을 입력할 때 \u0026rsquo;s\u0026rsquo;를 입력하지 않아도 된다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 오른쪽 정렬 \u0026gt; print(\u0026#39;{:\u0026gt;10}\u0026#39;.format(\u0026#39;likelike\u0026#39;)) likelike # 왼쪽 정렬 \u0026gt; print(\u0026#39;{:\u0026lt;10}\u0026#39;.format(\u0026#39;likelike\u0026#39;)) likelike \u0026gt; print(\u0026#39;{:10}\u0026#39;.format(\u0026#39;likelike\u0026#39;)) likelike # 가운데 정렬 \u0026gt; print(\u0026#39;{:^10}\u0026#39;.format(\u0026#39;likelike\u0026#39;)) likelike # blank에는 언더바가 있도록 하는 것 \u0026gt; print(\u0026#39;{:_\u0026gt;10}\u0026#39;.format(\u0026#39;like\u0026#39;)) ______like 그러면 지정한 자릿수보다 문자열이 더 길다면?? 1 2 3 \u0026gt; print(\u0026#39;%5s\u0026#39; % (\u0026#39;likelike\u0026#39;)) likelike # 다 출력된다. 지정한 자릿수를 넘는 문자열 부분들을 절삭하고 싶다면?? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # . 점을 아래와 같이 표시한다. \u0026gt; print(\u0026#39;%.5s\u0026#39; % \u0026#39;likelike\u0026#39;) likel # 이것은 어떻게 출력될까?? \u0026gt; print(\u0026#39;%10.5s\u0026#39; % (\u0026#39;likelike\u0026#39;)) # 지정한 문자열 총 자리수는 10자리고, 5자리를 넘으면 절삭한다. # blank가 5자리고, 왼쪽에서부터 오른쪽 방향으로 채워진다. # 나머지 5자리에 문자가 채워진다. _____likel # format으로 표현해보자 \u0026gt; print(\u0026#39;{:\u0026gt;10.5}\u0026#39;.format(\u0026#39;likelike\u0026#39;)) 결론 print(\u0026rsquo;%-n1.n2s\u0026rsquo; % (\u0026lsquo;출력하기 원하는 문자열\u0026rsquo;)) n1은 전체 자릿수 n2는 출력되길 원하는 문자열의 총 자리수를 의미 \u0026lsquo;-\u0026lsquo;는 정렬 방향을 역으로 한다. 정렬 방향 default는 오른쪽, (-)는 왼쪽 정렬을 의미 print(\u0026rsquo;{:^ \u0026gt; \u0026lt; n1.n2}\u0026rsquo;.format(\u0026lsquo;string\u0026rsquo;)) n1은 전체 자릿수 n2는 출력되길 원하는 문자열의 총 자리수를 의미 \u0026lsquo;^\u0026rsquo; 는 가운데 정렬 \u0026lsquo;\u0026gt;\u0026lsquo;은 오른쪽 정렬, \u0026lsquo;\u0026lt;\u0026rsquo; 는 왼쪽 정렬을 의미 .format은 s를 입력하지 않는다. 3. Integer 정수형 출력 (d) .format 은 문자열 s는 입력하지 않는다. 정수형 d or i, 실수형 f 은 입력한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026gt; print(\u0026#39;%d %d\u0026#39; % (1, 2)) 1,2 \u0026gt; print(\u0026#39;{} {}\u0026#39;.format(1,2)) 1,2 \u0026gt; print(\u0026#39;{1} {0}.format(1,2)\u0026#39;) 2,1 \u0026gt; print(\u0026#39;%4d\u0026#39; % (24)) \u0026gt; print(\u0026#39;{:\u0026gt;4d}\u0026#39;.format(24)) \u0026gt; print(\u0026#39;{:4d}\u0026#39;.format(24)) 24 \u0026gt; print(\u0026#39;%-4d\u0026#39; % (24)) \u0026gt; print(\u0026#39;{:\u0026lt;4d}\u0026#39;.format(24)) 24 \u0026gt; print(\u0026#39;{:^4d}\u0026#39;.format(24)) 24 \u0026gt; print(\u0026#39;{:_\u0026gt;4d}\u0026#39;.format(24)) __24 \u0026gt; print(\u0026#39;{:_\u0026lt;4d}\u0026#39;.format(24)) 24__ \u0026gt; print(\u0026#39;{:_^4d}\u0026#39;.format(24)) _24_ 결론 print(\u0026rsquo;%-n1d\u0026rsquo; % (integer))\nn1은 전체 자릿수 \u0026lsquo;-\u0026lsquo;는 정렬 방향을 역으로 한다. 정렬 방향 default는 오른쪽, (-)는 왼쪽 정렬을 의미 print(\u0026rsquo;{:^ \u0026gt; \u0026lt; n1d}\u0026rsquo;.format(integer))\nn1은 전체 자릿수 \u0026lsquo;^\u0026rsquo; 는 가운데 정렬 default와 \u0026lsquo;\u0026gt;\u0026lsquo;은 오른쪽 정렬, \u0026lsquo;\u0026lt;\u0026rsquo; 는 왼쪽 정렬을 의미 4. Float 실수형 출력 (f) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 전체 실수자리를 따로 지정하지 않으면 8자리까지 출력된다. \u0026gt; print(\u0026#39;%f\u0026#39; % (3.1415926535)) \u0026gt; print(\u0026#39;{:f}\u0026#39;.format(3.1415926535)) 3.141593 # 3.141592가 아니고, 반올림되어 3.141593 이다. # 소수 부분 8자리 \u0026gt; print(\u0026#39;%.8f\u0026#39; % (3.1415926535)) 3.14159265 # 반올림 되어 맨 마지막 자리 수가 5다. # 소수 부분 12자리 \u0026gt; print(\u0026#39;%.12f\u0026#39; % (3.1415926535)) 3.1415926535 # 소수점(.)까지 포함하여 6자리고, 소수 부분은 2자리, 빈 부분은 0으로 표시한다. \u0026gt; print(\u0026#39;%06.2f\u0026#39; % (3.1415926535)) \u0026gt; print(\u0026#39;{:06.2f}\u0026#39;.format(3.1415926535)) 003.14 # 소수점(.)까지 포함하여 6자리고, 소수 부분은 2자리, 빈 부분은 blank로 둔다. # blank가 있기 때문에 정렬 개념이 적용된다. 그래서 오른쪽 정렬된 상태 \u0026gt; print(\u0026#39;%6.2f\u0026#39; % (3.1415926535)) 3.14 # 왼쪽 정렬 상태 \u0026gt; print(\u0026#39;%-6.2f\u0026#39; % (3.1415926535)) 3.14 결론 print(\u0026rsquo;%n1.n2f\u0026rsquo; % ())\nprint(\u0026rsquo;{:n1.n2f}\u0026rsquo;.format())\nn1 은 전체 자릿수로서, 소수점을 포함한다. n2는 소수점 자리를 말한다. n1 앞에 0이 붙으면 정수 부분에서 비어있는 자리수는 0으로 표기된다. Reference Python tutorial 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_2_print/","summary":"첫 번째 print 함수를 사용할 때, separator와 end를 사용하여 다양하게 사용하는 것과 두 번째, stirng type, numeric type을 다양하게 출력을 해봄으로서 print 함수에 대해 이해해보겠다.","title":"[TIL] Python basic 2: print 사용법"},{"categories":["Python"],"content":"1. 변수 할당 설명 1.1 기본 선언 다른 프로그래밍 언어는 변수 타입을 정하고 나서 값을 할당한다. 반면에, python은 값을 정하고 나서 변수 타입을 알아서 할당해준다. 이 변수를 할당한다는 건 컴퓨터 내부적으로 컴퓨터 메모리의 일부를 할당하는 의미로, \u0026lsquo;고유 주소\u0026rsquo;가 지정된다는 걸 의미한다. 이 \u0026lsquo;고유 주소\u0026rsquo;는 id 라는 명령어로 확인할 수 있다. 함수 id: 객체(object)의 고유값 id(identity) 을 확인 1 2 3 4 5 6 7 8 # 700이라는 int type의 data를 n에 할당한다. \u0026gt; n = 700 # \u0026#39;n\u0026#39;이라는 변수의 data type을 확인해보자. \u0026gt; print(type(n)) # \u0026#39;n\u0026#39; 이라는 변수에 할당된 메모리 고유주소를 확인해보자. \u0026gt; print(id(n)) - 결론 : 선언을 한다는 건 메모리 값을 할당하는 걸 의미한다. 이는 id 값을 통해 고유주소를 확인하여 알 수 있다.\n1.2 동시 선언 만약 명칭만 다른 세 변수에 동일한 value가 할당된 경우, id는 어떻게 나올까? 1 2 3 4 5 6 7 8 9 10 11 12 # x, y, z에 동일한 값을 할당한다. # 동일한 object 참조 \u0026gt; x = y = z = 700 \u0026gt; print(x, y, z) # x의 id 와 y의 id는 같은가? \u0026gt; print(id(x) == id(y)) \u0026gt; print(id(x), id(y)) # y의 id 와 z의 id는 같은가? \u0026gt; print(id(y) == id(z)) \u0026gt; print(id(z)) 위 두 질문의 결과는 True가 나온다. 동일한 값과 type을 가지고 있기 때문에 메모리 주소가 동일하다는 걸 알 수 있다. 즉, 3개를 선언했지만 실제로 존재하는 건 1개라는 의미다. 파이썬이 하나의 오브젝트로 생성한다. 이러한 걸 동시선언 이라고 하며, 파이썬에서는 가능하다. 이처럼 하나 하나 최적화를 시키면 원활하고 빠른 프로그램 실행 흐름이 가능하다. - 결론: 여러 변수에 똑같은 값을 할당하면 파이썬은 내부에서 하나만 만들어진다.\n추가로 [TIL] Python basic 41: Shallow copy \u0026amp; Deep copy 을 참고하자.\n1.3 재선언 변수의 명칭은 동일하나 다른 value를 할당해보겠다. 1 2 3 4 5 6 7 8 9 10 11 12 # 동일 명칭의 변수가 다른 object를 참조 # var이란 변수에 75라는 정수형 데이터를 할당되었다. \u0026gt; var = 75 \u0026gt; print(type(var)) \u0026gt; print(id(var)) # int. 형이 아닌 string 형 데이터를 재할당한다. \u0026gt; var = \u0026#34;Change Value\u0026#34; \u0026gt; print(var) \u0026gt; print(type(var)) \u0026gt; print(id(var)) 결과는 다음과 같다. 1 2 3 4 5 \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; 2298218369712 Change Value \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; 2298224531568 data type과 value가 변하자 id값이 달라진 걸 알 수 있다. 이것이 가능한 이유가 파이썬에는 garbage collector 가 있기 때문이다. 실제로 재선언할 때는 프로그램의 흐름이 끝날 때까지 잘 추적하는 게 중요하다. 재선언을 통해서 프로그램의 흐름이 꼬일 수도 있기 때문이다. 그래서 큰 project에서는 변수의 사전이 엑셀이나 기타 문서로 존재한다고 한다. - 결론: 동일한 명칭의 변수여도 할당된 값이 변하면 파이썬이 알아서 id 값을 바꾼다.\n추가로 [TIL] Python basic 40: Call by object reference 을 참고하자.\n2. Object References 변수가 할당 상태일 때, 아래와 같은 상태가 일어나는 걸 의미한다.\n예 : n = 700이라 선언했을 때 다음과 같은 순서로 일어난다.\n첫 번째, data type에 맞는 object를 생성한다.\ntype ()을 통해서 class int의 object가 생성된다. 두 번째, 값 생성\n700을 안에서 생성 세 번째, 콘솔 출력\n700이 출력된다. 더 다양한 예제를 살펴보자.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #예1) 아래 출력은 동일하다. 즉, int() 를 하지 않아도 내부적으로 처리된다. \u0026gt; print(300) \u0026gt; print(int(300)) #예2) # int형의 오브젝트임로 생성되었다. 그리고 출력된다. \u0026gt; n = 800 \u0026gt; print(n, type(n)) 800 \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; \u0026gt; m = n \u0026gt; print(m, n) 800 800 \u0026gt; print(type(m), type(n)) \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; # 동시 선언 시에는 동일 \u0026gt; print(id(m), id(n)) 140596291737872 140596291737872 \u0026gt; m = 400 \u0026gt; print(m, n) 400 800 \u0026gt; print(type(m), type(n)) \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; # 하나를 개별 선언하니 메모리 값이 바꼈다. \u0026gt; print(id(m), id(n)) 140596293562160 140596291737872 \u0026gt; m = 800 \u0026gt; n = 600 #m과 n의 고유값이 다르다. \u0026gt; print(id(m), id(n)) 140464489928976 140463953248432 \u0026gt; print(id(m)==id(n)) False 3. 다양한 변수 선언 방법과 예약어 이 규칙으로 변수를 선언하면 세련되고, 코드를 재활용할 때 가독성이 좋은 소스 코드로 만들 수 있다.\n3.1 다양한 변수 선언 방법 camelCase : method 및 함수를 선언할 때 사용.\nex) numberOfCollegeGraduates PascalCase : 언어 상관 없이 class를 주로 선언할 때 사용.\nex) NumberOfCollegeGraduates snake_case: 파이썬에서 변수를 선언 시 사용.\nex) number_of_college_graduates Camel과 Pascal의 차이는 첫 문자가 소문자냐 대문자냐의 차이다.\n이외에 허용하는 변수 선언법은 다음과 같다.\n숫자로 시작하지 않는다. 변수는 되도록 snake case로 선언한다. 예약어 같이 문법에 사용되는 단어는 변수명으로 불가능하다. 1 2 3 4 5 6 7 8 9 10 #알파벳, 언더바로 시작 \u0026gt; age = 1 \u0026gt; Age = 2 \u0026gt; aGe = 3 \u0026gt; AGE = 4 \u0026gt; a_g_e = 5 \u0026gt; _age = 6 \u0026gt; age_ = 7 \u0026gt; _AGE_ = 8 3.2 예약어 예약어는 python reserved words로 검색하면 나온다. 예약어의 종류는 다음과 같다. 1 2 3 4 5 6 7 8 9 False\tdef\tif\traise None\tdel\timport\treturn True\telif\tin\ttry and\telse\tis\twhile as\texcept\tlambda\twith assert\tfinally\tnonlocal\tyield break\tfor\tnot class\tfrom\tor continue\tglobal\tpass Reference Python tutorial 프로그래밍 시작하기: 파이썬 입문 (Inflearn Original) ","permalink":"http://jeha00.github.io/post/python/python_basic_1/","summary":"첫 번째, 기본적인 선언 방법과 동시 선언, 재선언을 알아본다. 두 번째, 각 선언에 따른 id 값을 확인하여 파이썬 내부 원리를 이해한다. 세 번째, 선언 방법의 종류인 Camel case, Pascal case, Snake case가 무엇인지 알아본다.","title":"[TIL] Python basic 1: 변수 선언"},{"categories":"dev-contents","content":"0. Introduction 🔆 업데이트 날짜: 2022-08-28 Error 기록\nwindow 10 환경에서 Hugo 라는 SSG의 한 종류를 사용해서 총 6단계를 거쳐서 \u0026lt;user-id\u0026gt;.github.io 주소의 github page를 만들고 배포한 후, contents를 업로드하는 것까지 내용을 다룬다.\n모든 내용은 공식 기술 문서 -\u0026gt; stackoverflow -\u0026gt; googling 순서로 접근하여 해결해나갔다.\nhugo는 한국어 소스가 별로 없었고, Jekyll에 비해서도 영어 소스가 별로 없었다. 마지막으로, 테마를 커스텀마이징하는 지름길과 후기를 남겼다.\n위 과정들에서 필요한 개념들, 부딪혔던 error 및 해결책도 각 단계 마지막 부분에 작성했다.\n🚩 동일한 주제로 다룬 블로그들을 보면 3단계와 4단계의 순서를 바꿔서 진행한다. 4단계 진행 후, 3단계를 진행해도 무방하다. 다만, 나는 그 과정에서 헷갈린 부분이 있어서 마지막에 theme 적용을 하기로 선택했다.\n1. Static Site Generator 로 Hugo를 선택한 이유 1.1 SSG란? Github page를 만들 때 SSG의 종류들로 \u0026lsquo;Jekyll\u0026rsquo;, \u0026lsquo;Hexo\u0026rsquo;, \u0026lsquo;Hugo\u0026rsquo; 가 많이 언급된다.\n그러면 SSG란 무엇인가??\n\u0026lsquo;정적 페이지(Static Site)\u0026lsquo;란 HTML, CSS, JS를 미리 올려서 서버가 바뀌지 않는 HTML page를 보여주는 것을 말하는데, 이 정적 페이지를 보다 간편하게 만들어주는 것이 SSG(Static Site Generator)다. 이와 반대로 동적 페이지는 client에 반응하여 HTML page를 동적으로 만들어진 페이지를 말한다. 더 상세한 정보를 원하시는 분은 정적 웹은 뭐고 동적 웹은 뭔가요? 이 영상을 참고하시길 바란다.\n1.2 SSG의 종류와 Hugo를 선택한 이유 hugo를 선택하기에 앞서 각 SSG의 특징들에 대해 알아야 하기 때문에, Jekyll, Hexo, Hugo의 각 특징들은 다음과 같다. Jekyll -루비 기반 -현재 가장 인기 있음(깃헙 별 수 제일 많음) -한글 레퍼런스도 제일 많음 -느리다는 제보가 많음(몇 십개의 포스팅 뿐인데도 빌드 하는데 5분씩 걸린다고) -윈도우 공식 지원 안됨 Hexo -자바스크립트(Node.js) 기반 -한글 레퍼런스 꽤 많음 -메인 개발자가 손을 놓은 듯 -개발자가 중국인? 이라 구글링하면 중국어 글이 많이 나옴 Hugo -Golang 기반 -빌드 빠름 -문서화 잘돼있음 -깃헙 별 수가 헥소보다 많음 -한글 레퍼런스가 거의 없음 출처: http://tadakichi.tistory.com/188 그래서 4가지 이유로 Hugo를 선택했다. 남들이 안해본 걸 해보자. 한글 레퍼런스가 거의 없기 때문에, 내가 기여할 수 있는 부분이 다른 것보다 있을 것이다. 내가 원하는 디자인 대부분이 Hugo였다. 앞으로 계속해서 기술 블로그를 작성할 것이기 때문에, 빠른 빌드를 원했다. 2. Github page 만들기 위한 local 환경 조성 첫 번째, git을 설치한다. 그리고, github 에 가입한다.\n두 번째, Visual Studio Code (VSC), Atom 같은 에디터를 설치한다.\n세 번째, window 환경에 Hugo를 설치한다.\n2.1 첫 번째 github 가입은 Github 에 들어가서 오른쪽 상단에 있는 Sign up을 클릭하여 진행한다. 그러면 최종적으로 https://github.com/user-name/ 을 가진다. github page의 url은 [user-name].github.io 로 가진다. 2.2 두 번째 나는 visual studio code를 사용한다. visual studio code 여기에 들어가 설치한다. 2.3 세 번째 window 환경에 hugo를 설치한다. window에서 Hugo 설치하기 이 영상 하나 따라하면 쉽다. 하지만, 글로 보고 싶은 분들을 위해 작성한다. hugo 다운로드 로 들어가서 아래로 scroll을 내리면 window 버전을 다운받아 C:\\Hugo\\bin 디렉토리를 생성해서 다운받은 압축 파일을 해제 어느 위치에서나 Hugo가 실행할 수 있도록 윈도우 검색으로 시스템 환경 변수 편집을 검색하여 들어간다. 고급 탭의 환경 변수 로 들어간다. 사용자 변수 란의 path를 클릭 후, 편집 을 클릭한다. 새로 만들기를 클릭하여 C:\\Hugo\\bin 경로를 추가한다. cmd에 echo %PATH% 를 입력하여 추가한 경로가 있는지 확인한다. 해제한 압축 파일에서 hugo 실행하여 설치 후, cmd에 hugo version 으로 동작 확인한다. 3. 새로운 2개 github repo 와 local 연결하기 3.1 Submodule 개념 이해하기 ❗ 이런 개념이 있구나 정도만 이해하고 3.1을 넘어가기. 이해하기 어렵다면 생략하고 바로 다음 3.2 chapter로 넘어가 따라해보자.\n이 단계를 진행하기 전에 submodule 개념을 알아야 한다. 영어 독해가 가능하신 분들은 How to Set Up a Hugo Site on Github Pages - with Git Submodules! 이 링크에 들어가 보시기 바란다. submodule에 대해 그림과 함께 잘 설명되어있다. 아래 내용은 위 블로그에서 submodule에 대한 부분을 번역한 내용이다. 오역이 있다면 댓글로 알려주시면 감사하겠다.\npublic folder는 3.4 B repo를 public 폴더에 submodule로 연결하기 파트에서 아래 명령어로 만들어진다.\n1 2 3 # blog 폴더의 submodule로 branch main에 B repo를 add 한다. # sample: git submodule add https://github.com/JeHa00/JeHa00.github.io.git public \u0026gt; git submodule add -b main https://github.com/\u0026lt;user-name\u0026gt;/\u0026lt;B repo 명칭\u0026gt;.git public 출처: How to Set Up a Hugo Site on Github Pages - with Git Submodules!\n왜 Git submodule인가??\n모든 git project는 repository에 저장된다.\n이 git submodule은 한 레포 안에서 다른 레포를 참조하도록 해준다.\n그래서 프로젝트 안에 프로젝트를 효과적으로 운영할 수 있다.\n중요한 건 submodule은 main project와 달리 자신만의 commit과 branch histroy를 가진다.\n그래서 프로젝트들을 분리시킬 수 있다. 이는 매우 강력한 도구다. 아래 그림에서는 git project에서 submodule을 사용할 시, 어떻게 코드가 포함되는지를 보여준다. \u0026hellip;.\n메인 repository의 submodule로 public folder를 하위 폴더로 설정하여, 독립된 branch history를 갖는 개체로 대할 수 있다.\n출처: https://www.adamormsby.com/posts/000/how-to-set-up-a-hugo-site-on-github-pages-with-submodules/\nA repo가 blog 에 remote origin으로 연결된다.\nB repo가 public 폴더 형태로, blog의 submodule로 들어간다.\n출처: How to Set Up a Hugo Site on Github Pages - with Git Submodules!\n3.2 New repository 2개 만들기 자신의 github에 2개의 repository를 만든다.\n2개의 repository를 각각 A,B라고 하자. 2개의 repository는 public과 private 중 public으로 만든다. private 으로 하면 site에 배포가 안될 수도 있다. A는 user-name/blog 로, B는 user-name/user-name.github.io 로 명칭을 만든다.\nex) A의 url은 github.com/JeHa00/blog / B의 url은 github/JeHa00/JeHa00.github.io B repo의 이름이 github page로 쓰일 url. ❗❗ 주의: 두 repo를 만들 때 주의사항\nA repo에는 README.md 만들지 말기\nREADME.md가 있다면 나중에 git push 시에 충돌이 일어난다. B repo에 README.md를 만들기\nrepo가 비어있으면 submodule로 연결이 안된다. 3.3 Hugo new site 생성 및 remote add origin A repo 실행 Visual Studio Code의 terminal 또는 Window의 cmd에 입력한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 경로 C:\\Hugo # 새로운 Hugo project 생성 # sample: Hugo new site blog \u0026gt; Hugo new site \u0026lt;project 명칭\u0026gt; # project folder인 blog로 이동 # sample: cd blog \u0026gt; cd \u0026lt;project 명칭\u0026gt; #3. local git 초기화 \u0026gt; git init # blog의 remote origin으로 A repo 추가하기 # sample: git remote add origin https://github.com/Jeha00/blog.git \u0026gt; git remote add origin https://github.com/\u0026lt;user-name\u0026gt;/\u0026lt;A repo 명칭\u0026gt;.git # commit 하기 위해 모든 파일을 stage에 올리기 \u0026gt; git add . # commit \u0026gt; git commit -m \u0026#34;add origin\u0026#34; # the remote origin 에 push 하겠다. branch는 master로 하겠다. \u0026gt; git push origin master remote origin이 잘 되었는지 확인하기 위해서는 git remote -v를 입력하면 뜬다.\nerror: src refspec master does not match any 가 뜬다면 이는 stage에 오른 파일이 없다는 의미이므로, git add . 를 했는지 확인하기\nhugo new site \u0026lt;project 명칭\u0026gt; 명령으로 local에서 컨텐츠를 관리하기 위한 장소 생성\n이 때 경로는 C:\\Hugo 인 상태에서 terminal에 입력한다.\n\u0026lt;project 명칭\u0026gt;을 A repo 이름과 똑같이 한다.\nproject를 새로 생성해서 project 파일 경로는 C:\\Hugo\\\u0026lt;project 명칭\u0026gt; 일 것이다.\n위 명령어로 생긴 tree는 다음과 같다.\n1 2 3 4 5 6 7 8 Hugo/project 명칭 ├─archetypes ├─content ├─data ├─layouts ├─static ├─themes └─config.toml git remote add origin https://github.com/\u0026lt;user-name\u0026gt;/\u0026lt;A repo 명칭\u0026gt;.git Hugo new site로 만든 project 에 대한 remote origin으로 A repo를 추가하겠다는 의미다.\nC:\\Hugo\\\u0026lt;project 명칭\u0026gt; 경로에서 git push를 하면 앞으로 A repo에 저장된다.\n그 결과, A repo안에 구성은 다음과 같다.\n1 2 3 \u0026lt;user-name\u0026gt;/A repo 이름 ├─archetypes └─config.toml 3.4 B repo를 public 폴더에 submodule로 연결하기 1 2 3 # blog 폴더의 submodule로 branch main에 B repo를 add 한다. # sample: git submodule add https://github.com/JeHa00/JeHa00.github.io.git public \u0026gt; git submodule add -b main https://github.com/\u0026lt;user-name\u0026gt;/\u0026lt;B repo 명칭\u0026gt;.git public 이 명령어로 public 폴더가 생성되고, 이 폴더의 remote origin이 B repo가 된다. public 폴더가 생긴 걸 알 수 있다. 1 2 3 4 5 6 7 8 9 10 Hugo/project 명칭 ├─archetypes ├─content ├─data ├─layouts ├─public ├─static ├─themes ├─.gitmodules └─config.toml 하지만 public 폴더가 생긴다고 연결된 게 아니다. 확실하게 연결이 되었다면 .gitmodules 파일이 생기고, 이 안에 아래와 같은 코드가 생겨야 한다. [submodule \u0026#34;public\u0026#34;] path = public url = https://github.com/JeHa00/jeha0.github.io.git branch = main 만약 public folder는 생겼지만, .gitmodules와 위 코드가 없다면 다음 조치를 취한다.\n첫 번째, public folder를 삭제한다.\n두 번째, local 문서에서 C:\\Hugo\\\u0026lt;new project 명칭\u0026gt; folder로 들어가 숨긴 파일 보이기를 하여, .git 폴더의 modules 폴더를 삭제한다.\n세 번째, terminal에 C:\\Hugo\\\u0026lt;new project 명칭\u0026gt; 경로에서 git rm --cached public 을 입력한다.\n첫 번째, 두 번째만 실행한다면 다음과 같은 error 종류들이 뜰 수 있다.\nerror: 'public' does not have a commit checked out\nerror: 'public' already exists in the index\nerror: a git directory for 'public' is found locally with remote(s)\n이렇게 뜨는 이유는 cach에 public이 아직 남아있기 때문이다. 그래서 이를 제거하고자 git rm --cached public 을 입력한다.\n그리고, 다시 submodule 명령어를 실행하여, .gitmodules 에 위 코드가 생기는지 확인한다.\n다시 https://github.com/\u0026lt;user-name\u0026gt;/blog.git 에 public @ 폴더가 생겼는지 확인한다. 이 폴더가 생겼다면 submodule 등록이 확실하게 완료되었다.\n만약, Permission denied (publickey) 오류가 뜬다면 SSH 보안키를 등록해야한다.\n위 방법대로 했지만 public 폴더와 B repo가 submodule 연결이 되지 않는다면, B repo에 아무런 file이 존재하지 않아서다.\n3.2 New repository 2개 만들기 내용처럼 B repo에 README.md를 추가하여 empty repo로 만들지 말자.\n3.5 public directory와 project root directoy git push 단계 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # public directory에 site build 수행하기 \u0026gt; hugo # public dicrectory로 이동 \u0026gt; cd public \u0026gt; git add . \u0026gt; git commit -m \u0026#39;first build\u0026#39; \u0026gt; git push origin main # the project root 로 되돌아가기 \u0026gt; cd .. \u0026gt; git add . \u0026gt; git commit -m \u0026#39;first build - update submodule reference\u0026#39; \u0026gt; git push origin master 위 명령어로 생긴 tree는 다음과 같다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Hugo/\u0026lt;project 명칭\u0026gt; ├─archetypes ├─content ├─data ├─layouts ├─public │ ├─categories │ └─tags ├─resources │ │─_gen │ ├─assets │ └─images ├─static │─themes ├─.gitmodules └─config.toml A repo의 directory는 아래와 같다. 아래 image처럼 public@가 떠야 한다. submodule이 잘 연결되었다는 의미다. 4. Github page에 theme 적용 4.1 원하는 테마 찾기 Hugo Theme Star Ranking, jamstackthemes 그리고, Hugo Themes: Complete List 이 3가지 사이트 정도라면 충분히 찾을 수 있다.\n처음에 테마 찾는 데 많은 시간을 썼는데, 지금 생각해보면 기본 테마를 찾은 다음에 customizing 하는 방법이 더 빠른 방향이었다.\n4.2 submodule을 사용하여 테마 적용하기 submodule로 테마를 적용한 이유는 업데이트된 테마를 쉽게 가져올 수 있기 때문에, clone보다 submodule로 만드는 게 더 낫다고 한다. (by submodule이 나은 이유)\n테마 또한 submodule로 적용한다. 구조는 아래와 같다. 출처: How to Set Up a Hugo Site on Github Pages - with Git Submodules!\n1 2 3 4 경로 C:\\Hugo\\\u0026lt;New Project 명칭\u0026gt; # root project folder에 submodule로 테마를 적용한다 # git submodule add .git themes/Paper-Mod \u0026gt; git submodule add \u0026lt;theme 경로\u0026gt;.git themes/\u0026lt;테마명\u0026gt; 원하는 theme을 fork 한다.\nfork를 하는 이유는 테마를 직접 수정할 수 없고, 수정한 버전을 유지하기 어렵기 때문에, fork하여 자신의 github으로 가져온다.\nfork한 테마의 경로를 복사하는 방법은 다음과 같다.\n위 이미지에서 url 옆에 있는 버튼을 클릭하면 복사된다. git submodule add \u0026lt;theme 경로\u0026gt;.git themes/\u0026lt;테마명\u0026gt; 에서 themes란 밑에 이미지의 themes folder를 말한다. 이 folder 밑에 \u0026lt;테마명\u0026gt; folder를 만들어, 테마 자료들을 다운받는다는 의미다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Hugo/\u0026lt;project 명칭\u0026gt; ├─archetypes ├─content ├─data ├─layouts ├─public │ ├─categories │ └─tags ├─resources │ │─_gen │ ├─assets │ └─images ├─static │─themes │ └─\u0026lt;테마명\u0026gt; ├─.gitmodules └─config.toml 다음으로 config.toml 에 theme = 이 없으면 추가하여, theme = \u0026lt;테마명\u0026gt; 을 적는다. BaseURL을 B repo의 끝 부분인 https://\u0026lt;user-name\u0026gt;.github.io/ 로 수정한다. 이 경로가 앞으로 github page의 URL이 된다. theme 적용 또한 submodule이므로 .gitmodules 파일에 다음과 같이 2개가 등록되었다. 1 2 3 4 5 6 7 8 9 #example [submodule \u0026#34;public\u0026#34;] path = public url = https://github.com/\u0026lt;user-name\u0026gt;/\u0026lt;B repo 명칭\u0026gt;.git branch = main [submodule \u0026#34;\u0026lt;테마명\u0026gt;\u0026#34;] path = themes/\u0026lt;테마명\u0026gt; url = 테마 url theme 적용 후, theme 폴더 안에 examplesite 란 의미의 폴더가 있다면, 그 폴더 안에 있는 config.toml을 복사하여 C:\\Hugo\\\u0026lt;New Project 명칭\u0026gt; 경로에 있는 config.toml에 복사 붙여 넣는다. BaseURL만 다시 수정한다. 4.3 테마 적용되었는지 테스트하기 1 2 3 경로 C:\\Hugo\\\u0026lt;New Project 명칭\u0026gt; # D 란 draft 문서까지 포함해서 보겠다는 의미다. \u0026gt; hugo server -D 그러면 https://localhost:1313/ 이 뜬다. 이를 클릭하면 테마가 적용되었는지 알 수 있다. terminal 작업을 다시 할려면 Ctrl + C를 눌러 중단한다. hugo server -D 가 돌아가는 동안에는 글의 수정을 바로 확인할 수 있다. 5. Contents 생성과 업로드 5.1 Contents 생성과 public folder에 반영하기 1 2 3 4 5 6 경로 C:\\Hugo\\\u0026lt;New Project 명칭\u0026gt; # contents 생성 \u0026gt; hugo new post/test1.md # 생성된 글 public 폴더에 반영하기 \u0026gt; hugo -t \u0026lt;테마이름\u0026gt; hugo new post/test1.md는 \\content\\post\\test1.md 경로로 생성된다.\ncontents 생성 후, hugo server -D로 localhost에는 생성한 contents가 보이는데, github page에는 안보인다면 hugo -t \u0026lt;테마이름\u0026gt;명령을 하지 않았기 때문이다.\n여기서 \u0026lt;테마이름\u0026gt;은 git submodule add \u0026lt;theme 경로\u0026gt;.git themes/\u0026lt;테마명\u0026gt; 에서 테마명과 동일해야 한다.\n❗️❗️ 2022.08.28 Error 기록 배경: Window에서 MacOS로 이동하여 pjt를 clone하는 과정 중에 생긴 error\n만약 새롭게 blog와 submodule을 git clone해야하는 상황이라면 서브모듈 업데이트를 참고한다.\n이 명령어를 입력해도 안된다면 각 서브 모듈 파일로 경로를 이동하여 git log를 통해 최신 commit hash 번호를 확인 후, git reset --hard \u0026lt;commit hash number\u0026gt;를 입력하여 그 시점으로 초기화한다.\n그 후, main project folder 로 이동한다. (submodule directory를 담고 있는 directory로 이동)\ngit pull을 실행하여 최신화한다.\n5.2 컨텐츠 업로드 1 2 3 4 5 6 7 8 9 10 11 12 13 # public dicrectory로 이동 \u0026gt; cd public \u0026gt; git add . \u0026gt; git commit -m \u0026#39;commit message\u0026#39; \u0026gt; git push origin main # the project root 로 되돌아가기 \u0026gt; cd .. \u0026gt; git add . \u0026gt; git commit -m \u0026#39;commit message\u0026#39; \u0026gt; git push origin master 6. Utterances로 댓글 기능 추가, deploy.sh로 자동화 6.1 Utterances로 댓글 기능 추가 사용 방법 Github에 \u0026lt;user-name\u0026gt;/blog-comments 같이 private이 아닌 public 저장소를 만든다. Utterance에서 1번에서 만든 repository를 입력한다. Utterance에서 Mapping 방식 6가지 중 한 가지를 선택한다. 2번 3번에 따라 Utterance에서 생성된 script를 복사하여 각자의 적절한 템플릿 위치가 추가한다. 추가 위치는 각 theme의 README.md 를 꼼꼼히 읽어본다. 아웃사이더님의 블로그 글에서 보고 가져온다.\n6.2 deploy.sh로 자동화 deploy.sh 파일명으로 아래 코드를 저장한 후, C:\\Hugo\\\u0026lt;프로젝트 명칭\u0026gt; 경로에 저장한다. 이후 Git Bash 프로그램을 사용하여 C:\\Hugo\\\u0026lt;프로젝트 명칭\u0026gt; 경로로 이동 후, bash deploy.sh를 입력하면 the project root와 submodule 모두 순차적으로 push가 실행된다. 나는 submodule은 main default branch에, the project root는 master default branch로 설정했다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #!/bin/bash echo -e \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026#34; # Build the project. hugo -t \u0026lt;테마명\u0026gt; # Go To Public folder cd public # Add changes to git. git add . # Commit changes. msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. ## master 대신 각자 연결한 branch 명으로 수정하면 된다. git push origin main # Come Back up to the Project Root cd .. # blog 저장소 Commit \u0026amp; Push git add . msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; ## master 대신 각자 연결한 branch 명으로 수정하면 된다. git push origin master 7. To customize blog theme \u0026amp; 후기 To customize blog theme 커스텀마이징을 위한 제일 좋은 방법은 각자 선택한 테마 템플릿의 README.md를 꼼꼼히 읽어보는 게 제일 빠른 지름길이라 생각한다.\n사용자가 원하는 기능들을 어떻게 추가하면 되는지 설명해논 템플릿이 많기 때문에, 반드시 README.md 를 꼼꼼히 읽기 바란다.\n후기 git에 대해 더 숙지를 하고 나서 git page를 만들기 시작했다면 시간 소모를 줄일 수 있었을 것이다. 급한 마음에 github page를 시작하여 생각보다 많은 시행착오와 error들을 격었다. 이 error들은 대체로 git을 정확히 이해하지 못해서 발생하는 문제점들이다.\n이번 일을 통해서 git이 개발자에게 사람의 숨쉬기와 같다는 걸 느껴서 Pro git 이란 책을 사서 꾸준히 공부하기로 결정했다.\ngith page를 만들었으니, TIL부터 시작하여 꾸준히 공부하자. Hugo를 선택한 것이 처음 시도할 때는 매우 힘들었지만, 지금 와서는 잘한 선택임을 느낀다.\n진행하다가 부딪힌 error들에 대해서는 바로 바로 기록을 하자. 이는 반복적인 똑같은 삽질을 예방할 수 있다.\nReference 정적 웹은 뭐고 동적 웹은 뭔가요?\nJekyll, Hexo, Hugo 차이점 설명\nHugo로 Github.io 블로그 만들기\nHow to Set Up a Hugo Site on Github Pages - with Git Submodules!\ntheme 적용에 submodule이 나은 이유\n아웃사이더님의 블로그 글\n","permalink":"http://jeha00.github.io/post/dev-contents/hugo%EB%A1%9C-github-page-%EB%A7%8C%EB%93%A4%EA%B3%A0-%EB%B0%B0%ED%8F%AC%ED%95%98%EA%B8%B0/","summary":"SSG의 한 종류 \u0026lsquo;Hugo\u0026rsquo;와 \u0026lsquo;git remote, git submodule\u0026rsquo;로 Github page를 만든다. 그 후, 컨텐츠 생성과 업로드를 한다. 마지막으로 utterances로 댓글 기능 추가, deploy.sh를 사용하여 업로드하는 방법을 다룬다.","title":"Window에서 Hugo로 Github page 만들고 배포하기"},{"categories":null,"content":"왜 많은 회사들에서 AWS 인프라를 이용하는지\nAWS에서 제공하는 여러 가상 서버 서비스에 대해 논의\nAWS에서 제공하는 메세지 큐와 DB를 언제 어느 인프라에 사용해야하는데\n여태 배운 인프라로 간단한 서버 만들기\n","permalink":"http://jeha00.github.io/post/aws/wanted/intro/","summary":"왜 많은 회사들에서 AWS 인프라를 이용하는지\nAWS에서 제공하는 여러 가상 서버 서비스에 대해 논의\nAWS에서 제공하는 메세지 큐와 DB를 언제 어느 인프라에 사용해야하는데\n여태 배운 인프라로 간단한 서버 만들기","title":""},{"categories":null,"content":"Question 1 라우팅에 들어가는 함수를 async def 로 비동기로 만들어 사용하는 것과 그냥 def 라고 만들어서 쓰는것의 차이가 궁금힙니다. 이렇게 쓴다는건 db도 asyncSession으로 되있는걸로 사용할텐데 이걸로 하면 장점이 무엇인가요? 속도차이가 많이 나나요?\nAnswer 1 def 을 쓰면, 요청마다 쓰레드를 만드니, 멀티 쓰레딩에 대한 오버헤드가 나고 async def을 쓰면, 이벤트 루프 하나에 코루틴으로 핸들러를 등록하니, 멀티 쓰레딩에서 일어나는 오버헤드가 없습니다. https://fastapi.tiangolo.com/async/#asynchronous-code\n속도 차이가 많이 나느냐 -\u0026gt; 요거는 실제로 async, sync로 만들고 프로덕션 서비스에서 테스트 해보신 분들이 답변해주실텐데, 보통 그렇다고들 합니다. 일단 여기의 전제는 대부분의 웹 서버는 I/O Bound 하다는 전제가 있습니다.\nQuestion 2 기존에는 flask로 api서비스를 만들었는데 async def로 요청을 받지 않고 def로 요청을 받아오 flask 보다 더 빠른가요? 만약에 빠르다고 하면 빠른 이유가 있나요? 저는 async def를 써야지만 빠르겠구나, def로 요청을 받으면 플라스크랑 비슷하겠지 생각을 했는데, 제가 잘못생각한건가요?\nAnser 2 일단 앞단에서 받는 서버가 async로 동작하기 때문에 (ASGI), 요청 핸들링 자체가 비동기입니다. 따라서 flask를 \u0026ldquo;그냥\u0026rdquo; 쓰는거보다는 훨씬 빠른거 같습니다. (제말이 틀릴 수도 있어요.) https://gist.github.com/nhymxu/814cf9b3294276629d2231248b709e26\n위 링크 보시면, 누군가가 벤치마킹 테스트한 게 있는데요.\n그리고 Flask -\u0026gt; FastAPI로 넘어오는 분들은 이런 비동기 성능 문제도 물론 있지만, 이걸 고려할 타이밍이 아닌경우, 대부분 FastAPI가 주는 기능 (Validation, Swaager)과 사용성 (Typing, Community) 때문에 넘어오시는거 같습니다.\nasync를 안서도 flask과 request 차이가 많이 난다 이 의견에 대한 답변: 아마 그건 시리얼라이징 성능이지 않을까 싶네요 저 벤치마킹에서 각기 어떻게 코드를 작성했는지는 모르겠지만.\n의견: 시리얼라이징이라면 json library 를 바꾸는것만으로도 속도가 증가 할까요~? 노드가 JSON 시리얼라이징 할 때 기본 자바스크립트 라이브러리를 권장하지 않는 것도 그 이유였으니깐요 물론 확실하지는 않습니다. 정확한건 벤치마킹했을 때 어떤 코드를 썼는지 봐야 가장 확실하겠지요\nPydantic이 나오기 이전까지만 해도 여러 시리얼라이징 라이브러리 (Marshmallow 등)가 있었지만 Pydantic이 런타임에서 타입까지 봐주면서도 성능이 더 좋았지요\n다른 분의 근거: 그러고보니 Pydantic 2.0 프리릴리즈의 경우, 코어 validation 로직을 Rust로 바꾸면서 성능향상을 목표로 하고있는 것 같더군요 https://docs.pydantic.dev/latest/blog/pydantic-v2-alpha/\n맞습니다. 노드 진영에서 Rust로 빌드 속도를 늘린것처럼 파이썬 진영에서도 그런 모습을 보이고 있는 대표적인 사례가 Pydantic 입니다.\n","permalink":"http://jeha00.github.io/post/fastapi/%EC%82%AC%EC%9A%A9%EC%9E%90%EB%AA%A8%EC%9E%84%EB%A9%94%EB%AA%A8/","summary":"Question 1 라우팅에 들어가는 함수를 async def 로 비동기로 만들어 사용하는 것과 그냥 def 라고 만들어서 쓰는것의 차이가 궁금힙니다. 이렇게 쓴다는건 db도 asyncSession으로 되있는걸로 사용할텐데 이걸로 하면 장점이 무엇인가요? 속도차이가 많이 나나요?\nAnswer 1 def 을 쓰면, 요청마다 쓰레드를 만드니, 멀티 쓰레딩에 대한 오버헤드가 나고 async def을 쓰면, 이벤트 루프 하나에 코루틴으로 핸들러를 등록하니, 멀티 쓰레딩에서 일어나는 오버헤드가 없습니다. https://fastapi.tiangolo.com/async/#asynchronous-code\n속도 차이가 많이 나느냐 -\u0026gt; 요거는 실제로 async, sync로 만들고 프로덕션 서비스에서 테스트 해보신 분들이 답변해주실텐데, 보통 그렇다고들 합니다.","title":""},{"categories":null,"content":"models.py에서 Field로 선언되는 것들은 각 인스턴스 간에 값이 공유되는 클래스 변수가 아니라, 클래스 공간에 선언되는\n디스크립터(Descriptor) 객체다.\nEmail model 관련 질문 authentication_check 는 인증 여부에 대한 속성값인데, pocket에서 인증하는게 있는가?\nemail의 EmailField에는 max_length 값이 이미 내장되어 있는데, 굳이 max_length를 입력할 필요가 있을까?\nUser model 관련 질문 upload_to=f\u0026quot;profile/\u0026ldquo;에서 f-string을 쓴 이유: 기억이 안나서 다시 여쭤봅니다.\npassword 속성에서 max_length = 15에서 128로 왜 수정했는지?\nUSERNAME_FIELD 를 \u0026lsquo;password\u0026rsquo;로 수정한 이유\nSite model 관련 질문 thumbnail_url에서 max_length로 2000을 한 이유 url = models.CharField(verbose_name=\u0026lsquo;url\u0026rsquo;, max_length=2000, null=True) 에서 max_length 부분 host_name 에서 max_length를 500으로 한 부분 (완료)\nfavortie 속성이 TextField로 되어 있는데 BooleanField로 수정하기 (완료) max_length a max_length argument which specifies the size of the VARCHAR database field used to store the data. Field options\nVARCHAR 는 mysql에서 bytes 였다가 글자수로 바뀌었다. 버전 4에서는 bytes였지만, 버전 5부터는 글자수로 바뀌었다.\nTags model 관련 질문 list 속성의 verbose_name을 \u0026lsquo;목록\u0026rsquo;으로 바꾸기 Hightlight model 관련 질문 list 속성의 verbose_name을 \u0026lsquo;목록\u0026rsquo;으로 바꾸기 content_text, content_location 에서 null=True를 한 이유 PaymentManager merchant_id 부분의 5를 10으로 수정하기 -\u0026gt; 블로그에 정리하기 5를 한 이유는 기존 iamport에서 20이 최대였는데, 주문 번호가 그리 많지 않기 때문에 반으로 줄이도록 결정. 그리고, 아이디와 주문 시간 두 가지를 섞어서 만들기 때문에 10의 반반인 5를 입력한 것이다. 아임포트 API 문서에서는 payments.validation 부분을 보면 merchant_id의 string(40) 을 알 수 있다.\nPayment payment_id와 merchant_id의 max_length를 120으로 한 이유\n책을 보고 그대로 따라하다보니 그렇게 된 것 같다. sha1로 생성했을 때, 자리수가 몇 개인지 확인하자. 이는 string(20)과 연결되는 부분이므로 수정해야 한다. PaymentSerializer의 payment_id, merchant_id의 max_length와 안맞는다. 결제 상태를 awaiting 을 \u0026lsquo;ready\u0026rsquo;로 바꾸자.\nhttps://api.iamport.kr/#!/payments/getPaymentsByStatus post_save 더 자세히 알아보기 ","permalink":"http://jeha00.github.io/post/project/devket/django/db_modeling_question/","summary":"models.py에서 Field로 선언되는 것들은 각 인스턴스 간에 값이 공유되는 클래스 변수가 아니라, 클래스 공간에 선언되는\n디스크립터(Descriptor) 객체다.\nEmail model 관련 질문 authentication_check 는 인증 여부에 대한 속성값인데, pocket에서 인증하는게 있는가?\nemail의 EmailField에는 max_length 값이 이미 내장되어 있는데, 굳이 max_length를 입력할 필요가 있을까?\nUser model 관련 질문 upload_to=f\u0026quot;profile/\u0026ldquo;에서 f-string을 쓴 이유: 기억이 안나서 다시 여쭤봅니다.\npassword 속성에서 max_length = 15에서 128로 왜 수정했는지?\nUSERNAME_FIELD 를 \u0026lsquo;password\u0026rsquo;로 수정한 이유\nSite model 관련 질문 thumbnail_url에서 max_length로 2000을 한 이유 url = models.","title":""},{"categories":null,"content":"Introduce SW engineer로 오기까지 결정들과 그 이유 공대 입학 후 기술을 사용하는 \u0026lsquo;엔지니어 \u0026lsquo; 에 흥미를 느꼈습니다. 그래서 더 여러 분야를 공부하고자 편입에 도전했습니다.\n편입 및 졸업 후 플랜트 엔지니어로 근무했었습니다. 하지만 근무하면서 제가 흥미를 느끼고 해결하고 싶은 문제는 \u0026lsquo;사용자의 생활에 밀접하게 물려있는 문제 \u0026lsquo; 임을 깨달았습니다. 이 문제를 해결하기 좋은 수단은 소프트웨어라 판단했고, 프로젝트를 진행하면서 여러 어려움에 부딪혀도 이를 극복했을 때 큰 보람을 느끼는 저 자신을 발견하여 sw engineer로 방향을 바꾸기로 했습니다.\nSW engineer로 오기까지 짧지 않은 시간이 걸렸지만, 이 경험들로 제 자신에 대해 잘 알 수 있었습니다.\n저는 이런 엔지니어입니다.\n부족한 기억력을 돕기 위해 문서화 를 좋아하는 엔지니어\n2022년부터 총 159개 를 작성 부족한 코드 품질을 돕기 위해 테스트 를 좋아하는 엔지니어\n현재 진행 중인 프로젝트의 테스트 코드 수: 121개 CS 과목 을 계속해서 학습하는 엔지니어\n학습 포스팅 수: 32개 🔗 Channel \u0026amp; Contact Github. https://github.com/JeHa00 🔗 Email. rudtls0611@gmail.com 🔗 Linkedin. Jeha Kim 🔗 Skill 최근 프로젝트에 사용한 기술들입니다.\nPython, FastAPI, Django, DRF, MySQL, Redis, Docker Projects 나만의 SNS 커뮤니티: 백엔드 담당 🔗 해당 프로젝트를 개발한 이유\n첫 번째: sns 특성의 커뮤니티가 가진 기능들을 좋아하여 이를 직접 만들기로 결정\n두 번째: 만들어진 sns에 특정 소재(ex: 반려 동물 사료)를 추가하여 서비스를 직접 상용화할 계획으로 결정\n기간 : 2023.03. ~ (프론트엔드: 1명 / 백엔드: 1명)\n사용 기술\nPython, FastAPI, MySQL, Redis, docker Development\n‘직관적인 api 설계’ 를 위해 RESTful API 방식으로 프로젝트 전체 CRUD 구축 ‘코드 결합도에 따른 유지보수’ 와 ‘소통의 용이성 ’ 을 위해 DDD layered architecture 적용 ‘코드 신뢰성 ’ 을 위해 Pytest 를 사용하여 47개 unit test와 74개 EndToEnd test 작성 총 121개 테스트 코드 작성 사용자에게 ‘빠른 응답성 ’ 을 주기 위해 background task로 non-blocking 작업을 구현 ‘생산성 ’ 을 위해 FastAPI 내장 모듈을 사용하여 JWT 를 통한 인증 및 인가 방식 적용 ‘조회속도 향상 ’ 을 위해 Redis 를 사용하여 좋아요 조회 속도 6배 향상 (미적용시 6ms → 적용 후 1ms) ‘실시간성과 네트워크 비용 ’ 을 고려하여 여러 통신 방법 중 SSE(Server Sent Event) 를 통해 알림 기능을 구현 Deployment\n서비스 개발 및 배포 시 ‘격리’ 하기 위해 Docker compose를 사용 나노디그리 팀 프로젝트: Devket 🔗 실제 제품인 pocket 사이트를 클론 코딩하기\n기간 : 2022.11.15 - 2022.12.14 (1개월 / 4명)\n사용 기술\nBackend: Django, DRF, docker-compose, AWS EC2, AWS RDS, AWS S3 Frontend: Vanilla JS pocket 사이트 설명\n사용자가 보관 및 읽고 싶은 타 웹 사이트 컨텐츠를 크롤링으로 저장 크롤링한 컨텐츠에 하이라이트 표시로 원하는 부분을 강조하는 기능 결제에 따라 저장할 수 있는 컨텐츠 수와 하이라이트 수 제한 Frontend: 저장한 각 웹 사이트 hover 시 하단에 뜨는 하단툴바 렌더링 🔗\nBackend\n저장된 웹 사이트의 즐겨찾기 값 변경, 저장한 웹 사이트 삭제 api 구축 개발 기간과 확장성을 고려하여 결제 모듈로 아임포트를 선정하여 결제 api 구축 Project: Iamport 선정 이유, 그리고 아임포트 javascript SDK를 사용하여 구축한 결제 흐름 🔗 Project: Payment 개발 과정에서의 고려사항들과 개발 이슈들 🔗 AWS EC2, RDS, S3와 docker-compose를 사용한 배포 🔗 Team and Communication\n팀 전체 성장과 커뮤니케이션 효율을 위해 주도적으로 PR template 도입 추진 및 제작 🔗 Experience IT 분야: Ulift 컨텐츠팀 근무기간: 2024.02 - (근무 중) 근무내용: 코딩밸리 앱의 콘텐츠 제작 주로 Python 기반의 프로그래밍 컨텐츠를 만들고 있습니다. Python 문법 기본, 도약, 심화 핸드북 제작 및 검수 Python 데이터 분석 입문 과정 제작 그 외 네트워크, git 과정 핸드북 제작 및 검수도 했습니다. 위 경험을 통해 얻은 것 저의 책임감과 커뮤니케이션 능력으로 스타트업의 속도와 문화에 잘 녹아들 수 있다는 걸 확인했습니다. 사용자에게 내용을 정확하고 쉽게 전달하고자 글과 코드를 가독성 있게 작성하는 능력을 향상시키고 있습니다. 비 IT 분야: 선우플랜트엔지니어링(H.V.A.C 설계부서) 근무기간: 2021.03 - 2021.12 분야: 건설업 플랜트 / 직급: 사원 위 경력이 도움 되는 이유 IT 분야 회사는 아니지만 설계 업무의 특성사 여러 명과 반드시 협력해야하기 때문에, 협업 경험을 가지고 있습니다. 협업 경험을 통해 Soft skill 중 커뮤니케이션 능력을 향상시켰습니다. 인정받은 역량: 책임감 하루 16시간 주 6일 ~ 7일 근무 시간을 쏟을 만큼 제 역량을 향상시키고, 선임들에게 도움이 되어 해당 프로젝트를 잘 완료하기 위해 책임감을 갖고 프로젝트에 임했습니다. 그 결과, 프로젝트는 잘 완료되었고 선임들, 인사팀 그리고 임원분에게 인정 받을 수 있었습니다. About me 두려워도 계속해서 도전하도록 노력하는 사람 계속해서 도전하는 건 쉬운 일이 아니라고 생각합니다. 하지만, 도전 후의 발전된 모습이 좋아서 도전에 대한 두려움이 있어도 계속해서 시도하고 있습니다. 목표에 도전한 후에는 노력의 결과로 저 자신에 대해 잘 알 수 있고 발전한 걸 느낄 수 있기 때문입니다.\n또한, 앞으로 긴 인생을 살 텐데 제 시간을 쏟고 싶은 일을 찾기 위해 편입, 편입 후 졸업 논문 동상 수상, 커리어 전환 등 여러 도전을 했습니다.\n이 과정에서 여러 극복할 수 있었던 건 2가지 를 잊지 않았기 때문입니다.\n첫 번째, 학습한 것을 기록으로 남기도록 노력합니다 새롭게 학습한 내용을 놓치지 않기 위해 \u0026lsquo;기록 \u0026lsquo; 을 자주 했습니다.\n말로 전달되는 내용들은 다시 듣기도 어렵기 때문에 기록으로 정리하여,\n블로그에 공유한 포스팅을 같이 부트캠프에 참여했을 때 동료들에게 공유하여 이해를 도왔습니다.\n협업 프로젝트를 할 때는 부딪힌 문제들을 기록으로 정리하여, 다시 발생했을 때 금방 해결할 수 있었습니다.\n두 번째, 모르는 것을 부끄러워하지 않도록 노력합니다 그리고, 새롭게 도전할 때마다 느끼는 건 모르는 것이 많다는 것입니다. 이 부족함을 드러내는 걸 부끄러워한다면 질문을 잘 안하게 되는 저를 발견할 수 있었습니다. 그래서 \u0026lsquo;좋은 질문 \u0026lsquo; 을 하기 위해서 부끄러워하지 않도록 노력합니다.\n‘좋은 질문’을 하기 위해서 다음과 같은 노력을 하고 있습니다. 질문을 하기 전 먼저 글로 작성하여 무엇을 하려고 했고, 어떤 것들을 시도했고, 그 결과가 무엇인지를 정리하여 질문을 하고 있습니다. 오프라인이나 줌으로 만나는 게 아니라면 정리된 질문을 하는 게 서로의 시간을 아낄 수 있고, 상대방의 장점을 더 빨리 배울 수 있는 방법이라 생각합니다.\n가독성과 테스트에 신경쓰는 개발자 개발자로서 김제하는 다음 2가지 에 신경 쓰며 코드를 작성했습니다.\n첫 번째, 인지비용을 줄이는 가독성 기록으로 남길 때 타인이 읽으면서 이해하기 쉽도록 작성한 노력이 코드를 작성할 때도 도움이 되는 걸 느꼈습니다.\n왜냐하면 이해하기 쉬운 글이나 코드는 공통으로 사람의 \u0026lsquo;인지 비용 \u0026lsquo; 을 줄이기 때문입니다.\n그래서 단지 정수를 사용하기보다는 이 정수가 무엇을 의미하는지 변수를 통해서 사용되도록 작성했습니다. 그리고, 약어를 최대한 사용하지 않도록 노력했습니다. 너무 짧아 이해하기 어려운 코드보다, 좀 길더라도 의도를 명확하게 드러내는 코드가 좋다고 생각합니다.\n두 번째, 테스트 코드를 통해 확인하기 기능을 만들고 나서 시나리오별로 의도한 대로 작동되는지, 예상치 못한 문제가 발생하는지 확인하기 위해 \u0026lsquo;테스트 코드 \u0026lsquo; 를 꼭 작성하려고 합니다.\n테스트 코드를 작성할 줄 몰랐을 때는 포스트맨이나 프론트에서 입력값을 줘서 확인하는 방식으로 했으나, 이와 같은 방식은 시간을 많이 소모하기 때문에 pytest를 통해 테스트 코드를 작성하는 방법을 학습했습니다.\n학습한 이후로는 원격에 push하기 전에 전체 테스트 코드 또는 해당 기능에 대한 테스트 코드를 @pytest.mark 를 사용하여 재실행한 후, 원격에 push하는 습관을 지니고 있습니다.\nSelf-study about Computer Science 공대 출신으로 어느 공학 분야든지 기본 과목들의 중요성을 깊이 느끼고 있기 때문에 CS 과목을 꾸준히 학습하고 있습니다.\n운영체제 학습: 16개 🔗 네트워크 학습: 14개 🔗 데이터 베이스 학습: 2개 🔗 자료 구조 및 알고리즘 학습: TIL study 🔗 Education 한국항공대학교 항공우주 및 기계공학부 2017.03 - 2020.02 (편입학 및 졸업)\n학점: 3.51 / 4.5 졸업 논문 프로젝트 16팀 중 열유체 분야 동상 수상 유연부가 있는 진동형 heat pipe를 이용한 노트북 PC 방열 설계: 3D 모델링 설계 및 실험 진행 🔗\n기간 : 2018.09.03 - 2019.06.30 (1년) 교내 종합설계 프로젝트 16개팀 중 열유체 분야 동상 수상 1차, 2차 모델로 나눠서 점진적으로 진행한 결과, 1차 모델보다 10℃ 낮은 방열 성능으로 개선 flexible display 방열을 주제로 한 대학원 연구의 기반 감사합니다.\nBackend Engineer, 김제하(jeha)\nLatest updated 2024.04.13\n","permalink":"http://jeha00.github.io/me/","summary":"about","title":"Introduce Me. 🌱"}]